1．1　基本概念
1．2　安装与配置
1．3　生产与消费
1．4　服务端参数配置
1．5　总结
第2章　生产者
2．1　客户端开发
2．1．1　必要的参数配置
2．1．2　消息的发送
2．1．3　序列化
2．1．4　分区器
2．1．5　生产者拦截器
2．2　原理分析
2．2．1　整体架构
2．2．2　元数据的更新
2．3　重要的生产者参数
2．4　总结
第3章　消费者
3．1　消费者与消费组
3．2　客户端开发
3．2．1　必要的参数配置
3．2．2　订阅主题与分区
3．2．3　反序列化
3．2．4　消息消费
3．2．5　位移提交
3．2．6　控制或关闭消费
3．2．7　指定位移消费
3．2．8　再均衡
3．2．9　消费者拦截器
3．2．10　多线程实现
3．2．11　重要的消费者参数
3．3　总结
第4章　主题与分区
4．1　主题的管理
4．1．1　创建主题
4．1．2　分区副本的分配
4．1．3　查看主题
4．1．4　修改主题
4．1．5　配置管理
4．1．6　主题端参数
4．1．7　删除主题
4．2　初识KafkaAdminClient
4．2．1　基本使用
4．2．2　主题合法性验证
4．3　分区的管理
4．3．1　优先副本的选举
4．3．2　分区重分配
4．3．3　复制限流
4．3．4　修改副本因子
4．4　如何选择合适的分区数
4．4．1　性能测试工具
4．4．2　分区数越多吞吐量就越高吗
4．4．3　分区数的上限
4．4．4　考量因素
4．5　总结
第5章　日志存储
5．1　文件目录布局
5．2　日志格式的演变
5．2．1　v0版本
5．2．2　v1版本
5．2．3　消息压缩
5．2．4　变长字段
5．2．5　v2版本
5．3　日志索引
5．3．1　偏移量索引
5．3．2　时间戳索引
5．4　日志清理
5．4．1　日志删除
5．4．2　日志压缩
5．5　磁盘存储
5．5．1　页缓存
5．5．2　磁盘I/O流程
5．5．3　零拷贝
5．6　总结
第6章　深入服务端
6．1　协议设计
6．2　时间轮
6．3　延时操作
6．4　控制器
6．4．1　控制器的选举及异常恢复
6．4．2　优雅关闭
6．4．3　分区leader的选举
6．5　参数解密
6．5．1　broker．id
6．5．2　bootstrap．servers
6．5．3　服务端参数列表
6．6　总结
第7章　深入客户端
7．1　分区分配策略
7．1．1　RangeAssignor分配策略
7．1．2　RoundRobinAssignor分配策略
7．1．3　StickyAssignor分配策略
7．1．4　自定义分区分配策略
7．2　消费者协调器和组协调器
7．2．1　旧版消费者客户端的问题
7．2．2　再均衡的原理
7．3　__consumer_offsets剖析
7．4　事务
7．4．1　消息传输保障
7．4．2　幂等
7．4．3　事务
7．5　总结
第8章　可靠性探究
8．1　副本剖析
8．1．1　失效副本
8．1．2　ISR的伸缩
8．1．3　LEO与HW
8．1．4　Leader Epoch的介入
8．1．5　为什么不支持读写分离
8．2　日志同步机制
8．3　可靠性分析
8．4　总结
第9章　Kafka应用
9．1　命令行工具
9．1．1　消费组管理
9．1．2　消费位移管理
9．1．3　手动删除消息
9．2　Kafka Connect
9．2．1　独立模式
9．2．2　REST API
9．2．3　分布式模式
9．3　Kafka Mirror Maker
9．4　Kafka Streams
9．5　总结
第10章　Kafka监控
10．1　监控数据的来源
10．1．1　OneMinuteRate
10．1．2　获取监控指标
10．2　消费滞后
10．3　同步失效分区
10．4　监控指标说明
10．5　监控模块
10．6　总结
第11章　高级应用
11．1　过期时间（TTL）
11．2　延时队列
11．3　死信队列和重试队列
11．4　消息路由
11．5　消息轨迹
11．6　消息审计
11．7　消息代理
11．7．1　快速入门
11．7．2　REST API介绍及示例
11．7．3　服务端配置及部署
11．7．4　应用思考
11．8　消息中间件选型
11．8．1　各类消息中间件简述
11．8．2　选型要点概述
11．8．3　消息中间件选型误区探讨
11．9　总结
第12章　Kafka与Spark的集成
12．1　Spark的安装及简单应用
12．2　Spark编程模型
12．3　Spark的运行结构
12．4　Spark Streaming简介
12．5　Kafka与Spark Streaming的整合
12．6　Spark SQL
12．7　Structured Streaming
12．8　Kafka与Structured Streaming的整合
12．9　总结
附录A　Kafka源码环境搭建

1.1　发布与订阅消息系统　　1
1.1.1　如何开始　　2
1.1.2　独立的队列系统　　3
1.2　Kafka登场　　4
1.2.1　消息和批次　　4
1.2.2　模式　　4
1.2.3　主题和分区　　5
1.2.4　生产者和消费者　　5
1.2.5　broker和集群　　6
1.2.6　多集群　　7
1.3　为什么选择Kafka　　8
1.3.1　多个生产者　　8
1.3.2　多个消费者　　8
1.3.3　基于磁盘的数据存储　　9
1.3.4　伸缩性　　9
1.3.5　高性能　　9
1.4　数据生态系统　　9
1.5　起源故事　　11
1.5.1　LinkedIn的问题　　11
1.5.2　Kafka的诞生　　12
1.5.3　走向开源　　12
1.5.4　命名　　13
1.6　开始Kafka之旅　　13
第2章　安装Kafka　　14
2.1　要事先行　　14
2.1.1　选择操作系统　　14
2.1.2　安装Java　　14
2.1.3　安装Zookeeper　　15
2.2　安装Kafka Broker　　17
2.3　broker配置　　18
2.3.1　常规配置　　18
2.3.2　主题的默认配置　　19
2.4　硬件的选择　　23
2.4.1　磁盘吞吐量　　23
2.4.2　磁盘容量　　23
2.4.3　内存　　23
2.4.4　网络　　24
2.4.5　CPU　　24
2.5　云端的Kafka　　24
2.6　Kafka集群　　24
2.6.1　需要多少个broker　　25
2.6.2　broker配置　　25
2.6.3　操作系统调优　　26
2.7　生产环境的注意事项　　28
2.7.1　垃圾回收器选项　　28
2.7.2　数据中心布局　　29
2.7.3　共享Zookeeper　　29
2.8　总结　　30
第3章　Kafka生产者——向Kafka写入数据　　31
3.1　生产者概览　　32
3.2　创建Kafka生产者　　33
3.3　发送消息到Kafka　　34
3.3.1　同步发送消息　　35
3.3.2　异步发送消息　　35
3.4　生产者的配置　　36
3.5　序列化器　　39
3.5.1　自定义序列化器　　39
3.5.2　使用Avro序列化　　41
3.5.3　在Kafka里使用Avro　　42
3.6　分区　　45
3.7　旧版的生产者API　　46
3.8　总结　　47
第4章　Kafka消费者——从Kafka读取数据　　48
4.1　KafkaConsumer概念　　48
4.1.1　消费者和消费者群组　　48
4.1.2　消费者群组和分区再均衡　　51
4.2　创建Kafka 消费者　　52
4.3　订阅主题　　53
4.4　轮询　　53
4.5　消费者的配置　　55
4.6　提交和偏移量　　57
4.6.1　自动提交　　58
4.6.2　提交当前偏移量　　59
4.6.3　异步提交　　59
4.6.4　同步和异步组合提交　　61
4.6.5　提交特定的偏移量　　61
4.7　再均衡监听器　　62
4.8　从特定偏移量处开始处理记录　　64
4.9　如何退出　　66
4.10　反序列化器　　67
4.11　独立消费者——为什么以及怎样使用没有群组的消费者　　71
4.12　旧版的消费者API　　71
4.13　总结　　72
第5章　深入Kafka　　73
5.1　集群成员关系　　73
5.2　控制器　　74
5.3　复制　　74
5.4　处理请求　　76
5.4.1　生产请求　　78
5.4.2　获取请求　　78
5.4.3　其他请求　　80
5.5　物理存储　　81
5.5.1　分区分配　　81
5.5.2　文件管理　　82
5.5.3　文件格式　　83
5.5.4　索引　　84
5.5.5　清理　　84
5.5.6　清理的工作原理　　84
5.5.7　被删除的事件　　86
5.5.8　何时会清理主题　　86
5.6　总结　　86
第6章　可靠的数据传递　　87
6.1　可靠性保证　　87
6.2　复制　　88
6.3　broker配置　　89
6.3.1　复制系数　　89
6.3.2　不完全的首领选举　　90
6.3.3　最少同步副本　　91
6.4　在可靠的系统里使用生产者　　92
6.4.1　发送确认　　92
6.4.2　配置生产者的重试参数　　93
6.4.3　额外的错误处理　　94
6.5　在可靠的系统里使用消费者　　94
6.5.1　消费者的可靠性配置　　95
6.5.2　显式提交偏移量　　95
6.6　验证系统可靠性　　97
6.6.1　配置验证　　98
6.6.2　应用程序验证　　98
6.6.3　在生产环境监控可靠性　　99
6.7　总结　　100
第7章　构建数据管道　　101
7.1　构建数据管道时需要考虑的问题　　102
7.1.1　及时性　　102
7.1.2　可靠性　　102
7.1.3　高吞吐量和动态吞吐量　　103
7.1.4　数据格式　　103
7.1.5　转换　　104
7.1.6　安全性　　104
7.1.7　故障处理能力　　104
7.1.8　耦合性和灵活性　　105
7.2　如何在Connect API和客户端API之间作出选择　　105
7.3　Kafka Connect　　106
7.3.1　运行Connect　　106
7.3.2　连接器示例——文件数据源和文件数据池　　107
7.3.3　连接器示例——从MySQL到ElasticSearch　　109
7.3.4　深入理解Connect　　114
7.4　Connect之外的选择　　116
7.4.1　用于其他数据存储的摄入框架　　116
7.4.2　基于图形界面的ETL 工具　　117
7.4.3　流式处理框架　　117
7.5　总结　　117
第8章　跨集群数据镜像　　118
8.1　跨集群镜像的使用场景　　118
8.2　多集群架构　　119
8.2.1　跨数据中心通信的一些现实情况　　119
8.2.2　Hub和Spoke架构　　120
8.2.3　双活架构　　121
8.2.4　主备架构　　123
8.2.5　延展集群　　127
8.3　Kafka的MirrorMaker　　128
8.3.1　如何配置　　129
8.3.2　在生产环境部署MirrorMaker　　130
8.3.3　MirrorMaker调优　　132
8.4　其他跨集群镜像方案　　134
8.4.1　优步的uReplicator　　134
8.4.2　Confluent的Replicator　　135
8.5　总结　　135
第9章　管理Kafka　　136
9.1　主题操作　　136
9.1.1　创建主题　　137
9.1.2　增加分区　　138
9.1.3　删除主题　　138
9.1.4　列出集群里的所有主题　　139
9.1.5　列出主题详细信息　　139
9.2　消费者群组　　140
9.2.1　列出并描述群组　　140
9.2.2　删除群组　　142
9.2.3　偏移量管理　　142
9.3　动态配置变更　　143
9.3.1　覆盖主题的默认配置　　143
9.3.2　覆盖客户端的默认配置　　145
9.3.3　列出被覆盖的配置　　145
9.3.4　移除被覆盖的配置　　146
9.4　分区管理　　146
9.4.1　首选的首领选举　　146
9.4.2　修改分区副本　　147
9.4.3　修改复制系数　　150
9.4.4　转储日志片段　　151
9.4.5　副本验证　　152
9.5　消费和生产　　153
9.5.1　控制台消费者　　153
9.5.2　控制台生产者　　155
9.6　客户端ACL　　157
9.7　不安全的操作　　157
9.7.1　移动集群控制器　　157
9.7.2　取消分区重分配　　157
9.7.3　移除待删除的主题　　158
9.7.4　手动删除主题　　158
9.8　总结　　159
第10章　监控Kafka　　160
10.1　度量指标基础　　160
10.1.1　度量指标在哪里　　160
10.1.2　内部或外部度量　　161
10.1.3　应用程序健康检测　　161
10.1.4　度量指标的覆盖面　　161
10.2　broker的度量指标　　162
10.2.1　非同步分区　　162
10.2.2　broker度量指标　　166
10.2.3　主题和分区的度量指标　　173
10.2.4　Java虚拟机监控　　174
10.2.5　操作系统监控　　175
10.2.6　日志　　176
10.3　客户端监控　　177
10.3.1　生产者度量指标　　177
10.3.2　消费者度量指标　　179
10.3.3　配额　　181
10.4　延时监控　　182
10.5　端到端监控　　183
10.6　总结　　183
第11章　流式处理　　184
11.1　什么是流式处理　　185
11.2　流式处理的一些概念　　186
11.2.1　时间　　187
11.2.2　状态　　188
11.2.3　流和表的二元性　　188
11.2.4　时间窗口　　189
11.3　流式处理的设计模式　　190
11.3.1　单个事件处理　　191
11.3.2　使用本地状态　　191
11.3.3　多阶段处理和重分区　　193
11.3.4　使用外部查找——流和表的连接　　193
11.3.5　流与流的连接　　195
11.3.6　乱序的事件　　195
11.3.7　重新处理　　196
11.4　Streams示例　　197
11.4.1　字数统计　　197
11.4.2　股票市场统计　　199
11.4.3　填充点击事件流　　201
11.5　Kafka Streams的架构概览　　202
11.5.1　构建拓扑　　202
11.5.2　对拓扑进行伸缩　　203
11.5.3　从故障中存活下来　　205
11.6　流式处理使用场景　　205
11.7　如何选择流式处理框架　　206
11.8　总结　　208
附录A　在其他操作系统上安装Kafka　　209
作者介绍　　214
封面介绍　　214




第1章　Kafka入门 1
1．1　Kafka流式数据平台 1
1．2　Kafka的基本概念 3
1．2．1　分区模型 3
1．2．2　消费模型 4
1．2．3　分布式模型 5
1．3　Kafka的设计与实现 6
1．3．1　文件系统的持久化与数据传输效率 6
1．3．2　生产者与消费者 8
1．3．3　副本机制和容错处理 10
1．4　快速开始 11
1．4．1　单机模式 12
1．4．2　分布式模式 14
1．4．3　消费组示例 16
1．5　环境准备 18
第2章　生产者 22
2．1　新生产者客户端 22
2．1．1　同步和异步发送消息 23
2．1．2　客户端消息发送线程 29
2．1．3　客户端网络连接对象 31
2．1．4　选择器处理网络请求 35
2．2　旧生产者客户端 43
2．2．1　事件处理器处理客户端发送的消息 44
2．2．2　对消息集按照节点和分区进行整理 46
2．2．3　生产者使用阻塞通道发送请求 48
2．3　服务端网络连接 49
2．3．1　服务端使用接收器接受客户端的连接 50
2．3．2　处理器使用选择器的轮询处理网络请求 53
2．3．3　请求通道的请求队列和响应队列 56
2．3．4　Kafka请求处理线程 58
2．3．5　服务端的请求处理入口 58
2．4　小结 60
第3章　消费者：高级API和低级API 61
3．1　消费者启动和初始化 67
3．1．1　创建并初始化消费者连接器 69
3．1．2　消费者客户端的线程模型 70
3．1．3　重新初始化消费者 72
3．2　消费者再平衡操作 73
3．2．1　分区的所有权 74
3．2．2　为消费者分配分区 75
3．2．3　创建分区信息对象 78
3．2．4　关闭和更新拉取线程管理器 80
3．2．5　分区信息对象的偏移量 80
3．3　消费者拉取数据 82
3．3．1　拉取线程管理器 82
3．3．2　抽象拉取线程 87
3．3．3　消费者拉取线程 90
3．4　消费者消费消息 94
3．4．1　Kafka消息流 94
3．4．2　消费者迭代消费消息 95
3．5　消费者提交分区偏移量 97
3．5．1　提交偏移量到ZK 98
3．5．2　提交偏移量到内部主题 99
3．5．3　连接偏移量管理器 101
3．5．4　服务端处理提交偏移量的请求 103
3．5．5　缓存分区的偏移量 106
3．6　消费者低级API示例 108
3．6．1　消息消费主流程 109
3．6．2　找出分区的主副本 112
3．6．3　获取分区的读取偏移量 113
3．6．4　发送拉取请求并消费消息 116
3．7　小结 117
3．7．1　消费者线程模型 117
3．7．2　再平衡和分区分配 119
第4章　新消费者 121
4．1　新消费者客户端 125
4．1．1　消费者的订阅状态 125
4．1．2　消费者轮询的准备工作 134
4．1．3　消费者轮询的流程 138
4．1．4　消费者拉取消息 146
4．1．5　消费者获取记录 149
4．1．6　消费消息 160
4．2　消费者的网络客户端轮询 161
4．2．1　异步请求 162
4．2．2　异步请求高级模式 169
4．2．3　网络客户端轮询 184
4．3　心跳任务 188
4．3．1　发送心跳请求 188
4．3．2　心跳状态 189
4．3．3　运行心跳任务 191
4．3．4　处理心跳结果的示例 192
4．3．5　心跳和协调者的关系 193
4．4　消费者提交偏移量 195
4．4．1　自动提交任务 195
4．4．2　将拉取偏移量作为提交偏移量 197
4．4．3　同步提交偏移量 201
4．4．4　消费者的消息处理语义 202
4．5　小结 206
第5章　协调者 210
5．1　消费者加入消费组 211
5．1．1　元数据与分区分配器 212
5．1．2　消费者的加入组和同步组 213
5．1．3　主消费者执行分配任务 220
5．1．4　加入组的准备、完成和监听器 224
5．2　协调者处理请求 229
5．2．1　服务端定义发送响应结果的回调方法 229
5．2．2　消费者和消费组元数据 232
5．2．3　协调者处理请求前的条件检查 236
5．2．4　协调者调用回调方法发送响应给客户端 237
5．3　延迟的加入组操作 242
5．3．1 “准备再平衡” 242
5．3．2　延迟操作和延迟缓存 244
5．3．3　尝试完成延迟的加入操作 246
5．3．4　消费组稳定后，原有消费者重新加入消费组 250
5．3．5　消费组未稳定，原有消费者重新加入消费组 251
5．4　消费组状态机 254
5．4．1　再平衡操作与监听器 254
5．4．2　消费组的状态转换 262
5．4．3　协调者处理“加入组请求” 264
5．4．4　协调者处理“同步组请求” 274
5．4．5　协调者处理“离开组请求” 276
5．4．6　再平衡超时与会话超时 278
5．4．7　延迟的心跳 282
5．5　小结 290
第6章　存储层 293
6．1　日志的读写 293
6．1．1　分区、副本、日志、日志
分段 294
6．1．2　写入日志 297
6．1．3　日志分段 305
6．1．4　读取日志 315
6．1．5　日志管理 329
6．1．6　日志压缩 336
6．2　服务端处理读写请求 348
6．2．1　副本管理器 351
6．2．2　分区与副本 362
6．3　延迟操作 373
6．3．1　延迟操作接口 374
6．3．2　延迟操作与延迟缓存 383
6．3．3　延迟缓存 391
6．4　小结 400
第7章　控制器 402
7．1　Kafka控制器 402
7．1．1　控制器选举 403
7．1．2　控制器上下文 406
7．1．3　ZK监听器 408
7．1．4　分区状态机和副本状态机 410
7．1．5　删除主题 430
7．1．6　重新分配分区 436
7．1．7　控制器的网络通道管理器 445
7．2　服务端处理LeaderAndIsr请求 448
7．2．1　创建分区 449
7．2．2　创建主副本、备份副本 451
7．2．3　消费组元数据迁移 463
7．3　元数据缓存 468
7．3．1　服务端的元数据缓存 472
7．3．2　客户端更新元数据 473
7．4　Kafka服务关闭 483
7．5　小结 487
第8章　基于Kafka构建数据流管道 490
8．1　Kafka集群同步工具：MirrorMaker 490
8．1．1　单机模拟数据同步 491
8．1．2　数据同步的流程 493
8．2　Uber集群同步工具：uReplicator 498
8．2．1　Apache Helix介绍 498
8．2．2　Helix控制器 501
8．2．3　Helix工作节点 504
8．3　Kafka连接器 505
8．3．1　连接器的使用示例 507
8．3．2　开发一个简单的连接器 510
8．3．3　连接器的架构模型 515
8．3．4　Herder的实现 520
8．3．5　Worker的实现 524
8．3．6　配置存储与状态存储 530
8．3．7　连接器与任务的实现 550
8．4　小结 565
第9章　Kafka流处理 569
9．1　低级Processor API 569
9．1．1　流处理应用程序示例 569
9．1．2　流处理的拓扑 575
9．1．3　流处理的线程模型 580
9．1．4　状态存储 613
9．2　高级流式DSL 636
9．2．1　DSL应用程序示例 636
9．2．2　KStream和KTable 638
9．2．3　连接操作 665
9．2．4　窗口操作 672
9．3　小结 684
第10章　高级特性介绍 686
10．1　客户端配额 686
10．2　消息与时间戳 692
10．3　事务处理 699
10．4　小结 703

1.1　Kafka快速入门 1
1.1.1　下载并解压缩Kafka二进制代码压缩包文件 2
1.1.2　启动服务器 3
1.1.3　创建topic 3
1.1.4　发送消息 4
1.1.5　消费消息 4
1.2　消息引擎系统 5
1.2.1　消息设计 6
1.2.2　传输协议设计 6
1.2.3　消息引擎范型 6
1.2.4　Java消息服务 8

1.3　Kafka概要设计 8
1.3.1　吞吐量/延时 8
1.3.2　消息持久化 11
1.3.3　负载均衡和故障转移 12
1.3.4　伸缩性 13

1.4　Kafka基本概念与术语 13
1.4.1　消息 14
1.4.2　topic和partition 16
1.4.3　offset 17
1.4.4　replica 18
1.4.5　leader和follower 18
1.4.6　ISR 19

1.5　Kafka使用场景 20

1.5.1　消息传输 20

1.5.2　网站行为日志追踪 20

1.5.3　审计数据收集 20

1.5.4　日志收集 20

1.5.5　Event Sourcing 21

1.5.6　流式处理 21

2.1　Kafka的历史 22

2.1.1　背景 22

2.1.2　Kafka横空出世 23

2.1.3　Kafka开源 24

2.2　Kafka版本变迁 25

2.2.1　Kafka的版本演进 25

2.2.2　Kafka的版本格式 26

2.2.3　新版本功能简介 26

2.2.4　旧版本功能简介 31

2.3　如何选择Kafka版本 35

2.3.1　根据功能场景 35

2.3.2　根据客户端使用场景 35

2.4　Kafka与Confluent 36

2.5　本章小结 37

第3章　Kafka线上环境部署 38

3.1　集群环境规划 38

3.1.1　操作系统的选型 38

3.1.2　磁盘规划 40

3.1.3　磁盘容量规划 42

3.1.4　内存规划 43

3.1.5　CPU规划 43

3.1.6　带宽规划 44

3.1.7　典型线上环境配置 45

3.2　伪分布式环境安装 45

3.2.1　安装Java 46

3.2.2　安装ZooKeeper 47

3.2.3　安装单节点Kafka集群 48

3.3　多节点环境安装 49

3.3.1　安装多节点ZooKeeper集群 50

3.3.2　安装多节点Kafka 54

3.4　验证部署 55

3.4.1　测试topic创建与删除 55

3.4.2　测试消息发送与消费 57

3.4.3　生产者吞吐量测试 58

3.4.4　消费者吞吐量测试 58

3.5　参数设置 59

3.5.1　broker端参数 59

3.5.2　topic级别参数 62

3.5.3　GC参数 63

3.5.4　JVM参数 64

3.5.5　OS参数 64

3.6　本章小结 65

第4章　producer开发 66

4.1　producer概览 66

4.2　构造producer 69

4.2.1　producer程序实例 69

4.2.2　producer主要参数 75

4.3　消息分区机制 80

4.3.1　分区策略 80

4.3.2　自定义分区机制 80

4.4　消息序列化 83

4.4.1　默认序列化 83

4.4.2　自定义序列化 84

4.5　producer拦截器 87

4.6　无消息丢失配置 90

4.6.1　producer端配置 91

4.6.2　broker端配置 92

4.7　消息压缩 92

4.7.1　Kafka支持的压缩算法 93

4.7.2　算法性能比较与调优 93

4.8　多线程处理 95

4.9　旧版本producer 96

4.10　本章小结 98

第5章　consumer开发 99

5.1　consumer概览 99

5.1.1　消费者（consumer） 99

5.1.2　消费者组（consumer group） 101

5.1.3　位移（offset） 102

5.1.4　位移提交 103

5.1.5　__consumer_offsets 104

5.1.6　消费者组重平衡（consumer group rebalance） 106

5.2　构建consumer 106

5.2.1　consumer程序实例 106

5.2.2　consumer脚本命令 111

5.2.3　consumer主要参数 112

5.3　订阅topic 115

5.3.1　订阅topic列表 115

5.3.2　基于正则表达式订阅topic 115

5.4　消息轮询 115

5.4.1　poll内部原理 115

5.4.2　poll使用方法 116

5.5　位移管理 118

5.5.1　consumer位移 119

5.5.2　新版本consumer位移管理 120

5.5.3　自动提交与手动提交 121

5.5.4　旧版本consumer位移管理 123

5.6　重平衡（rebalance） 123

5.6.1　rebalance概览 123

5.6.2　rebalance触发条件 124

5.6.3　rebalance分区分配 124

5.6.4　rebalance generation 126

5.6.5　rebalance协议 126

5.6.6　rebalance流程 127

5.6.7　rebalance监听器 128

5.7　解序列化 130

5.7.1　默认解序列化器 130

5.7.2　自定义解序列化器 131

5.8　多线程消费实例 132

5.8.1　每个线程维护一个KafkaConsumer 133

5.8.2　单KafkaConsumer实例+多worker线程 135

5.8.3　两种方法对比 140

5.9　独立consumer 141

5.10　旧版本consumer 142

5.10.1　概览 142

5.10.2　high-level consumer 143

5.10.3　low-level consumer 147

5.11　本章小结 153

第6章　Kafka设计原理 154

6.1　broker端设计架构 154

6.1.1　消息设计 155

6.1.2　集群管理 166

6.1.3　副本与ISR设计 169

6.1.4　水印（watermark）和leader epoch 174

6.1.5　日志存储设计 185

6.1.6　通信协议（wire protocol） 194

6.1.7　controller设计 205

6.1.8　broker请求处理 216

6.2　producer端设计 219

6.2.1　producer端基本数据结构 219

6.2.2　工作流程 220

6.3　consumer端设计 223

6.3.1　consumer group状态机 223

6.3.2　group管理协议 226

6.3.3　rebalance场景剖析 227

6.4　实现精确一次处理语义 230

6.4.1　消息交付语义 230

6.4.2　幂等性producer（idempotent producer） 231

6.4.3　事务（transaction） 232

6.5　本章小结 234

第7章　管理Kafka集群 235

7.1　集群管理 235

7.1.1　启动broker 235

7.1.2　关闭broker 236

7.1.3　设置JMX端口 237

7.1.4　增加broker 238

7.1.5　升级broker版本 238

7.2　topic管理 241

7.2.1　创建topic 241

7.2.2　删除topic 243

7.2.3　查询topic列表 244

7.2.4　查询topic详情 244

7.2.5　修改topic 245

7.3　topic动态配置管理 246

7.3.1　增加topic配置 246

7.3.2　查看topic配置 247

7.3.3　删除topic配置 248

7.4　consumer相关管理 248

7.4.1　查询消费者组 248

7.4.2　重设消费者组位移 251

7.4.3　删除消费者组 256

7.4.4　kafka-consumer-offset-checker 257

7.5　topic分区管理 258

7.5.1　preferred leader选举 258

7.5.2　分区重分配 260

7.5.3　增加副本因子 263

7.6　Kafka常见脚本工具 264

7.6.1　kafka-console-producer脚本 264

7.6.2　kafka-console-consumer脚本 265

7.6.3　kafka-run-class脚本 267

7.6.4　查看消息元数据 268

7.6.5　获取topic当前消息数 270

7.6.6　查询__consumer_offsets 271

7.7　API方式管理集群 273

7.7.1　服务器端API管理topic 273

7.7.2　服务器端API管理位移 275

7.7.3　客户端API管理topic 276

7.7.4　客户端API查看位移 280

7.7.5　0.11.0.0版本客户端API 281

7.8　MirrorMaker 285

7.8.1　概要介绍 285

7.8.2　主要参数 286

7.8.3　使用实例 287

7.9　Kafka安全 288

7.9.1　SASL+ACL 289

7.9.2　SSL加密 297

7.10　常见问题 301

7.11　本章小结 304

第8章　监控Kafka集群 305

8.1　集群健康度检查 305

8.2　MBean监控 306

8.2.1　监控指标 306

8.2.2　指标分类 308

8.2.3　定义和查询JMX端口 309

8.3　broker端JMX监控 310

8.3.1　消息入站/出站速率 310

8.3.2　controller存活JMX指标 311

8.3.3　备份不足的分区数 312

8.3.4　leader分区数 312

8.3.5　ISR变化速率 313

8.3.6　broker I/O工作处理线程空闲率 313

8.3.7　broker网络处理线程空闲率 314

8.3.8　单个topic总字节数 314

8.4　clients端JMX监控 314

8.4.1　producer端JMX监控 314

8.4.2　consumer端JMX监控 316

8.5　JVM监控 317

8.5.1　进程状态 318

8.5.2　GC性能 318

8.6　OS监控 318

8.7　主流监控框架 319

8.7.1　JmxTool 320

8.7.2　kafka-manager 320

8.7.3　Kafka Monitor 325

8.7.4　Kafka Offset Monitor 327

8.7.5　CruiseControl 329

8.8　本章小结 330

第9章　调优Kafka集群 331

9.1　引言 331

9.2　确定调优目标 333

9.3　集群基础调优 334

9.3.1　禁止atime更新 335

9.3.2　文件系统选择 335

9.3.3　设置swapiness 336

9.3.4　JVM设置 337

9.3.5　其他调优 337

9.4　调优吞吐量 338

9.5　调优延时 342

9.6　调优持久性 343

9.7　调优可用性 347

9.8　本章小结 349

第10章　Kafka Connect与Kafka Streams 350

10.2　Kafka Connect 351
10.2.1　概要介绍 351
10.2.2　standalone Connect 353
10.2.3　distributed Connect 356
10.2.4　开发connector 359
10.3　Kafka Streams 362
10.3.1　流处理 362

10.3.2　Kafka Streams核心概念 364
10.3.3　Kafka Streams与其他框架的异同 368
10.3.4　Word Count实例 369
10.3.5　Kafka Streams应用开发 372
10.3.6　Kafka Streams状态查询 382






152. kafka 可以脱离 zookeeper 单独使用吗？为什么？

kafka 不能脱离 zookeeper 单独使用，因为 kafka 使用 zookeeper 管理和协调 kafka 的节点服务器。

153. kafka 有几种数据保留的策略？

kafka 有两种数据保存策略：按照过期时间保留和按照存储的消息大小保留。

154. kafka 同时设置了 7 天和 10G 清除数据，到第五天的时候消息达到了 10G，这个时候 kafka 将如何处理？

这个时候 kafka 会执行数据清除工作，时间和大小不论那个满足条件，都会清空数据。

155. 什么情况会导致 kafka 运行变慢？

cpu 性能瓶颈

磁盘读写瓶颈

网络瓶颈


156. 使用 kafka 集群需要注意什么？

集群的数量不是越多越好，最好不要超过 7 个，因为节点越多，消息复制需要的时间就越长，整个群组的吞吐量就越低。

集群数量最好是单数，因为超过一半故障集群就不能用了，设置为单数容错率更高。