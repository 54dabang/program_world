第13章Kafka设计理念与基本架构
13.1Kafka产生的背景
13.2消息队列系统
13.2.1概述
13.2.2常用的消息队列系统对比
13.2.3Kafka特点及特性
13.2.4Kafka系统应用场景
13.3Kafka设计理念
13.3.1专业术语解析
13.3.2消息存储与缓存设计
13.3.3消费者与生产者模型
13.3.4Push与Pull机制
13.3.5镜像机制
13.4Kafka整体架构
13.4.1Kafka基本组成结构
13.4.2Kafka工作流程
13.5Kafka性能分析及优化
13.6Kafka未来研究方向
13.7小结
第14章Kafka核心组件及核心特性剖析
14.1Kafka核心组件剖析
14.1.1Producers
14.1.2Consumers
14.1.3Low Level Consumer
14.1.4High Level Consumer
14.2Kafka核心特性剖析
14.2.1Topic、Partitions
14.2.2Replication和Leader Election
14.2.3Consumer Rebalance
14.2.4消息传送机制
14.2.5Kafka的可靠性
14.2.6Kafka的高效性
14.3Kafka即将发布版本核心组件及特性剖析
14.3.1重新设计的Consumer
14.3.2Coordinator Rebalance
14.4小结
第15章Kafka应用实践
15.1Kafka开发环境搭建及运行环境部署
15.1.1Kafka开发环境配置
15.1.2Kafka运行环境安装与部署
15.2基于Kafka客户端开发
15.2.1消息生产者（Producer）设计
15.2.2消息消费者（Consumer）设计
15.2.3Kafka消费者与生产者配置

．1　基本概念
1．2　安装与配置
1．3　生产与消费
1．4　服务端参数配置
1．5　总结
第2章　生产者
2．1　客户端开发
2．1．1　必要的参数配置
2．1．2　消息的发送
2．1．3　序列化
2．1．4　分区器
2．1．5　生产者拦截器
2．2　原理分析
2．2．1　整体架构
2．2．2　元数据的更新
2．3　重要的生产者参数
2．4　总结
第3章　消费者
3．1　消费者与消费组
3．2　客户端开发
3．2．1　必要的参数配置
3．2．2　订阅主题与分区
3．2．3　反序列化
3．2．4　消息消费
3．2．5　位移提交
3．2．6　控制或关闭消费
3．2．7　指定位移消费
3．2．8　再均衡
3．2．9　消费者拦截器
3．2．10　多线程实现
3．2．11　重要的消费者参数
3．3　总结
第4章　主题与分区
4．1　主题的管理
4．1．1　创建主题
4．1．2　分区副本的分配
4．1．3　查看主题
4．1．4　修改主题
4．1．5　配置管理
4．1．6　主题端参数
4．1．7　删除主题
4．2　初识KafkaAdminClient
4．2．1　基本使用
4．2．2　主题合法性验证
4．3　分区的管理
4．3．1　优先副本的选举
4．3．2　分区重分配
4．3．3　复制限流
4．3．4　修改副本因子
4．4　如何选择合适的分区数
4．4．1　性能测试工具
4．4．2　分区数越多吞吐量就越高吗
4．4．3　分区数的上限
4．4．4　考量因素
4．5　总结
第5章　日志存储
5．1　文件目录布局
5．2　日志格式的演变
5．2．1　v0版本
5．2．2　v1版本
5．2．3　消息压缩
5．2．4　变长字段
5．2．5　v2版本
5．3　日志索引
5．3．1　偏移量索引
5．3．2　时间戳索引
5．4　日志清理
5．4．1　日志删除
5．4．2　日志压缩
5．5　磁盘存储
5．5．1　页缓存
5．5．2　磁盘I/O流程
5．5．3　零拷贝
5．6　总结
第6章　深入服务端
6．1　协议设计
6．2　时间轮
6．3　延时操作
6．4　控制器
6．4．1　控制器的选举及异常恢复
6．4．2　优雅关闭
6．4．3　分区leader的选举
6．5　参数解密
6．5．1　broker．id
6．5．2　bootstrap．servers
6．5．3　服务端参数列表
6．6　总结
第7章　深入客户端
7．1　分区分配策略
7．1．1　RangeAssignor分配策略
7．1．2　RoundRobinAssignor分配策略
7．1．3　StickyAssignor分配策略
7．1．4　自定义分区分配策略
7．2　消费者协调器和组协调器
7．2．1　旧版消费者客户端的问题
7．2．2　再均衡的原理
7．3　__consumer_offsets剖析
7．4　事务
7．4．1　消息传输保障
7．4．2　幂等
7．4．3　事务
7．5　总结
第8章　可靠性探究
8．1　副本剖析
8．1．1　失效副本
8．1．2　ISR的伸缩
8．1．3　LEO与HW
8．1．4　Leader Epoch的介入
8．1．5　为什么不支持读写分离
8．2　日志同步机制
8．3　可靠性分析
8．4　总结
第9章　Kafka应用
9．1　命令行工具
9．1．1　消费组管理
9．1．2　消费位移管理
9．1．3　手动删除消息
9．2　Kafka Connect
9．2．1　独立模式
9．2．2　REST API
9．2．3　分布式模式
9．3　Kafka Mirror Maker
9．4　Kafka Streams
9．5　总结
第10章　Kafka监控
10．1　监控数据的来源
10．1．1　OneMinuteRate
10．1．2　获取监控指标
10．2　消费滞后
10．3　同步失效分区
10．4　监控指标说明
10．5　监控模块
10．6　总结
第11章　高级应用
11．1　过期时间（TTL）
11．2　延时队列
11．3　死信队列和重试队列
11．4　消息路由
11．5　消息轨迹
11．6　消息审计
11．7　消息代理
11．7．1　快速入门
11．7．2　REST API介绍及示例
11．7．3　服务端配置及部署
11．7．4　应用思考
11．8　消息中间件选型
11．8．1　各类消息中间件简述
11．8．2　选型要点概述
11．8．3　消息中间件选型误区探讨
11．9　总结
第12章　Kafka与Spark的集成
12．1　Spark的安装及简单应用
12．2　Spark编程模型
12．3　Spark的运行结构
12．4　Spark Streaming简介
12．5　Kafka与Spark Streaming的整合
12．6　Spark SQL
12．7　Structured Streaming
12．8　Kafka与Structured Streaming的整合
12．9　总结
附录A　Kafka源码环境搭建

1.1.1 下载并解压缩Kafka二进制代码压缩包文件
1.1.2 启动服务器
1.1.3 创建topic
1.1.4 发送消息
1.1.5 消费消息
1.2 消息引擎系统
1.2.1 消息设计
1.2.2 传输协议设计
1.2.3 消息引擎范型
1.2.4 Java消息服务
1.3 Kafka概要设计
1.3.1 吞吐量/延时
1.3.2 消息持久化
1.3.3 负载均衡和故障转移
1.3.4 伸缩性
1.4 Kafka基本概念与术语
1.4.1 消息
1.4.2 topic和partition
1.4.3 offset
1.4.4 replica
1.4.5 leader和follower
1.4.6 ISR
1.5 Kafka使用场景
1.5.1 消息传输
1.5.2 网站行为日志追踪
1.5.3 审计数据收集
1.5.4 日志收集
1.5.5 Event Sourcing
1.5.6 流式处理
1.6 本章小结
第2章 Kafka发展历史
2.1 Kafka的历史
2.1.1 背景
2.1.2 Kafka横空出世
2.1.3 Kafka开源
2.2 Kafka版本变迁
2.2.1 Kafka的版本演进
2.2.2 Kafka的版本格式
2.2.3 新版本功能简介
2.2.4 旧版本功能简介
2.3 如何选择Kafka版本
2.3.1 根据功能场景
2.3.2 根据客户端使用场景
2.4 Kafka与Confluent
2.5 本章小结
第3章 Kafka线上环境部署
3.1 集群环境规划
3.1.1 操作系统的选型
3.1.2 磁盘规划
3.1.3 磁盘容量规划
3.1.4 内存规划
3.1.5 CPU规划
3.1.6 带宽规划
3.1.7 典型线上环境配置
3.2 伪分布式环境安装
3.2.1 安装Java
3.2.2 安装ZooKeeper
3.2.3 安装单节点Kafka集群
3.3 多节点环境安装
3.3.1 安装多节点ZooKeeper集群
3.3.2 安装多节点Kafka
3.4 验证部署
3.4.1 测试topic创建与删除
3.4.2 测试消息发送与消费
3.4.3 生产者吞吐量测试
3.4.4 消费者吞吐量测试
3.5 参数设置
3.5.1 broker端参数
3.5.2 topic级别参数
3.5.3 GC参数
3.5.4 JVM参数
3.5.5 OS参数
3.6 本章小结
第4章 producer开发
4.1 producer概览
4.2 构造producer
4.2.1 producer程序实例
4.2.2 producer主要参数
4.3 消息分区机制
4.3.1 分区策略
4.3.2 自定义分区机制
4.4 消息序列化
4.4.1 默认序列化
4.4.2 自定义序列化
4.5 producer拦截器
4.6 无消息丢失配置
4.6.1 producer端配置
4.6.2 broker端配置
4.7 消息压缩
4.7.1 Kafka支持的压缩算法
4.7.2 算法性能比较与调优
4.8 多线程处理
4.9 旧版本producer
4.10 本章小结
第5章 consumer开发
5.1 consumer概览
5.1.1 消费者（consumer）
5.1.2 消费者组（consumer group）
5.1.3 位移（offset）
5.1.4 位移提交
5.1.5__consumer_offsets
5.1.6 消费者组重平衡（consumer group rebalance）
5.2 构建consumer
5.2.1 consumer程序实例
5.2.2 consumer脚本命令
5.2.3 consumer主要参数
5.3 订阅topic
5.3.1 订阅topic列表
5.3.2 基于正则表达式订阅topic
5.4 消息轮询
5.4.1 poll内部原理
5.4.2 poll使用方法
5.5 位移管理
5.5.1 consumer位移
5.5.2 新版本consumer位移管理
5.5.3 自动提交与手动提交
5.5.4 旧版本consumer位移管理
5.6 重平衡（rebalance）
5.6.1 rebalance概览
5.6.2 rebalance触发条件
5.6.3 rebalance分区分配
5.6.4 rebalance generation
5.6.5 rebalance协议
5.6.6 rebalance流程
5.6.7 rebalance监听器
5.7 解序列化
5.7.1 默认解序列化器
5.7.2 自定义解序列化器
5.8 多线程消费实例
5.8.1 每个线程维护一个KafkaConsumer
5.8.2 单KafkaConsumer实例+多worker线程
5.8.3 两种方法对比
5.9 独立consumer
5.10 旧版本consumer
5.10.1 概览
5.10.2 high-level consumer
5.10.3 low-level consumer
5.11 本章小结
第6章 Kafka设计原理
6.1 broker端设计架构
6.1.1 消息设计
6.1.2 集群管理
6.1.3 副本与ISR设计
6.1.4 水印（watermark）和leader epoch
6.1.5 日志存储设计
6.1.6 通信协议（wire protocol）
6.1.7 controller设计
6.1.8 broker请求处理
6.2 producer端设计
6.2.1 producer端基本数据结构
6.2.2 工作流程
6.3 consumer端设计
6.3.1 consumer group状态机
6.3.2 group管理协议
6.3.3 rebalance场景剖析
6.4 实现精确一次处理语义
6.4.1 消息交付语义
6.4.2 幂等性producer（idempotent producer）
6.4.3 事务（transaction）
6.5 本章小结
第7章 管理Kafka集群
7.1 集群管理
7.1.1 启动broker
7.1.2 关闭broker
7.1.3 设置JMX端口
7.1.4 增加broker
7.1.5 升级broker版本
7.2 topic管理
7.2.1 创建topic
7.2.2 删除topic
7.2.3 查询topic列表
7.2.4 查询topic详情
7.2.5 修改topic
7.3 topic动态配置管理
7.3.1 增加topic配置
7.3.2 查看topic配置
7.3.3 删除topic配置
7.4 consumer相关管理
7.4.1 查询消费者组
7.4.2 重设消费者组位移
7.4.3 删除消费者组
7.4.4 kafka-consumer-offset-checker
7.5 topic分区管理
7.5.1 preferred leader选举
7.5.2 分区重分配
7.5.3 增加副本因子
7.6 Kafka常见脚本工具
7.6.1 kafka-console-producer脚本
7.6.2 kafka-console-consumer脚本
7.6.3 kafka-run-class脚本
7.6.4 查看消息元数据
7.6.5 获取topic当前消息数
7.6.6 查询__consumer_offsets
7.7 API方式管理集群
7.7.1 服务器端API管理topic
7.7.2 服务器端API管理位移
7.7.3 客户端API管理topic
7.7.4 客户端API查看位移
7.7.5 0.11.0.0版本客户端API
7.8 MirrorMaker
7.8.1 概要介绍
7.8.2 主要参数
7.8.3 使用实例
7.9 Kafka安全
7.9.1 SASL+ACL
7.9.2 SSL加密
7.10 常见问题
7.11 本章小结
第8章 监控Kafka集群
8.1 集群健康度检查
8.2 MBean监控
8.2.1 监控指标
8.2.2 指标分类
8.2.3 定义和查询JMX端口
8.3 broker端JMX监控
8.3.1 消息入站/出站速率
8.3.2 controller存活JMX指标
8.3.3 备份不足的分区数
8.3.4 leader分区数
8.3.5 ISR变化速率
8.3.6 broker I/O工作处理线程空闲率
8.3.7 broker网络处理线程空闲率
8.3.8 单个topic总字节数
8.4 clients端JMX监控
8.4.1 producer端JMX监控
8.4.2 consumer端JMX监控
8.5 JVM监控
8.5.1 进程状态
8.5.2 GC性能
8.6 OS监控
8.7 主流监控框架
8.7.1 JmxTool
8.7.2 kafka-manager
8.7.3 Kafka Monitor
8.7.4 Kafka Offset Monitor
8.7.5 CruiseControl
8.8 本章小结
第9章 调优Kafka集群
9.1 引言
9.2 确定调优目标
9.3 集群基础调优
9.3.1 禁止atime更新
9.3.2 文件系统选择
9.3.3 设置swapiness
9.3.4 JVM设置
9.3.5 其他调优
9.4 调优吞吐量
9.5 调优延时
9.6 调优持久性
9.7 调优可用性
9.8 本章小结
第10章 Kafka Connect与Kafka Streams
10.1 引言
10.2 Kafka Connect
10.2.1 概要介绍
10.2.2 standalone Connect
10.2.3 distributed Connect
10.2.4 开发connector
10.3 Kafka Streams
10.3.1 流处理
10.3.2 Kafka Streams核心概念
10.3.3 Kafka Streams与其他框架的异同
10.3.4 Word Count实例
10.3.5 Kafka Streams应用开发
10.3.6 Kafka Streams状态查询
第1章　初识 Kafka
1.1　发布与订阅消息系统
1.2　Kafka登场
1.3　为什么选择Kafka
1.4　数据生态系统
1.5　起源故事
1.6　开始Kafka之旅
第2章　安装 Kafka
2.1　要事先行
2.2　安装Kafka Broker
2.3　broker配置
2.4　硬件的选择
2.5　云端的Kafka
2.6　Kafka集群
2.7　生产环境的注意事项
2.8　总结
第3章　Kafka 生产者——向 Kafka 写入数据
3.1　生产者概览
3.2　创建Kafka生产者
3.3　发送消息到Kafka
3.4　生产者的配置
3.5　序列化器
3.6　分区
3.7　旧版的生产者API
3.8　总结
第4章　Kafka 消费者——从 Kafka 读取数据
4.1　KafkaConsumer概念
4.2　创建Kafka消费者
4.3　订阅主题
4.4　轮询
4.5　消费者的配置
4.6　提交和偏移量
4.7　再均衡监听器
4.8　从特定偏移量处开始处理记录
4.9　如何退出
4.10　反序列化器
4.11　独立消费者——为什么以及怎样使用没有群组的消费者
4.12　旧版的消费者API
4.13　总结
第5章　深入 Kafka
5.1　集群成员关系
5.2　控制器
5.3　复制
5.4　处理请求
5.5　物理存储
5.6　总结
第6章　可靠的数据传递
6.1　可靠性保证
6.2　复制
6.3　broker配置
6.4　在可靠的系统里使用生产者
6.5　在可靠的系统里使用消费者
6.6　验证系统可靠性
6.7　总结
第7章　构建数据管道
7.1　构建数据管道时需要考虑的问题
7.2　如何在Connect API和客户端API之间作出选择
7.3　Kafka Connect
7.4　Connect之外的选择
7.5　总结
第8章　跨集群数据镜像
8.1　跨集群镜像的使用场景
8.2　多集群架构
8.3　Kafka的MirrorMaker
8.4　其他跨集群镜像方案
8.5　总结
第9章　管理 Kafka
9.1　主题操作
9.2　消费者群组
9.3　动态配置变更
9.4　分区管理
9.5　消费和生产
9.6　客户端ACL
9.7　不安全的操作
9.8　总结
第10章　监控 Kafka
10.1　度量指标基础
10.2　broker的度量指标
10.3　客户端监控
10.4　延时监控
10.5　端到端监控
10.6　总结
第11章　流式处理
11.1　什么是流式处理
11.2　流式处理的一些概念
11.3　流式处理的设计模式
11.4　Streams示例
11.5　Kafka Streams的架构概览
11.6　流式处理使用场景
11.7　如何选择流式处理框架
11.8　总结
附录A　在其他操作系统上安装 Kafka
A.1　在Windows上安装Kafka
A.2　在MacOS上安装Kafka

1．1　基本概念
1．2　安装与配置
1．3　生产与消费
1．4　服务端参数配置
1．5　总结
第2章　生产者
2．1　客户端开发
2．1．1　必要的参数配置
2．1．2　消息的发送
2．1．3　序列化
2．1．4　分区器
2．1．5　生产者拦截器
2．2　原理分析
2．2．1　整体架构
2．2．2　元数据的更新
2．3　重要的生产者参数
2．4　总结
第3章　消费者
3．1　消费者与消费组
3．2　客户端开发
3．2．1　必要的参数配置
3．2．2　订阅主题与分区
3．2．3　反序列化
3．2．4　消息消费
3．2．5　位移提交
3．2．6　控制或关闭消费
3．2．7　指定位移消费
3．2．8　再均衡
3．2．9　消费者拦截器
3．2．10　多线程实现
3．2．11　重要的消费者参数
3．3　总结
第4章　主题与分区
4．1　主题的管理
4．1．1　创建主题
4．1．2　分区副本的分配
4．1．3　查看主题
4．1．4　修改主题
4．1．5　配置管理
4．1．6　主题端参数
4．1．7　删除主题
4．2　初识KafkaAdminClient
4．2．1　基本使用
4．2．2　主题合法性验证
4．3　分区的管理
4．3．1　优先副本的选举
4．3．2　分区重分配
4．3．3　复制限流
4．3．4　修改副本因子
4．4　如何选择合适的分区数
4．4．1　性能测试工具
4．4．2　分区数越多吞吐量就越高吗
4．4．3　分区数的上限
4．4．4　考量因素
4．5　总结
第5章　日志存储
5．1　文件目录布局
5．2　日志格式的演变
5．2．1　v0版本
5．2．2　v1版本
5．2．3　消息压缩
5．2．4　变长字段
5．2．5　v2版本
5．3　日志索引
5．3．1　偏移量索引
5．3．2　时间戳索引
5．4　日志清理
5．4．1　日志删除
5．4．2　日志压缩
5．5　磁盘存储
5．5．1　页缓存
5．5．2　磁盘I/O流程
5．5．3　零拷贝
第6章　深入服务端
6．1　协议设计
6．2　时间轮
6．3　延时操作
6．4　控制器
6．4．1　控制器的选举及异常恢复
6．4．2　优雅关闭
6．4．3　分区leader的选举
6．5　参数解密
6．5．1　broker．id
6．5．2　bootstrap．servers
6．5．3　服务端参数列表
6．6　总结
第7章　深入客户端
7．1　分区分配策略
7．1．1　RangeAssignor分配策略
7．1．2　RoundRobinAssignor分配策略
7．1．3　StickyAssignor分配策略
7．1．4　自定义分区分配策略
7．2　消费者协调器和组协调器
7．2．1　旧版消费者客户端的问题
7．2．2　再均衡的原理
7．3　__consumer_offsets剖析
7．4　事务
7．4．1　消息传输保障
7．4．2　幂等
7．4．3　事务
第8章　可靠性探究
8．1　副本剖析
8．1．1　失效副本
8．1．2　ISR的伸缩
8．1．3　LEO与HW
8．1．4　Leader Epoch的介入
8．1．5　为什么不支持读写分离
8．2　日志同步机制
8．3　可靠性分析
第9章　Kafka应用
9．1　命令行工具
9．1．1　消费组管理
9．1．2　消费位移管理
9．1．3　手动删除消息
9．2　Kafka Connect
9．2．1　独立模式
9．2．2　REST API
9．2．3　分布式模式
9．3　Kafka Mirror Maker
9．4　Kafka Streams
第10章　Kafka监控
10．1　监控数据的来源
10．1．1　OneMinuteRate
10．1．2　获取监控指标
10．2　消费滞后
10．3　同步失效分区
10．4　监控指标说明
10．5　监控模块
第11章　高级应用
11．1　过期时间（TTL）
11．2　延时队列
11．3　死信队列和重试队列
11．4　消息路由
11．5　消息轨迹
11．6　消息审计
11．7　消息代理
11．7．1　快速入门
11．7．2　REST API介绍及示例
11．7．3　服务端配置及部署
11．7．4　应用思考
11．8　消息中间件选型
11．8．1　各类消息中间件简述
11．8．2　选型要点概述
11．8．3　消息中间件选型误区探讨
11．9　总结
第12章　Kafka与Spark的集成
12．1　Spark的安装及简单应用
12．2　Spark编程模型
12．3　Spark的运行结构
12．4　Spark Streaming简介
12．5　Kafka与Spark Streaming的整合
12．6　Spark SQL
12．7　Structured Streaming
12．8　Kafka与Structured Streaming的整合
附录A　Kafka源码环境搭建

1.1　发布与订阅消息系统　　1
1.1.1　如何开始　　2
1.1.2　独立的队列系统　　3
1.2　Kafka登场　　4
1.2.1　消息和批次　　4
1.2.2　模式　　4
1.2.3　主题和分区　　5
1.2.4　生产者和消费者　　5
1.2.5　broker和集群　　6
1.2.6　多集群　　7
1.3　为什么选择Kafka　　8
1.3.1　多个生产者　　8
1.3.2　多个消费者　　8
1.3.3　基于磁盘的数据存储　　9
1.3.4　伸缩性　　9
1.3.5　高性能　　9
1.4　数据生态系统　　9
1.5　起源故事　　11
1.5.1　LinkedIn的问题　　11
1.5.2　Kafka的诞生　　12
1.5.3　走向开源　　12
1.5.4　命名　　13
1.6　开始Kafka之旅　　13
第2章　安装Kafka　　14
2.1　要事先行　　14
2.1.1　选择操作系统　　14
2.1.2　安装Java　　14
2.1.3　安装Zookeeper　　15
2.2　安装Kafka Broker　　17
2.3　broker配置　　18
2.3.1　常规配置　　18
2.3.2　主题的默认配置　　19
2.4　硬件的选择　　23
2.4.1　磁盘吞吐量　　23
2.4.2　磁盘容量　　23
2.4.3　内存　　23
2.4.4　网络　　24
2.4.5　CPU　　24
2.5　云端的Kafka　　24
2.6　Kafka集群　　24
2.6.1　需要多少个broker　　25
2.6.2　broker配置　　25
2.6.3　操作系统调优　　26
2.7　生产环境的注意事项　　28
2.7.1　垃圾回收器选项　　28
2.7.2　数据中心布局　　29
2.7.3　共享Zookeeper　　29
2.8　总结　　30
第3章　Kafka生产者——向Kafka写入数据　　31
3.1　生产者概览　　32
3.2　创建Kafka生产者　　33
3.3　发送消息到Kafka　　34
3.3.1　同步发送消息　　35
3.3.2　异步发送消息　　35
3.4　生产者的配置　　36
3.5　序列化器　　39
3.5.1　自定义序列化器　　39
3.5.2　使用Avro序列化　　41
3.5.3　在Kafka里使用Avro　　42
3.6　分区　　45
3.7　旧版的生产者API　　46
3.8　总结　　47
第4章　Kafka消费者——从Kafka读取数据　　48
4.1　KafkaConsumer概念　　48
4.1.1　消费者和消费者群组　　48
4.1.2　消费者群组和分区再均衡　　51
4.2　创建Kafka 消费者　　52
4.3　订阅主题　　53
4.4　轮询　　53
4.5　消费者的配置　　55
4.6　提交和偏移量　　57
4.6.1　自动提交　　58
4.6.2　提交当前偏移量　　59
4.6.3　异步提交　　59
4.6.4　同步和异步组合提交　　61
4.6.5　提交特定的偏移量　　61
4.7　再均衡监听器　　62
4.8　从特定偏移量处开始处理记录　　64
4.9　如何退出　　66
4.10　反序列化器　　67
4.11　独立消费者——为什么以及怎样使用没有群组的消费者　　71
4.12　旧版的消费者API　　71
4.13　总结　　72
第5章　深入Kafka　　73
5.1　集群成员关系　　73
5.2　控制器　　74
5.3　复制　　74
5.4　处理请求　　76
5.4.1　生产请求　　78
5.4.2　获取请求　　78
5.4.3　其他请求　　80
5.5　物理存储　　81
5.5.1　分区分配　　81
5.5.2　文件管理　　82
5.5.3　文件格式　　83
5.5.4　索引　　84
5.5.5　清理　　84
5.5.6　清理的工作原理　　84
5.5.7　被删除的事件　　86
5.5.8　何时会清理主题　　86
5.6　总结　　86
第6章　可靠的数据传递　　87
6.1　可靠性保证　　87
6.2　复制　　88
6.3　broker配置　　89
6.3.1　复制系数　　89
6.3.2　不完全的首领选举　　90
6.3.3　最少同步副本　　91
6.4　在可靠的系统里使用生产者　　92
6.4.1　发送确认　　92
6.4.2　配置生产者的重试参数　　93
6.4.3　额外的错误处理　　94
6.5　在可靠的系统里使用消费者　　94
6.5.1　消费者的可靠性配置　　95
6.5.2　显式提交偏移量　　95
6.6　验证系统可靠性　　97
6.6.1　配置验证　　98
6.6.2　应用程序验证　　98
6.6.3　在生产环境监控可靠性　　99
6.7　总结　　100
第7章　构建数据管道　　101
7.1　构建数据管道时需要考虑的问题　　102
7.1.1　及时性　　102
7.1.2　可靠性　　102
7.1.3　高吞吐量和动态吞吐量　　103
7.1.4　数据格式　　103
7.1.5　转换　　104
7.1.6　安全性　　104
7.1.7　故障处理能力　　104
7.1.8　耦合性和灵活性　　105
7.2　如何在Connect API和客户端API之间作出选择　　105
7.3　Kafka Connect　　106
7.3.1　运行Connect　　106
7.3.2　连接器示例——文件数据源和文件数据池　　107
7.3.3　连接器示例——从MySQL到ElasticSearch　　109
7.3.4　深入理解Connect　　114
7.4　Connect之外的选择　　116
7.4.1　用于其他数据存储的摄入框架　　116
7.4.2　基于图形界面的ETL 工具　　117
7.4.3　流式处理框架　　117
7.5　总结　　117
第8章　跨集群数据镜像　　118
8.1　跨集群镜像的使用场景　　118
8.2　多集群架构　　119
8.2.1　跨数据中心通信的一些现实情况　　119
8.2.2　Hub和Spoke架构　　120
8.2.3　双活架构　　121
8.2.4　主备架构　　123
8.2.5　延展集群　　127
8.3　Kafka的MirrorMaker　　128
8.3.1　如何配置　　129
8.3.2　在生产环境部署MirrorMaker　　130
8.3.3　MirrorMaker调优　　132
8.4　其他跨集群镜像方案　　134
8.4.1　优步的uReplicator　　134
8.4.2　Confluent的Replicator　　135
第9章　管理Kafka　　136
9.1　主题操作　　136
9.1.1　创建主题　　137
9.1.2　增加分区　　138
9.1.3　删除主题　　138
9.1.4　列出集群里的所有主题　　139
9.1.5　列出主题详细信息　　139
9.2　消费者群组　　140
9.2.1　列出并描述群组　　140
9.2.2　删除群组　　142
9.2.3　偏移量管理　　142
9.3　动态配置变更　　143
9.3.1　覆盖主题的默认配置　　143
9.3.2　覆盖客户端的默认配置　　145
9.3.3　列出被覆盖的配置　　145
9.3.4　移除被覆盖的配置　　146
9.4　分区管理　　146
9.4.1　首选的首领选举　　146
9.4.2　修改分区副本　　147
9.4.3　修改复制系数　　150
9.4.4　转储日志片段　　151
9.4.5　副本验证　　152
9.5　消费和生产　　153
9.5.1　控制台消费者　　153
9.5.2　控制台生产者　　155
9.6　客户端ACL　　157
9.7　不安全的操作　　157
9.7.1　移动集群控制器　　157
9.7.2　取消分区重分配　　157
9.7.3　移除待删除的主题　　158
9.7.4　手动删除主题　　158
第10章　监控Kafka　　160
10.1　度量指标基础　　160
10.1.1　度量指标在哪里　　160
10.1.2　内部或外部度量　　161
10.1.3　应用程序健康检测　　161
10.1.4　度量指标的覆盖面　　161
10.2　broker的度量指标　　162
10.2.1　非同步分区　　162
10.2.2　broker度量指标　　166
10.2.3　主题和分区的度量指标　　173
10.2.4　Java虚拟机监控　　174
10.2.5　操作系统监控　　175
10.2.6　日志　　176
10.3　客户端监控　　177
10.3.1　生产者度量指标　　177
10.3.2　消费者度量指标　　179
10.3.3　配额　　181
10.4　延时监控　　182
10.5　端到端监控　　183
第11章　流式处理　　184
11.1　什么是流式处理　　185
11.2　流式处理的一些概念　　186
11.2.1　时间　　187
11.2.2　状态　　188
11.2.3　流和表的二元性　　188
11.2.4　时间窗口　　189
11.3　流式处理的设计模式　　190
11.3.1　单个事件处理　　191
11.3.2　使用本地状态　　191
11.3.3　多阶段处理和重分区　　193
11.3.4　使用外部查找——流和表的连接　　193
11.3.5　流与流的连接　　195
11.3.6　乱序的事件　　195
11.3.7　重新处理　　196
11.4　Streams示例　　197
11.4.1　字数统计　　197
11.4.2　股票市场统计　　199
11.4.3　填充点击事件流　　201
11.5　Kafka Streams的架构概览　　202
11.5.1　构建拓扑　　202
11.5.2　对拓扑进行伸缩　　203
11.5.3　从故障中存活下来　　205
11.6　流式处理使用场景　　205
11.7　如何选择流式处理框架　　206
附录A　在其他操作系统上安装Kafka　　209

1．1　Kafka流式数据平台 1
1．2　Kafka的基本概念 3
1．2．1　分区模型 3
1．2．2　消费模型 4
1．2．3　分布式模型 5
1．3　Kafka的设计与实现 6
1．3．1　文件系统的持久化与数据传输效率 6
1．3．2　生产者与消费者 8
1．3．3　副本机制和容错处理 10
1．4　快速开始 11
1．4．1　单机模式 12
1．4．2　分布式模式 14
1．4．3　消费组示例 16
1．5　环境准备 18
第2章　生产者 22
2．1　新生产者客户端 22
2．1．1　同步和异步发送消息 23
2．1．2　客户端消息发送线程 29
2．1．3　客户端网络连接对象 31
2．1．4　选择器处理网络请求 35
2．2　旧生产者客户端 43
2．2．1　事件处理器处理客户端发送的消息 44
2．2．2　对消息集按照节点和分区进行整理 46
2．2．3　生产者使用阻塞通道发送请求 48
2．3　服务端网络连接 49
2．3．1　服务端使用接收器接受客户端的连接 50
2．3．2　处理器使用选择器的轮询处理网络请求 53
2．3．3　请求通道的请求队列和响应队列 56
2．3．4　Kafka请求处理线程 58
2．3．5　服务端的请求处理入口 58

第3章　消费者：高级API和低级API 61
3．1　消费者启动和初始化 67
3．1．1　创建并初始化消费者连接器 69
3．1．2　消费者客户端的线程模型 70
3．1．3　重新初始化消费者 72
3．2　消费者再平衡操作 73
3．2．1　分区的所有权 74
3．2．2　为消费者分配分区 75
3．2．3　创建分区信息对象 78
3．2．4　关闭和更新拉取线程管理器 80
3．2．5　分区信息对象的偏移量 80
3．3　消费者拉取数据 82
3．3．1　拉取线程管理器 82
3．3．2　抽象拉取线程 87
3．3．3　消费者拉取线程 90
3．4　消费者消费消息 94
3．4．1　Kafka消息流 94
3．4．2　消费者迭代消费消息 95
3．5　消费者提交分区偏移量 97
3．5．1　提交偏移量到ZK 98
3．5．2　提交偏移量到内部主题 99
3．5．3　连接偏移量管理器 101
3．5．4　服务端处理提交偏移量的请求 103
3．5．5　缓存分区的偏移量 106
3．6　消费者低级API示例 108
3．6．1　消息消费主流程 109
3．6．2　找出分区的主副本 112
3．6．3　获取分区的读取偏移量 113
3．6．4　发送拉取请求并消费消息 116
3．7．1　消费者线程模型 117
3．7．2　再平衡和分区分配 119

第4章　新消费者 121
4．1　新消费者客户端 125
4．1．1　消费者的订阅状态 125
4．1．2　消费者轮询的准备工作 134
4．1．3　消费者轮询的流程 138
4．1．4　消费者拉取消息 146
4．1．5　消费者获取记录 149
4．1．6　消费消息 160
4．2　消费者的网络客户端轮询 161
4．2．1　异步请求 162
4．2．2　异步请求高级模式 169
4．2．3　网络客户端轮询 184
4．3　心跳任务 188
4．3．1　发送心跳请求 188
4．3．2　心跳状态 189
4．3．3　运行心跳任务 191
4．3．4　处理心跳结果的示例 192
4．3．5　心跳和协调者的关系 193
4．4　消费者提交偏移量 195
4．4．1　自动提交任务 195
4．4．2　将拉取偏移量作为提交偏移量 197
4．4．3　同步提交偏移量 201
4．4．4　消费者的消息处理语义 202
4．5　小结 206
第5章　协调者 210
5．1　消费者加入消费组 211
5．1．1　元数据与分区分配器 212
5．1．2　消费者的加入组和同步组 213
5．1．3　主消费者执行分配任务 220
5．1．4　加入组的准备、完成和监听器 224
5．2　协调者处理请求 229
5．2．1　服务端定义发送响应结果的回调方法 229
5．2．2　消费者和消费组元数据 232
5．2．3　协调者处理请求前的条件检查 236
5．2．4　协调者调用回调方法发送响应给客户端 237
5．3　延迟的加入组操作 242
5．3．1 “准备再平衡” 242
5．3．2　延迟操作和延迟缓存 244
5．3．3　尝试完成延迟的加入操作 246
5．3．4　消费组稳定后，原有消费者重新加入消费组 250
5．3．5　消费组未稳定，原有消费者重新加入消费组 251
5．4　消费组状态机 254
5．4．1　再平衡操作与监听器 254
5．4．2　消费组的状态转换 262
5．4．3　协调者处理“加入组请求” 264
5．4．4　协调者处理“同步组请求” 274
5．4．5　协调者处理“离开组请求” 276
5．4．6　再平衡超时与会话超时 278
5．4．7　延迟的心跳 282
5．5　小结 290
第6章　存储层 293
6．1　日志的读写 293
6．1．1　分区、副本、日志、日志
分段 294
6．1．2　写入日志 297
6．1．3　日志分段 305
6．1．4　读取日志 315
6．1．5　日志管理 329
6．1．6　日志压缩 336
6．2　服务端处理读写请求 348
6．2．1　副本管理器 351
6．2．2　分区与副本 362
6．3　延迟操作 373
6．3．1　延迟操作接口 374
6．3．2　延迟操作与延迟缓存 383
6．3．3　延迟缓存 391
6．4　小结 400
第7章　控制器 402
7．1　Kafka控制器 402
7．1．1　控制器选举 403
7．1．2　控制器上下文 406
7．1．3　ZK监听器 408
7．1．4　分区状态机和副本状态机 410
7．1．5　删除主题 430
7．1．6　重新分配分区 436
7．1．7　控制器的网络通道管理器 445
7．2　服务端处理LeaderAndIsr请求 448
7．2．1　创建分区 449
7．2．2　创建主副本、备份副本 451
7．2．3　消费组元数据迁移 463
7．3　元数据缓存 468
7．3．1　服务端的元数据缓存 472
7．3．2　客户端更新元数据 473
7．4　Kafka服务关闭 483
7．5　小结 487
第8章　基于Kafka构建数据流管道 490
8．1　Kafka集群同步工具：MirrorMaker 490
8．1．1　单机模拟数据同步 491
8．1．2　数据同步的流程 493
8．2　Uber集群同步工具：uReplicator 498
8．2．1　Apache Helix介绍 498
8．2．2　Helix控制器 501
8．2．3　Helix工作节点 504
8．3　Kafka连接器 505
8．3．1　连接器的使用示例 507
8．3．2　开发一个简单的连接器 510
8．3．3　连接器的架构模型 515
8．3．4　Herder的实现 520
8．3．5　Worker的实现 524
8．3．6　配置存储与状态存储 530
8．3．7　连接器与任务的实现 550
8．4　小结 565
第9章　Kafka流处理 569
9．1　低级Processor API 569
9．1．1　流处理应用程序示例 569
9．1．2　流处理的拓扑 575
9．1．3　流处理的线程模型 580
9．1．4　状态存储 613
9．2　高级流式DSL 636
9．2．1　DSL应用程序示例 636
9．2．2　KStream和KTable 638
9．2．3　连接操作 665
9．2．4　窗口操作 672
9．3　小结 684
第10章　高级特性介绍 686
10．1　客户端配额 686
10．2　消息与时间戳 692
10．3　事务处理 699
10．4　小结 703

1.1　Kafka快速入门 1
1.1.1　下载并解压缩Kafka二进制代码压缩包文件 2
1.1.2　启动服务器 3
1.1.3　创建topic 3
1.1.4　发送消息 4
1.1.5　消费消息 4
1.2　消息引擎系统 5
1.2.1　消息设计 6
1.2.2　传输协议设计 6
1.2.3　消息引擎范型 6
1.2.4　Java消息服务 8

1.3　Kafka概要设计 8
1.3.1　吞吐量/延时 8
1.3.2　消息持久化 11
1.3.3　负载均衡和故障转移 12
1.3.4　伸缩性 13

1.4　Kafka基本概念与术语 13
1.4.1　消息 14
1.4.2　topic和partition 16
1.4.3　offset 17
1.4.4　replica 18
1.4.5　leader和follower 18
1.4.6　ISR 19

1.5　Kafka使用场景 20

1.5.1　消息传输 20

1.5.2　网站行为日志追踪 20

1.5.3　审计数据收集 20

1.5.4　日志收集 20

1.5.5　Event Sourcing 21

1.5.6　流式处理 21

2.1　Kafka的历史 22

2.1.1　背景 22

2.1.2　Kafka横空出世 23

2.1.3　Kafka开源 24

2.2　Kafka版本变迁 25

2.2.1　Kafka的版本演进 25

2.2.2　Kafka的版本格式 26

2.2.3　新版本功能简介 26

2.2.4　旧版本功能简介 31

2.3　如何选择Kafka版本 35

2.3.1　根据功能场景 35

2.3.2　根据客户端使用场景 35

2.4　Kafka与Confluent 36

2.5　本章小结 37

第3章　Kafka线上环境部署 38

3.1　集群环境规划 38

3.1.1　操作系统的选型 38

3.1.2　磁盘规划 40

3.1.3　磁盘容量规划 42

3.1.4　内存规划 43

3.1.5　CPU规划 43

3.1.6　带宽规划 44

3.1.7　典型线上环境配置 45

3.2　伪分布式环境安装 45

3.2.1　安装Java 46

3.2.2　安装ZooKeeper 47

3.2.3　安装单节点Kafka集群 48

3.3　多节点环境安装 49

3.3.1　安装多节点ZooKeeper集群 50

3.3.2　安装多节点Kafka 54

3.4　验证部署 55

3.4.1　测试topic创建与删除 55

3.4.2　测试消息发送与消费 57

3.4.3　生产者吞吐量测试 58

3.4.4　消费者吞吐量测试 58

3.5　参数设置 59

3.5.1　broker端参数 59

3.5.2　topic级别参数 62

3.5.3　GC参数 63

3.5.4　JVM参数 64

3.5.5　OS参数 64

3.6　本章小结 65

第4章　producer开发 66

4.1　producer概览 66

4.2　构造producer 69

4.2.1　producer程序实例 69

4.2.2　producer主要参数 75

4.3　消息分区机制 80

4.3.1　分区策略 80

4.3.2　自定义分区机制 80

4.4　消息序列化 83

4.4.1　默认序列化 83

4.4.2　自定义序列化 84

4.5　producer拦截器 87

4.6　无消息丢失配置 90

4.6.1　producer端配置 91

4.6.2　broker端配置 92

4.7　消息压缩 92

4.7.1　Kafka支持的压缩算法 93

4.7.2　算法性能比较与调优 93

4.8　多线程处理 95

4.9　旧版本producer 96

4.10　本章小结 98

第5章　consumer开发 99

5.1　consumer概览 99

5.1.1　消费者（consumer） 99

5.1.2　消费者组（consumer group） 101

5.1.3　位移（offset） 102

5.1.4　位移提交 103

5.1.5　__consumer_offsets 104

5.1.6　消费者组重平衡（consumer group rebalance） 106

5.2　构建consumer 106

5.2.1　consumer程序实例 106

5.2.2　consumer脚本命令 111

5.2.3　consumer主要参数 112

5.3　订阅topic 115

5.3.1　订阅topic列表 115

5.3.2　基于正则表达式订阅topic 115

5.4　消息轮询 115

5.4.1　poll内部原理 115

5.4.2　poll使用方法 116

5.5　位移管理 118

5.5.1　consumer位移 119

5.5.2　新版本consumer位移管理 120

5.5.3　自动提交与手动提交 121

5.5.4　旧版本consumer位移管理 123

5.6　重平衡（rebalance） 123

5.6.1　rebalance概览 123

5.6.2　rebalance触发条件 124

5.6.3　rebalance分区分配 124

5.6.4　rebalance generation 126

5.6.5　rebalance协议 126

5.6.6　rebalance流程 127

5.6.7　rebalance监听器 128

5.7　解序列化 130

5.7.1　默认解序列化器 130

5.7.2　自定义解序列化器 131

5.8　多线程消费实例 132

5.8.1　每个线程维护一个KafkaConsumer 133

5.8.2　单KafkaConsumer实例+多worker线程 135

5.8.3　两种方法对比 140

5.9　独立consumer 141

5.10　旧版本consumer 142

5.10.1　概览 142

5.10.2　high-level consumer 143

5.10.3　low-level consumer 147

5.11　本章小结 153

第6章　Kafka设计原理 154

6.1　broker端设计架构 154

6.1.1　消息设计 155

6.1.2　集群管理 166

6.1.3　副本与ISR设计 169

6.1.4　水印（watermark）和leader epoch 174

6.1.5　日志存储设计 185

6.1.6　通信协议（wire protocol） 194

6.1.7　controller设计 205

6.1.8　broker请求处理 216

6.2　producer端设计 219

6.2.1　producer端基本数据结构 219

6.2.2　工作流程 220

6.3　consumer端设计 223

6.3.1　consumer group状态机 223

6.3.2　group管理协议 226

6.3.3　rebalance场景剖析 227

6.4　实现精确一次处理语义 230

6.4.1　消息交付语义 230

6.4.2　幂等性producer（idempotent producer） 231

6.4.3　事务（transaction） 232

6.5　本章小结 234

第7章　管理Kafka集群 235

7.1　集群管理 235

7.1.1　启动broker 235

7.1.2　关闭broker 236

7.1.3　设置JMX端口 237

7.1.4　增加broker 238

7.1.5　升级broker版本 238

7.2　topic管理 241

7.2.1　创建topic 241

7.2.2　删除topic 243

7.2.3　查询topic列表 244

7.2.4　查询topic详情 244

7.2.5　修改topic 245

7.3　topic动态配置管理 246

7.3.1　增加topic配置 246

7.3.2　查看topic配置 247

7.3.3　删除topic配置 248

7.4　consumer相关管理 248

7.4.1　查询消费者组 248

7.4.2　重设消费者组位移 251

7.4.3　删除消费者组 256

7.4.4　kafka-consumer-offset-checker 257

7.5　topic分区管理 258

7.5.1　preferred leader选举 258

7.5.2　分区重分配 260

7.5.3　增加副本因子 263

7.6　Kafka常见脚本工具 264

7.6.1　kafka-console-producer脚本 264

7.6.2　kafka-console-consumer脚本 265

7.6.3　kafka-run-class脚本 267

7.6.4　查看消息元数据 268

7.6.5　获取topic当前消息数 270

7.6.6　查询__consumer_offsets 271

7.7　API方式管理集群 273

7.7.1　服务器端API管理topic 273

7.7.2　服务器端API管理位移 275

7.7.3　客户端API管理topic 276

7.7.4　客户端API查看位移 280

7.7.5　0.11.0.0版本客户端API 281

7.8　MirrorMaker 285

7.8.1　概要介绍 285

7.8.2　主要参数 286

7.8.3　使用实例 287

7.9　Kafka安全 288

7.9.1　SASL+ACL 289

7.9.2　SSL加密 297

7.10　常见问题 301

7.11　本章小结 304

第8章　监控Kafka集群 305

8.1　集群健康度检查 305

8.2　MBean监控 306

8.2.1　监控指标 306

8.2.2　指标分类 308

8.2.3　定义和查询JMX端口 309

8.3　broker端JMX监控 310

8.3.1　消息入站/出站速率 310

8.3.2　controller存活JMX指标 311

8.3.3　备份不足的分区数 312

8.3.4　leader分区数 312

8.3.5　ISR变化速率 313

8.3.6　broker I/O工作处理线程空闲率 313

8.3.7　broker网络处理线程空闲率 314

8.3.8　单个topic总字节数 314

8.4　clients端JMX监控 314

8.4.1　producer端JMX监控 314

8.4.2　consumer端JMX监控 316

8.5　JVM监控 317

8.5.1　进程状态 318

8.5.2　GC性能 318

8.6　OS监控 318

8.7　主流监控框架 319

8.7.1　JmxTool 320

8.7.2　kafka-manager 320

8.7.3　Kafka Monitor 325

8.7.4　Kafka Offset Monitor 327

8.7.5　CruiseControl 329

8.8　本章小结 330

第9章　调优Kafka集群 331

9.1　引言 331

9.2　确定调优目标 333

9.3　集群基础调优 334

9.3.1　禁止atime更新 335

9.3.2　文件系统选择 335

9.3.3　设置swapiness 336

9.3.4　JVM设置 337

9.3.5　其他调优 337

9.4　调优吞吐量 338

9.5　调优延时 342

9.6　调优持久性 343

9.7　调优可用性 347

9.8　本章小结 349

第10章　Kafka Connect与Kafka Streams 350

10.2　Kafka Connect 351
10.2.1　概要介绍 351
10.2.2　standalone Connect 353
10.2.3　distributed Connect 356
10.2.4　开发connector 359
10.3　Kafka Streams 362
10.3.1　流处理 362

10.3.2　Kafka Streams核心概念 364
10.3.3　Kafka Streams与其他框架的异同 368
10.3.4　Word Count实例 369
10.3.5　Kafka Streams应用开发 372
10.3.6　Kafka Streams状态查询 382






152. kafka 可以脱离 zookeeper 单独使用吗？为什么？

kafka 不能脱离 zookeeper 单独使用，因为 kafka 使用 zookeeper 管理和协调 kafka 的节点服务器。

153. kafka 有几种数据保留的策略？

kafka 有两种数据保存策略：按照过期时间保留和按照存储的消息大小保留。

154. kafka 同时设置了 7 天和 10G 清除数据，到第五天的时候消息达到了 10G，这个时候 kafka 将如何处理？

这个时候 kafka 会执行数据清除工作，时间和大小不论那个满足条件，都会清空数据。

155. 什么情况会导致 kafka 运行变慢？

cpu 性能瓶颈

磁盘读写瓶颈

网络瓶颈


156. 使用 kafka 集群需要注意什么？

集群的数量不是越多越好，最好不要超过 7 个，因为节点越多，消息复制需要的时间就越长，整个群组的吞吐量就越低。

集群数量最好是单数，因为超过一半故障集群就不能用了，设置为单数容错率更高。

https://help.aliyun.com/document_detail/68165.html?spm=a2c4g.11174283.6.592.2f2e1eefpIsinD

发布者最佳实践
更新时间：2019-04-17 17:32:10


本页目录
Key 和 Value
失败重试
异步发送
线程安全
Acks
Batch
OOM
分区顺序
技术交流
本文主要介绍消息队列 Kafka 发布者的最佳实践，从而帮助您更好的使用该产品。

注意：以下最佳实践基于消息队列 Kafka 的 Java 客户端；对于其它语言的客户端，其基本概念与思想是通用的，但实现细节可能有差异，仅供参考。

Kafka 的发送非常简单，示例代码片段如下：

 Future<RecordMetadata> metadataFuture = producer.send(new ProducerRecord<String, String>(
            topic,   \\ topic
            null,    \\ 分区编号，这里最好为 null，交给 producer 去分配
            System.currentTimeMillis(), \\时间戳
            String.valueOf(message.hashCode()), \\ key，可以在控制台通过这个 Key 查找消息，这个 key 最好唯一；
            message)); \\ value，消息内容
详细 Demo 可参见 Demo 示例。

Key 和 Value
Kafka 0.10.0.0 的消息字段只有两个：Key 和 Value。Key 是消息的标识，Value 即消息内容。为了便于追踪，重要消息最好都设置一个唯一的 Key。通过 Key 追踪某消息，打印发送日志和消费日志，了解该消息的发送和消费情况；更重要的是，您可以在控制台可以根据 Key 查询消息的内容。

失败重试
在分布式环境下，由于网络等原因，偶尔的发送失败是常见的。导致这种失败的原因有可能是消息已经发送成功，但是 Ack 失败，也有可能是确实没发送成功。

消息队列 Kafka 是 VIP 网络架构，会主动掐掉空闲连接（30 秒没活动），也就是说，不是一直活跃的客户端会经常收到”connection rest by peer”这样的错误，因此建议都考虑重试消息发送。

异步发送
发送接口是异步的；如果你想得到发送的结果，可以调用metadataFuture.get(timeout, TimeUnit.MILLISECONDS)。

线程安全
Producer 是线程安全的，且可以往任何 Topic 发送消息。通常情况下，一个应用对应一个 Producer 就足够了。

Acks
acks=0，表示无需服务端的 Response，性能较高，丢数据风险较大；

acks=1，服务端主节点写成功即返回Response，性能中等，丢数据风险中等，主节点宕机可能导致数据丢失；

acks=all，服务端主节点写成功，且备节点同步成功，才返回Response，性能较差，数据较为安全，主节点和备节点都宕机才会导致数据丢失。

一般建议选择acks=1，重要的服务可以设置acks=all。

Batch
Batch 的基本思路是：把消息缓存在内存中，并进行打包发送。Kafka 通过 Batch 来提高吞吐，但同时也会增加延迟，生产时应该对两者予以权衡。
在构建 Producer 时，需要考虑以下两个参数：

batch.size : 发往每个分区（Partition）的消息缓存量（消息内容的字节数之和，不是条数）达到这个数值时，就会触发一次网络请求，然后客户端把消息真正发往服务器；
linger.ms : 每条消息待在缓存中的最长时间。若超过这个时间，就会忽略 batch.size 的限制，然后客户端立即把消息发往服务器。
由此可见，Kafka 客户端什么时候把消息真正发往服务器，是通过上面两个参数共同决定的：
batch.size 有助于提高吞吐，linger.ms有助于控制延迟。您可以根据具体业务需求进行调整。

OOM
结合 Kafka 的 Batch 设计思路，Kafka 会缓存消息并打包发送，如果缓存太多，则有可能造成 OOM（Out of Memory）。

buffer.memory : 所有缓存消息的总体大小超过这个数值后，就会触发把消息发往服务器。此时会忽略 batch.size 和 linger.ms 的限制。
buffer.memory 的默认数值是 32MB，对于单个 Producer 来说，可以保证足够的性能。需要注意的是，如果你在同一个 JVM 中启动多个 Producer，那么每个 Producer 都有可能占用 32MB 缓存空间，此时便有可能触发 OOM。
在生产时，一般没有必要启动多个 Producer；如果特殊情况需要，则需要考虑buffer.memory的大小，避免触发 OOM。
分区顺序
单个分区（Partition）内，消息是按照发送顺序储存的，是基本有序的。

默认情况下，消息队列 Kafka 为了提升可用性，并不保证单个分区内绝对有序，在升级或者宕机时，会发生少量消息乱序（某个分区挂掉后把消息 Failover 到其它分区）。

如果业务要求分区保证严格有序，请在创建Topic时指定保序。

技术交流
如果你有其它使用方面的困惑，可通过在github demo地址里提交 Issue 进行反馈。






订阅者最佳实践
更新时间：2019-04-28 12:01:16


本页目录
消费消息基本流程
负载均衡
多个订阅
消费位点
消费位点提交
消费位点重置
消息重复和消费幂等
消费失败
消费阻塞以及堆积
提高消费速度
消息过滤
消息广播
订阅关系
本文主要介绍消息队列 Kafka 订阅者的最佳实践，从而帮助您更好的使用该产品。

消费消息基本流程
Kafka 订阅者在订阅消息时的基本流程是：

Poll 数据
执行消费逻辑
再次 poll 数据
负载均衡
每个 Consumer Group 可以包含多个消费实例，即可以启动多个 Kafka Consumer，并把参数 group.id 设置成相同的值。属于同一个 Consumer Group 的消费实例会负载消费订阅的 Topic。

举例：Consumer Group A 订阅了 Topic A，并开启三个消费实例 C1、C2、C3，则发送到 Topic A 的每条消息最终只会传给 C1、C2、C3 的某一个。Kafka 默认会均匀地把消息传给各个消息实例，以做到消费负载均衡。

Kafka 负载消费的内部原理是，把订阅的 Topic 的分区，平均分配给各个消费实例。因此，消费实例的个数不要大于分区的数量，否则会有实例分配不到任何分区而处于空跑状态。这个负载均衡发生的时间，除了第一次启动上线之外，后续消费实例发生重启、增加、减少等变更时，都会触发一次负载均衡。

消息队列 Kafka 的每个 Topic 的分区数量默认是 16 个，已经足够满足大部分场景的需求，且云上服务会根据容量调整分区数。

多个订阅
一个 Consumer Group 可以订阅多个 Topic。一个 Topic 也可以被多个 Consumer Group 订阅，且各个 Consumer Group 独立消费 Topic 下的所有消息。

举例：Consumer Group A 订阅了 Topic A，Consumer Group B 也订阅了 Topic A，则发送到 Topic A 的每条消息，不仅会传一份给 Consumer Group A 的消费实例，也会传一份给 Consumer Group B 的消费实例，且这两个过程相互独立，相互没有任何影响。

消费位点
每个 Topic 会有多个分区，每个分区会统计当前消息的总条数，这个称为最大位点 MaxOffset。Kafka Consumer 会按顺序依次消费分区内的每条消息，记录已经消费了的消息条数，称为ConsumerOffset。

剩余的未消费的条数（也称为消息堆积量） = MaxOffset - ConsumerOffset

消费位点提交
Kafka 消费者有两个相关参数：

enable.auto.commit：默认值为 true。
auto.commit.interval.ms： 默认值为 1000，也即 1s。
这两个参数组合的结果就是，每次 poll 数据前会先检查上次提交位点的时间，如果距离当前时间已经超过参数auto.commit.interval.ms规定的时长，则客户端会启动位点提交动作。

因此，如果将enable.auto.commit设置为 true，则需要在每次 poll 数据时，确保前一次 poll 出来的数据已经消费完毕，否则可能导致位点跳跃。

如果想自己控制位点提交，请把 enable.auto.commit 设为 false，并调用 commit(offsets)函数自行控制位点提交。

消费位点重置
以下两种情况，会发生消费位点重置：

当服务端不存在曾经提交过的位点时（比如客户端第一次上线）
当从非法位点拉取消息时（比如某个分区最大位点是10，但客户端却从11开始拉取消息）
Java 客户端可以通过auto.offset.reset来配置重置策略，主要策略有：

“latest”，从最大位点开始消费
“earliest”，从最小位点开始消费
‘none’, 不做任何操作，也即不重置
建议：

强烈建议设置成“latest”，而不要设置成“earliest”，避免因位点非法时从头开始消费，从而造成大量重复
如果是客户自己管理位点，可以设置成”none”
消息重复和消费幂等
Kafka 消费的语义是 “at least once”， 也就是至少投递一次，保证消息不丢，但是不会保证消息不重复。在出现网络问题、客户端重启时均有可能出现少量重复消息，此时应用消费端如果对消息重复比较敏感（比如说订单交易类），则应该做到消息幂等。

以数据库类应用为例，常用做法是：

发送消息时，传入 key 作为唯一流水号ID；
消费消息时，判断 key 是否已经消费过，如果已经消费过了，则忽略，如果没消费过，则消费一次；
当然，如果应用本身对少量消息重复不敏感，则不需要做此类幂等检查。

消费失败
Kafka 是按分区一条一条消息顺序向前推进消费的，如果消费端拿到某条消息后执行消费逻辑失败，比如应用服务器出现了脏数据，导致某条消息处理失败，等待人工干预，那么有以下两种处理方式：

失败后一直尝试再次执行消费逻辑。这种方式有可能造成消费线程阻塞在当前消息，无法向前推进，造成消息堆积；
由于 Kafka 自身没有处理失败消息的设计，实践中通常会打印失败的消息、或者存储到某个服务（比如创建一个 Topic 专门用来放失败的消息），然后定时 check 失败消息的情况，分析失败原因，根据情况处理。
消费阻塞以及堆积
消费端最常见的问题就是消费堆积，最常造成堆积的原因是：

消费速度跟不上生产速度，此时应该提高消费速度，详见下一节《提高消费速度》；
消费端产生了阻塞。
消费端拿到消息后，执行消费逻辑，通常会执行一些远程调用，如果这个时候同步等待结果，则有可能造成一直等待，消费进程无法向前推进。

消费端应该竭力避免堵塞消费线程，如果存在等待调用结果的情况，建议设置等待的超时时间，超时后作消费失败处理。

提高消费速度
提高消费速度有以下两个办法：

增加 Consumer 实例个数
增加消费线程
增加 Consumer 实例
可以在进程内直接增加（需要保证每个实例对应一个线程，否则没有太大意义），也可以部署多个消费实例进程；需要注意的是，实例个数超过分区数量后就不再能提高速度，将会有消费实例不工作。

增加消费线程
增加 Consumer 实例本质上也是增加线程的方式来提升速度，因此更加重要的性能提升方式是增加消费线程，最基本的步骤如下：

定义一个线程池；
Poll 数据；
把数据提交到线程池进行并发处理；
等并发结果返回成功后，再次 poll 数据执行。
消息过滤
Kafka 自身没有消息过滤的语义。实践中可以采取以下两个办法：

如果过滤的种类不多，可以采取多个 Topic 的方式达到过滤的目的；
如果过滤的种类多，则最好在客户端业务层面自行过滤。
实践中请根据业务具体情况进行选择，也可以综合运用上面两种办法。

消息广播
Kafka 自身没有消息广播的语义，可以通过创建不同的 Consumer Group 来模拟实现。

订阅关系
同一个 Consumer Group 内，各个消费实例订阅的 Topic 最好保持一致，避免给排查问题带来干扰。



======================================================

Apache Kafka是一款流行的分布式数据流平台，它已经广泛地被诸如New Relic(数据智能平台)、Uber、Square(移动支付公司)等大型公司用来构建可扩展的、高吞吐量的、且高可靠的实时数据流系统。例如，在New Relic的生产环境中，Kafka群集每秒能够处理超过1500万条消息，而且其数据聚合率接近1 Tbps。

可见，Kafka大幅简化了对于数据流的处理，因此它也获得了众多应用开发人员和数据管理专家的青睐。然而，在大型系统中Kafka的应用会比较复杂。如果您的consumers无法跟上数据流的话，各种消息往往在未被查看之前就已经消失掉了。同时，它在自动化数据保留方面的限制，高流量的发布+订阅(publish-subscribe，pub/sub)模式等，可能都会影响到您系统的性能。可以毫不夸张地说，如果那些存放着数据流的系统无法按需扩容、或稳定性不可靠的话，估计您经常会寝食难安了。

针对Partitions的最佳实践
• 了解分区的数据速率，以确保提供合适的数据保存空间。此处所谓“分区的数据速率”是指数据的生成速率。换言之，它是由“平均消息大小”乘以“每秒消息数”得出的。数据速率决定了在给定时间内，所能保证的数据保存空间的大小(以字节为单位)。如果您不知道数据速率的话，则无法正确地计算出满足基于给定时间跨度的数据，所需要保存的空间大小。同时，数据速率也能够标识出单个consumer在不产生延时的情况下，所需要支持的最低性能值。

• 除非您有其他架构上的需要，否则在写topic时请使用随机分区。在您进行大型操作时，各个分区在数据速率上的参差不齐是非常难以管理的。其原因来自于如下三个方面：

首先，“热”(有较高吞吐量)分区上的consumer势必会比同组中的其他consumer处理更多的消息，因此很可能会导致出现在处理上和网络上的瓶颈。

其次，那些为具有最高数据速率的分区，所配置的最大保留空间，会导致topic中其他分区的磁盘使用量也做相应地增长。

第三，根据分区的leader关系所实施的最佳均衡方案，比简单地将leader关系分散到所有broker上，要更为复杂。在同一topic中，“热”分区会“承载”10倍于其他分区的权重。

针对Consumers的最佳实践

如果consumers运行的是比Kafka 0.10还要旧的版本，那么请马上升级。


在0.8.x 版中，consumer使用Apache ZooKeeper来协调consumer group，而许多已知的bug会导致其长期处于再均衡状态，或是直接导致再均衡算法的失败(我们称之为“再均衡风暴”)。因此在再均衡期间，一个或多个分区会被分配给同一组中的每个consumer。而在再均衡风暴中，分区的所有权会持续在各个consumers之间流转，这反而阻碍了任何一个consumer去真正获取分区的所有权。

调优consumer的套接字缓冲区(socket buffers)，以应对数据的高速流入。

在Kafka的0.10.x版本中，参数receive.buffer.bytes的默认值为64 kB。而在Kafka的0.8.x版本中，参数socket.receive.buffer.bytes的默认值为100 kB。这两个默认值对于高吞吐量的环境而言都太小了，特别是如果broker和consumer之间的网络带宽延迟积(bandwidth-delay product)大于局域网(local area network，LAN)时。对于延迟为1毫秒或更多的高带宽的网络(如10 Gbps或更高)，请考虑将套接字缓冲区设置为8或16 MB。

如果您的内存不足，也至少考虑设置为1 MB。当然，您也可以设置为-1，它会让底层操作系统根据网络的实际情况，去调整缓冲区的大小。

但是，对于需要启动“热”分区的consumers来说，自动调整可能不会那么快。


设计具有高吞吐量的consumers，以便按需实施背压(back-pressure)。通常，我们应该保证系统只去处理其能力范围内的数据，而不要超负荷“消费”，进而导致进程中断“挂起”，或出现consume group的溢出。如果是在Java虚拟机(JVM)中运行，consumers应当使用固定大小的缓冲区(请参见Disruptor模式：http://lmax-exchange.github.io/disruptor/files/Disruptor-1.0.pdf)，而且最好是使用堆外内存(off-heap)。固定大小的缓冲区能够阻止consumer将过多的数据拉到堆栈上，以至于JVM花费掉其所有的时间去执行垃圾回收，进而无法履行其处理消息的本质工作。

在JVM上运行各种consumers时，请警惕垃圾回收对它们可能产生的影响。例如，长时间垃圾回收的停滞，可能导致ZooKeeper的会话被丢弃、或consumer group处于再均衡状态。对于broker来说也如此，如果垃圾回收停滞的时间太长，则会产生集群掉线的风险。

针对Producers的最佳实践
• 配置producer，以等待各种确认。籍此producer能够获知消息是否真正被发送到了broker的分区上。在Kafka的0.10.x版本上，其设置是acks;而在0.8.x版本上，则为request.required.acks。Kafka通过复制，来提供容错功能，因此单个节点的故障、或分区leader关系的更改不会影响到系统的可用性。如果您没有用acks来配置producer(或称“fire and forget”)的话，则消息可能会悄然丢失。

• 为各个producer配置retries。其默认值为3，当然是非常低的。不过，正确的设定值取决于您的应用程序，即：就那些对于数据丢失零容忍的应用而言，请考虑设置为Integer.MAX_VALUE(有效且最大)。这样将能够应对broker的leader分区出现无法立刻响应produce请求的情况。

• 为高吞吐量的producer，调优缓冲区的大小，特别是buffer.memory和batch.size(以字节为单位)。由于batch.size是按照分区设定的，而producer的性能和内存的使用量，都可以与topic中的分区数量相关联。因此，此处的设定值将取决于如下几个因素：producer数据速率(消息的大小和数量)、要生成的分区数、以及可用的内存量。请记住，将缓冲区调大并不总是好事，如果producer由于某种原因而失效了(例如，某个leader的响应速度比确认还要慢)，那么在堆内内存(on-heap)中的缓冲的数据量越多，其需要回收的垃圾也就越多。

• 检测应用程序，以跟踪诸如生成的消息数、平均消息大小、以及已使用的消息数等指标。

针对Brokers的最佳实践

• 在各个brokers上，请压缩topics所需的内存和CPU资源。日志压缩需要各个broker上的堆栈(内存)和CPU周期都能成功地配合实现。而如果让那些失败的日志压缩数据持续增长的话，则会给brokers分区带来风险。您可以在broker上调整log.cleaner.dedupe.buffer.size和log.cleaner.threads这两个参数，但是请记住，这两个值都会影响到各个brokers上的堆栈使用。如果某个broker抛出OutOfMemoryError异常，那么它将会被关闭、并可能造成数据的丢失。而缓冲区的大小和线程的计数，则取决于需要被清除的topic partition数量、以及这些分区中消息的数据速率与密钥的大小。对于Kafka的0.10.2.1版本而言，通过ERROR条目来监控日志清理程序的日志文件，是检测其线程可能出现问题的最可靠方法。

• 通过网络吞吐量来监控brokers。请监控发向(transmit，TX)和收向(receive，RX)的流量，以及磁盘的I/O、磁盘的空间、以及CPU的使用率，而且容量规划是维护群集整体性能的关键步骤。

• 在群集的各个brokers之间分配分区的leader关系。Leader通常会需要大量的网络I/O资源。例如，当我们将复制因子(replication factor)配置为3、并运行起来时，leader必须首先获取分区的数据，然后将两套副本发送给另两个followers，进而再传输到多个需要该数据的consumers上。因此在该例子中，单个leader所使用的网络I/O，至少是follower的四倍。而且，leader还可能需要对磁盘进行读操作，而follower只需进行写操作。

• 不要忽略监控brokers的in-sync replica(ISR)shrinks、under-replicated partitions和unpreferred leaders。这些都是集群中潜在问题的迹象。例如，单个分区频繁出现ISR收缩，则暗示着该分区的数据速率超过了leader的能力，已无法为consumer和其他副本线程提供服务了。

• 按需修改Apache Log4j的各种属性。Kafka的broker日志记录会耗费大量的磁盘空间，但是我们却不能完全关闭它。因为有时在发生事故之后，需要重建事件序列，那么broker日志就会是我们最好的、甚至是唯一的方法。

• 禁用topic的自动创建，或针对那些未被使用的topics建立清除策略。例如，在设定的x天内，如果未出现新的消息，您应该考虑该topic是否已经失效，并将其从群集中予以删除。此举可避免您花时间去管理群集中被额外创建的元数据。

• 对于那些具有持续高吞吐量的brokers，请提供足够的内存，以避免它们从磁盘子系统中进行读操作。我们应尽可能地直接从操作系统的缓存中直接获取分区的数据。然而，这就意味着您必须确保自己的consumers能够跟得上“节奏”，而对于那些延迟的consumer就只能强制broker从磁盘中读取了。

• 对于具有高吞吐量服务级别目标(service level objectives，SLOs)的大型群集，请考虑为brokers的子集隔离出不同的topic。至于如何确定需要隔离的topics，则完全取决于您自己的业务需要。例如，您有一些使用相同群集的联机事务处理(multiple online transaction processing，OLTP)系统，那么将每个系统的topics隔离到不同brokers子集中，则能够有助于限制潜在事件的影响半径。

• 在旧的客户端上使用新的topic消息格式。应当代替客户端，在各个brokers上加载额外的格式转换服务。当然，最好还是要尽量避免这种情况的发生。

• 不要错误地认为在本地主机上测试好broker，就能代表生产环境中的真实性能了。要知道，如果使用复制因子为1，并在环回接口上对分区所做的测试，是与大多数生产环境截然不同的。在环回接口上网络延迟几乎可以被忽略的，而在不涉及到复制的情况下，接收leader确认所需的时间则同样会出现巨大的差异。


本文英文原文《20 Best Practices for Working With Apache Kafka at Scale》：https://blog.newrelic.com/engineering/kafka-best-practices/

--------


“ 这篇文章，同样给大家聊一个硬核的技术知识，我们通过Kafka内核源码中的一些设计思想，来看你设计Kafka架构的技术大牛，是怎么优化JVM的GC问题的？



1、Kafka的客户端缓冲机制
首先，先得给大家明确一个事情，那就是在客户端发送消息给kafka服务器的时候，一定是有一个内存缓冲机制的。



也就是说，消息会先写入一个内存缓冲中，然后直到多条消息组成了一个Batch，才会一次网络通信把Batch发送过去。



整个过程如下图所示：







2、内存缓冲造成的频繁GC问题
那么这种内存缓冲机制的本意，其实就是把多条消息组成一个Batch，一次网络请求就是一个Batch或者多个Batch。



这样每次网络请求都可以发送很多数据过去，避免了一条消息一次网络请求。从而提升了吞吐量，即单位时间内发送的数据量。



但是问题来了，大家可以思考一下，一个Batch中的数据，会取出来然后封装在底层的网络包里，通过网络发送出去到达Kafka服务器。



那么然后呢？这个Batch里的数据都发送过去了，现在Batch里的数据应该怎么处理？



你要知道，这些Batch里的数据此时可还在客户端的JVM的内存里啊！那么此时从代码实现层面，一定会尝试避免任何变量去引用这些Batch对应的数据，然后尝试触发JVM自动回收掉这些内存垃圾。



这样不断的让JVM回收垃圾，就可以不断的清理掉已经发送成功的Batch了，然后就可以不断的腾出来新的内存空间让后面新的数据来使用。



这种想法很好，但是实际线上运行的时候一定会有问题，最大的问题，就是JVM GC问题。



大家都知道一点，JVM GC在回收内存垃圾的时候，他会有一个“Stop the World”的过程，也就是垃圾回收线程运行的时候，会导致其他工作线程短暂的停顿，这样可以便于他自己安安静静的回收内存垃圾。



这个也很容易想明白，毕竟你要是在回收内存垃圾的时候，你的工作线程还在不断的往内存里写数据，制造更多的内存垃圾，那你让人家JVM怎么回收垃圾？



这就好比在大马路上，如果地上有很多垃圾，现在要把垃圾都扫干净，最好的办法是什么？大家都让开，把马路空出来，然后清洁工就是把垃圾清理干净。



但是如果清洁工在清扫垃圾的时候，结果一帮人在旁边不停的嗑瓜子扔瓜子壳，吃西瓜扔西瓜皮，不停的制造垃圾，你觉得清洁工内心啥感受？当然是很愤慨了，照这么搞，地上的垃圾永远的都搞不干净了！



通过了上面的语言描述，我们再来一张图，大家看看就更加清楚了







现在JVM GC是越来越先进，从CMS垃圾回收器到G1垃圾回收器，核心的目标之一就是不断的缩减垃圾回收的时候，导致其他工作线程停顿的时间。



所以现在越是新款的垃圾回收器导致工作线程停顿的时间越短，但是再怎么短，他也还是存在啊！



所以说，如何尽可能在自己的设计上避免JVM频繁的GC就是一个非常考验水平的事儿了。

3、Kafka设计者实现的缓冲池机制
在Kafka客户端内部，对这个问题实现了一个非常优秀的机制，就是缓冲池的机制

简单来说，就是每个Batch底层都对应一块内存空间，这个内存空间就是专门用来存放写入进去的消息的。

然后呢，当一个Batch被发送到了kafka服务器，这个Batch的数据不再需要了，就意味着这个Batch的内存空间不再使用了。



此时这个Batch底层的内存空间不要交给JVM去垃圾回收，而是把这块内存空间给放入一个缓冲池里。



这个缓冲池里放了很多块内存空间，下次如果你又有一个新的Batch了，那么不就可以直接从这个缓冲池里获取一块内存空间就ok了？



然后如果一个Batch发送出去了之后，再把内存空间给人家还回来不就好了？以此类推，循环往复。



同样，听完了上面的文字描述，再来一张图，看完这张图相信大伙儿就明白了：





一旦使用了这个缓冲池机制之后，就不涉及到频繁的大量内存的GC问题了。



为什么呢？因为他可以上来就占用固定的内存，比如32MB。然后把32MB划分为N多个内存块，比如说一个内存块是16KB，这样的话这个缓冲池里就会有很多的内存块。



然后你需要创建一个新的Batch，就从缓冲池里取一个16KB的内存块就可以了，然后这个Batch就不断的写入消息，但是最多就是写16KB，因为Batch底层的内存块就16KB。



接着如果Batch被发送到Kafka服务器了，此时Batch底层的内存块就直接还回缓冲池就可以了。



下次别人再要构建一个Batch的时候，再次使用缓冲池里的内存块就好了。这样就可以利用有限的内存，对他不停的反复重复的利用。因为如果你的Batch使用完了以后是把内存块还回到缓冲池中去，那么就不涉及到垃圾回收了。



如果没有频繁的垃圾回收，自然就避免了频繁导致的工作线程的停顿了，JVM GC问题是不是就得到了大幅度的优化？



没错，正是这个设计思想让Kafka客户端的性能和吞吐量都非常的高，这里蕴含了大量的优秀的机制。



那么此时有人说了，如果我现在把一个缓冲池里的内存资源都占满了，现在缓冲池里暂时没有内存块了，怎么办呢？



很简单，阻塞你的写入操作，不让你继续写入消息了。把你给阻塞住，不停的等待，直到有内存块释放出来，然后再继续让你写入消息。



4、总结一下
这篇文章我们从Kafka内存缓冲机制的设计思路开始，一直分析到了JVM GC问题的产生原因以及恶劣的影响。



接着谈到了Kafka优秀的缓冲池机制的设计思想以及他是如何解决这个问题的，分析了很多Kafka作者在设计的时候展现出的优秀的技术设计思想和能力。



希望大家多吸取这里的精华，在以后面试或者工作的时候，可以把这些优秀的思想纳为己用。



“ 请你简述一下Kafka中的分区分配 ！”



Duang！！！



当面试官问你这个问题的时候，你会怎么回答？



其实，这道题目里面就暗藏汹涌，因为Kafka中的分区分配在多处出现，而这个问题的表述方式是在潜意识里暗示你回答一种。



这样在你自认为很完美的回答完这个问题之后，面试官会冷不丁的来一句：还有呢？

当你回答完一个点的时候，面试官来一句还有呢，当你再补上一个的时候，他还是会来一句还有呢，就算你又补上第三个的时候，他还是会来一句还有呢？这个时候你会不会一脸懵逼？

今天就针对这个问题来告诉大家怎么样回答才能严丝合缝地抢得先机。

在Kafka中，分区分配是一个很重要的概念，却往往会被读者忽视，它会影响Kafka整体的性能均衡。

当遇到“分区分配”这个字眼的时候，一定要记住有三处地方，分别是生产者发送消息、消费者消费消息和创建主题。

虽然这三处的对应操作都可以被称之为“分区分配”，但是其实质上所包含的内容却并不相同。

在面对开篇的问题的时候，不如一下就进行总结性的陈词，说有三处，第一、第二、第三balabala。

当真的让你讲完三处的时候，时间也就差不多了。。聪明的面试官看到你一上来就做了一个规划总结，那他顶多也就让你说说你最熟悉的一种，其实说不定内心已经确认你是对的人。

下面针对这三处做个讲解。不过本文旨在罗列相关知识点，进行相关性的科普描述，让读者可以追根溯源，但并不陈述具体细节，因为细节很多，篇幅有限，如有需要请详参老朽的《深入理解Kafka》。

生产者的分区分配
对于用户而言，当调用send方法发送消息之后，消息就自然而然的发送到了broker中。

其实在这一过程中，有可能还要经过拦截器、序列化器和分区器（Partitioner）的一系列作用之后才能被真正地发往broker。

producer.send(record);
消息在发往broker之前是需要确定它所发往的分区的，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。

如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。

Kafka中提供的默认分区器是DefaultPartitioner，它实现了Partitioner接口（用户可以实现这个接口来自定义分区器），其中的partition方法就是用来实现具体的分区分配逻辑：

public int partition(String topic, Object key, byte[] keyBytes,
                     Object value, byte[] valueBytes, Cluster cluster);


默认情况下，如果消息的key不为null，那么默认的分区器会对key进行哈希（采用MurmurHash2算法，具备高运算性能及低碰撞率）

最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息将会以轮询的方式发往主题内的各个可用分区。

注意：如果key不为null，那么计算得到的分区号会是所有分区中的任意一个；



如果key为null并且有可用分区，那么计算得到的分区号仅为可用分区中的任意一个，注意两者之间的差别。


消费者的分区分配
在Kafka的默认规则中，每一个分区只能被同一个消费组中的一个消费者消费。消费者的分区分配是指为消费组中的消费者分配所订阅主题中的分区。



如图所示，某个主题中共有4个分区（Partition）：P0、P1、P2、P3。

有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者（C0、C1、C2和C3），消费组B中有2个消费者（C4和C5）。

按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。

对于消费者的分区分配而言，Kafka自身提供了三种策略，分别为RangeAssignor、RoundRobinAssignor以及StickyAssignor

其中RangeAssignor为默认的分区分配策略，至于这三种策略具体代表什么含义，可以去查阅相关资料，比如《深入理解Kafka》，嘿嘿。当然也可以通过实现ParitionAssignor接口来自定义分区分配策略。

在消费组中如果有多个消费者，那么这些消费者又可能会采用不同的分配策略，那么最后怎么“拍板”使用哪一种具体的分配策略呢？

对于这里，我想留一道思考题给大家：在Kafka的默认规则中，每一个分区只能被同一个消费组中的一个消费者消费，那么这个规则可以被打破么？

如果可以，怎么打破？打破的收益又是什么？



broker端的分区分配
生产者的分区分配是指为每条消息指定其所要发往的分区，消费者中的分区分配是指为消费者指定其可以消费消息的分区

而这里的分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本。

分区分配是否均衡会影响到Kafka整体的负载均衡，具体还会牵涉到优先副本等概念。

在创建主题时，如果使用了replica-assignment参数，那么就按照指定的方案来进行分区副本的创建；

如果没有使用replica-assignment参数，那么就需要按照内部的逻辑来计算分配方案了。

使用kafka-topics.sh脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略：未指定机架信息和指定机架信息。

如果集群中所有的broker节点都没有配置broker.rack参数，或者使用disable-rack-aware参数来创建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。



大数据基础系列之kafka011生产者缓存超时，幂等性和事务实现
原创： 浪尖  Spark学习技巧  2017-07-30
一，demo及相关类

1，基本介绍

KafkaProducer是线程安全的，多线程间共享一个实例比共享多个实例更加高效。首先搞一个demo

Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("acks", "all");
props.put("retries", 0);
props.put("batch.size", 16384);
props.put("linger.ms", 1);
props.put("buffer.memory", 33554432);
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

Producer<String, String> producer = new KafkaProducer<>(props);
for (int i = 0; i < 100; i++)
producer.send(new ProducerRecord<String, String>("my-topic", Integer.toString(i), Integer.toString(i)));

producer.close();

2，ProducerRecord

发往kafka的key/value对。由topic，分区id(可选)，key(可选)，timestamp(可选)，value组成。

如果一个有效的分区ID被指定，Record就会被发到指定的分区。如果，没指定分区id，只指定了key，就会按照key做hash后对分区数取余得到的数值作为分区的id。如果分区id，和key都没有指定，就会以轮训的形式发送Records。

Record还有一个timestamp属性。如果用户没有提供timestamp，生产者将会使用当前时间作为Record的timestamp。Kafka最终使用的时间戳取决于topic配置的时间类型。

1),如果topic配置使用了CreateTime，Broker就会使用生产者生产Record时带的时间戳。

2),如果topic配置使用了LogAppendTime，Record追加到log的时候，Broker会有本地时间代替Producer生产时带的时间戳。

无论是采用的上文中的哪种形式，timestamp都会被包含在RecordMetadata中返回。

ProducerRecord(String topic, Integer partition, K key, V value)
Creates a record to be sent to a specified topic and partition
  ProducerRecord(String topic, Integer partition, K key, V value, Iterable<Header> headers)
Creates a record to be sent to a specified topic and partition
  ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value)
Creates a record with a specified timestamp to be sent to a specified topic and partition
  ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value, Iterable<Header> headers)
Creates a record with a specified timestamp to be sent to a specified topic and partition
  ProducerRecord(String topic, K key, V value)
Create a record to be sent to Kafka
  ProducerRecord(String topic, V value)
Create a record with no key

二，缓存和超时

生产者内部有一个buffer，用来缓存Record，同时内部有一个后台线程负责将Record转化为请求，然后将请求发给kafka集群。使用生产者后未关闭，会导致这些资源泄漏。

send方法是异步的。调用他实际上是将Record添加到Buffer中，然后立即返回。这使得生产者可以批量提交消息来提升性能。

acks配置控制发送请求完成的标准。如果设置成all，将会导致生产阻塞，等待所有副本提交日志成功后才算发送完成，超级低效但是可以最大限度的容错。

如果请求失败，生产者会自动尝试，前提是不要设置retries为零。当然，开启失败尝试也就意味着带来了数据重复发送的风险。

生产者为每个分区维护一个buffer，这个buffer的大小由batch.size指定，该值越大表示批量发送的消息数越多，也意味着需要更大的内存。内存数可以估计的。

默认情况下，即使buffer还有剩余的空间没有填充，消息也会被立即发送。如果你想减少请求的次数，可以设置linger.ms参数为大于0的某一值。使生产者发送消息前等待linger.ms指定的时间，这样就可以有更多的消息加入到该batch来。这很像TCP中的Nagle原理。例如，在上面的代码片段中，由于我们设置linger.ms为1ms，100条消息可能在一次请求中全部发送到了Server端。然而，这也意味着加入消息一直不能填充满buffer，我们要延迟一毫秒。

buffer.memory决定者生产者所能用于buffer的总内存大小。如果，消息发送的速度比传输到Server端的速度快，这个buffer空间就会耗尽。当buffer空间耗尽，send调用就会阻塞，超过max.block.ms设置的超时时间后会抛出TimeoutException。

三，序列化

Key.serializer和value.serialize决定者如何将key和value对象转化为字节数组。你可以使用包括bytearrayserializer或stringserializer简单的字符串或字节类型。也可以实现自定义的序列化方式。

四，幂等性

从kafka0.11版本开始，Kafka支持两种额外的模式：幂等性生产者和事务生产者。幂等性强化消息的传递语义，从至少一次到仅仅一次。特别是生产者重试将不再导致消息重复发送。事务生产者允许应用程序将消息原子的发送到多个分区（和主题！）。

设置enable.idempotence为true来开启幂等性，如果设置了这个参数retries配置将会被设置为默认值，也即Integer.MAX_VALUE，max.inflight.requests.per.connection会被设置为1，acks会被设置为all。幂等性生产者不需要修改API，所以现有的应用程序不需要修改就可以使用该特性。

为了利用幂等生产者，必须避免应用程序级重新发送，因为这些不能被去重。例如，如果应用程序运行幂等性，建议不要设置retries，因为他会被设置为默认值(Integer.MAX_VALUE).此外，如果send（producerrecord）返回一个错误甚至无限重试（例如,如果消息送前缓冲区满了），建议关闭生产和检查最后产生消息的内容以确保不重复。

五，事务

为了使用事务生产者和相关的APIs，必须要设置transactional.id属性.如果设置了transactional.id幂等性会自动被启用。支持事务的topic必须要进行容错配置。特别的replication.factor应该设置为3，topic的min.insync.replicas配置必须设置为2.最后，为了从端到端实现事务性保证，必须配置消费者只读取committed 的消息。

transactional.id目的是单生产者实例能从多会话中恢复。该特性就是分区的，状态的应用程序程序中的一个碎片标识符。transactional.id值在一个分区的应用中每个消费者实例必须是唯一的。

所有新的事务性API都会被阻塞，将在失败时抛出异常。举一个简单的例子，一次事务中提交100条消息。

Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("transactional.id", "my-transactional-id");
Producer<String, String> producer = new KafkaProducer<>(props, new StringSerializer(), new StringSerializer());

producer.initTransactions();

try {
  producer.beginTransaction();
  for (int i = 0; i < 100; i++)
  producer.send(new ProducerRecord<>("my-topic", Integer.toString(i), Integer.toString(i)));
  producer.commitTransaction();
} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {
  // We can't recover from these exceptions, so our only option is to close the producer and exit.
  producer.close();
} catch (KafkaException e) {
  // For all other exceptions, just abort the transaction and try again.
  producer.abortTransaction();
}
producer.close();

就如例子一样，每个消费者只能有一个事务开启。在beginTransaction() 和commitTransaction()中间发送的所有消息，都是一次事务的一部分。

事务生产者使用execeptions进行错误状态交流。特别之处，我们不需要为producer.send指定回调函数。任何在事务中不可恢复的错误发生都会抛出一个KafkaException异常(http://kafka.apache.org/0110/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html#send(org.apache.kafka.clients.producer.ProducerRecord))。

在接受到一个kafkaexection异常之后，通过调用producer.abortTransaction()，可以保证所有的已经写入成功的消息会被标记为aborted，因此保证事务传输。