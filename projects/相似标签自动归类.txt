背景
本文档使用机器学习平台的文本分析功能，实现一版简单的商品标签自动归类系统。具体场景如下：

双十一购物狂欢节马上又要到来了，各种关于双十一的爆品购物列表在网上层出不穷。对于经常网购的用户来说，一定清楚通常一件商品会有很多维度的标签来展示。比如一个鞋子，它的商品描述可能是“韩都少女英伦风系带马丁靴女磨砂真皮厚底休闲短靴”。如果是一个包，那么它的商品描述可能是“天天特价包包2016新款秋冬斜挎包韩版手提包流苏贝壳包女包单肩包”。

每个产品的描述都包含非常多的维度，可能是时间、产地、款式等，如何按照特定的维度将数以万计的产品进行归类，往往是电商平台最头痛的问题。其中最大的挑战是如何判断每种商品的维度由哪些标签组成。如果可以通过算法自动学习标签词语，例如“日本”、“福建”、“韩国”等与地点相关的标签，那么就可以快速地构建标签归类体系。

数据说明
数据是在网上直接下载并且整理的一份2016年双十一购物清单，一共有两千多条商品描述，每一行代表一款商品的标签聚合，如下图所示。


将数据导入机器学习平台进行处理，数据上传方式请参考数据准备。

实验说明
数据上传完成后，通过拖拽机器学习组件，生成如下实验逻辑图，每一步的具体功能如下图所示。



各步骤的详细说明如下。

1. 上传数据并分词
参考数据准备上传shopping_data数据，代表底层数据存储。
通过分词组件对数据分词，分词是NLP的基础操作，本文不做介绍。

2. 增加序号列
由于上传的数据只有一个字段，需要通过增加序号列为每个数据增加主键，处理后的数据如下图所示。



3. 统计词频
展示了每个商品中出现的各种词语的个数。

4. 生成词向量
使用word2vector算法，将每个词按照意义在向量维度展开，词向量有两层含义。

向量距离近的两个词的真实含义比较相近，比如数据中的“新加坡”和“日本”都表示产品的产地，那么这两个词的向量距离就比较近。
不同词之间的距离差值也具有一定的意义，比如“北京”是“中国”的首都，“巴黎”是“法国”的首都，在训练量足够的情况下，可以得到“|中国|-|北京|=|法国|-|巴黎|”。
经过word2vector算法，将每个词被映射到百维空间上，结果如下图所示。


5. 词向量聚类
使用kmeans算法，在已经产生的词向量的基础上，计算出哪些词的向量距离比较近，并按照意义将标签词自动归类。结果展示的是每个词属于哪个聚类簇，如下图所示。


结果验证
通过SQL组件，在聚类簇中随意挑选一个类别，判断是否将同一类别的标签进行了自动归类，本实验选用第10组聚类簇。



结果如下图所示。



通过结果中的“日本”、“俄罗斯”、“韩国”、“云南”、“新疆”、“台湾”等词可以发现系统自动将一些跟地理相关的标签进行了归类，但是里面混入了“男士内裤”、“坚果”等明显与类别不符合的标签。可能是训练样本数量不足造成的，如果训练样本足够大，那么标签聚类结果会非常准确。