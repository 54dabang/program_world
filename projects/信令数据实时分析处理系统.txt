信令数据实时分析处理系统
开发环境： IDEA+eclipse+maven+jdk
系统架构： hadoop+zookeeper+Spark+hive+mysql+sqoop+Oracle
项目描述：
数据源端的信令数据，包含了联通用户11种业务类型，对应的11张表的数据信息，通过socket协议将信令数据传输给sparkStreaming，sparkStreaming首先解析出每张表的数据信息，然后针对每张表的数据信息，对其手机号加密处理，截取所需要的字段，并通过信息字段lac ci（基站信息） 实时关联码表打标签，不同的合作厂商的接入，会有不同的码表文件。最后将处理好的数据保存到hadoop上，并且通过ftp的client，实时的写到共享平台上，供合作厂商取走使用。同时每天定时对hadoop上的数据利用hive建立外部分区表，每天定时的执行脚本，统计分析出联通用户每天的上网行为，利用sqoop工具将分析统计的结果导入到Oracle中，生产报表，供前端展现。
责任描述 :
  1. 根据信令数据11张表的业务规则，理清楚满足业务需求的字段的下标。
  2. 开发sparkSteaming流处理代码，解析出11张表数据信息
  3. 对表数据中的信息字段lac ci与码表关联，对数据进行实时打标签
  4. 对共享平台上以及hadoop上产生的碎小文件数据，开启多线程对小文件进行实时合并。
  5. 负责spark集群处理的优化，处理线上出现的一些错误信息，让系统处于稳定，高可用状态。
  6. 写定时脚本任务，通过建立hive表对数据进行分析统计。
  7. 系统监控，主要是正对于集群中的硬件以及集群的节点的运行状体进行监控


  项目名称： 信令数据实时分析处理系统
  开发环境： IDEA+eclipse+maven+jdk
  系统架构： hadoop+zookeeper+Spark+hive+mysql+sqoop+Oracle
  项目描述：
  数据源端的信令数据，包含了联通用户11种业务类型，对应的11张表的数据信息，通过socket协议将信令数据传输给sparkStreaming，sparkStreaming首先解析出每张表的数据信息，然后针对每张表的数据信息，对其手机号加密处理，截取所需要的字段，并通过信息字段lac ci（基站信息） 实时关联码表打标签，不同的合作厂商的接入，会有不同的码表文件。最后将处理好的数据保存到hadoop上，并且通过ftp的client，实时的写到共享平台上，供合作厂商取走使用。同时每天定时对hadoop上的数据利用hive建立外部分区表，每天定时的执行脚本，统计分析出联通用户每天的上网行为，利用sqoop工具将分析统计的结果导入到Oracle中，生产报表，供前端展现。
  责任描述 :
    1. 根据信令数据11张表的业务规则，理清楚满足业务需求的字段的下标。
    2. 开发sparkSteaming流处理代码，解析出11张表数据信息
    3. 对表数据中的信息字段lac ci与码表关联，对数据进行实时打标签
    4. 对共享平台上以及hadoop上产生的碎小文件数据，开启多线程对小文件进行实时合并。
    5. 负责spark集群处理的优化，处理线上出现的一些错误信息，让系统处于稳定，高可用状态。
    6. 写定时脚本任务，通过建立hive表对数据进行分析统计。
    7. 系统监控，主要是正对于集群中的硬件以及集群的节点的运行状体进行监控

