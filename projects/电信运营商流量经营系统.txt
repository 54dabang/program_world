运营商掌握了大量的用户上网行为数据
用户上网行为数据丰富的商业价值
相对廉价方便的大数据处理技术使得海量数据挖掘分析成为可能
互联网企业对传统电信运营商的倒逼（市场，业务，技术）


集群：3个
数据采集集群（6-10节点）
行为轨迹增强处理集群（20-25节点）
ETL、统计分析集群（35节点）

数据量：每天2T左右（10亿行以上），并在不断增长

项目组规模
	研发团队、实施团队、运维团队


数据来源：
数据的采集可以是从硬件设备（如网关、Gn口、分光设备）直接获取并解析

也可以是从其它系统（如BOSS和VGOP）导入

数据类型：
	HTTP日志/WAP日志/MMS日志/ CONN日志/DNS日志

数据格式及内容：
http日志示例：
1374609560.11	1374609560.16	1374609560.16	1374609560.16	110	5	8615038208365	460023383869133	8696420056841778	2	460	0	14615			54941	10.188.77.252	61.145.116.27	35020	80	6	cmnet	1	221.177.218.34	221.177.217.161	221.177.218.34	221.177.217.167	ad.veegao.com	http://ad.veegao.com/veegao/iris.action		Apache-HttpClient/UNAVAILABLE (java 1.4)	POST	200	593	310	4	3	0	0	4	3	0	0	0	0	http://ad.veegao.com/veegao/iris.action	5903903079251243019	5903903103500771339	5980728

数据采集清洗、分类、合并上传HDFS集群

数据处理：内容识别用户行为轨迹增强

数据挖掘、统计分析

业务应用、BI报表展示

原始日志（plain text）
分类合并日志（plain text）
行为轨迹增强日志（plain text）
待爬清单（plain text）
挖掘、分析结果入库（关系型数据表）


系统整体架构（系统分界，子系统划分，模块结构、层次结构）
主要技术选型
关键子系统SCA数据处理流程
关键子系统SCA主要功能模块

-----------
主要技术选型：

数据采集：根据不同生产环境，有多种形式
云存储：HDFS，事实上的大数据技术标准
海量数据批处理：MAP/REDUCE
爬虫系统：Nutch，技术成熟，功能齐全，文档丰富，易扩展易改造
内容识别：模板匹配，XPATH，贝叶斯分类
云ETL： HIVE，最通用成熟的大数据平台ETL/数据仓库工具；Python脚本


核心子系统SCA功能模块组成
数据采集：根据不同生产环境，有多种形式
数据预处理
数据上传HDFS
行为轨迹增强
内容识别


数据预处理（采集，分类，上传HDFS）
规则分类（在mapreduce中查询关系型数据库）
实例分类（在mapreduce中查询kv数据库）
内容识别（爬虫，模板、语义识别）
定时任务、结果推送
BI统计分析（实际投产脚本选样讲解）
报表展现（JAVA WEB）


数据采集

规则库设计：分类体系，MYSQL关系库
使用MAP/RED并发处理
Mysql数据库的并发访问瓶颈
MAP/RED设计技巧——setup()
两类输出结果（增强日志，待爬清单）
MAP/REDUCE 自定义OutputFormat

实例分类

实例库设计：使用KV内存数据库Flare/Redis
使用MAP/RED并发处理
需要实时更新（setup函数不适用）


内容识别

爬虫模块——Nutch（权限验证，防封策略，动态代理，动态改变agent）

网页信息清洗、整理（标签补全，格式化，特定信息抽取）

主题分类——自然语言处理（分词，模型训练），PLSA模型


BI统计

云ETL——HIVE
Python脚本
HIVE任务调度
业务模型
数据入库



报表展现
Mysql cluster
Spring MVC
AJAX
数据可视化组件


系统功能界面：全景分析-用户

系统功能界面：综合分析




内容的一级分类，目前有35个一级分类；根据目前互联网的内容分类方式。

偏好某个分类下的用户号码列表，目前隐藏了中间四位。


“新闻”类的域名的根据点击量进行排行

该内容标签的点击次数占该用户总点击次数的比重


流量分析


数据预处理

数据采集：FTP，SHELL脚本，FLUME
数据预处理：JAVA （多线程，IO操作）
数据上传HDFS：HDFS API


需求、设计
技术难点、要点（原子性，上传效率，失败重传、记录）
涉及到的Hadoop相关知识（HDFS）的复习
实战HDFS代码开发及部署运行


规则库生成

需求、设计
技术难点、要点（TOP K算法的mapreduce实现）
涉及到的Hadoop相关知识（MAPRED）的复习
实战mapreduce代码开发及部署运行


从样本数据中提取有代表性的url

需求：从样本数据中提取有代表性的url
设计（流程）：
读入日志数据
根据url访问的流量进行排序
输出流量占总流量前80%的url
将url列表文本数据导入mysql表

用mapreduce实现排序
用mapreduce实现topk
将hdfs数据导入mysql


内容增强

需求、设计
技术难点、要点（如何实现高效查询外部数据）
涉及到的Hadoop相关知识（MAPRED）的复习
实战mapreduce代码开发及部署运行


需求：对原始日志进行分类信息增强
设计（流程）：
读入日志数据
过滤脏数据
抽取url字段，查询规则分类表
添加到原始日志
根据分类情况输出两类结果


Mapreduce中访问外部资源
Mapreduce中如何克服外部资源访问瓶颈
自定义OutputFormat类


==================



































