使用 Redis 搭建电商秒杀系统

秒杀活动是绝大部分电商选择的低价促销、推广品牌的方式。不仅可以给平台带来用户量，还可以提高平台知名度。一个好的秒杀系统，可以提高平台系统的稳定性和公平性，获得更好的用户体验，提升平台的口碑，从而提升秒杀活动的最大价值。

本文讨论云数据库 Redis 版缓存设计高并发的秒杀系统。

秒杀的特征
秒杀活动对稀缺或者特价的商品进行定时定量售卖，吸引成大量的消费者进行抢购，但又只有少部分消费者可以下单成功。因此，秒杀活动将在较短时间内产生比平时大数十倍，上百倍的页面访问流量和下单请求流量。

秒杀活动可以分为3个阶段：

秒杀前：用户不断刷新商品详情页，页面请求达到瞬时峰值。
秒杀开始：用户点击秒杀按钮，下单请求达到瞬时峰值。
秒杀后：一部分成功下单的用户不断刷新订单或者产生退单操作，大部分用户继续刷新商品详情页等待退单机会。
消费者提交订单，一般做法是利用数据库的行级锁，只有抢到锁的请求可以进行库存查询和下单操作。但是在高并发的情况下，数据库无法承担如此大的请求，往往会使整个服务 blocked，在消费者看来就是服务器宕机。

秒杀系统

秒杀系统的流量虽然很高，但是实际有效流量是十分有限的。利用系统的层次结构，在每个阶段提前校验，拦截无效流量，可以减少大量无效的流量涌入数据库。

利用浏览器缓存和 CDN 抗压静态页面流量

秒杀前，用户不断刷新商品详情页，造成大量的页面请求。所以，我们需要把秒杀商品详情页与普通的商品详情页分开。对于秒杀商品详情页尽量将能静态化的元素静态化处理，除了秒杀按钮需要服务端进行动态判断，其他的静态数据可以缓存在浏览器和 CDN 上。这样，秒杀前刷新页面导致的流量进入服务端的流量只有很小的一部分。

利用读写分离 Redis 缓存拦截流量

CDN 是第一级流量拦截，第二级流量拦截我们使用支持读写分离的 Redis。在这一阶段我们主要读取数据，读写分离 Redis 能支持高达60万以上 qps，完全可以支持需求。

首先通过数据控制模块，提前将秒杀商品缓存到读写分离 Redis，并设置秒杀开始标记如下：

"goodsId_count": 100 //总数
"goodsId_start": 0   //开始标记
"goodsId_access": 0  //接受下单数
秒杀开始前，服务集群读取 goodsId_Start 为 0，直接返回未开始。

数据控制模块将 goodsId_start 改为1，标志秒杀开始。

服务集群缓存开始标记位并开始接受请求，并记录到 redis 中 goodsId_access，商品剩余数量为(goodsId_count - goodsId_access)。

当接受下单数达到 goodsId_count 后，继续拦截所有请求，商品剩余数量为 0。

可以看出，最后成功参与下单的请求只有少部分可以被接受。在高并发的情况下，允许稍微多的流量进入。因此可以控制接受下单数的比例。

利用主从版 Redis 缓存加速库存扣量

成功参与下单后，进入下层服务，开始进行订单信息校验，库存扣量。为了避免直接访问数据库，我们使用主从版 Redis 来进行库存扣量，主从版 Redis 提供10万级别的 QPS。使用 Redis 来优化库存查询，提前拦截秒杀失败的请求，将大大提高系统的整体吞吐量。

通过数据控制模块提前将库存存入 Redis，将每个秒杀商品在 Redis 中用一个 hash 结构表示。

"goodsId" : {
    "Total": 100
    "Booked": 100
}
扣量时，服务器通过请求 Redis 获取下单资格，通过以下 lua 脚本实现，由于 Redis 是单线程模型，lua 可以保证多个命令的原子性。

local n = tonumber(ARGV[1])
if not n  or n == 0 then
    return 0
end
local vals = redis.call("HMGET", KEYS[1], "Total", "Booked");
local total = tonumber(vals[1])
local blocked = tonumber(vals[2])
if not total or not blocked then
    return 0
end
if blocked + n <= total then
    redis.call("HINCRBY", KEYS[1], "Booked", n)
    return n;
end
return 0
先使用SCRIPT LOAD将 lua 脚本提前缓存在 Redis，然后调用EVALSHA调用脚本，比直接调用EVAL节省网络带宽：

redis 127.0.0.1:6379>SCRIPT LOAD "lua code"
"438dd755f3fe0d32771753eb57f075b18fed7716"
redis 127.0.0.1:6379>EVAL 438dd755f3fe0d32771753eb57f075b18fed7716 1 goodsId 1
秒杀服务通过判断 Redis 是否返回抢购个数 n，即可知道此次请求是否扣量成功。

使用主从版 Redis 实现简单的消息队列异步下单入库

扣量完成后，需要进行订单入库。如果商品数量较少的时候，直接操作数据库即可。如果秒杀的商品是1万，甚至10万级别，那数据库锁冲突将带来很大的性能瓶颈。因此，利用消息队列组件，当秒杀服务将订单信息写入消息队列后，即可认为下单完成，避免直接操作数据库。

消息队列组件依然可以使用 Redis 实现，在 R2 中用 list 数据结构表示。
 orderList {
     [0] = {订单内容}
     [1] = {订单内容}
     [2] = {订单内容}
     ...
 }
将订单内容写入 Redis:
LPUSH orderList {订单内容}
异步下单模块从 Redis 中顺序获取订单信息，并将订单写入数据库。
 BRPOP orderList 0
通过使用 Redis 作为消息队列，异步处理订单入库，有效的提高了用户的下单完成速度。

数据控制模块管理秒杀数据同步

最开始，利用读写分离 Redis 进行流量限制，只让部分流量进入下单。对于下单检验失败和退单等情况，需要让更多的流量进来。因此，数据控制模块需要定时将数据库中的数据进行一定的计算，同步到主从版 Redis，同时再同步到读写分离的 Redis，让更多的流量进来


==================






之前在 Java-Interview 中提到过秒杀架构的设计，这次基于其中的理论简单实现了一下。

本次采用循序渐进的方式逐步提高性能达到并发秒杀的效果，文章较长请准备好瓜子板凳(liushuizhang😂)。

本文所有涉及的代码：

https://github.com/crossoverJie/SSM

https://github.com/crossoverJie/distributed-redis-tool

最终架构图：



先简单根据这个图谈下请求的流转，因为后面不管怎么改进这个都是没有变的。

前端请求进入 web 层，对应的代码就是 controller。

之后将真正的库存校验、下单等请求发往 Service 层（其中 RPC 调用依然采用的 dubbo，只是更新为最新版本，本次不会过多讨论 dubbo 相关的细节，有兴趣的可以查看 基于dubbo 的分布式架构）。

Service 层再对数据进行落地，下单完成。

无限制
其实抛开秒杀这个场景来说正常的一个下单流程可以简单分为以下几步：

校验库存

扣库存

创建订单

支付

基于上文的架构所以我们有了以下实现：

先看看实际项目的结构：



还是和以前一样：

提供出一个 API 用于 Service 层实现，以及 web 层消费。

web 层简单来说就是一个 SpringMVC。

Service 层则是真正的数据落地。

SSM-SECONDS-KILL-ORDER-CONSUMER 则是后文会提到的 Kafka 消费。

数据库也是只有简单的两张表模拟下单：

CREATE TABLE
`stock`
(


`id`
int
(
11
)
unsigned
NOT NULL AUTO_INCREMENT
,


`name`
varchar
(
50
)
NOT NULL DEFAULT
''
COMMENT
'名称'
,


`count`
int
(
11
)
NOT NULL COMMENT
'库存'
,


`sale`
int
(
11
)
NOT NULL COMMENT
'已售'
,


`version`
int
(
11
)
NOT NULL COMMENT
'乐观锁，版本号'
,

 PRIMARY KEY
(
`id`
)

)
ENGINE
=
InnoDB
AUTO_INCREMENT
=
2
DEFAULT CHARSET
=
utf8
;



CREATE TABLE
`stock_order`
(


`id`
int
(
11
)
unsigned
NOT NULL AUTO_INCREMENT
,


`sid`
int
(
11
)
NOT NULL COMMENT
'库存ID'
,


`name`
varchar
(
30
)
NOT NULL DEFAULT
''
COMMENT
'商品名称'
,


`create_time`
timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT
'创建时间'
,

 PRIMARY KEY
(
`id`
)

)
ENGINE
=
InnoDB
AUTO_INCREMENT
=
55
DEFAULT CHARSET
=
utf8
;

web 层 controller 实现:


@Autowired


private

StockService
 stockService
;



@Autowired


private

OrderService
 orderService
;



@RequestMapping
(
"/createWrongOrder/{sid}"
)


@ResponseBody


public

String
 createWrongOrder
(
@PathVariable

int
 sid
)

{

        logger
.
info
(
"sid=[{}]"
,
 sid
);


int
 id
=

0
;


try

{

            id
=
 orderService
.
createWrongOrder
(
sid
);


}

catch

(
Exception
 e
)

{

            logger
.
error
(
"Exception"
,
e
);


}


return

String
.
valueOf
(
id
);


}

其中 web 作为一个消费者调用看 OrderService 提供出来的 dubbo 服务。

Service 层， OrderService 实现：

首先是对 API 的实现(会在 API 提供出接口)：

@Service

public

class

OrderServiceImpl

implements

OrderService

{



@Resource
(
name
=

"DBOrderService"
)


private
 com
.
crossoverJie
.
seconds
.
kill
.
service
.
OrderService
 orderService
;



@Override


public

int
 createWrongOrder
(
int
 sid
)

throws

Exception

{


return
 orderService
.
createWrongOrder
(
sid
);


}

}

这里只是简单调用了 DBOrderService 中的实现，DBOrderService 才是真正的数据落地，也就是写数据库了。

DBOrderService 实现：

Transactional
(
rollbackFor
=

Exception
.
class
)

@Service
(
value
=

"DBOrderService"
)

public

class

OrderServiceImpl

implements

OrderService

{


@Resource
(
name
=

"DBStockService"
)


private
 com
.
crossoverJie
.
seconds
.
kill
.
service
.
StockService
 stockService
;



@Autowired


private

StockOrderMapper
 orderMapper
;



@Override


public

int
 createWrongOrder
(
int
 sid
)

throws

Exception
{



//校验库存


Stock
 stock
=
 checkStock
(
sid
);



//扣库存

        saleStock
(
stock
);



//创建订单


int
 id
=
 createOrder
(
stock
);



return
 id
;


}



private

Stock
 checkStock
(
int
 sid
)

{


Stock
 stock
=
 stockService
.
getStockById
(
sid
);


if

(
stock
.
getSale
().
equals
(
stock
.
getCount
()))

{


throw

new

RuntimeException
(
"库存不足"
);


}


return
 stock
;


}



private

int
 saleStock
(
Stock
 stock
)

{

        stock
.
setSale
(
stock
.
getSale
()

+

1
);


return
 stockService
.
updateStockById
(
stock
);


}



private

int
 createOrder
(
Stock
 stock
)

{


StockOrder
 order
=

new

StockOrder
();

        order
.
setSid
(
stock
.
getId
());

        order
.
setName
(
stock
.
getName
());


int
 id
=
 orderMapper
.
insertSelective
(
order
);


return
 id
;


}



}

预先初始化了 10 条库存。

手动调用下 createWrongOrder/1 接口发现：

库存表：

订单表：

一切看起来都没有问题，数据也正常。

但是当用 JMeter 并发测试时：



测试配置是：300个线程并发，测试两轮来看看数据库中的结果：







请求都响应成功，库存确实也扣完了，但是订单却生成了 124 条记录。

这显然是典型的超卖现象。

其实现在再去手动调用接口会返回库存不足，但为时晚矣。

乐观锁更新
怎么来避免上述的现象呢？

最简单的做法自然是乐观锁了，这里不过多讨论这个，不熟悉的朋友可以看下这篇。

来看看具体实现：

其实其他的都没怎么改，主要是 Service 层。


@Override


public

int
 createOptimisticOrder
(
int
 sid
)

throws

Exception

{



//校验库存


Stock
 stock
=
 checkStock
(
sid
);



//乐观锁更新库存

        saleStockOptimistic
(
stock
);



//创建订单


int
 id
=
 createOrder
(
stock
);



return
 id
;


}



private

void
 saleStockOptimistic
(
Stock
 stock
)

{


int
 count
=
 stockService
.
updateStockByOptimistic
(
stock
);


if

(
count
==

0
){


throw

new

RuntimeException
(
"并发更新库存失败"
)

;


}


}

对应的 XML：


<update

id
=
"updateByOptimistic"

parameterType
=
"com.crossoverJie.seconds.kill.pojo.Stock"
>

        update stock


<set>

            sale = sale + 1,

            version = version + 1,


</set>


        WHERE id = #{id,jdbcType=INTEGER}

        AND version = #{version,jdbcType=INTEGER}



</update>

同样的测试条件，我们再进行上面的测试 /createOptimisticOrder/1：







这次发现无论是库存订单都是 OK 的。

查看日志发现：



很多并发请求会响应错误，这就达到了效果。

提高吞吐量
为了进一步提高秒杀时的吞吐量以及响应效率，这里的 web 和 Service 都进行了横向扩展。

web 利用 Nginx 进行负载。

Service 也是多台应用。





再用 JMeter 测试时可以直观的看到效果。

由于我是在阿里云的一台小水管服务器进行测试的，加上配置不高、应用都在同一台，所以并没有完全体现出性能上的优势（ Nginx 做负载转发时候也会增加额外的网络消耗）。

shell 脚本实现简单的 CI
由于应用多台部署之后，手动发版测试的痛苦相信经历过的都有体会。

这次并没有精力去搭建完整的 CI CD，只是写了一个简单的脚本实现了自动化部署，希望对这方面没有经验的同学带来一点启发：

构建 web
#!/bin/bash


# 构建 web 消费者


#read appname


appname
=
"consumer"

echo
"input="
$appname


PID
=
$
(
ps
-
ef
|
 grep $appname
|
 grep
-
v grep
|
 awk
'{print $2}'
)


# 遍历杀掉 pid

for

var

in
 $
{
PID
[@]};

do

    echo
"loop pid= $var"

    kill
-
9
 $var

done


echo
"kill $appname success"


cd
..


git pull


cd SSM
-
SECONDS
-
KILL


mvn
-
Dmaven
.
test
.
skip
=
true
 clean
package


echo
"build war success"


cp
/
home
/
crossoverJie
/
SSM
/
SSM
-
SECONDS
-
KILL
/
SSM
-
SECONDS
-
KILL
-
WEB
/
target
/
SSM
-
SECONDS
-
KILL
-
WEB
-
2.2
.
0
-
SNAPSHOT
.
war
/
home
/
crossoverJie
/
tomcat
/
tomcat
-
dubbo
-
consumer
-
8083
/
webapps

echo
"cp tomcat-dubbo-consumer-8083/webapps ok!"


cp
/
home
/
crossoverJie
/
SSM
/
SSM
-
SECONDS
-
KILL
/
SSM
-
SECONDS
-
KILL
-
WEB
/
target
/
SSM
-
SECONDS
-
KILL
-
WEB
-
2.2
.
0
-
SNAPSHOT
.
war
/
home
/
crossoverJie
/
tomcat
/
tomcat
-
dubbo
-
consumer
-
7083
-
slave
/
webapps

echo
"cp tomcat-dubbo-consumer-7083-slave/webapps ok!"


sh
/
home
/
crossoverJie
/
tomcat
/
tomcat
-
dubbo
-
consumer
-
8083
/
bin
/
startup
.
sh

echo
"tomcat-dubbo-consumer-8083/bin/startup.sh success"


sh
/
home
/
crossoverJie
/
tomcat
/
tomcat
-
dubbo
-
consumer
-
7083
-
slave
/
bin
/
startup
.
sh

echo
"tomcat-dubbo-consumer-7083-slave/bin/startup.sh success"


echo
"start $appname success"

构建 Service
# 构建服务提供者


#read appname


appname
=
"provider"


echo
"input="
$appname



PID
=
$
(
ps
-
ef
|
 grep $appname
|
 grep
-
v grep
|
 awk
'{print $2}'
)


#if [ $? -eq 0 ]; then

#    echo "process id:$PID"

#else

#    echo "process $appname not exit"

#    exit

#fi


# 遍历杀掉 pid

for

var

in
 $
{
PID
[@]};

do

    echo
"loop pid= $var"

    kill
-
9
 $var

done


echo
"kill $appname success"



cd
..


git pull


cd SSM
-
SECONDS
-
KILL


mvn
-
Dmaven
.
test
.
skip
=
true
 clean
package


echo
"build war success"


cp
/
home
/
crossoverJie
/
SSM
/
SSM
-
SECONDS
-
KILL
/
SSM
-
SECONDS
-
KILL
-
SERVICE
/
target
/
SSM
-
SECONDS
-
KILL
-
SERVICE
-
2.2
.
0
-
SNAPSHOT
.
war
/
home
/
crossoverJie
/
tomcat
/
tomcat
-
dubbo
-
provider
-
8080
/
webapps


echo
"cp tomcat-dubbo-provider-8080/webapps ok!"


cp
/
home
/
crossoverJie
/
SSM
/
SSM
-
SECONDS
-
KILL
/
SSM
-
SECONDS
-
KILL
-
SERVICE
/
target
/
SSM
-
SECONDS
-
KILL
-
SERVICE
-
2.2
.
0
-
SNAPSHOT
.
war
/
home
/
crossoverJie
/
tomcat
/
tomcat
-
dubbo
-
provider
-
7080
-
slave
/
webapps


echo
"cp tomcat-dubbo-provider-7080-slave/webapps ok!"


sh
/
home
/
crossoverJie
/
tomcat
/
tomcat
-
dubbo
-
provider
-
8080
/
bin
/
startup
.
sh

echo
"tomcat-dubbo-provider-8080/bin/startup.sh success"


sh
/
home
/
crossoverJie
/
tomcat
/
tomcat
-
dubbo
-
provider
-
7080
-
slave
/
bin
/
startup
.
sh

echo
"tomcat-dubbo-provider-8080/bin/startup.sh success"


echo
"start $appname success"

之后每当我有更新，只需要执行这两个脚本就可以帮我自动构建。

都是最基础的 Linux 命令，相信大家都看得明白。

乐观锁更新 + 分布式限流
上文的结果看似没有问题，其实还差得远呢。

这里只是模拟了 300 个并发没有问题，但是当请求达到了 3000 ，3W，300W 呢？

虽说可以横向扩展可以支撑更多的请求。

但是能不能利用最少的资源解决问题呢？

其实仔细分析下会发现：

假设我的商品一共只有 10 个库存，那么无论你多少人来买其实最终也最多只有 10 人可以下单成功。

所以其中会有 99% 的请求都是无效的。

大家都知道：大多数应用数据库都是压倒骆驼的最后一根稻草。

通过 Druid 的监控来看看之前请求数据库的情况：

因为 Service 是两个应用。





数据库也有 20 多个连接。

怎么样来优化呢？ 其实很容易想到的就是分布式限流。

我们将并发控制在一个可控的范围之内，然后快速失败这样就能最大程度的保护系统。

distributed-redis-tool ⬆️v1.0.3
为此还对 https://github.com/crossoverJie/distributed-redis-tool 进行了小小的升级。

因为加上该组件之后所有的请求都会经过 Redis，所以对 Redis 资源的使用也是要非常小心。

API 更新
修改之后的 API 如下：

@Configuration

public

class

RedisLimitConfig

{



private

Logger
 logger
=

LoggerFactory
.
getLogger
(
RedisLimitConfig
.
class
);



@Value
(
"${redis.limit}"
)


private

int
 limit
;




@Autowired


private

JedisConnectionFactory
 jedisConnectionFactory
;



@Bean


public

RedisLimit
 build
()

{


RedisLimit
 redisLimit
=

new

RedisLimit
.
Builder
(
jedisConnectionFactory
,

RedisToolsConstant
.
SINGLE
)


.
limit
(
limit
)


.
build
();



return
 redisLimit
;


}

}

这里构建器改用了 JedisConnectionFactory，所以得配合 Spring 来一起使用。

并在初始化时显示传入 Redis 是以集群方式部署还是单机（强烈建议集群，限流之后对 Redis 还是有一定的压力）。

限流实现
既然 API 更新了，实现自然也要修改：


/**

     * limit traffic

     * @return if true

     */


public

boolean
 limit
()

{



//get connection


Object
 connection
=
 getConnection
();



Object
 result
=
 limitRequest
(
connection
);



if

(
FAIL_CODE
!=

(
Long
)
 result
)

{


return

true
;


}

else

{


return

false
;


}


}



private

Object
 limitRequest
(
Object
 connection
)

{


Object
 result
=

null
;


String
 key
=

String
.
valueOf
(
System
.
currentTimeMillis
()

/

1000
);


if

(
connection
instanceof

Jedis
){

            result
=

((
Jedis
)
connection
).
eval
(
script
,

Collections
.
singletonList
(
key
),

Collections
.
singletonList
(
String
.
valueOf
(
limit
)));


((
Jedis
)
 connection
).
close
();


}
else

{

            result
=

((
JedisCluster
)
 connection
).
eval
(
script
,

Collections
.
singletonList
(
key
),

Collections
.
singletonList
(
String
.
valueOf
(
limit
)));


try

{


((
JedisCluster
)
 connection
).
close
();


}

catch

(
IOException
 e
)

{

                logger
.
error
(
"IOException"
,
e
);


}


}


return
 result
;


}



private

Object
 getConnection
()

{


Object
 connection
;


if

(
type
==

RedisToolsConstant
.
SINGLE
){


RedisConnection
 redisConnection
=
 jedisConnectionFactory
.
getConnection
();

            connection
=
 redisConnection
.
getNativeConnection
();


}
else

{


RedisClusterConnection
 clusterConnection
=
 jedisConnectionFactory
.
getClusterConnection
();

            connection
=
 clusterConnection
.
getNativeConnection
()

;


}


return
 connection
;


}

如果是原生的 Spring 应用得采用 @SpringControllerLimit(errorCode=200)注解。

实际使用如下：

web 端：


/**

     * 乐观锁更新库存 限流

     * @param sid

     * @return

     */


@SpringControllerLimit
(
errorCode
=

200
)


@RequestMapping
(
"/createOptimisticLimitOrder/{sid}"
)


@ResponseBody


public

String
 createOptimisticLimitOrder
(
@PathVariable

int
 sid
)

{

        logger
.
info
(
"sid=[{}]"
,
 sid
);


int
 id
=

0
;


try

{

            id
=
 orderService
.
createOptimisticOrder
(
sid
);


}

catch

(
Exception
 e
)

{

            logger
.
error
(
"Exception"
,
e
);


}


return

String
.
valueOf
(
id
);


}

Service 端就没什么更新了，依然是采用的乐观锁更新数据库。

再压测看下效果 /createOptimisticLimitOrderByRedis/1：











首先是看结果没有问题，再看数据库连接以及并发请求数都有明显的下降。

乐观锁更新 + 分布式限流 + Redis 缓存
其实仔细观察 Druid 监控数据发现这个 SQL 被多次查询：



其实这是实时查询库存的 SQL，主要是为了在每次下单之前判断是否还有库存。

这也是个优化点。

这种数据我们完全可以放在内存中，效率比在数据库要高很多。

由于我们的应用是分布式的，所以堆内缓存显然不合适，Redis 就非常适合。

这次主要改造的是 Service 层：

每次查询库存时走 Redis。

扣库存时更新 Redis。

需要提前将库存信息写入 Redis（手动或者程序自动都可以）。

主要代码如下：


@Override


public

int
 createOptimisticOrderUseRedis
(
int
 sid
)

throws

Exception

{


//检验库存，从 Redis 获取


Stock
 stock
=
 checkStockByRedis
(
sid
);



//乐观锁更新库存 以及更新 Redis

        saleStockOptimisticByRedis
(
stock
);



//创建订单


int
 id
=
 createOrder
(
stock
);


return
 id
;


}




private

Stock
 checkStockByRedis
(
int
 sid
)

throws

Exception

{


Integer
 count
=

Integer
.
parseInt
(
redisTemplate
.
opsForValue
().
get
(
RedisKeysConstant
.
STOCK_COUNT
+
 sid
));


Integer
 sale
=

Integer
.
parseInt
(
redisTemplate
.
opsForValue
().
get
(
RedisKeysConstant
.
STOCK_SALE
+
 sid
));


if

(
count
.
equals
(
sale
)){


throw

new

RuntimeException
(
"库存不足 Redis currentCount="

+
 sale
);


}


Integer
 version
=

Integer
.
parseInt
(
redisTemplate
.
opsForValue
().
get
(
RedisKeysConstant
.
STOCK_VERSION
+
 sid
));


Stock
 stock
=

new

Stock
()

;

        stock
.
setId
(
sid
);

        stock
.
setCount
(
count
);

        stock
.
setSale
(
sale
);

        stock
.
setVersion
(
version
);



return
 stock
;


}





/**

     * 乐观锁更新数据库 还要更新 Redis

     * @param stock

     */


private

void
 saleStockOptimisticByRedis
(
Stock
 stock
)

{


int
 count
=
 stockService
.
updateStockByOptimistic
(
stock
);


if

(
count
==

0
){


throw

new

RuntimeException
(
"并发更新库存失败"
)

;


}


//自增

        redisTemplate
.
opsForValue
().
increment
(
RedisKeysConstant
.
STOCK_SALE
+
 stock
.
getId
(),
1
)

;

        redisTemplate
.
opsForValue
().
increment
(
RedisKeysConstant
.
STOCK_VERSION
+
 stock
.
getId
(),
1
)

;


}


压测看看实际效果 /createOptimisticLimitOrderByRedis/1：









最后发现数据没问题，数据库的请求与并发也都下来了。

乐观锁更新 + 分布式限流 + Redis 缓存 + Kafka 异步
最后的优化还是想如何来再次提高吞吐量以及性能的。

我们上文所有例子其实都是同步请求，完全可以利用同步转异步来提高性能啊。

这里我们将写订单以及更新库存的操作进行异步化，利用 Kafka 来进行解耦和队列的作用。

每当一个请求通过了限流到达了 Service 层通过了库存校验之后就将订单信息发给 Kafka ，这样一个请求就可以直接返回了。

消费程序再对数据进行入库落地。

因为异步了，所以最终需要采取回调或者是其他提醒的方式提醒用户购买完成。

这里代码较多就不贴了，消费程序其实就是把之前的 Service 层的逻辑重写了一遍，不过采用的是 SpringBoot。

感兴趣的朋友可以看下。

https://github.com/crossoverJie/SSM/tree/master/SSM-SECONDS-KILL/SSM-SECONDS-KILL-ORDER-CONSUMER

总结
其实经过上面的一顿优化总结起来无非就是以下几点：

尽量将请求拦截在上游。

还可以根据 UID 进行限流。

最大程度的减少请求落到 DB。

多利用缓存。

同步操作异步化。

fail fast，尽早失败，保护应用。
=================

