风控是什么：
• 顾名思义,风控就是风险控制,最大程度地控制作弊和欺诈的发生,保障网站 的正常运营和用户体验
• 风险和作弊行为的发现、识别和处置
• 风控和反作弊是持续的博弈过程,cat-and-mouse game,时效性强,对抗性
强
• 三板斧:rules；models；strategy

流程包括：

产品体系：



数据：

一般业务数据：用户、商品、交易、点击、浏览、搜索、评价、服务、处罚等
安全业务数据：设备数据（UA、cookie、MAC、Umid、IMEI、IMSI）、位置数据（IP/LBS/GPS）、行为信息、生物信息、其他

算法：

机器学习：分类、聚类、graph算法
异常检测
图像算法：人脸识别、OCR、图像搜索

绝大多数场景使用RF/GBDT+LR/C5.0

注意点：

• 部分高风险业务,可以投入人力审核,追求更高的准确率/召回率
• 风险(异常)占比少,属于非平衡数据集
• 对抗意识强,模型衰减快,需要结合处置手段
• 风控的成本与回报意识,平衡人力和风险
• 能够采用更复杂的算法,但需要平衡用户体验和可解释性

效果评估：
case 1：如何判断某笔交易是否虚假？



其他：

  ● 具体的问题定义需要从业务的漏洞、运营规则、法律等方面去思考判断
  ● 处罚的机制需要平衡用户的体验
  ● 样本和特征、召回都需要大量领域的知识沉淀
  ● 评分和识别逻辑要能讲的通

---------------------

风控分贷前风控，贷中风控，贷后风控，说穿了，就是别人找你借钱，前期你要评估这钱借出去有没得还，该以多少点借出去，借出去之后到钱还回来整个过程你还要盯着，避免他突然跑路或者是
风控具体指的是什么？万一他耍赖皮说不还你要怎么让他还。
数据么，当然是金融行为数据最相关了，现在用电商啊社交什么的数据来做分析，就跟你走访时候了解他朋友他平时都是些什么生活习惯差不多啦。算法每家各不同，但是应该没有谁真的愿意讲出来吧，毕竟是核心。
风控应用案例：蚂蚁花呗借呗、腾讯的微粒贷都算是啊。
至于效果么，估计怎么也得明年才会有相关的报告出来，毕竟数据积淀需要时间，而且前期应该不会太好看。然而大数据风控是趋势，各家产品在市场的不断调整中竞争优化，会越来越有效的。前期尝试或者作为必需信息来源的补充渠道嘛。产品那么多肯定有个自然的筛选过程的。蜜蜂数据对接多家大数据征信产品，也是会经过筛选对比的。虽然目前发展的时间跟整个行业一样，不长，但是可以为征信公司和平台的沟通搭桥，避免他们相互交叉一一对接试错来着！
发布于 2016-04-13

王乐石
律师
感觉大数据对风控没有明显的作用。 针对消费者的小贷业务也是根据存款额，消费额来定，同样是万分之五的利率。逻辑和银行是一样一样的。而且借贷到期后强制扣款，这点比不上银行。 不看好。总体上，国内对大数据抱有过高的不切实际的期待。实际上消费者的消费决策并不能依靠过去的数据来进行判断。 it做流程规范的空间，做娱乐的空间也是有限的。在信用社会，总会有一只或者无数只猪在天上飞，问题是它们掉下来时别砸到自己。
发布于 2015-12-04

耿树文
关注互联网金融产品、运营、风控
楼上有很说了很多技术方面的，这些技术的运用挖掘了用户的还款能力、还款意愿。
但还有一个核心问题，不是用了什么模型，而且是风控的有效性如何评价？
风控的有效性，一定是定价、准入、坏账达到均衡。
不是简单说好坏的二元法则，那基本上就是传统风控，传统风控就是一些准入条件，条件一旦达不到就拒，这跟互联网大数据的原则是相违背的，互联网大数据风控要实现的是“千人千面”。



手机答题，忽略排版！帮题主缩小一点范围，我姑且把题主的模型认为是现在的互金公司的风控模型，而不是一般的互联网公司防盗号,防薅羊毛的那种。
现在的这一类风控模型大多仍然是沿用之前传统银行信用卡中心那一套，俗称评分卡。这种评分卡一般分为三种，分别是a卡，用于客户申请信用评估;一种是b卡，也被称为行为评分卡，用于评估客户贷中的风险;一种是c卡，用于催收策略。前两种模型有过接触，最后一种不太清楚具体的业务方法。
现在一般说的风险模型就是a卡，也是三种模型里面最重要的，因为如果在前面能成功的把坏客户挡在申请外面，后面两种模型就显得无足轻重了。相比之前的信用卡时代，现在的小贷公司能拿到的数据远远比以前拿到的数据要多，但触碰到的隐私红线的机会也会更多，这其中也和现在第三方征信公司的野蛮发展有很大关系。通常在申请的时候，客户会被要求填几个基本信息，如姓名，身份证，手机号及其他一些人口属性信息，贷款公司拿到几要素之后就会去抛第三方征信公司的数据接口，从而拿到自己没有能力拿到的数据。综合各方的数据，一般拿到的数据可以分为这么几类:一类是人口属性信息，这其中比较重要的如性别，年龄，学历，行业等;一类是device信息，包括手机型号，ip地址，lbs地址等;一类是借贷信息，如在各种机构下面的申请，借款，还款信息等；还有一类是补充信息，这类信息通常会触碰隐私红线，如话单信息，通讯录信息，app使用信息，历史lbs轨迹等。另外多一嘴，很多人认为话单的作用会随着微信的盛行而大幅减弱，从而完全失效，但是在实际使用中，尤其是在负面信息的表达上，话单的效果还是相当抢眼的，另外一个比较好用的信息就是设备上app的安装和使用情况，简直就是弥补了多头借贷的信息，并且相比借贷信息，也增加了一部分正面信息，这能更好的提高模型区分好坏的能力。
现在风控模型中最常用的算法仍然是逻辑回归，它的地位这么稳也是有一定道理的，最大的好处就是可解释性，可解释性在这一领域有很大用处，这一好处不仅仅是对客户好解释，这也和现在小贷公司获取外部数据有关，现在公司从外部数据拿到的数据一般不是底层的原始数据，而是中间加工过的数据，有加工就意味着不稳定性，这种不稳定也会造成风控模型的不稳定，所以当某一变量发生较大变化时，如何评估对现有模型的影响，比如预测的结果会前偏还是会后偏，如何调整策略等。其他的算法，如随机森林，gbdt，xgboost等都会做一些尝试。
模型建好之后，会面临比较复杂的测算过程，如模型在外推样本上的稳定性、有效性如何，如何定策略，在这一策略下，我的拒件率，逾期率会怎么变化，都需要评估出来
所以在我的认知当中，算法和跑模型不是最重要的，预测目的，建模样本选取，变量衍生，模型测算，策略制定才是关键。
后续有空再针对某一点做详细的介绍。




现在国内的云图征信是专门做这一块儿的，贷中、贷前、贷后有14种大数据风控模型，实时动态监控，可以参考 http://www.yuntucredit.com

不邀自来；觉得光摆一些Fancy的图表流程一点用都没有…骗几个外行赞而已…
我就只谈一谈保险行业的欺诈风控吧…
目前保险行业做的风控最好的是平安。其他几个基本停留在业务风控上。为什么这么说呢？因为平安是少有的做了业务数据外的操作数据风控的集团。
其次人保人寿也都搭建了基于业务数据的风控模型，构建了黑名单灰名单，有一套完整的风控体系。（主要说的是寿险财险车险）单就结果来看，事后查出并追回的骗保费用全国来看少说也有几千万级别了。
我倒觉得现行模型表现并不如树模型好，尤其是保险行业树模型反而更贴近业务更能Make Sense地发现风险点。

我们也尝试做了预测总模型，效果怎么说呢，比猜好很多，但是依旧离实用比较少。


另外银行的欺诈方面建行，汇丰都做得不错，不过细说就深了，因为银行内部风险特别大，此外欺诈风险只是银行面临风险很小的一部分。

总之数据质量很重要。比它更重要的是领导的支持，大数据风控这个东西你没个领导的支持，没个管理的部门，没有激励的机制，只有模型，都是空的。





由于题主提出的问题围绕着风控模型，而讨论模型必定和实际的应用场景和数据源相关，因此就前四个问题一并回答。
首先金融科技公司大致分为三类，基于线上垂直领域（教育、医疗、电商）、基于特定客群（学生、蓝领、白领）、基于线下场景（车贷、租房）。不同公司在数据维度、授信客群、产品上都有较大区别。基本而言，风险主要集中于信用风险及欺诈风险。
在此简单介绍下消费信贷产品在贷款各个环节风控主要模型对两类风险的把控。

一、模型在信用风险的用途：
1.授信准入阶段
首先是授信准入阶段，此阶段最重要的模型是进件评分卡模型，数据来源主要分为申请信息、历史消费信息、外部信息（例如多投借贷、公积金等）。常用模型包含LR、Xgboost、FFM等。不同模型的选取由是否需要在线更新、可解释性、线上部署环境等多种因素决定。LR的研究非常成熟，有完整的工业分布式解决方案和在线增量学习的理论基础，包括各种带正则项的变种，是非常理想的建模方法，很多时候它还会作为基准型，用于评价复杂模型的提升效果。
一般的线性模型会遇到两个问题：
一是非线性特征的学习，比如年龄。一般使用的方法是进行变量离散化，把年龄分成不同的段或者使用稀疏编码或者自编码等算法对品类或者其他信息进行重构。
二是交互影响，例如收入特征和年龄特征的交叉。高收入的中年人是干爹和干妈，高收入的年轻人是高富帅和白富美，两者的特点完全不一样。所以我们也会使用Xgboost等模型加工非线性特征，或使用FM/FFM类算法学习交叉特征，以此提升模型拟合能力。
此外在这个环节需要注意的是，由于很多公司的数据维度是有限的，分数低的用户并不一定是逾期风险较高的，而可能仅仅是留下数据较少的用户，随着业务的逐步扩张，怎么再去找更多的维度或者在原有数据维度上构建更细腻度的特征来刻画之前无法覆盖的用户群体是关键。
其次由于黑产的猖獗，时刻需要提防刷分、养号的用户，最好的解决方式是通过分析异常群体的行为，构建有区分度的特征或者引入更多数据维度使得可以更加细腻的刻画正常用户的行为，最后还需要结合产品去完善模型。
业务扩张的时候，客群的分布可能发生较大变化，引起的概念漂移也是值得关注的。

2.用户生命周期阶段
当用户准入后需要进行用户生命周期管理，常用到模型是行为评分卡。
和准入阶段不一样，在这个阶段，用户由于大多已经有过至少一次的还款行为，因此可以在数据维度加入借贷数据。
除此之外，需要考虑如何调整额度和息费，保证优质的用户得到更低的息费和更高的额度，而数据表现较差的用户需要用更高的息费来覆盖风险。
但不顾风险的一味最求高收益和不求收益的低风险都是没有意义的。定价模型的重点在于对用户需求和风险的合理预估，调整各个用户群体的息费和额度档次。实则可以看成对资金在不同风险回报的分配，使得在一定的风险下，总体风险收益最大化，技术上会涉及很多带约束的优化问题。

3.催收阶段
最后一个阶段，一小部分用户会逾期进入催收阶段。
这个时期重点是失联修复和催收评分卡，即刻画用户经过一定的催收动作后还款的可能性。
失联修复很好理解，就是通过各种社交数据，建立起关系网络找出与欠款人可能相关的人或者欠款人的其他联系方式。而催收评分卡需要使用到催收数据，催收数据大多是文本音频类型文件备份，因此对这种非结构类型数据的挖掘是这个阶段的核心。
催收的时机，是催收成功最重要的因素。由于催收资源有限，我们需要按照一定的分配规则来分配催收资源。在逾期的较早时期，应该将更多的资源放在较难催收的用户上，而其他的用户可能由于是忘记还款或者其他的非恶意拖欠原因没有还钱，可能给予一段时间会自我救赎；而在催收晚期，则需要放置更多催收资源在能够催回的用户上，尽最大可能降低损失。

二、模型在反欺诈风险方面的用途：
除了上述的信用风险，还有一块较大的职责就是欺诈风险。
现阶段，业界更多关注的是有组织参与的中介欺诈，常见的如批注、盗号、薅羊毛、养号、套现等诸多行为的识别。由于是团伙作案，更多是基于社交网络的社团发现算法来对中介的识别，或者是利用套现中的地址集中性相似性等特点来识别中介，或使用时间序列算法来分析用户的历史行为轨迹，手机传感器信息等生物指纹数据来核实身份。
欺诈风险的难点有别于信用风险，在较多场景下很难定义好坏用户。因此关键在于标签的获得。通常需要同案件调查人员配合，因为他们能够准确定义欺诈，同时能够还原犯罪手法，针对于模型Y变量定义，X变量设计都很有帮助。
其次，由于对抗性强，因此如何检测未发现的欺诈模式和模型的更新速度更加关键。目前这一块工作业界发展都比较滞后。
最后，授信客群的变化或者欺诈团伙作案手法的变化导致原有模型可能失效，加上风险的滞后性，最新可用的训练数据可能已经离目前较远，如何从最新的数据获取模式与旧的数据模式的遗忘是难点。

三、补充
最后，补充如下几点模型评测的注意事项：
1. 由于线下训练环境和线上真实用户群体存在差异，模型的泛化能力很重要，需要确保模型学习到的是有区分度的模式而不是数据中的噪音。
2. 线下使用评测指标主要是刻画准确度与区分度的ks、auc、洛伦兹曲线和Lift曲线等和模型稳定性指标psi。
3. 客群逾期率的高低和公司产品的形态有重要关系，短期提升可以通过反欺诈技术得到改善、而中长期需要依托信用风险模型、但最终还得看产品的授信客群，面向不同客群的风控模型的指标对比试没有意义的。


更新一下有效性指标中的区分能力指标：
KS(Kolmogorov-Smirnov)：KS用于模型风险区分能力进行评估，指标衡量的是好坏样本累计分部之间的差值。好坏样本累计差异越大，KS指标越大，那么模型的风险区分能力越强。
KS的计算步骤如下：
1. 计算每个评分区间的好坏账户数。
2. 计算每个评分区间的累计好账户数占总好账户数比率(good%)和累计坏账户数占总坏账户数比率(bad%)。
3. 计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值（累计good%-累计bad%），然后对这些绝对值取最大值即得此评分卡的K-S值。


·GINI系数:也是用于模型风险区分能力进行评估。GINI统计值衡量坏账户数在好账户数上的的累积分布与随机分布曲线之间的面积，好账户与坏账户分布之间的差异越大，GINI指标越高，表明模型的风险区分能力越强。
GINI系数的计算步骤如下：
1. 计算每个评分区间的好坏账户数。
2. 计算每个评分区间的累计好账户数占总好账户数比率（累计good%）和累计坏账户数占总坏账户数比率(累计bad%)。
3. 按照累计好账户占比和累计坏账户占比得出下图所示曲线ADC。
4. 计算出图中阴影部分面积，阴影面积占直角三角形ABC面积的百分比，即为GINI系数。



以下是原文
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
楼主范围太广。不同的行业有不同的风控目标，不同的风控过程和程度，也有不同的风控结果。其次同一行业风险也分多种风险，对不同的风险（信用风险，操作风险，市场风险）也有不同的应对办法以及模型建设。


只讲一讲中国金融行业中的银行的信用风控与大数据的渊源。


1，风控意义与大数据建模分析优点: 中国的金融行业必定在金融全球化的洗礼下一步步找到更大市场，相比中国制造业有成长更快的趋势。而此刻，风控就显得尤为重要。都知道收益越大风险越大，当然而我们更想的如果是在中间找到一个平衡点让收益大的情况下拥有尽可能小的风险。而大数据建模就可以尽可能实现这点:提高审批效率，降低人工成本，减少因非客观判断原因造成的失误的风险。


2,大数据建模目标。第一点目标做信贷工厂的量化建设:清洗银行历史数据用于数据建模形成评分卡，再与规则结合对贷款生命周期三个阶段（申请贷后催收）的好坏客户提供决策建议的预测框架（自动通过，人工审核，审慎审核，还是建议拒绝）。 第二点目标内评合规:背景是巴塞尔协议:衡量银行的资本充足率和资本准备是符合巴塞尔协议的规定，如果不符合应该采取什么样的措施。


3，关于建模:前:建模的变量以及数据都是通过层层原始分析，挖掘分析，变量分组，变量降维，过度拟合VIF检测，以及业务逻辑选择出来的。中:而模型的建设本来有方差分析，相关性分析，逻辑回归，决策树，神经网络分析这几种。但是由于Y变量都一般为非线性所以基本都用LOGISTIC逻辑回归。后:模型建好后还需要用PSI检验模型客群的稳定性，用KS或者GINI函数检验模型的区分能力。（公式我就不给啦~感兴趣的孩子肯定有自己学习的方式）如果不太理想就再改进，这是一个做循环的闭环式过程直到选到最佳的。（PS:建模工具:SAS， 由于可以处理相当庞大的数据且在美国极其权威的认证而著称的。别的我就不评价了嘿）


4,好的信用风控的评估效果一主要从准确性，稳定性，可解释性三个方面来评估模型。其中准确性指标包括感受性曲线下面积(ROC_AUC)和区分度指标(Kolmogorov-Smirnov，KS)，稳定性指标主要参考群体稳定指数(Population Shift Index，PSI)。可解释性可通过指标重要度来进行评估，其中指标重要度用于衡量各个解释变量对算法预测结果影响的程度。注意:一定要将大数据建模与业务逻辑紧密联系!
分割线---------------------------------------------------------- 当然，个人觉得知道模型背后的理论也是非常有必要的。让我们顺着逻辑回归来讲。 一 首先是假设检验中假设建立。什么是假设检验呢，假设检验背后的原理是什么呢，我们模型中具体的假设是什么呢。
假设检验分为原假设H和备择假设H0，我们后面会推翻H来证明我们的H0是正确的。
假设检验的原理也就是我们要推翻的这个H的理由是:小概率事件不可能发生。（在此我举一个经典的例子）

在模型中我们的假设便是我们逻辑回归的因变量和自变量之间没有线性关系。

也就是这里面的beta们都是0。
二，never say yes.在原假设正确的前提下，确定检验统计数并计算出统计数的估计值（即构造统计量并计算统计量的估计值)
一般我们会把统计量构造成符合正态分布、卡方分布、F分布的情况，由构造的统计量不同可分为u检验、卡方检验、F检验等。
这里我们以卡方分布统计量为例子：

在各种假设情形下，实际频数与理论频数偏离的总和即为卡方值，它近似服从卡方为V的卡方分布，因此可以用卡方分布的理论来进行假设检验。


三、计算P值，或确定临界值，并比较临界值与统计数值的大小，根据”小概率事件在一次实验中几乎是不可能发生的原理“得出结论统计结果分析
显著性水平：这里的显著是一个统计学的概念，是指原假设发生是一个小概率事件，统计学上用来确定或否定原假设为小概率事件的概率标准叫做显著性水平。原假设发生的概率如果小于或等于5%，一般认为认为是小概率事件，这也是统计学上达到了”显著“，这时的显著性水平为5%。
拒绝域：当由样本计算的统计量落入该区域内则拒绝原假设，接受备择假设，拒绝域的边界称为临界值。当原假设正确时，它被拒绝的概率不得超过给定的显著性水平a（阿尔法），阿尔法通常取值为0.05,0.01，因此落在拒绝域内是一个小概率事件。
还是以卡方检验为例
以下是卡方分布的密度函数，X轴是卡方值，Y轴是发生的P概率。

换句简单易懂的话就是，我们计算实际频数与理论频数的偏离程度即卡方值非常大的情况下概率是非常小的是不会发生的，当X2卡方值远远大于3.84，相应的我们X轴远方对应的就是越来越小的P概率。那么也就是说我们的假设是不成立的，也就是说因变量和自变量之间他们是相关的。并且在原假设情况下卡方值越大也就代表越不可能不相关，也就是越可能相关。
当然在确定检验我们单个系数的时候会用来卡方检验，整个模型的检验的时候就会用到我们F检验，T检验，他们都和我们的卡方有一定的联系。

Logistic回归
目前国内90%以上的建模团队都使用Logistic回归做评分卡，当然还有少数人使用决策树，神经网络和机器学习目前还没在此行业有显著成果。
Logistic制作评分卡模型的衡量标准是K-S值的大小，依据数据质量和建模能力在0-0.5之间，一般在0.3以上才可用，好的模型可以达到0.35。
芝麻分模型的K-S值在0.32左右。


一、什么是风控，具体指什么？
很多行业会用到风控这个词汇，像券商、保险、银行甚至制造业，都会设置风控这个岗位，风控的意义是通过各种手段去管理可以预见的风险，保证公司业务的收益。
本人做的是个人贷款风险建模，对其他行业不是很了解，这里主要讲个贷。个人贷款的风控具体通过反欺诈、信贷策略、审批、贷后管理手段保证贷款本金和利息能够收回。

二、用到的大数据有哪些，获取渠道？
目前用来建模的数据包含：
1、申请表数据（身份信息、收入水平、工作单位、联系人等），这部分是申请贷款时客户自己填写的。
2、行为数据（消费能力、地理位置、购物偏好等），这部分是通过客户授权采集到的。
3、信贷历史（信用卡数量、还款历史、房贷信息等），这部分是央行征信查询获得的。
4、行内数据（存款额、卡数量、用户等级等），这部分是存量客户在某行存款、开卡等记录。

三、应用案例
1、欺诈风险用到模型主要是社会关系网络模型，通过每笔案件之间的关系，判断新案件是欺诈申请的可能性。
2、信用风险主要用到模型是逻辑回归建立评分卡（也有的用决策树），量化新申请人可能违约的概率，根据评分高低制定不同的授信规则和催收策略。
3、贷后管理也用到行为评分卡，例如额度调整和客户风险分池管理等。
现在很多金融机构都能够用大数据模型自动做出决策，大数据风控也用到很多场景中，比如租房分期、手机分期、二手车等。前几天本人刚刚通过某知名房产中介的app，贷款租了一套房子，全程无人工审核，两分钟搞定，非常便捷。

四、评估效果
模型效果评估指标大同小异，KS值，GINI系数，ROC等都是评价模型区分好坏客户的能力，以目前我国数据质量来看，一般来说KS达到37以上就不错了。再一个是人群稳定性PSI指数，当客户趋于不稳定时，就该重新调整风控策略，或者重建评分卡了。
五、风控工作的注意点
每个行业不一样，单以个贷来说，每家公司的优势都不尽相同，目前做消费贷款的公司既有企业，也有网商，还有银行系。这个问题真是不好回答，只能说八仙过海各显神通吧。








风控是什么：
• 顾名思义,风控就是风险控制,最大程度地控制作弊和欺诈的发生,保障网站 的正常运营和用户体验
• 风险和作弊行为的发现、识别和处置
• 风控和反作弊是持续的博弈过程,cat-and-mouse game,时效性强,对抗性
强
• 三板斧:rules；models；strategy

流程包括：

产品体系：



数据：

一般业务数据：用户、商品、交易、点击、浏览、搜索、评价、服务、处罚等
安全业务数据：设备数据（UA、cookie、MAC、Umid、IMEI、IMSI）、位置数据（IP/LBS/GPS）、行为信息、生物信息、其他

算法：

机器学习：分类、聚类、graph算法
异常检测
图像算法：人脸识别、OCR、图像搜索

绝大多数场景使用RF/GBDT+LR/C5.0

注意点：

• 部分高风险业务,可以投入人力审核,追求更高的准确率/召回率
• 风险(异常)占比少,属于非平衡数据集
• 对抗意识强,模型衰减快,需要结合处置手段
• 风控的成本与回报意识,平衡人力和风险
• 能够采用更复杂的算法,但需要平衡用户体验和可解释性

效果评估：
case 1：如何判断某笔交易是否虚假？



其他：

  ● 具体的问题定义需要从业务的漏洞、运营规则、法律等方面去思考判断
  ● 处罚的机制需要平衡用户的体验
  ● 样本和特征、召回都需要大量领域的知识沉淀
  ● 评分和识别逻辑要能讲的通



目前贷款的风控因为每一个样本的收集都需要放款来收集，想想每人放一万，一个亿也就只能放1万人，所以样本量不会太大。所以所谓大数据风控主要是大在特征的数据上。很多时候是用了很多传统上不怎么敢用的特征。比如传统风控比较害怕missing value 比较害怕不稳定的特征 这些都是大数据风控需要解决的。
说到模型，既然是特征多，样本少，那就需要一个非常抗过拟合的模型。另外如果是单独针对反欺诈而不是信用，因为问题比较非线性，所以需要一个有非线性能力的模型。满足这两者要求的都可以。
当然上面说到的只是针对预测贷款用户好坏的二分类问题，至于很多风控领域的其他问题，就有不同的解决方案了。
说到有效性。据我所知目前市场上有一些非常小额短期的产品已经可以完全按照一个模型放款并盈利了。完全不需要人参与。这类产品通过小额解决了样本少的问题。通过短期解决了收集label慢的问题。所以还不太容易推广到大额长期产品上去。


结合平时的工作经验回答下，大数据风控一般来讲有如下几个特征：

1.高对抗性
现在黑产非常庞大，刷单、薅羊毛、密码爆破、扫号、发帖机、灌水等等时时刻刻都在发生，无时无刻不在攻防。

2.灵活性
攻击者不断变化特征和行为，风控策略每天都需要更新，必须要保证风控策略的灵活性。

3.准确性
风控策略首先需要保证准确性，在保证准确性的同时再去提高召回率，准确性太低肯定会引起大量用户投诉。


大数据风控对模型的挑战：

1.模型的泛化能力
我们平时上线的一些模型，上线时可能效果非常好，但是上线后命中量基本是直线下降状态，一周后命中量可能降到接近零。不得不佩服黑产的强大，比较简单的模型意义不大，几天甚至几个小时就可以尝试出来并规避。我们知道复杂的特征和模型可以增强模型的泛化能力，采用复杂特征和更多维度的特征是很有效的。

2.模型的可解释性
风控模型识别出来的数据需要做相应的处理，任何机器识别处理都不可能完全避免用户的投诉和异义，对于模型一定要了解业务特征，能够转化为客服和用户可以理解的语言去解释，使得任何处理我们都有理有据。

3.模型的更新速度
高对抗性场景下，模型快速更新是关键


使用的模型：
1.聚类： 比如常见的相似文本聚类，大量用户发相似帖子是常见的灌水行为，需要处理。
2.分类：比如我们根据已经识别的有风险和无风险的行为，去预测现在正在发生的行为，根据关键字动态去识别预测效果不错。
3.离群点检测：比如登录行为，当同ip登录大量登录失败，这种行为可能是暴力破解，当同ip登录基本全部成功，这种行为可能是机器登录，采用离群点检测发现这两类行为并处理。
4.深度学习：广告图像识别，黄色图像识别等
具体模型和技术：
我们主要使用了kmeans，dbscan，随机森林，c4.5决策树，logistic regression，cart，adaboost，svm，em，深度学习等模型。数据和特征比模型更重要，数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。使用的框架有spark，storm，hadoop，caffe，libsvm，scikit-learn等













