双十一购物狂欢节马上又要到来了，最近各种关于双十一的爆品购物列表在网上层出不穷。如果是网购老司机，一定清楚通常一件商品会有很多维度的标签来展示，比如一个鞋子，它的商品描述可能会是这样的“韩都少女英伦风系带马丁靴女磨砂真皮厚底休闲短靴”。如果是一个包，那么它的商品描述可能是“天天特价包包2016新款秋冬斜挎包韩版手提包流苏贝壳包女包单肩包”。

每个产品的描述都包含非常多的维度，可能是时间、产地、款式等等，如何按照特定的维度将数以万计的产品进行归类，往往是电商平台最头痛的问题。这里面最大的挑战是如何获取每种商品的维度由哪些标签组成，如果可以通过算法自动学习出例如 地点相关的标签有“日本”、“福建”、“韩国”等词语，那么可以快速的构建标签归类体系，本文将借助PAI平台的文本分析功能，实现一版简单的商品标签自动归类系统。

数据说明
数据是在网上直接下载并且整理的一份2016双十一购物清单，一共2千多个商品描述，每一行代表一款商品的标签聚合，如下图：


我们把这份数据导入PAI进行处理，具体数据上传方式可以查阅PAI的官方文档：https://help.aliyun.com/product/30347.html

实验说明
数据上传完成后，通过拖拽PAI的组件，可以生成如下实验逻辑图，每一步的具体功能已经标注：



下面分模块说明下每个部分的具体功能：

1.上传数据并分词
将数据上传，由shopping_data代表底层数据存储，然后通过分词组件对数据分词，分词是NLP的基础操作，这里不多介绍。

2.增加序号列
因为上传的数据只有一个字段，通过增加序号列为每个数据增加主键，方便接下来的计算，处理后数据如下图：


3.统计词频
展示的是每一个商品中出现的各种词语的个数。

4.生成词向量
使用的是word2vector这个算法，这个算法可以将每个词按照意义在向量维度展开，这个词向量有两层含义。

向量距离近的两个词他们的真实含义会比较相近，比如在我们的数据中，“新加坡”和“日本”都表示产品的产地，那么这两个词的向量距离会比较近。
不同词之间的距离差值也是有意义的，比如“北京”是“中国”的首都，“巴黎”是“法国”的首都，在训练量足够的情况下。|中国|-|北京|=|法国|-|巴黎|
经过word2vector，每个词被映射到百维空间上，生成结果如下图展示：


5.词向量聚类
现在已经产生了词向量，接下来只需要计算出哪些词的向量距离比较近，就可以实现按照意义将标签词归类。这里采用kmeans算法来自动归类，聚类结果展示的是每个词属于哪个聚类簇：


结果验证
最后通过SQL组件，在聚类簇中随意挑选一个类别出来，检验下是否将同一类别的标签进行了自动归类，这里选用第10组聚类簇。

看一下第10组的结果：

通过结果中的“日本”、“俄罗斯”、“韩国”、“云南”、“新疆”、“台湾”
等词可以发现系统自动将一些跟地理相关的标签进行了归类，但是里面混入了“男士内裤”、“坚果”等明显与类别不符合的标签，这个很有可能是因为训练样本数量不足所造成的，如果训练样本足够大，那么标签聚类结果会非常准确。

其它
本文案例已经集成到了PAI首页的模板，请注册使用PAI：https://data.aliyun.com/product/learn
在模板中点击创建即可使用，包含逻辑以及数据：


本文为云栖社区原创内容，未经允许不得转载，如需转载请发送邮件至yqeditor@list.alibaba-inc.com；如果您发现本社区中有涉嫌抄袭的内容，欢迎发送邮件至：yqgroup@service.aliyun.com 进行举报，并提供相关证据，一经查实，本社区将立刻删除涉嫌侵权内容。
【云栖快讯】阿里巴巴小程序繁星计划，20亿补贴第一弹云应用免费申请，限量从速！  详情请点击