本示例主要介绍如何通过数加 MaxCompute + DataWorks 两个产品实现简单的网站数据统计分析。

您通过本示例可快速上手 MaxCompute 进行大数据开发，简单了解在 MaxCompute 做大数据 ETL 的过程，同时了解一些 MaxCompute SQL 和常用数据库 SQL 的基本区别。

适用人群
MaxCompute 初学者，特别是无大数据开发基础但有数据库使用基础者。

示例介绍
房产网上经常会看到一些排行榜，如最近 30 日签约的楼盘排行、签约金额的楼盘排行等，本示例将简单介绍通过对二手房产数据信息表（house_basic_info）的统计分析，得出每个城市二手房均价 Top 5 的楼盘，并且给出该楼盘所在城区，最后让这些数据能够在房产网上呈现。

需求分析
核心目标
统计分析出每个城市二手房均价 Top 5 的楼盘，并且给出该楼盘所在城区，即（城市、楼盘、均价、排名和所在城区）。

数据现状
信息表中，每个楼盘可能有多条记录，多个均价信息，本示例只针对整个楼盘的均价求平均。

信息表中，house_region 中包含城区、街道地址信息，需要拆分出城区信息。

每天数据都有变化，每个数据日期的数据都是全量数据。

操作步骤
步骤1：准备数据

步骤2：配置 RDS 数据源

步骤3：配置数据同步任务

步骤4：执行数据导入任务

步骤5：数据统计分析

步骤6：数据回流

数据回流是指：将结果表回流到网站业务系统，以便网站直接调用数据进行前端显示。

总结
通过后续示例中对数据统计分析的实现，您可以了解到以下内容：

DataWorks（数据工场，原大数据开发套件）是架构在 MaxCompute 的 web 工具，提供界面操作以及数据集成和任务调度功能，而 MaxCompute 提供计算和存储服务。

MaxCompute SQL 作业提交后会有几十秒到数分钟不等的排队调度，所以适合处理跑批作业，一次作业批量处理海量数据，不适合直接对接需要每秒处理几千至数万笔事务的前台业务系统。

MaxCompute SQL 采用的是类似于 SQL 的语法，可以看作是标准 SQL 的子集，但不能因此简单的把 MaxCompute 等价成一个数据库，它在很多方面并不具备数据库的特征，如事务、主键约束、索引等都不支持，更多差异请参见 与其他 SQL 的语法差异。

DataWorks（数据工场）中的数据同步可以实现跨 region 的 RDS 与 MaxCompute 的数据互传，无需特殊处理。


步骤1：数据准备
更新时间：2017-09-06 11:40:31


本页目录
后续步骤
本示例中的数据为二手房网产品数据信息表 house_basic_info，存储于 RDS-MySQL（区域：阿里云华南 1 可用区 A，网络为专有网络），表数据每天全量更新。

注意：

您可以通过 数加平台公开数据集-二手房产数据集 直接使用 二手房网产品数据信息表 ，不过数据量可能与本示例呈现的不完全一致。

数据说明如下：

字段	字段类型	字段说明
house_id	varchar	房产 ID
house_city	varchar	房产所在城市
house_total_price	Double	房产总价
house_unit_price	Double	房产均价
house_type	varchar	房产类型
house_floor	varchar	房产楼层
house_direction	varchar	房产方向
house_deckoration	varchar	房产装修
house_area	Double	房产面积
house_community_name	varchar	房产所在小区
house_region	varchar	房产所在地区
proj_name	varchar	楼盘名称
proj_addr	varchar	项目地址
period	int	产权年限
property	varchar	物业公司
greening_rate	varchar	绿化率
property_costs	varchar	物业费用
datetime	varchar	数据日期
数据样例（英文逗号分隔）：

000404705c6add1dc08e54ba10720698,beijing,8000000,72717,3室1厅,低楼层/共24层,南,平层/精装,137,玺萌丽苑,丰台 草桥 三至四环,null,null,null,null,null,null,20170605
RDS-MySQL 上 house_basic_info 表的建表语句，如下所示：

CREATE TABLE `house_basic_info` (
    `house_id` varchar(1024) NOT NULL COMMENT '房产 ID',
    `house_city` varchar(1024) NULL COMMENT '房产所在城市',
    `house_total_price` double NULL COMMENT '房产总价',
    `house_unit_price` double NULL COMMENT '房产均价',
    `house_type` varchar(1024) NULL COMMENT '房产类型',
    `house_floor` varchar(1024) NULL COMMENT '房产楼层',
    `house_direction` varchar(1024) NULL COMMENT '房产方向',
    `house_deckoration` varchar(512) NULL COMMENT '房产装修',
    `house_area` double NULL COMMENT '房产面积',
    `house_community_name` varchar(1024) NULL COMMENT '房产所在小区',
    `house_region` varchar(1024) NULL COMMENT '房产所在地区',
    `proj_name` varchar(1024) NULL,
    `proj_addr` varchar(1024) NULL,
    `period` int(11) NULL,
    `property` varchar(1024) NULL,
    `greening_rate` varchar(1024) NULL,
    `property_costs` varchar(1024) NULL,
    `datetime` varchar(512) NULL COMMENT '数据日期'
) ENGINE=InnoDB
DEFAULT CHARACTER SET=utf8 COLLATE=utf8_general_ci
COMMENT='二手房网产品数据信息表';
后续步骤
现在，您已经对实验所需的数据做了一定的准备和了解，您可以继续学习下一个教程。在该教程中您将学习如何配置实验所需的 RDS 数据源。详情请参见 配置 RDS 数据源。


步骤2：配置RDS数据源
更新时间：2017-11-08 13:40:05


本页目录
前提条件
操作步骤
后续步骤
前提条件
因 RDS 数据安全的限制，DataWorks（数据工场，原大数据开发套件）的数据同步任务要与 RDS 数据库进行连通，必须将执行数据同步任务的机器 IP 添加到 RDS 的白名单中，详情请参见 IP 白名单，您也可通过配置数据源界面中的 IP 查看入口进行查看。

操作步骤
以开发者身份进入 DataWorks 管理控制台，单击对应项目操作栏中的 进入工作区。

单击顶部菜单栏中的 数据集成，导航至 数据源 页面。

单击 新增数据源。

在新建数据源弹出框中，选择数据源类型为 RDS > MySQL。

选择以 RDS 实例形配置该 MySQL 数据源。

1

查看 RDS > MySQL 中的实例 ID，如下图所示：

instance_id

单击 测试连通性。

测试连通性通过后，单击 确定。

注意：

本示例中 RDS 实例所在区域为华南 1，网络类型为专有网络，通过 DataWorks 进行数据同步时，属于跨 region 走专有网络方式导数据。

DataWorks 的数据集成针对 RDS 通过反向代理自动检测使得网络能够互通，无需其他特殊处理即可保证数据同步正常连通。

后续步骤
现在，您已经学习了如何配置 RDS 数据源，您可以继续学习下一个教程。在该教程中您将学习如何通过创建同步任务来把 RDS 数据导入到 MaxCompute 中。详情请参见 配置数据同步任务。

步骤3：配置数据同步任务
更新时间：2017-11-08 15:32:09


本页目录
操作步骤
后续步骤
根据前文的操作，您已经成功 配置 RDS 数据源，本文将为您介绍如何配置数据同步任务，以将 RDS 数据源中的数据同步至 MaxCompute 中。

操作步骤
以开发者身份进入 DataWorks 管理控制台，单击对应项目操作栏中的 进入工作区。

单击顶部菜单栏中的 数据集成，导航至 数据同步 页面。

单击 向导模式，新建一个同步任务。

选择来源。

选择 mysql 数据源及源头表 hw_test，然后单击 下一步，如下图所示：

1

表每天全量更新，每次统计数据时，只需统计数据日期为昨天完整一天数据。因此数据过滤时，每天自动调度取 datatime 为昨天的日期，可以使用系统参数 ${bdp.system.bizdate} 代替，使任务每天调度执行自动替换字段值，系统参数详情请参见 系统调度参数。

选择目标。

本示例是将数据导入到 MaxCompute 项目中，所以目标选择默认的数据源 odps_first(odps)，此时并未创建目标表，所以需要单击 快速建表 来创建目标表。更多建表方式请参见 创建表。

1

快速建表弹框中显示系统自动根据源表结构生成的对应 MaxCompute 建表语句：

CREATE TABLE IF NOT EXISTS   your_table_name   (
house_id                      STRING   COMMENT '*',
house_city                    STRING   COMMENT '*',
house_total_price             DOUBLE   COMMENT '*',
house_unit_price              DOUBLE   COMMENT '*',
house_type                    STRING   COMMENT '*',
house_floor                   STRING   COMMENT '*',
house_direction               STRING   COMMENT '*',
house_deckoration             STRING   COMMENT '*',
house_area                    DOUBLE   COMMENT '*',
house_community_name          STRING   COMMENT '*',
house_region                  STRING   COMMENT '*',
proj_name                     STRING   COMMENT '*',
proj_addr                     STRING   COMMENT '*',
period                        BIGINT   COMMENT '*',
property                      STRING   COMMENT '*',
greening_rate                 STRING   COMMENT '*',
property_costs                STRING   COMMENT '*',
datetime                      STRING   COMMENT '*'
)
COMMENT '*'
PARTITIONED BY (pt STRING);
注意：

自动生成的代码中，表名需要修改成真正的目标表表名，可以与源表表名一致，即 house_basic_info。

自动生成的代码中，源表中 varchar 类型会对应 string 类型，int 类型会对应 bigint 类型。MaxCompute 目前 只支持 6 种数据类型，与常用数据库数据类型有所差异。

自动生成的代码中，字段不能指定默认值、不能指定是否非空默认都是可空、不能指定长度默认每个字段长度上限为 8M。

自动生成的代码会创建分区表，且分区名称为 pt。MySQL 数据库中没有分区概念，MaxCompute 的分区概念与 Hadoop 分区概念类似，详情请参见 分区 。本示例中的目标表可以保留分区设置，以时间作为分区。

既然已经有时间分区，那么源表的 datetime 字段可以不需要同步到目标表，表也可以不需要创建该字段。

常用数据库 SQL 与 MaxCompute SQL 的更多差异请参见 与主流 SQL 的差异。

综上所述，修改弹出框中的建表语句，并单击 提交。MaxCompute 建表语句如下所示：

CREATE TABLE IF NOT EXISTS   house_basic_info   (
house_id                      STRING   COMMENT '*',
house_city                    STRING   COMMENT '*',
house_total_price             DOUBLE   COMMENT '*',
house_unit_price              DOUBLE   COMMENT '*',
house_type                    STRING   COMMENT '*',
house_floor                   STRING   COMMENT '*',
house_direction               STRING   COMMENT '*',
house_deckoration             STRING   COMMENT '*',
house_area                    DOUBLE   COMMENT '*',
house_community_name          STRING   COMMENT '*',
house_region                  STRING   COMMENT '*',
proj_name                     STRING   COMMENT '*',
proj_addr                     STRING   COMMENT '*',
period                        BIGINT   COMMENT '*',
property                      STRING   COMMENT '*',
greening_rate                 STRING   COMMENT '*',
property_costs                STRING   COMMENT '*'
)
COMMENT '*'
PARTITIONED BY (pt STRING);
配置目标如下：

1

分区值保留默认的 ${bdp.system.bizdate}，与来源表的过滤条件取的 datetime 数据日期对应，表示该分区存放的数据为源表中 datetime=${bdp.system.bizdate} 的数据。

清理规则保留默认选项，写入前清理已有数据，若是分区表，则只清理当前分区中的数据（若有）。

字段映射。

直接保留默认设置即可。源表和目标表字段名都一致会自动对应好，源表 datetime 字段无对应目标字段且不用同步，因此无需做任何处理。

通道控制。

本示例中都保留默认设置即可，通道控制各项配置的详细说明请参见 数据同步通道控制参数设置。

保存 并 提交。

保存任务时，您可以创建单独的目录进行存放，本示例直接用目标表名称作为任务名称。

提交任务主要是将任务提交到调度系统，使得任务可以按照调度配置进行自动运行。本示例调度配置保留默认配置，调度周期为 天 调度。

后续步骤
现在，您已经学习了如何配置数据同步任务，您可以继续学习下一个教程。在该教程中您将学习如何执行数据同步任务，将 RDS 中的数据成功导入 MaxCompute 中。详情请参见 执行数据导入任务。



步骤4：执行数据导入任务
更新时间：2017-11-08 15:33:05


本页目录
操作步骤
后续步骤
根据前文的操作，您已成功 配置数据同步任务，本文将为您介绍如何执行数据同步任务，将 RDS 中的数据成功导入 MaxCompute 中。

操作步骤
进入 运维中心 > 任务管理 页面。

打开任务 house_basic_info，在任务视图上右键单击任务名，选择 测试节点。

1

根据跳转页面的提示，单击 确认 和 运行。

等待任务执行成功后，进入 DataWorks > 数据开发 页面，创建一个脚本文件。

执行 select 语句，查看表 house_basic_info 数据是否同步成功。如下图所示：

图片名称

后续步骤
现在，您已经学习了如何执行数据同步任务，并验证是否同步成功，您可以继续学习下一个教程。在该教程中您将学习如何通过 MaxCompute SQL、MR 等对数据进行加工处理。详情请参见 数据统计分析。


步骤5：数据统计分析
更新时间：2017-09-06 12:19:12


本页目录
操作步骤
后续步骤
通过 前文 的操作，您已经成功将 RDS 数据源中的数据同步至 MaxCompute 表中，本文将为您介绍如何通过 MaxCompute SQL、MR 等对数据进行统计分析。

操作步骤
创建目标表
本示例的核心目标为：统计分析出每个城市二手房均价 Top 5 的楼盘，并且给出该楼盘所在城区，即（城市、楼盘、均价、排名和所在城区）。所以要首先创建目标表。

以项目管理员身份进入 大数据开发套件管理控制台，单击 项目列表 下对应项目操作栏中的 进入工作区。

进入顶部菜单栏中的 数据开发 页面，单击 新建，选择 新建表。如下图所示：



在新建表页面，输入如下建表语句，单击 确认。

CREATE TABLE IF NOT EXISTS house_unit_price_top5 (
 house_city STRING,
 house_community_name STRING,
 house_unit_price_all DOUBLE,
 area STRING,
 tops BIGINT
)
PARTITIONED BY (
 pt STRING
);
创建任务进行数据统计分析
进入顶部菜单栏中的 数据开发 页面，单击 新建，选择 新建任务。如下图所示：



新建 ODPS_SQL 节点任务，如下图所示：

编辑 SQL 代码
进入 ODPS_SQL 节点任务页面后，编辑如下 SQL 代码：

--产出每个城市每个楼盘的均价临时表
--分区值是对应数据导入任务配置的分区值，保证每天运行都是取当天导入的最新分区。
DROP TABLE IF EXISTS t_house_unit_price_info;
CREATE TABLE IF NOT EXISTS t_house_unit_price_info
AS
SELECT house_city,
     house_community_name,
     AVG(house_unit_price) AS house_unit_price_all
FROM house_basic_info
WHERE pt = '${bdp.system.bizdate}'
GROUP BY house_city,
    house_community_name;
--拆分house_region字段只取城区名称输出字段为area，并存储到一个临时表。
--分区值是对应数据导入任务配置的分区值，保证每天运行都是取当天导入的最新分区。
DROP TABLE IF EXISTS t_house_area;
CREATE TABLE IF NOT EXISTS t_house_area
AS
SELECT distinct  house_city,
    house_community_name,
    split_part(house_region, ' ', 1) AS area
FROM house_basic_info
WHERE pt = '${bdp.system.bizdate}';
--产出最终目标表：每天每个城市二手房均价top 5的楼盘并且给出该楼盘所在城区。
--分区值是对应数据导入任务配置的分区值，保证每天运行产出的日期分区值与源表数据日期一致。
INSERT OVERWRITE TABLE house_unit_price_top5 PARTITION (pt='${bdp.system.bizdate}')
SELECT a.house_city,
       a.house_community_name,
       a.house_unit_price_all,
       b.area,
       a.tops
FROM (
    SELECT house_city
           house_community_name,
           house_unit_price_all,
           ROW_NUMBER() OVER (PARTITION BY house_city ORDER BY house_unit_price_all DESC) AS tops
    FROM t_house_unit_price_info
) a
JOIN t_house_area b
ON a.house_city = b.house_city
    AND a.house_community_name = b.house_community_name
    AND a.tops < 6;
注意：

MaxCompoute SQL 语法类似于常用 SQL 语法，可以看作是标准 SQL 的子集，但 MaxCompute 在很多方面并不具备常用数据库的特征，如事务、主键约束、索引等都不支持，因而 SQL 也有一定的差异。

在将数据导入目标表时，已经简单介绍了一些 DDL 语法的差异，针对此处的 DML 语句，简单补充以下内容：

产出每个城市每个楼盘的均价临时表 的整个语句只需要修改 where 条件中的 pt 条件，即可直接在 MySQL 上执行。

拆分 house_region 字段 语句中 split_part() 函数是 MaxCompute 内置的字符串函数，可以直接在 SQL 中使用，对应 MySQL 上 substring_index() 或其他。

产出目标表语句中，ROW_NUMBER() 是 MaxCompute 内置的窗口函数，在本示i例中主要作用于计算排行，可在 SQL 中直接使用，MySQL 上没有可直接对应的函数。

产出目标表语句中，insert overwrite（或 insert into） 后要加 table 关键字，MySQL 或 Oracle 不需要 table 关键字。

MaxCompute SQL 和常用 SQl 的更多差异请参见 与其他 SQL 的差异。

调度配置和参数配置
编辑好代码后，单击工具栏中的执行按钮执行 SQL 语句，对其进行探查。确定无误后进行调度配置。主要包括调度属性和依赖属性：

调度属性：由于每天调度一次，直接保留默认配置即可。

依赖属性：由于本任务处理的数据来源是数据导入任务 house_basic_info 产出大数据，为了保证本任务执行时，数据导入已经完成，需要将导入任务设置为本任务的上游任务（即父任务）。

1

注意：

由于本任务中只用到系统参数 ${bdp.system.bizdate}，这个参数在系统调度任务时会自动替换，所以无需再进行参数的其他配置。详情请参见 系统参数说明。

保存并提交
单击工具栏中的 保存 和 提交 按钮，将任务提交到调度系统。

单击工作区右上角 前往运维 按钮，即可到运维中心查看工作流状态。

1

执行任务
与执行数据导入任务的操作类似。执行成功后可以在 数据开发 模块的 SQL 脚本中查看目标表数据。如下图所示：

1

到目前为止，目标表已经正常产出。但是 MaxCompute SQL 在执行时会有一定的等待调度时间，适合做大数据批处理，网站前端读取数据就不适合直接读 MaxCompute 的数据，所以接下来需要把目标表回流到网站业务库。

后续步骤
现在，您已经学习了如何通过 MaxCompute SQL 对数据进行加工处理，并产出最终目标表，您可以继续学习下一个教程。在该教程中您将学习如何把目标表回流到网站业务库。详情请参见 数据回流。

--------------

步骤6：数据回流
更新时间：2017-11-08 15:33:05


本页目录
操作步骤
数据回流与数据导入一样，需要配置数据同步任务，不过回流任务来源是 MaxCompute 的表，目标库是业务库，即示例中的 RDS-MySQL 的 house_web_master 数据库。

操作步骤
在 RDS > MySQL 中创建好对应的表，若需要保留每天的数据，可以加一个字段保存日期信息。

进入 DataWorks > 数据集成 页面配置数据源，详情请参见 配置 RDS 数据源。

创建并配置数据同步任务。

假设命名为 house_unit_price_top5_2_mysql，将 MaxCompute 表中的数据同步至 RDS > MySql 中。其中的两项配置如下：

字段配置：如果想直接把源表的分区字段同步到 MySQL 的日期信息字段，如下图所示：

1

依赖属性中，为了保证每次回流都是最新的数据，将数据加工任务 house_unit_price_top5 设置为父任务。如下图所示：

1

保存并提交任务后，在运维管理可以看到工作流状态：

1

执行回流任务，具体操作可参见 执行数据导入任务。

执行成功后，即可到 RDS > MySQL 上查看表数据是否正常导入。



