



于是在之前的基础上我完善了一些内容，先来看看这个项目的介绍吧：

CIM(CROSS-IM) 一款面向开发者的 IM(即时通讯)系统；同时提供了一些组件帮助开发者构建一款属于自己可水平扩展的 IM 。

借助 CIM 你可以实现以下需求：

IM 即时通讯系统。
适用于 APP 的消息推送中间件。
IOT 海量连接场景中的消息透传中间件。
完整源码托管在 GitHub : https://github.com/crossoverJie/cim

演示
本次主要涉及到 IM 即时通讯，所以特地录了两段视频演示（群聊、私聊）。

点击下方链接可以查看视频版 Demo。

YouTube	Bilibili
群聊 私聊	群聊 私聊

也在公网部署了一套演示环境，想要试一试的可以联系我加入内测群获取账号一起尬聊😋。

架构设计
下面来看看具体的架构设计。



CIM 中的各个组件均采用 SpringBoot 构建。
采用 Netty + Google Protocol Buffer 构建底层通信。
Redis 存放各个客户端的路由信息、账号信息、在线状态等。
Zookeeper 用于 IM-server 服务的注册与发现。
整体主要由以下模块组成：

cim-server
IM 服务端；用于接收 client 连接、消息透传、消息推送等功能。

支持集群部署。

cim-forward-route
消息路由服务器；用于处理消息路由、消息转发、用户登录、用户下线以及一些运营工具（获取在线用户数等）。

cim-client
IM 客户端；给用户使用的消息终端，一个命令即可启动并向其他人发起通讯（群聊、私聊）；同时内置了一些常用命令方便使用。

流程图
整体的流程也比较简单，流程图如下：



客户端向 route 发起登录。
登录成功从 Zookeeper 中选择可用 IM-server 返回给客户端，并保存登录、路由信息到 Redis。
客户端向 IM-server 发起长连接，成功后保持心跳。
客户端下线时通过 route 清除状态信息。
所以当我们自己部署时需要以下步骤：

搭建基础中间件 Redis、Zookeeper。
部署 cim-server，这是真正的 IM 服务器，为了满足性能需求所以支持水平扩展，只需要注册到同一个 Zookeeper 即可。
部署 cim-forward-route，这是路由服务器，所有的消息都需要经过它。由于它是无状态的，所以也可以利用 Nginx 代理提高可用性。
cim-client 真正面向用户的客户端；启动之后会自动连接 IM 服务器便可以在控制台收发消息了。
更多使用介绍可以参考快速启动。

详细设计
接下来重点看看具体的实现，比如群聊、私聊消息如何流转；IM 服务端负载均衡；服务如何注册发现等等。

IM 服务端
先来看看服务端；主要是实现客户端上下线、消息下发等功能。

首先是服务启动：




由于是在 SpringBoot 中搭建的，所以在应用启动时需要启动 Netty 服务。

从 pipline 中可以看出使用了 Protobuf 的编解码（具体报文在客户端中分析）。

注册发现
需要满足 IM 服务端的水平扩展需求，所以 cim-server 是需要将自身数据发布到注册中心的。

这里参考之前分享的《搞定服务注册与发现》有具体介绍。

所以在应用启动成功后需要将自身数据注册到 Zookeeper 中。




最主要的目的就是将当前应用的 ip + cim-server-port+ http-port 注册上去。



上图是我在演示环境中注册的两个 cim-server 实例（由于在一台服务器，所以只是端口不同）。

这样在客户端（监听这个 Zookeeper 节点）就能实时的知道目前可用的服务信息。

登录
当客户端请求 cim-forward-route 中的登录接口（详见下文）做完业务验证（就相当于日常登录其他网站一样）之后，客户端会向服务端发起一个长连接，如之前的流程所示：



这时客户端会发送一个特殊报文，表明当前是登录信息。

服务端收到后就需要将该客户端的 userID 和当前 Channel 通道关系保存起来。




同时也缓存了用户的信息，也就是 userID 和 用户名。

离线
当客户端断线后也需要将刚才缓存的信息清除掉。



同时也需要调用 route 接口清除相关信息（具体接口看下文）。

IM 路由


从架构图中可以看出，路由层是非常重要的一环；它提供了一系列的 HTTP 服务承接了客户端和服务端。

目前主要是以下几个接口。

注册接口



由于每一个客户端都是需要登录才能使用的，所以第一步自然是注册。

这里就设计的比较简单，直接利用 Redis 来存储用户信息；用户信息也只有 ID 和 userName 而已。

只是为了方便查询在 Redis 中的 KV 又反过来存储了一份 VK，这样 ID 和 userName 都必须唯一。

登录接口
这里的登录和 cim-server 中的登录不一样，具有业务性质，



登录成功之后需要判断是否是重复登录（一个用户只能运行一个客户端）。
登录成功后需要从 Zookeeper 中获取服务列表（cim-server）并根据某种算法选择一台服务返回给客户端。
登录成功之后还需要保存路由信息，也就是当前用户分配的服务实例保存到 Redis 中。
为了实现只能一个用户登录，使用了 Redis 中的 set 来保存登录信息；利用 userID 作为 key ，重复的登录就会写入失败。




类似于 Java 中的 HashSet，只能去重保存。

获取一台可用的路由实例也比较简单：



先从 Zookeeper 获取所有的服务实例做一个内部缓存。
轮询选择一台服务器（目前只有这一种算法，后续会新增）。
当然要获取 Zookeeper 中的服务实例前自然是需要监听 cim-server 之前注册上去的那个节点。

具体代码如下：





也是在应用启动之后监听 Zookeeper 中的路由节点，一旦发生变化就会更新内部缓存。

这里使用的是 Guava 的 cache，它基于 ConcurrentHashMap，所以可以保证清除、新增缓存的原子性。

群聊接口
这是一个真正发消息的接口，实现的效果就是其中一个客户端发消息，其余所有客户端都能收到！

流程肯定是客户端发送一条消息到服务端，服务端收到后在上文介绍的 SessionSocketHolder 中遍历所有 Channel（通道）然后下发消息即可。

服务端是单机倒也可以，但现在是集群设计。所以所有的客户端会根据之前的轮询算法分配到不同的 cim-server 实例中。

因此就需要路由层来发挥作用了。




路由接口收到消息后首先遍历出所有的客户端和服务实例的关系。

路由关系在 Redis 中的存放如下：



由于 Redis 单线程的特质，当数据量大时；一旦使用 keys 匹配所有 cim-route:* 数据，会导致 Redis 不能处理其他请求。

所以这里改为使用 scan 命令来遍历所有的 cim-route:*。

接着会挨个调用每个客户端所在的服务端的 HTTP 接口用于推送消息。

在 cim-server 中的实现如下：




cim-server 收到消息后会在内部缓存中查询该 userID 的通道，接着只需要发消息即可。

在线用户接口
这是一个辅助接口，可以查询出当前在线用户信息。




实现也很简单，也就是查询之前保存 ”用户登录状态的那个去重 set “即可。

私聊接口
之所以说获取在线用户是一个辅助接口，其实就是用于辅助私聊使用的。

一般我们使用私聊的前提肯定得知道当前哪些用户在线，接着你才会知道你要和谁进行私聊。

类似于这样：



在我们这个场景中，私聊的前提就是需要获得在线用户的 userID。



所以私聊接口在收到消息后需要查询到接收者所在的 cim-server 实例信息，后续的步骤就和群聊一致了。调用接收者所在实例的 HTTP 接口下发信息。

只是群聊是遍历所有的在线用户，私聊只发送一个的区别。

下线接口
一旦客户端下线，我们就需要将之前存放在 Redis 中的一些信息删除掉（路由信息、登录状态）。




IM 客户端
客户端中的一些逻辑其实在上文已经谈到一些了。

登录
第一步也就是登录，需要在启动时调用 route 的登录接口，获得 cim-server 信息再创建连接。



image-20190102001525565



登录过程中 route 接口会判断是否为重复登录，重复登录则会直接退出程序。



接下来是利用 route 接口返回的 cim-server 实例信息（ip+port）创建连接。

最后一步就是发送一个登录标志的信息到服务端，让它保持客户端和 Channel 的关系。



自定义协议
上文提到的一些登录报文、真正的消息报文这些其实都是在我们自定义协议中可以区别出来的。

由于是使用 Google Protocol Buffer 编解码，所以先看看原始格式。



其实这个协议中目前一共就三个字段：

requestId 可以理解为 userId。
reqMsg 就是真正的消息。
type 也就是上文提到的消息类别。
目前主要是三种类型，分别对应不同的业务：



心跳
为了保持客户端和服务端的连接，每隔一段时间没有发送消息都需要自动的发送心跳。

目前的策略是每隔一分钟就是发送一个心跳包到服务端：




这样服务端每隔一分钟没有收到业务消息时就会收到 ping 的心跳包：



内置命令
客户端也内置了一些基本命令来方便使用。

命令	描述
:q	退出客户端
:olu	获取所有在线用户信息
:all	获取所有命令
:	更多命令正在开发中。。


比如输入 :q 就会退出客户端，同时会关闭一些系统资源。




当输入 :olu(onlineUser 的简写)就会去调用 route 的获取所有在线用户接口。




群聊
群聊的使用非常简单，只需要在控制台输入消息回车即可。

这时会去调用 route 的群聊接口。



私聊
私聊也是同理，但前提是需要触发关键字；使用 userId;;消息内容 这样的格式才会给某个用户发送消息，所以一般都需要先使用 :olu 命令获取所以在线用户才方便使用。



消息回调
为了满足一些定制需求，比如消息需要保存之类的。

所以在客户端收到消息之后会回调一个接口，在这个接口中可以自定义实现。




因此先创建了一个 caller 的 bean，这个 bean 中包含了一个 CustomMsgHandleListener 接口，需要自行处理只需要实现此接口即可。

自定义界面
由于我自己不怎么会写界面，但保不准有其他大牛会写。所以客户端中的群聊、私聊、获取在线用户、消息回调等业务(以及之后的业务)都是以接口形式提供。

也方便后面做页面集成，只需要调这些接口就行了；具体实现不用怎么关心。

总结
cim 目前只是第一版，BUG 多，功能少（只拉了几个群友做了测试）；不过后续还会接着完善，至少这一版会给那些没有相关经验的朋友带来一些思路。

后续计划：



完整源码：

https://github.com/crossoverJie/cim

言归正传，上周更新了 cim 第一版：为自己搭建一个分布式 IM(即时通讯) 系统；没想到反响热烈，最高时上了 GitHub Trending Java 版块的首位，一天收到了 300+ 的 star。



现在总共也有 1.3K+ 的 star，有几十个朋友参加了测试，非常感谢大家的支持。

在这过程中也收到一些 bug 反馈，feature 建议；因此这段时间我把一些影响较大的 bug 以及需求比较迫切的 feature 调整了，本次更新的 v1.0.1 版本：

客户端超时自动下线。
新增 AI 模式。
聊天记录查询。
在线用户前缀模糊匹配。
下面谈下几个比较重点的功能。

客户端超时自动下线 这个功能涉及到客户端和服务端的心跳设计，比较有意思，也踩了几个坑；所以准备留到下次单独来聊。

AI 模式
大家应该还记得这个之前刷爆朋友圈的 估值两个一个亿的 AI 核心代码。

和我这里的场景再合适不过了。

于是我新增了一个命令用于一键开启 AI 模式，使用情况大概如下。



欢迎大家更新源码体验，融资的请私聊我🤣。

聊天记录
聊天记录也是一个比较迫切的功能。



使用命令 :q 关键字 即可查询与个人相关的聊天记录。

这个功能其实比较简单，只需要在消息发送及接收消息时保存即可。

但要考虑的一点是，这个保存消息是 IO 操作，不可避免的会有耗时；需要尽量避免对消息发送、接收产生影响。

异步写入消息
因此我把消息写入的过程异步完成，可以不影响真正的业务。

实现起来也挺简单，就是一个典型的生产者消费者模式。



主线程收到消息之后直接写入队列，另外再有一个线程一直源源不断的从队列中取出数据后保存聊天记录。

大概的代码如下：




写入消息的同时会把消费消息的线程打开：



而最终存放消息记录的策略，考虑后还是以最简单的方式存放在客户端，可以降低复杂度。



简单来说就是根据当前日期+用户名写入到磁盘里。

当客户端关闭时利用线程中断的方式停止了消费队列的线程。




这点的设计其实和 logback 写日志的方式比较类似，感兴趣的可以去翻翻 logback 的源码，更加详细。

回调接口
至于收到其他客户端发来的消息时则是利用之前预留的消息回调接口来写入日志。



收到消息后会执行自定义的回调接口。



于是在这个回调方法中实现写入逻辑即可，当后续还有其他的消息处理逻辑时也能在这里直接添加。

当处理逻辑增多时最好是改为责任链模式，更加清晰易维护。

查找算法
接下来是本文着重要讨论的一个查找算法，准确的说是一个前缀模糊匹配的算法。

实现的效果如下：



使用命令 :qu prefix 可以按照前缀的方式搜索用户信息。

当然在命令行中其实意义不大，但是在移动端中确是比较有用的。类似于微信按照用户名匹配：



因为后期打算出一个移动端 APP，所以就先把这个功能实现了。

从效果也看得出来：就是按照输入的前缀匹配字符串（目前只支持英文）。

在没有任何限制的条件下最快、最简单的实现方式可以直接把所有的字符串存放在一个容器中 （List、Set），查询时则挨个遍历；利用 String.startsWith("prefix") 进行匹配。

但这样会有几个问题：

存储资源比较浪费，不管是 list 还是 Set 都会有额外的损耗。
查询效率较低，需要遍历集合后再遍历字符串的 char 数组（String.startsWith 的实现方式）。
字典树
基于以上的问题我们可以考虑下：

假设我需要存放 java,javascript,jsp,php 这些字符串时在 ArrayList 中会怎么存放？



很明显，会是这样完整的存放在一个数组中；同时这个数组还可能存在浪费，没有全部使用完。

但其实仔细观察这些数据会发现有一些共同特点，比如 java,javascript 有共同的前缀 java;和 jsp 有共同的前缀 j。

那是否可以把这些前缀利用起来呢？这样就可以少存储一份。

比如写入 java,javascript 这两个字符串时存放的结构如下：



当再存入一个 jsp 时：



最后再存入 jsf 时：



相信大家应该已经看明白了，按照这样的存储方式可以节省很多内存，同时查询效率也比较高。

比如查询以 jav 开头的数据，只需要从头结点 j 开始往下查询，最后会查询到 ava 以及 script 这两个个结点，所以整个查询路径所经历的字符拼起来就是查询到的结果java+javascript。

如果以 b 开头进行查询，那第一步就会直接返回，这样比在 list 中的效率高很多。

但这个图还不完善，因为不知道查询到啥时候算是匹配到了一个之前写入的字符串。

比如在上图中怎么知道 j+ava 是一个我们之前写入的 java 这个字符呢。

因此我们需要对这种是一个完整字符串的数据打上一个标记：



比如这样，我们将 ava、script、p、f 这几个节点都换一个颜色表示。表明查询到这个字符时就算是匹配到了一个结果。

而查到 s 这个字符颜色不对，代表还需要继续往下查。

比如输入关键字 js 进行匹配时，当它的查询路径走到 s 这里时判断到 s 的颜色不对，所以不会把 js 作为一个匹配结果。而是继续往下查，发现有两个子节点 p、f 颜色都正确，于是把查询的路径 jsp 和 jsf 都作为一个匹配结果。

而只输入 j，则会把下面所有有色的字符拼起来作为结果集合。

这其实就一个典型的字典树。

具体实现
下面则是具体的代码实现，其实算法不像是实现一个业务功能这样好用文字分析；具体还是看源码多调试就明白了。

谈下几个重点的地方吧：



字典树的节点实现，其中的 isEnd 相当于图中的上色。

利用一个 Node[] children 来存放子节点。



为了可以区分大小写查询，所以子节点的长度相当于是 26*2。

写入数据


这里以一个单测为例，写入了三个字符串，那最终形成的数据结构如下：



图中有与上图有几点不同：

每个节点都是一个字符，这样树的高度最高为52。
每个节点的子节点都是长度为 52 的数组；所以可以利用数组的下标表示他代表的字符值。比如 0 就是大 A,26 则是小 a，以此类推。
有点类似于之前提到的布隆过滤器，可以节省内存。
debug 时也能看出符合上图的数据结构：



所以真正的写入步骤如下：



把字符串拆分为 char 数组，并判断大小写计算它所存放在数组中的位置 index。
将当前节点的子节点数组的 index 处新增一个节点。
如果是最后一个字符就将新增的节点置为最后一个节点，也就是上文的改变节点颜色。
最后将当前节点指向下一个节点方便继续写入。



查询总的来说要麻烦一些，其实就是对树进行深度遍历；最终的思想看图就能明白。

所以在 cim 中进行模糊匹配时就用到了这个结构。



字典树的源码在此处：

https://github.com/crossoverJie/cim/blob/master/cim-common/src/main/java/com/crossoverjie/cim/common/data/construct/TrieTree.java

其实利用这个结构还能实现判断某个前缀的单词是否在某堆数据里、某个前缀的单词出现的次数等。

总结
目前 cim 还在火热内测中（虽然群里只有20几人）,感兴趣的朋友可以私聊我拉你入伙☺️



再没有新的 BUG 产生前会着重把这些功能完成了，不出意外下周更新 cim 的心跳重连等机制。

完整源码：

https://github.com/crossoverJie/cim


