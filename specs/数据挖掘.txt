第1章　引论
1.1　为什么进行数据挖掘
1.1.1　迈向信息时代
1.1.2　数据挖掘是信息技术的进化
1.2　什么是数据挖掘
1.3　可以挖掘什么类型的数据
1.3.1　数据库数据
1.3.2　数据仓库
1.3.3　事务数据
1.3.4　其他类型的数据
1.4　可以挖掘什么类型的模式
1.4.1　类/概念描述：特征化与区分
1.4.2　挖掘频繁模式、关联和相关性
1.4.3　用于预测分析的分类与回归
1.4.4　聚类分析
1.4.5　离群点分析
1.4.6　所有模式都是有趣的吗
1.5　使用什么技术
1.5.1　统计学
1.5.2　机器学习
1.5.3　数据库系统与数据仓库
1.5.4　信息检索
1.6　面向什么类型的应用
1.6.1　商务智能
1.6.2　Web搜索引擎
1.7　数据挖掘的主要问题
1.7.1　挖掘方法
1.7.2　用户界面
1.7.3　有效性和可伸缩性
1.7.4　数据库类型的多样性
1.7.5　数据挖掘与社会
1.8　小结
1.9　习题
1.10　文献注释

第2章　认识数据
2.1　数据对象与属性类型
2.1.1　什么是属性
2.1.2　标称属性
2.1.3　二元属性
2.1.4　序数属性
2.1.5　数值属性
2.1.6　离散属性与连续属性
2.2　数据的基本统计描述
2.2.1　中心趋势度量：均值、中位数和众数
2.2.2　度量数据散布：极差、四分位数、方差、标准差和四分位数极差
2.2.3　数据的基本统计描述的图形显示
2.3　数据可视化
2.3.1　基于像素的可视化技术
2.3.2　几何投影可视化技术
2.3.3　基于图符的可视化技术
2.3.4　层次可视化技术
2.3.5　可视化复杂对象和关系
2.4　度量数据的相似性和相异性
2.4.1　数据矩阵与相异性矩阵
2.4.2　标称属性的邻近性度量
2.4.3　二元属性的邻近性度量
2.4.4　数值属性的相异性：闵可夫斯基距离
2.4.5　序数属性的邻近性度量
2.4.6　混合类型属性的相异性
2.4.7　余弦相似性
2.5　小结
2.6　习题
2.7　文献注释

第3章　数据预处理
3.1　数据预处理：概述
3.1.1　数据质量：为什么要对数据预处理
3.1.2　数据预处理的主要任务
3.2　数据清理
3.2.1　缺失值
3.2.2　噪声数据
3.2.3　数据清理作为一个过程
3.3　数据集成
3.3.1　实体识别问题
3.3.2　冗余和相关分析
3.3.3　元组重复
3.3.4　数据值冲突的检测与处理
3.4　数据归约
3.4.1　数据归约策略概述
3.4.2　小波变换
3.4.3　主成分分析
3.4.4　属性子集选择
3.4.5　回归和对数线性模型：参数化数据归约
3.4.6　直方图
3.4.7　聚类
3.4.8　抽样
3.4.9　数据立方体聚集
3.5　数据变换与数据离散化
3.5.1　数据变换策略概述
3.5.2　通过规范化变换数据
3.5.3　通过分箱离散化
3.5.4　通过直方图分析离散化
3.5.5　通过聚类、决策树和相关分析离散化
3.5.6　标称数据的概念分层产生
3.6　小结
3.7　习题
3.8　文献注释

第4章　数据仓库与联机分析处理
4.1　数据仓库：基本概念
4.1.1　什么是数据仓库
4.1.2　操作数据库系统与数据仓库的区别
4.1.3　为什么需要分离的数据仓库
4.1.4　数据仓库：一种多层体系结构
4.1.5　数据仓库模型：企业仓库、数据集市和虚拟仓库
4.1.6　数据提取、变换和装入
4.1.7　元数据库
4.2　数据仓库建模：数据立方体与OLAP
4.2.1　数据立方体：一种多维数据模型
4.2.2　星形、雪花形和事实星座：多维数据模型的模式
4.2.3　维：概念分层的作用
4.2.4　度量的分类和计算
4.2.5　典型的OLAP操作
4.2.6　查询多维数据库的星网查询模型
4.3　数据仓库的设计与使用
4.3.1　数据仓库的设计的商务分析框架
4.3.2　数据仓库的设计过程
4.3.3　数据仓库用于信息处理
4.3.4　从联机分析处理到多维数据挖掘
4.4　数据仓库的实现
4.4.1　数据立方体的有效计算：概述
4.4.2　索引OLAP数据：位图索引和连接索引
4.4.3　OLAP查询的有效处理
4.4.4　OLAP服务器结构：ROLAP、MOLAP、HOLAP的比较
4.5　数据泛化：面向属性的归纳
4.5.1　数据特征的面向属性的归纳
4.5.2　面向属性归纳的有效实现
4.5.3　类比较的面向属性归纳
4.6　小结
4.7　习题
4.8　文献注释

第5章　数据立方体技术
5.1　数据立方体计算：基本概念
5.1.1　立方体物化：完全立方体、冰山立方体、闭立方体和立方体外壳
5.1.2　数据立方体计算的一般策略
5.2　数据立方体计算方法
5.2.1　完全立方体计算的多路数组聚集
5.2.2　BUC：从顶点方体向下计算冰山立方体
5.2.3　Star-Cubing：使用动态星树结构计算冰山立方体
5.2.4　为快速高维OLAP预计算壳片段
5.3　使用探索立方体技术处理高级查询
5.3.1　抽样立方体：样本数据上基于OLAP的挖掘
5.3.2　排序立方体：top-k查询的有效计算
5.4　数据立方体空间的多维数据分析
5.4.1　预测立方体：立方体空间的预测挖掘
5.4.2　多特征立方体：多粒度上的复杂聚集
5.4.3　基于异常的、发现驱动的立方体空间探查
5.5　小结
5.6　习题
5.7　文献注释

第6章　挖掘频繁模式、关联和相关性：基本概念和方法
6.1　基本概念
6.1.1　购物篮分析：一个诱发例子
6.1.2　频繁项集、闭项集和关联规则
6.2　频繁项集挖掘方法
6.2.1　Apriori算法：通过限制候选产生发现频繁项集
6.2.2　由频繁项集产生关联规则
6.2.3　提高Apriori算法的效率
6.2.4　挖掘频繁项集的模式增长方法
6.2.5　使用垂直数据格式挖掘频繁项集
6.2.6　挖掘闭模式和极大模式
6.3　哪些模式是有趣的：模式评估方法
6.3.1　强规则不一定是有趣的
6.3.2　从关联分析到相关分析
6.3.3　模式评估度量比较
6.4　小结
6.5　习题
6.6　文献注释

第7章　高级模式挖掘
7.1　模式挖掘：一个路线图
7.2　多层、多维空间中的模式挖掘
7.2.1　挖掘多层关联规则
7.2.2　挖掘多维关联规则
7.2.3　挖掘量化关联规则
7.2.4　挖掘稀有模式和负模式
7.3　基于约束的频繁模式挖掘
7.3.1　关联规则的元规则制导挖掘
7.3.2　基于约束的模式产生：模式空间剪枝和数据空间剪枝
7.4　挖掘高维数据和巨型模式
7.5　挖掘压缩或近似模式
7.5.1　通过模式聚类挖掘压缩模式
7.5.2　提取感知冗余的top-k模式
7.6　模式探索与应用
7.6.1　频繁模式的语义注解
7.6.2　模式挖掘的应用
7.7　小结
7.8　习题
7.9　文献注释

第8章　分类：基本概念
8.1　基本概念
8.1.1　什么是分类
8.1.2　分类的一般方法
8.2　决策树归纳
8.2.1　决策树归纳
8.2.2　属性选择度量
8.2.3　树剪枝
8.2.4　可伸缩性与决策树归纳
8.2.5　决策树归纳的可视化挖掘
8.3　贝叶斯分类方法
8.3.1　贝叶斯定理
8.3.2　朴素贝叶斯分类
8.4　基于规则的分类
8.4.1　使用IF-THEN规则分类
8.4.2　由决策树提取规则
8.4.3　使用顺序覆盖算法的规则归纳
8.5　模型评估与选择
8.5.1　评估分类器性能的度量
8.5.2　保持方法和随机二次抽样
8.5.3　交叉验证
8.5.4　自助法
8.5.5　使用统计显著性检验选择模型
8.5.6　基于成本效益和ROC曲线比较分类器
8.6　提高分类准确率的技术
8.6.1　组合分类方法简介
8.6.2　装袋
8.6.3　提升和AdaBoost
8.6.4　随机森林
8.6.5　提高类不平衡数据的分类准确率
8.7　小结
8.8　习题
8.9　文献注释

第9章　分类：高级方法
9.1　贝叶斯信念网络
9.1.1　概念和机制
9.1.2　训练贝叶斯信念网络
9.2　用后向传播分类
9.2.1　多层前馈神经网络
9.2.2　定义网络拓扑
9.2.3　后向传播
9.2.4　黑盒内部：后向传播和可解释性
9.3　支持向量机
9.3.1　数据线性可分的情况
9.3.2　数据非线性可分的情况
9.4　使用频繁模式分类
9.4.1　关联分类
9.4.2　基于有区别力的频繁模式分类
9.5　惰性学习法(或从近邻学习）
9.5.1　k-最近邻分类
9.5.2　基于案例的推理
9.6　其他分类方法
9.6.1　遗传算法
9.6.2　粗糙集方法
9.6.3　模糊集方法
9.7　关于分类的其他问题
9.7.1　多类分类
9.7.2　半监督分类
9.7.3　主动学习
9.7.4　迁移学习
9.8　小结
9.9　习题
9.10　文献注释

第10章　聚类分析：基本概念和方法
10.1　聚类分析
10.1.1　什么是聚类分析
10.1.2　对聚类分析的要求
10.1.3　基本聚类方法概述
10.2　划分方法
10.2.1　k-均值：一种基于形心的技术
10.2.2　k-中心点：一种基于代表对象的技术
10.3　层次方法
10.3.1　凝聚的与分裂的层次聚类
10.3.2　算法方法的距离度量
10.3.3　BIRCH：使用聚类特征树的多阶段聚类
10.3.4　Chameleon：使用动态建模的多阶段层次聚类
10.3.5　概率层次聚类
10.4　基于密度的方法
10.4.1　DBSCAN：一种基于高密度连通区域的基于密度的聚类
10.4.2　OPTICS：通过点排序识别聚类结构
10.4.3　DENCLUE：基于密度分布函数的聚类
10.5　基于网格的方法
10.5.1　STING：统计信息网格
10.5.2　CLIQUE：一种类似于Apriori的子空间聚类方法
10.6　聚类评估
10.6.1　估计聚类趋势
10.6.2　确定簇数
10.6.3　测定聚类质量
10.7　小结
10.8　习题
10.9　文献注释

第11章　高级聚类分析
11.1　基于概率模型的聚类
11.1.1　模糊簇
11.1.2　基于概率模型的聚类
11.1.3　期望最大化算法
11.2　聚类高维数据
11.2.1　聚类高维数据：问题、挑战和主要方法
11.2.2　子空间聚类方法
11.2.3　双聚类
11.2.4　维归约方法和谱聚类
11.3　聚类图和网络数据
11.3.1　应用与挑战
11.3.2　相似性度量
11.3.3　图聚类方法
11.4　具有约束的聚类
11.4.1　约束的分类
11.4.2　具有约束的聚类方法
11.5　小结
11.6　习题
11.7　文献注释

第12章　离群点检测
12.1　离群点和离群点分析
12.1.1　什么是离群点
12.1.2　离群点的类型
12.1.3　离群点检测的挑战
12.2　离群点检测方法
12.2.1　监督、半监督和无监督方法
12.2.2　统计方法、基于邻近性的方法和基于聚类的方法
12.3　统计学方法
12.3.1　参数方法
12.3.2　非参数方法
12.4　基于邻近性的方法
12.4.1　基于距离的离群点检测和嵌套循环方法
12.4.2　基于网格的方法
12.4.3　基于密度的离群点检测
12.5　基于聚类的方法
12.6　基于分类的方法
12.7　挖掘情境离群点和集体离群点
12.7.1　把情境离群点检测转换成传统的离群点检测
12.7.2　关于情境对正常行为建模
12.7.3　挖掘集体离群点
12.8　高维数据中的离群点检测
12.8.1　扩充的传统离群点检测
12.8.2　发现子空间中的离群点
12.8.3　高维离群点建模
12.9　小结
12.10　习题
12.11　文献注释

第13章　数据挖掘的发展趋势和研究前沿
13.1　挖掘复杂的数据类型
13.1.1　挖掘序列数据：时间序列、符号序列和生物学序列
13.1.2　挖掘图和网络
13.1.3　挖掘其他类型的数据
13.2　数据挖掘的其他方法
13.2.1　统计学数据挖掘
13.2.2　关于数据挖掘基础的观点
13.2.3　可视和听觉数据挖掘
13.3　数据挖掘应用
13.3.1　金融数据分析的数据挖掘
13.3.2　零售和电信业的数据挖掘
13.3.3　科学与工程数据挖掘
13.3.4　入侵检测和预防数据挖掘
13.3.5　数据挖掘与推荐系统
13.4　数据挖掘与社会
13.4.1　普适的和无形的数据挖掘
13.4.2　数据挖掘的隐私、安全和社会影响
13.5　数据挖掘的发展趋势


1.1　什么是数据挖掘　2

1.2　数据挖掘要解决的问题　2

1.3　数据挖掘的起源　3

1.4　数据挖掘任务　4

1.5　本书的内容与组织　7

文献注释　7

参考文献　8

习题　10

第2章　数据　13

2.1　数据类型　14

2.1.1　属性与度量　15

2.1.2　数据集的类型　18

2.2　数据质量　22

2.2.1　测量和数据收集问题　22

2.2.2　关于应用的问题　26

2.3　数据预处理　27

2.3.1　聚集　27

2.3.2　抽样　28

2.3.3　维归约　30

2.3.4　特征子集选择　31

2.3.5　特征创建　33

2.3.6　离散化和二元化　34

2.3.7　变量变换　38

2.4　相似性和相异性的度量　38

2.4.1　基础　39

2.4.2　简单属性之间的相似度和相异度　40

2.4.3　数据对象之间的相异度　41

2.4.4　数据对象之间的相似度　43

2.4.5　邻近性度量的例子　43

2.4.6　邻近度计算问题　48

2.4.7　选取正确的邻近性度量　50

文献注释　50

参考文献　52

习题　53

第3章　探索数据　59

3.1　鸢尾花数据集　59

3.2　汇总统计　60

3.2.1　频率和众数　60

3.2.2　百分位数　61

3.2.3　位置度量：均值和中位数　61

3.2.4　散布度量：极差和方差　62

3.2.5　多元汇总统计　63

3.2.6　汇总数据的其他方法　64

3.3　可视化　64

3.3.1　可视化的动机　64

3.3.2　一般概念　65

3.3.3　技术　67

3.3.4　可视化高维数据　75

3.3.5　注意事项　79

3.4　OLAP和多维数据分析　79

3.4.1　用多维数组表示鸢尾花数据　80

3.4.2　多维数据：一般情况　81

3.4.3　分析多维数据　82

3.4.4　关于多维数据分析的最后评述　84

文献注释　84

参考文献　85

习题　86

第4章　分类：基本概念、决策树与模型评估　89

4.1　预备知识　89

4.2　解决分类问题的一般方法　90

4.3　决策树归纳　92

4.3.1　决策树的工作原理　92

4.3.2　如何建立决策树　93

4.3.3　表示属性测试条件的方法　95

4.3.4　选择最佳划分的度量　96

4.3.5　决策树归纳算法　101

4.3.6　例子：Web机器人检测　102

4.3.7　决策树归纳的特点　103

4.4　模型的过分拟合　106

4.4.1　噪声导致的过分拟合　107

4.4.2　缺乏代表性样本导致的过分拟合　109

4.4.3　过分拟合与多重比较过程　109

4.4.4　泛化误差估计　110

4.4.5　处理决策树归纳中的过分拟合　113

4.5　评估分类器的性能　114

4.5.1　保持方法　114

4.5.2　随机二次抽样　115

4.5.3　交叉验证　115

4.5.4　自助法　115

4.6　比较分类器的方法　116

4.6.1　估计准确度的置信区间　116

4.6.2　比较两个模型的性能　117

4.6.3　比较两种分类法的性能　118

文献注释　118

参考文献　120

习题　122

第5章　分类：其他技术　127

5.1　基于规则的分类器　127

5.1.1　基于规则的分类器的工作原理　128

5.1.2　规则的排序方案　129

5.1.3　如何建立基于规则的分类器　130

5.1.4　规则提取的直接方法　130

5.1.5　规则提取的间接方法　135

5.1.6　基于规则的分类器的特征　136

5.2　最近邻分类器　137

5.2.1　算法　138

5.2.2　最近邻分类器的特征　138

5.3　贝叶斯分类器　139

5.3.1　贝叶斯定理　139

5.3.2　贝叶斯定理在分类中的应用　140

5.3.3　朴素贝叶斯分类器　141

5.3.4　贝叶斯误差率　145

5.3.5　贝叶斯信念网络　147

5.4　人工神经网络　150

5.4.1　感知器　151

5.4.2　多层人工神经网络　153

5.4.3　人工神经网络的特点　155

5.5　支持向量机　156

5.5.1　最大边缘超平面　156

5.5.2　线性支持向量机：可分情况　157

5.5.3　线性支持向量机：不可分情况　162

5.5.4　非线性支持向量机　164

5.5.5　支持向量机的特征　168

5.6　组合方法　168

5.6.1　组合方法的基本原理　168

5.6.2　构建组合分类器的方法　169

5.6.3　偏倚-方差分解　171

5.6.4　装袋　173

5.6.5　提升　175

5.6.6　随机森林　178

5.6.7　组合方法的实验比较　179

5.7　不平衡类问题　180

5.7.1　可选度量　180

5.7.2　接受者操作特征曲线　182

5.7.3　代价敏感学习　184

5.7.4　基于抽样的方法　186

5.8　多类问题　187

文献注释　189

参考文献　190

习题　193

第6章　关联分析：基本概念和算法　201

6.1　问题定义　202

6.2　频繁项集的产生　204

6.2.1　先验原理　205

6.2.2　Apriori算法的频繁项集产生　206

6.2.3　候选的产生与剪枝　208

6.2.4　支持度计数　210

6.2.5　计算复杂度　213

6.3　规则产生　215

6.3.1　基于置信度的剪枝　215

6.3.2　Apriori算法中规则的产生　215

6.3.3　例：美国国会投票记录　217

6.4　频繁项集的紧凑表示　217

6.4.1　极大频繁项集　217

6.4.2　闭频繁项集　219

6.5　产生频繁项集的其他方法　221

6.6　FP增长算法　223

6.6.1　FP树表示法　224

6.6.2　FP增长算法的频繁项集产生　225

6.7　关联模式的评估　228

6.7.1　兴趣度的客观度量　228

6.7.2　多个二元变量的度量　235

6.7.3　辛普森悖论　236

6.8　倾斜支持度分布的影响　237

文献注释　240

参考文献　244

习题　250

第7章　关联分析：高级概念　259

7.1　处理分类属性　259

7.2　处理连续属性　261

7.2.1　基于离散化的方法　261

7.2.2　基于统计学的方法　263

7.2.3　非离散化方法　265

7.3　处理概念分层　266

7.4　序列模式　267

7.4.1　问题描述　267

7.4.2　序列模式发现　269

7.4.3　时限约束　271

7.4.4　可选计数方案　274

7.5　子图模式　275

7.5.1　图与子图　276

7.5.2　频繁子图挖掘　277

7.5.3　类Apriori方法　278

7.5.4　候选产生　279

7.5.5　候选剪枝　282

7.5.6　支持度计数　285

7.6　非频繁模式　285

7.6.1　负模式　285

7.6.2　负相关模式　286

7.6.3　非频繁模式、负模式和负相关模式比较　287

7.6.4　挖掘有趣的非频繁模式的技术　288

7.6.5　基于挖掘负模式的技术　288

7.6.6　基于支持度期望的技术　290

文献注释　292

参考文献　293

习题　295

第8章　聚类分析：基本概念和算法　305

8.1　概述　306

8.1.1　什么是聚类分析　306

8.1.2　不同的聚类类型　307

8.1.3　不同的簇类型　308

8.2　K均值　310

8.2.1　基本K均值算法　310

8.2.2　K均值：附加的问题　315

8.2.3　二分K均值　316

8.2.4　K均值和不同的簇类型　317

8.2.5　优点与缺点　318

8.2.6　K均值作为优化问题　319

8.3　凝聚层次聚类　320

8.3.1　基本凝聚层次聚类算法　321

8.3.2　特殊技术　322

8.3.3　簇邻近度的Lance-Williams公式　325

8.3.4　层次聚类的主要问题　326

8.3.5　优点与缺点　327

8.4　DBSCAN　327

8.4.1　传统的密度：基于中心的方法　327

8.4.2　DBSCAN算法　328

8.4.3　优点与缺点　329

8.5　簇评估　330

8.5.1　概述　332

8.5.2　非监督簇评估：使用凝聚度和分离度　332

8.5.3　非监督簇评估：使用邻近度矩阵　336

8.5.4　层次聚类的非监督评估　338

8.5.5　确定正确的簇个数　339

8.5.6　聚类趋势　339

8.5.7　簇有效性的监督度量　340

8.5.8　评估簇有效性度量的显著性　343

文献注释　344

参考文献　345

习题　347

第9章　聚类分析：其他问题与算法　355

9.1　数据、簇和聚类算法的特性　355

9.1.1　例子：比较K均值和DBSCAN　355

9.1.2　数据特性　356

9.1.3　簇特性　357

9.1.4　聚类算法的一般特性　358

9.2　基于原型的聚类　359

9.2.1　模糊聚类　359

9.2.2　使用混合模型的聚类　362

9.2.3　自组织映射　369

9.3　基于密度的聚类　372

9.3.1　基于网格的聚类　372

9.3.2　子空间聚类　374

9.3.3　DENCLUE：基于密度聚类的一种基于核的方案　377

9.4　基于图的聚类　379

9.4.1　稀疏化　379

9.4.2　最小生成树聚类　380

9.4.3　OPOSSUM：使用METIS的稀疏相似度最优划分　381

9.4.4　Chameleon：使用动态建模的层次聚类　381

9.4.5　共享最近邻相似度　385

9.4.6　Jarvis-Patrick聚类算法　387

9.4.7　SNN密度　388

9.4.8　基于SNN密度的聚类　389

9.5　可伸缩的聚类算法　390

9.5.1　可伸缩：一般问题和方法　391

9.5.2　BIRCH　392

9.5.3　CURE　393

9.6　使用哪种聚类算法　395

文献注释　397

参考文献　398

习题　400

第10章　异常检测　403

10.1　预备知识　404

10.1.1　异常的成因　404

10.1.2　异常检测方法　404

10.1.3　类标号的使用　405

10.1.4　问题　405

10.2　统计方法　406

10.2.1　检测一元正态分布中的离群点　407

10.2.2　多元正态分布的离群点　408

10.2.3　异常检测的混合模型方法　410

10.2.4　优点与缺点　411

10.3　基于邻近度的离群点检测　411

10.4　基于密度的离群点检测　412

10.4.1　使用相对密度的离群点检测　413

10.4.2　优点与缺点　414

10.5　基于聚类的技术　414

10.5.1　评估对象属于簇的程度　415

10.5.2　离群点对初始聚类的影响　416

10.5.3　使用簇的个数　416

10.5.4　优点与缺点　416

文献注释　417

参考文献　418

习题　420

附录A　线性代数　423

附录B　维归约　433

附录C　概率统计　445

附录D　回归　451

附录E　优化　457

