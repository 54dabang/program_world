第1章　并发编程的挑战 1
1.1　上下文切换 1
1.1.1　多线程一定快吗 1
1.1.2　测试上下文切换次数和时长 3
1.1.3　如何减少上下文切换 3
1.1.4　减少上下文切换实战 4
1.2　死锁 5
1.3　资源限制的挑战 6
1.4　本章小结 7
第2章　Java并发机制的底层实现原理 8
2.1　volatile的应用 8
2.2　synchronized的实现原理与应用 11
2.2.1　Java对象头 12
2.2.2　锁的升级与对比 13
2.3　原子操作的实现原理 16
2.4　本章小结 20
第3章　Java内存模型 21
3.1　Java内存模型的基础 21
3.1.1　并发编程模型的两个关键问题 21
3.1.2　Java内存模型的抽象结构 22
3.1.3　从源代码到指令序列的重排序 23
3.1.4　并发编程模型的分类 24
3.1.5　happens-before简介 26
3.2　重排序 27
3.2.1　数据依赖性 28
3.2.2　as-if-serial语义 28
3.2.3　程序顺序规则 29
3.2.4　重排序对多线程的影响 29
3.3　顺序一致性 31
3.3.1　数据竞争与顺序一致性 31
3.3.2　顺序一致性内存模型 32
3.3.3　同步程序的顺序一致性效果 34
3.3.4　未同步程序的执行特性 35
3.4　volatile的内存语义 38
3.4.1　volatile的特性 38
3.4.2　volatile写-读建立的happens-before关系 39
3.4.3　volatile写-读的内存语义 40
3.4.4　volatile内存语义的实现 42
3.4.5　JSR-133为什么要增强volatile的内存语义 46
3.5　锁的内存语义 47
3.5.1　锁的释放-获取建立的
　　　happens-before关系 47
3.5.2　锁的释放和获取的内存语义 48
3.5.3　锁内存语义的实现 50
3.5.4　concurrent包的实现 54
3.6　final域的内存语义 55
3.6.1　final域的重排序规则 55
3.6.2　写final域的重排序规则 56
3.6.3　读final域的重排序规则 57
3.6.4　final域为引用类型 58
3.6.5　为什么final引用不能从构造函数内“溢出” 59
3.6.6　final语义在处理器中的实现 61
3.6.7　JSR-133为什么要增强f?inal的语义 62
3.7　happens-before 62
3.7.1　JMM的设计 62
3.7.2　happens-before的定义 64
3.7.3　happens-before规则 65
3.8　双重检查锁定与延迟初始化 67
3.8.1　双重检查锁定的由来 67
3.8.2　问题的根源 69
3.8.3　基于volatile的解决方案 71
3.8.4　基于类初始化的解决方案 72
3.9　Java内存模型综述 78
3.9.1　处理器的内存模型 78
3.9.2　各种内存模型之间的关系 80
3.9.3　JMM的内存可见性保证 80
3.9.4　JSR-133对旧内存模型的修补 81
3.10　本章小结 82
第4章　Java并发编程基础 83
4.1　线程简介 83
4.1.1　什么是线程 83
4.1.2　为什么要使用多线程 84
4.1.3　线程优先级 85
4.1.4　线程的状态 87
4.1.5　Daemon线程 90
4.2　启动和终止线程 91
4.2.1　构造线程 91
4.2.2　启动线程 92
4.2.3　理解中断 92
4.2.4　过期的suspend()、resume()和stop() 93
4.2.5　安全地终止线程 95
4.3　线程间通信 96
4.3.1　volatile和synchronized关键字 96
4.3.2　等待/通知机制 98
4.3.3　等待/通知的经典范式 101
4.3.4　管道输入/输出流 102
4.3.5　Thread.join()的使用 103
4.3.6　ThreadLocal的使用 105
4.4　线程应用实例 106
4.4.1　等待超时模式 106
4.4.2　一个简单的数据库连接池示例 106
4.4.3　线程池技术及其示例 110
4.4.4　一个基于线程池技术的简单Web服务器 114
4.5　本章小结 118
第5章　Java中的锁 119
5.1　Lock接口 119
5.2　队列同步器 121
5.2.1　队列同步器的接口与示例 121
5.2.2　队列同步器的实现分析 124
5.3　重入锁 136
5.4　读写锁 140
5.4.1　读写锁的接口与示例 141
5.4.2　读写锁的实现分析 142
5.5　LockSupport工具 146
5.6　Condition接口 147
5.6.1　Condition接口与示例 148
5.6.2　Condition的实现分析 150
5.7　本章小结 154
第6章　Java并发容器和框架 155
6.1　ConcurrentHashMap的实现原理与使用 155
6.1.1　为什么要使用ConcurrentHashMap 155
6.1.2　ConcurrentHashMap的结构 156
6.1.3　ConcurrentHashMap的初始化 157
6.1.4　定位Segment 159
6.1.5　ConcurrentHashMap的操作 160
6.2　ConcurrentLinkedQueue 161
6.2.1　ConcurrentLinkedQueue的结构 162
6.2.2　入队列 162
6.2.3　出队列 165
6.3　Java中的阻塞队列 167
6.3.1　什么是阻塞队列 167
6.3.2　Java里的阻塞队列 168
6.3.3　阻塞队列的实现原理 172
6.4　Fork/Join框架 175
6.4.1　什么是Fork/Join框架 175
6.4.2　工作窃取算法 176
6.4.3　Fork/Join框架的设计 177
6.4.4　使用Fork/Join框架 177
6.4.5　Fork/Join框架的异常处理 179
6.4.6　Fork/Join框架的实现原理 179
6.5　本章小结 181
第7章　Java中的13个原子操作类 182
7.1　原子更新基本类型类 182
7.2　原子更新数组 184
7.3　原子更新引用类型 185
7.4　原子更新字段类 187
7.5　本章小结 188
第8章　Java中的并发工具类 189
8.1　等待多线程完成的CountDownLatch 189
8.2　同步屏障CyclicBarrier 191
8.2.1　CyclicBarrier简介 191
8.2.2　CyclicBarrier的应用场景 193
8.2.3　CyclicBarrier和CountDownLatch的区别 195
8.3　控制并发线程数的Semaphore 196
8.4　线程间交换数据的Exchanger 198
8.5　本章小结 199
第9章　Java中的线程池 200
9.1　线程池的实现原理 200
9.2　线程池的使用 203
9.2.1　线程池的创建 203
9.2.2　向线程池提交任务 205
9.2.3　关闭线程池 205
9.2.4　合理地配置线程池 206
9.2.5　线程池的监控 206
9.3　本章小结 207
第10章　Executor框架 208
10.1　Executor框架简介 208
10.1.1　Executor框架的两级调度模型 208
10.1.2　Executor框架的结构与成员 208
10.2　ThreadPoolExecutor详解 213
10.2.1　FixedThreadPool详解 213
10.2.2　SingleThreadExecutor详解 214
10.2.3　CachedThreadPool详解 215
10.3　ScheduledThreadPoolExecutor详解 217
10.3.1　ScheduledThreadPoolExecutor的运行机制 217
10.3.2　ScheduledThreadPoolExecutor的实现 218
10.4　FutureTask详解 221
10.4.1　FutureTask简介 222
10.4.2　FutureTask的使用 222
10.4.3　FutureTask的实现 224
10.5　本章小结 227
第11章　Java并发编程实践 228
11.1　生产者和消费者模式 228
11.1.1　生产者消费者模式实战 229
11.1.2　多生产者和多消费者场景 231
11.1.3　线程池与生产消费者模式 234
11.2　线上问题定位 234
11.3　性能测试 236
11.4　异步任务池 238
11.5　本章小结 240

1.1　并发简史
1.2　线程的优势
1.2.1　发挥多处理器的强大能力
1.2.2　建模的简单性
1.2.3　异步事件的简化处理
1.2.4　响应更灵敏的用户界面
1.3　线程带来的风险
1.3.1　安全性问题
1.3.2　活跃性问题
1.3.3　性能问题
1.4　线程无处不在
第一部分　基础知识
第2章　线程安全性
2.1　什么是线程安全性
2.2　原子性
2.2.1　竞态条件
2.2.2　示例：延迟初始化中的竞态条件
2.2.3　复合操作
2.3　加锁机制
2.3.1　内置锁
2.3.2　重入
2.4　用锁来保护状态
2.5　活跃性与性能
第3章　对象的共享
3.1　可见性
3.1.1　失效数据
3.1.2　非原子的64位操作
3.1.3　加锁与可见性
3.1.4　Volatile变量
3.2　发布与逸出
3.3　线程封闭
3.3.1　Ad-hoc线程封闭
3.3.2　栈封闭
3.3.3　ThreadLocal类
3.4　不变性
3.4.1　Final域
3.4.2　示例：使用Volatile类型来发布不可变对象
3.5　安全发布
3.5.1　不正确的发布：正确的对象被破坏
3.5.2 　不可变对象与初始化安全性
3.5.3　安全发布的常用模式
3.5.4　事实不可变对象
3.5.5　可变对象
3.5.6　安全地共享对象
第4章　对象的组合
4.1　设计线程安全的类
4.1.1　收集同步需求
4.1.2　依赖状态的操作
4.1.3　状态的所有权
4.2　实例封闭
4.2.1　Java监视器模式
4.2.2　示例：车辆追踪
4.3　线程安全性的委托
4.3.1　示例：基于委托的车辆追踪器
4.3.2　独立的状态变量
4.3.3　当委托失效时
4.3.4　发布底层的状态变量
4.3.5　示例：发布状态的车辆追踪器
4.4　在现有的线程安全类中添加功能
4.4.1　客户端加锁机制
4.4.2　组合
4.5　将同步策略文档化
第5章　基础构建模块
5.1　同步容器类
5.1.1　同步容器类的问题
5.1.2　迭代器与Concurrent-ModificationException
5.1.3　隐藏迭代器
5.2　并发容器
5.2.1　ConcurrentHashMap
5.2.2　额外的原子Map操作
5.2.3　CopyOnWriteArrayList
5.3　阻塞队列和生产者-消费者模式
5.3.1　示例：桌面搜索
5.3.2　串行线程封闭
5.3.3　双端队列与工作密取
5.4　阻塞方法与中断方法
5.5　同步工具类
5.5.1　闭锁
5.5.2　FutureTask
5.5.3　信号量
5.5.4　栅栏
5.6　构建高效且可伸缩的结果缓存
第二部分　结构化并发应用程序
第6章　任务执行
6.1　在线程中执行任务
6.1.1　串行地执行任务
6.1.2　显式地为任务创建线程
6.1.3　无限制创建线程的不足
6.2　Executor框架
6.2.1　示例：基于Executor的Web服务器
6.2.2　执行策略
6.2.3　线程池
6.2.4　Executor的生命周期
6.2.5　延迟任务与周期任务
6.3　找出可利用的并行性
6.3.1　示例：串行的页面渲染器
6.3.2　携带结果的任务Callable与Future
6.3.3　示例：使用Future实现页面渲染器
6.3.4　在异构任务并行化中存在的局限
6.3.5　CompletionService:Executor与BlockingQueue
6.3.6　示例：使用CompletionService实现页面渲染器
6.3.7　为任务设置时限
6.3.8　示例：旅行预定门户网站
第7章　取消与关闭
第8章　线程池的使用
第9章　图形用户界面应用程序
第三部分　活跃性、性能与测试
第10章　避免活跃性危险
第11章　性能与可伸缩性
第12章　并发程序的测试
第四部分　高级主题
第13章　显式锁
第14章　构建自定义的同步工具
第15章　原子变量与非阻塞同步机制
第16章　Java内存模型
附录A　并发性标注

第1章：快速认识线程 22
1.1 线程的介绍 22
1.2 快速创建并启动一个线程 22
1.2.1 尝试并行运行 23
1.2.2 并发运行交替输出 24
1.2.3 使用Jconsole观察线程 25
1.3 线程的生命周期详解 26
1.3.1 线程的NEW状态 27
1.3.2 线程的RUNNABLE状态 28
1.3.3 线程的 RUNNING状态 28
1.3.4 线程的BLOCKED状态 29
1.3.5 线程的TERMINATED状态 29
1.4 线程的start方法剖析--模板设计模式在Thread中的应用 30
1.4.1 Thread start方法源码分析以及注意事项 30
1.4.2 模板设计模式在Thread中的应用 33
1.4.3 Thread模拟营业大厅叫号机程序 34
1.5 Runnable接口的引入以及策略模式在Thread中的使用 39
1.5.1 Runnable的职责 39
1.5.2 策略模式在Thread中的应用 40
1.5.3 模拟营业大厅叫号机程序 42
1.6 本章总结 43
第2章：深入理解Thread构造函数 45
2.1 线程的命名 45
2.1.1 线程的默认命名 45
2.1.2 命名线程 46
2.1.3 修改线程的名字 47
2.2 线程的父子关系 48
2.3 Thread与ThreadGroup 48
2.4 Thread与Runnable 50
2.5 Thread与JVM虚拟机栈 50
2.5.1 Thread与Stacksize 51
2.5.2 JVM内存结构 53
2.5.3 Thread与虚拟机栈 58
2.6 守护线程 62
2.6.1 什么是守护线程 62
2.6.2 守护线程的作用 64
2.7 本章总结 64
第3章：Thread API的详细介绍 66
3.1 线程sleep 66
3.1.1 sleep方法介绍 66
3.1.2 使用TimeUnit替代Thread.sleep 67
3.2 线程yield 68
3.2.1 yield方法介绍 68
3.2.2 yield vs sleep 69
3.3 设置线程的优先级 69
3.3.1 线程优先级介绍 70
3.3.2 线程优先级源码分析 71
3.3.3 关于优先级的一些总结 72
3.4 获取线程ID 73
3.5 获取当前线程 73
3.6 设置线程上下文类加载器 74
3.7 线程interrupt 75
3.7.1 interrupt 75
3.7.2 isInterrupted 77
3.7.3 interrupted 79
3.7.4 interrupt注意事项 81
3.8 线程join 82
3.8.1 线程join方法详解 83
3.8.2 join方法结合实战 85
3.9 如何关闭一个线程 90
3.9.1 正常关闭 90
3.9.2 异常退出 94
3.9.3 进程假死 94
3.10 本章总结 95
第4章：线程安全与数据同步 97
4.1 数据同步 97
4.1.1 数据不一致问题的引入 97
4.1.2 数据不一致问题原因分析 99
4.2 初识 synchronized关键字 101
4.2.1 什么是synchronized 102
4.2.2 synchronized关键字的用法 103
4.3 深入synchronized关键字 105
4.3.1 线程堆栈分析 105
4.3.2 JVM指令分析 108
4.3.3 使用synchronized需要注意的问题 112
4.4 This Monitor和Class Monitor的详细介绍 114
4.4.1 this monitor 114
4.4.2 class monitor 117
4.5 程序死锁的原因以及如何诊断 120
4.5.1 程序死锁 120
4.5.2 程序死锁举例 121
4.5.3 死锁诊断 124
4.6 本章总结 126
第5章：线程间通信 127
5.1 同步阻塞与异步非阻塞 127
5.1.1 同步阻塞消息处理 127
5.1.2 异步非阻塞消息处理 128
5.2 单线程间通信 129
5.2.1 初识wait和notify 129
5.2.2 wait和notify方法详解 133
5.2.3 wait和notify注意事项 135
5.2.4 wait vs sleep 137
5.3 多线程间通信 137
5.3.1 生产者消费者 137
5.3.2 线程休息室wait set 140
5.4 自定义显式锁BooleanLock 141
5.4.1 synchronized关键字的缺陷 142
5.4.2 显式锁BooleanLock 143
5.5 本章总结 153
第6章：ThreadGroup详细讲解 155
6.1 ThreadGroup与Thread 155
6.2 创建Thread Group 155
6.3 拷贝Thread数组和ThreadGroup数组 157
6.3.1 拷贝Thread数组 157
6.3.2 拷贝ThreadGroup数组 159
6.4 ThreadGroup操作 160
6.4.1 ThreadGroup的基本操作 161
6.4.2 ThreadGroup的interrupt 164
6.4.3 ThreadGroup的destroy 166
6.4.4 守护ThreadGroup 168
6.5 本章总结 169
第7章：Hook线程以及捕获线程执行异常 170
7.1 获取线程运行时异常 170
7.1.1 UncaughtExceptionHandler介绍 170
7.1.2 UncaughtExceptionHandler实例 171
7.1.3 UncaughtExceptionHandler源码分析 173
7.2 注入钩子线程（Hook） 175
7.2.1 Hook线程介绍 175
7.2.2 Hook线程实战 177
7.2.3 Hook线程应用场景以及注意事项 179
7.3 本章总结 179
第8章：线程池原理以及自定义线程池 180
8.1 线程池原理 180
8.2 线程池实现 181
8.2.1 线程池接口定义 182
8.2.2 线程池详细实现 188
8.3 线程池应用 198
8.4 本章总结 202
第二部分：Java ClassLoader 204
第9章 类的加载过程 205
9.1 类的加载过程介绍 205
9.2 类的主动使用和被动使用 206
9.3 类加载过程详解 209
9.3.1 类的加载阶段 210
9.3.2 类的连接阶段 212
9.3.3 类的初始化阶段 219
9.4 本章总结 221
第10章 JVM类加载器 224
10.1 JVM内置三大类加载器 224
10.1.1 根类加载器介绍 225
10.1.2 扩展类加载器介绍 226
10.1.3 系统类加载器介绍 227
10.2 自定义类加载器 227
10.2.1 自定义类加载器，问候世界 228
10.2.2 双亲委托机制详细介绍 233
10.2.3 破坏双亲委托机制 236
10.2.4 类加载器命名空间，运行时包，类的卸载等 239
10.3 本章总结 246
第11章 线程上下文类加载器 249
11.1 为什么需要线程上下文类加载器 249
11.2 数据库驱动的初始化源码分析 250
第三部分 深入理解volatile关键字 254
第12章 volatile关键字的介绍 255
12.1 初识volatile关键字 255
12.2 机器硬件CPU 257
12.3 Java 内存模型 262
第13章 深入volatile关键字 265
13.1 并发编程的三个重要特性 265
13.1.1 原子性 265
13.1.2 可见性 266
13.1.3 有序性 266
13.2 JMM如何保证三大特性 268
13.2.1 JMM与原子性 269
13.2.2 JMM与可见性 271
13.2.3 JMM与有序性 272
13.3 volatile关键字深入解析 273
13.3.1 volatile关键字的语义 274
13.3.2 volatile的原理和实现机制 277
13.3.3 volatile的使用场景 278

第1 章 并发编程线程基础 2

1.1 什么是线程 2

1.2 线程创建与运行 3

1.3 线程通知与等待 6

1.4 等待线程执行终止的join 方法 16

1.5 让线程睡眠的sleep 方法 19

1.6 让出CPU 执行权的yield 方法 23

1.7 线程中断 24

1.8 理解线程上下文切换 30

1.9 线程死锁 30

1.9.1 什么是线程死锁 30

1.9.2 如何避免线程死锁 33

1.10 守护线程与用户线程 35

1.11 ThreadLocal 39

1.11.1 ThreadLocal 使用示例 40

1.11.2 ThreadLocal 的实现原理 42

1.11.3 ThreadLocal 不支持继承性 45

1.11.4 InheritableThreadLocal 类 46

第2 章 并发编程的其他基础知识 50

2.1 什么是多线程并发编程 50

2.2 为什么要进行多线程并发编程 51

2.3 Java 中的线程安全问题 51

?2.4 Java 中共享变量的内存可见性问题 52

2.5 Java 中的synchronized 关键字 54

2.5.1 synchronized 关键字介绍 54

2.5.2 synchronized 的内存语义 55

2.6 Java 中的volatile 关键字 55

2.7 Java 中的原子性操作 57

2.8 Java 中的CAS 操作 59

2.9 Unsafe 类 59

2.9.1 Unsafe 类中的重要方法 59

2.9.2 如何使用Unsafe 类 61

2.10 Java 指令重排序 65

2.11 伪共享 67

2.11.1 什么是伪共享 67

2.11.2 为何会出现伪共享 68

2.11.3 如何避免伪共享 70

2.11.4 小结 72

2.12 锁的概述 72

2.12.1 乐观锁与悲观锁 72

2.12.2 公平锁与非公平锁 75

2.12.3 独占锁与共享锁 75

2.12.4 什么是可重入锁 76

2.12.5 自旋锁 77

2.13 总结 77

第二部分 Java 并发编程高级篇

第3 章 Java 并发包中ThreadLocalRandom 类原理剖析 80

3.1 Random 类及其局限性 80

3.2 ThreadLocalRandom 82

3.3 源码分析 84

3.4 总结 87

第4 章 Java 并发包中原子操作类原理剖析 88

4.1 原子变量操作类 88

4.2 JDK 8 新增的原子操作类LongAdder 93

4.2.1 LongAdder 简单介绍 93

4.2.2 LongAdder 代码分析 95

4.2.3 小结 101

4.3 LongAccumulator 类原理探究 102

4.4 总结 104

第5 章 Java 并发包中并发List 源码剖析 105

5.1 介绍 105

5.2 主要方法源码解析 106

5.2.1 初始化 106

5.2.2 添加元素 106

5.2.3 获取指定位置元素 108

5.2.4 修改指定元素 109

5.2.5 删除元素 110

5.2.6 弱一致性的迭代器 111

5.3 总结 114

第6 章 Java 并发包中锁原理剖析 115

6.1 LockSupport 工具类 115

6.2 抽象同步队列AQS 概述 122

6.2.1 AQS——锁的底层支持 122

6.2.2 AQS——条件变量的支持 128

6.2.3 基于AQS 实现自定义同步器 131

6.3 独占锁ReentrantLock 的原理 136

6.3.1 类图结构 136

6.3.2 获取锁 137

6.3.3 释放锁 142

6.3.4 案例介绍 143

6.3.5 小结 145

?6.4 读写锁ReentrantReadWriteLock 的原理 145

6.4.1 类图结构 145

6.4.2 写锁的获取与释放 147

6.4.3 读锁的获取与释放 151

6.4.4 案例介绍 156

6.4.5 小结 158

6.5 JDK 8 中新增的StampedLock 锁探究 158

6.5.1 概述 158

6.5.2 案例介绍 160

6.5.3 小结 164

第7 章 Java 并发包中并发队列原理剖析 165

7.1 ConcurrentLinkedQueue 原理探究 165

7.1.1 类图结构 165

7.1.2 ConcurrentLinkedQueue 原理介绍 166

7.1.3 小结 181

7.2 LinkedBlockingQueue 原理探究 182

7.2.1 类图结构 182

7.2.2 LinkedBlockingQueue 原理介绍 185

7.2.3 小结 194

7.3 ArrayBlockingQueue 原理探究 195

7.3.1 类图结构 195

7.3.2 ArrayBlockingQueue 原理介绍 197

7.3.3 小结 202

7.4 PriorityBlockingQueue 原理探究 203

7.4.1 介绍 203

7.4.2 PriorityBlockingQueue 类图结构 203

7.4.3 原理介绍 205

7.4.4 案例介绍 214

7.4.5 小结 216

7.5 DelayQueue 原理探究 217

7.5.1 DelayQueue 类图结构 217

7.5.2 主要函数原理讲解 219

7.5.3 案例介绍 222

7.5.4 小结 224

第8 章 Java 并发包中线程池ThreadPoolExecutor 原理探究 225

8.1 介绍 225

8.2 类图介绍 225

8.3 源码分析 230

8.3.1 public void execute(Runnable command) 230

8.3.2 工作线程Worker 的执行 235

8.3.3 shutdown 操作 238

8.3.4 shutdownNow 操作 240

8.3.5 awaitTermination 操作 241

8.4 总结 242

第9 章 Java 并发包中ScheduledThreadPoolExecutor 原理探究 243

9.1 介绍 243

9.2 类图介绍 243

9.3 原理剖析 245

9.3.1 schedule(Runnable command, long delay,TimeUnit unit) 方法 246

9.3.2 scheduleWithFixedDelay(Runnable command,long initialDelay, long delay,TimeUnit unit) 方法 252

9.3.3 scheduleAtFixedRate(Runnable command,long initialDelay,long period,TimeUnit unit) 方法 254

9.4 总结 255

第10 章 Java 并发包中线程同步器原理剖析 256

10.1 CountDownLatch 原理剖析 256

10.1.1 案例介绍 256

10.1.2 实现原理探究 259

10.1.3 小结 263

10.2 回环屏障CyclicBarrier 原理探究 264

10.2.1 案例介绍 264

10.2.2 实现原理探究 268

10.2.3 小结 272

?10.3 信号量Semaphore 原理探究 272

10.3.1 案例介绍 272

10.3.2 实现原理探究 276

10.3.3 小结 281

10.4 总结 281

第三部分 Java 并发编程实践篇

第11 章 并发编程实践 284

11.1 ArrayBlockingQueue 的使用 284

11.1.1 异步日志打印模型概述 284

11.1.2 异步日志与具体实现 285

11.1.3 小结 293

11.2 Tomcat 的NioEndPoint 中ConcurrentLinkedQueue 的使用 293

11.2.1 生产者——Acceptor 线程 294

11.2.2 消费者——Poller 线程 298

11.2.3 小结 300

11.3 并发组件ConcurrentHashMap 使用注意事项 300

11.4 SimpleDateFormat 是线程不安全的 304

11.4.1 问题复现 304

11.4.2 问题分析 305

11.4.3 小结 309

11.5 使用Timer 时需要注意的事情 309

11.5.1 问题的产生 309

11.5.2 Timer 实现原理分析 310

11.5.3 小结 313

11.6 对需要复用但是会被下游修改的参数要进行深复制 314

11.6.1 问题的产生 314

11.6.2 问题分析 316

11.6.3 小结 318

11.7 创建线程和线程池时要指定与业务相关的名称 319

11.7.1 创建线程需要有线程名 319

11.7.2 创建线程池时也需要指定线程池的名称 321

11.7.3 小结 325

11.8 使用线程池的情况下当程序结束时记得调用shutdown 关闭线程池 325

11.8.1 问题复现 325

11.8.2 问题分析 327

11.8.3 小结 329

11.9 线程池使用FutureTask 时需要注意的事情 329

11.9.1 问题复现 329

11.9.2 问题分析 332

11.9.3 小结 335

11.10 使用ThreadLocal 不当可能会导致内存泄漏 336

11.10.1 为何会出现内存泄漏 336

11.10.2 在线程池中使用ThreadLocal 导致的内存泄漏 339

11.10.3 在Tomcat 的Servlet 中使用ThreadLocal 导致内存泄漏 341

第 1 章 第 一步：并发设计原理 　　 1
1．1　基本的并发概念　1
1．1．1　并发与并行　1
1．1．2　同步　2
1．1．3　不可变对象　2
1．1．4　原子操作和原子变量　3
1．1．5　共享内存与消息传递　3
1．2　并发应用程序中可能出现的问题　3
1．2．1　数据竞争　3
1．2．2　死锁　4
1．2．3　活锁　4
1．2．4　资源不足　4
1．2．5　优先权反转　5
1．3　设计并发算法的方法论　5
1．3．1　起点：算法的一个串行版本　5
1．3．2　第 1 步：分析　5
1．3．3　第 2 步：设计　5
1．3．4　第3 步：实现　6
1．3．5　第4 步：测试　6
1．3．6　第5 步：调整　6
1．3．7　结论　7
1．4　Java 并发API　8
1．4．1　基本并发类　8
1．4．2　同步机制　8
1．4．3　执行器　9
1．4．4　Fork/Join 框架　9
1．4．5　并行流　9
1．4．6　并发数据结构　9
1．5　并发设计模式　10
1．5．1　信号模式　10
1．5．2　会合模式　11
1．5．3　互斥模式　11
1．5．4　多元复用模式　12
1．5．5　栅栏模式　12
1．5．6　双重检查锁定模式　12
1．5．7　读 写锁模式　13
1．5．8　线程池模式　14
1．5．9　线程局部存储模式　14
1．6　设计并发算法的提示和技巧　14
1．6．1　正确识别独立任务　14
1．6．2　在尽可能高的层面上实施并发处理　15
1．6．3　考虑伸缩性　15
1．6．4　使用线程安全API　15
1．6．5　绝不要假定执行顺序　16
1．6．6　在静态和共享场合尽可能使用局部线程变量　16
1．6．7　寻找更易于并行处理的算法版本　17
1．6．8　尽可能使用不可变对象　17
1．6．9　通过对锁排序来避免死锁　17
1．6．10　使用原子变量代替同步　18
1．6．11　占有锁的时间尽可能短　19
1．6．12　谨慎使用延迟初始化　19
1．6．13　避免在临界段中使用阻塞操作　19
1．7　小结　20
第　2 章 使用基本元素：Thread 和Runnable　21
2．1　Java 中的线程　21
2．1．1　Java 中的线程：特征和状态　22
2．1．2　Thread 类和Runnable 接口　23
2．2　第 一个例子：矩阵乘法　24
2．2．1　公共类　24
2．2．2　串行版本　25
2．2．3　并行版本　25
2．3　第二个例子：文件搜索　32
2．3．1　公共类　32
2．3．2　串行版本　32
2．3．3　并发版本　33
2．3．4　对比解决方案　37
2．4　小结　38
第3　章 管理大量线程：执行器　39
3．1　执行器简介　39
3．1．1　执行器的基本特征　39
3．1．2　执行器框架的基本组件　40
3．2　第 一个例子：k-最近邻算法　40
3．2．1　k-最近邻算法：串行版本　41
3．2．2　k-最近邻算法：细粒度并发版本　42
3．2．3　k-最近邻算法：粗粒度并发版本　45
3．2．4　对比解决方案　46
3．3　第二个例子：客户端/服务器环境下的并发处理　48
3．3．1　客户端/服务器：串行版　48
3．3．2　客户端/服务器：并行版本　51
3．3．3　额外的并发服务器组件　54
3．3．4　对比两种解决方案　59
3．3．5　其他重要方法　61
3．4　小结　62
第4　章 充分利用执行器　63
4．1　执行器的高级特性　63
4．1．1　任务的撤销　63
4．1．2　任务执行调度　64
4．1．3　重载执行器方法　64
4．1．4　更改一些初始化参数　64
4．2　第 一个例子：高级服务器应用程序　65
4．2．1　ServerExecutor 类　65
4．2．2　命令类　70
4．2．3　服务器部件　72
4．2．4　客户端部件　78
4．3　第二个例子：执行周期性任务　79
4．3．1　公共部件　79
4．3．2　基础阅读器　81
4．3．3　高级阅读器　84
4．4　有关执行器的其他信息　87
4．5　小结　87
第5　章 从任务获取数据：Callable接口与Future 接口　88
5．1　Callable 接口和Future 接口简介　88
5．1．1　Callable 接口　88
5．1．2　Future 接口　89
5．2　第 一个例子：单词最佳匹配算法　89
5．2．1　公共类　90
5．2．2　最佳匹配算法：串行版本　91
5．2．3　最佳匹配算法：第 一个并发版本　92
5．2．4　最佳匹配算法：第二个并发版本　95
5．2．5　单词存在算法：串行版本　96
5．2．6　单词存在算法：并行版本　98
5．2．7　对比解决方案　100
5．3　第二个例子：为文档集创建倒排索引　102
5．3．1　公共类　103
5．3．2　串行版本　104
5．3．3　第 一个并发版本：每个文档一个任务　105
5．3．4　第二个并发版本：每个任务多个文档　109
5．3．5　对比解决方案　112
5．3．6　其他相关方法　113
5．4　小结　113
第6　章 运行分为多阶段的任务：Phaser 类　115
6．1　Phaser 类简介　115
6．1．1　参与者的注册与注销　116
6．1．2　同步阶段变更　116
6．1．3　其他功能　116
6．2　第 一个例子：关键字抽取算法　117
6．2．1　公共类　118
6．2．2　串行版本　121
6．2．3　并发版本　123
6．2．4　对比两种解决方案　128
6．3　第二个例子：遗传算法　129
6．3．1　公共类　130
6．3．2　串行版本　132
6．3．3　并发版本　134
6．3．4　对比两种解决方案　139
6．4　小结　141
第7　章 优化分治解决方案：
Fork/Join　框架　142
7．1　Fork/Join 框架简介　142
7．1．1　Fork/Join 框架的基本特征　143
7．1．2　Fork/Join 框架的局限性　143
7．1．3　Fork/Join 框架的组件　144
7．2　第 一个例子：k-means 聚类算法　144
7．2．1　公共类　145
7．2．2　串行版本　149
7．2．3　并发版本　151
7．2．4　对比解决方案　155
7．3　第二个例子：数据筛选算法　157
7．3．1　公共特性　157
7．3．2　串行版　157
7．3．3　并发版本　159
7．3．4　对比两个版本　165
7．4　第三个例子：归并排序算法　166
7．4．1　共享类　166
7．4．2　串行版本　167
7．4．3　并发版本　169
7．4．4　对比两个版本　172
7．5　Fork/Join 框架的其他方法　172
7．6　小结　173
第8　章 使用并行流处理大规模数据集：MapReduce 模型　174
8．1　流的简介　174
8．1．1　流的基本特征　174
8．1．2　流的组成部分　175
8．1．3　MapReduce 与MapCollect　177
8．2　第 一个例子：数值综合分析应用程序　178
8．2．1　并发版本　178
8．2．2　串行版本　185
8．2．3　对比两个版本　186
8．3　第二个例子：信息检索工具　186
8．3．1　约简操作简介　187
8．3．2　第 一种方式：全文档查询　188
8．3．3　第二种方式：约简的文档查询　191
8．3．4　第三种方式：生成一个含有结果的HTML 文件　191
8．3．5　第四种方式：预先载入倒排索引　194
8．3．6　第五种方式：使用我们的执行器　195
8．3．7　从倒排索引获取数据：ConcurrentData 类　196
8．3．8　获取文件中的单词数　196
8．3．9　获取文件的平均tfxidf 值　196
8．3．10　获取索引中的最大tfxidf值和最小tfxidf 值　197
8．3．11　ConcurrentMain 类　198
8．3．12　串行版　199
8．3．13　对比两种解决方案　199
8．4　小结　202
第9　章 使用并行流处理大规模数据集：MapCollect 模型　203
9．1　使用流收集数据　203
9．2　第 一个例子：无索引条件下的数据搜索　205
9．2．1　基本类　205
9．2．2　第 一种方式：基本搜索　207
9．2．3　第二种方式：高级搜索　209
9．2．4　本例的串行实现　211
9．2．5　对比实现方案　211
9．3　第二个例子：推荐系统　212
9．3．1　公共类　212
9．3．2　推荐系统：主类　213
9．3．3　ConcurrentLoaderAccumulator 类　215
9．3．4　串行版　216
9．3．5　对比两个版本　216
9．4　第三个例子：社交网络中的共同联系人　217
9．4．1　基本类　218
9．4．2　并发版本　219
9．4．3　串行版本　223
9．4．4　对比两个版本　223
9．5　小结　224
第　10 章 异步流处理：反应流　225
10．1　Java 反应流简介　225
10．1．1　Flow．Publisher 接口　226
10．1．2　Flow．Subscriber 接口　226
10．1．3　Flow．Subscription 接口　226
10．1．4　SubmissionPublisher 类　226
10．2　第 一个例子：面向事件通知的集中式系统　227
10．2．1　Event 类　227
10．2．2　Producer 类　227
10．2．3　Consumer 类　228
10．2．4　Main 类　230
10．3　第二个例子：新闻系统　231
10．3．1　News 类　232
10．3．2　发布者相关的类　232
10．3．3　Consumer 类　235
10．3．4　Main 类　236
10．4　小结　238
第　11 章 探究并发数据结构和同步工具　240
11．1　并发数据结构　240
11．1．1　阻塞型数据结构和非阻塞型数据结构　241
11．1．2　并发数据结构　241
11．1．3　使用新特性　244
11．1．4　原子变量　251
11．1．5　变量句柄　252
11．2　同步机制　254
11．2．1　CommonTask 类　255
11．2．2　Lock 接口　255
11．2．3　Semaphore 类　256
11．2．4　CountDownLatch 类　258
11．2．5　CyclicBarrier 类　259
11．2．6　CompletableFuture 类　261
11．3　小结　268
第　12 章 测试与监视并发应用程序　269
12．1　监视并发对象　269
12．1．1　监视线程　269
12．1．2　监视锁　270
12．1．3　监视执行器　272
12．1．4　监视Fork/Join 框架　273
12．1．5　监视Phaser　274
12．1．6　监视流API　275
12．2　监视并发应用程序　276
12．2．1　Overview 选项卡　278
12．2．2　Memory 选项卡　279
12．2．3　Threads 选项卡　280
12．2．4　Classes 选项卡　280
12．2．5　VM Summary 选项卡　281
12．2．6　MBeans 选项卡　283
12．2．7　About 选项卡　284
12．3　测试并发应用程序　284
12．3．1　使用MultithreadedTC 测试并发应用程序　285
12．3．2　使用Java Pathfinder 测试并发应用程序　288
12．4　小结　293
第　13 章 JVM 中的并发处理：Clojure、带有GPars 库的Groovy 以及Scala　294
13．1　Clojure 的并发处理　294
13．1．1　使用Java 元素　295
13．1．2　引用类型　295
13．1．3　Ref 对象　298
13．1．4　Delay　299
13．1．5　Future　300
13．1．6　Promise　301
13．2　Groovy 及其GPars 库的并发处理　302
13．3　软件事务性内存　302
13．3．1　使用Java 元素　302
13．3．2　数据并行处理　303
13．3．3　Fork/Join 处理　307
13．3．4　Actor　308
13．3．5　Agent　315
13．3．6　Dataf low　316
13．4　Scala 的并发处理　322
13．4．1　Scala 中的Future 对象　322
13．4．2　Promise　328

第1章　概述　　1

1.1 并发还是并行？ 　　1

1.2 并行架构　　3

1.3 并发：不只是多核　　5

1.4 七个模型　　6

第2章　线程与锁　　7

2.1 简单粗暴　　7

2.2 第一天：互斥和内存模型　　8

2.3 第二天：超越内置锁　　17

2.4 第三天：站在巨人的肩膀上　　27

2.5 复习　　38

第3章　函数式编程　　41

3.1 若不爽，就另辟蹊径　　41

3.2 第一天：抛弃可变状态　　42

3.3 第二天：函数式并行　　51

3.4 第三天：函数式并发　　61

3.5 复习　　70

第4章　Clojure 之道——分离标识与状态　　73

4.1 混搭的力量　　73

4.2 第一天：原子变量与持久数据结构　　73

4.3 第二天：代理和软件事务内存　　84

4.4 第三天：深入学习　　92

4.5 复习　　98

第5章　Actor　　100

5.1 更加面向对象　　100

5.2 第一天：消息和信箱　　101

5.3 第二天：错误处理和容错性　　111

5.4 第三天：分布式　　120

5.5 复习　　132

第6章　通信顺序进程　　135

6.1 万物皆通信　　135

6.2 第一天：channel 和go 块　　136

6.3 第二天：多个channel 与IO　　146

6.4 第三天：客户端CSP　　157

6.5 复习　　164

第7章　数据并行　　167

7.1 隐藏在笔记本电脑中的超级计算机　　167

7.2 第一天：GPGPU编程　　167

7.3 第二天：多维空间与工作组　　177

7.4 第三天：OpenCL和OpenGL——全部在GPU 上运行　　187

7.5 复习　　194

第8章　Lambda架构　　196

8.1 并行计算搞定大数据　　196

8.2 第一天：MapReduce　　197

8.3 第二天：批处理层　　208

8.4 第三天：加速层　　218

8.5 复习　　229

第9章　圆满结束　　231

9.1 君欲何往　　231

9.2 未尽之路　　232

9.3 越过山丘　　234

第1部分 概述 / 1
1 交易型系统设计的一些原则 / 2
1.1 高并发原则 / 3
1.1.1 无状态 / 3
1.1.2 拆分 / 3
1.1.3 服务化 / 4
1.1.4 消息队列 / 4
1.1.5 数据异构 / 6
1.1.6 缓存银弹 / 7
1.1.7 并发化 / 9
1.2 高可用原则 / 10
1.2.1 降级 / 10
1.2.2 限流 / 11
1.2.3 切流量 / 12
1.2.4 可回滚 / 12
1.3 业务设计原则 / 12
1.3.1 防重设计 / 13
1.3.2 幂等设计 / 13
1.3.3 流程可定义 / 13
1.3.4 状态与状态机 / 13
1.3.5 后台系统操作可反馈 / 14
1.3.6 后台系统审批化 / 14
1.3.7 文档和注释 / 14
1.3.8 备份 / 14
1.4 总结 / 14
第2部分 高可用 / 17
2 负载均衡与反向代理 / 18
2.1 upstream配置 / 20
2.2 负载均衡算法 / 21
2.3 失败重试 / 23
2.4 健康检查 / 24
2.4.1 TCP心跳检查 / 24
2.4.2 HTTP心跳检查 / 25
2.5 其他配置 / 25
2.5.1 域名上游服务器 / 25
2.5.2 备份上游服务器 / 26
2.5.3 不可用上游服务器 / 26
2.6 长连接 / 26
2.7 HTTP反向代理示例 / 29
2.8 HTTP动态负载均衡 / 30
2.8.1 Consul+Consul-template / 31
2.8.2 Consul+OpenResty / 35
2.9 Nginx四层负载均衡 / 39
2.9.1 静态负载均衡 / 39
2.9.2 动态负载均衡 / 41
参考资料 / 42
3 隔离术 / 43
3.1 线程隔离 / 43
3.2 进程隔离 / 45
3.3 集群隔离 / 45
3.4 机房隔离 / 46
3.5 读写隔离 / 47
3.6 动静隔离 / 48
3.7 爬虫隔离 / 49
3.8 热点隔离 / 50
3.9 资源隔离 / 50
3.10 使用Hystrix实现隔离 / 51
3.10.1 Hystrix简介 / 51
3.10.2 隔离示例 / 52
3.11 基于Servlet 3实现请求隔离 / 56
3.11.1 请求解析和业务处理线程池分离 / 57
3.11.2 业务线程池隔离 / 58
3.11.3 业务线程池监控/运维/降级 / 58
3.11.4 如何使用Servlet 3异步化 / 59
3.11.5 一些Servlet 3异步化压测数据 / 64
4 限流详解 / 66
4.1 限流算法 / 67
4.1.1 令牌桶算法 / 67
4.1.2 漏桶算法 / 68
4.2 应用级限流 / 69
4.2.1 限流总并发/连接/请求数 / 69
4.2.2 限流总资源数 / 70
4.2.3 限流某个接口的总并发/请求数 / 70
4.2.4 限流某个接口的时间窗请求数 / 70
4.2.5 平滑限流某个接口的请求数 / 71
4.3 分布式限流 / 75
4.3.1 Redis+Lua实现 / 76
4.3.2 Nginx+Lua实现 / 77
4.4 接入层限流 / 78
4.4.1 ngx_http_limit_conn_module / 78
4.4.2 ngx_http_limit_req_module / 80
4.4.3 lua-resty-limit-traffic / 88
4.5 节流 / 90
4.5.1 throttleFirst/throttleLast / 90
4.5.2 throttleWithTimeout / 91
参考资料 / 92
5 降级特技 / 93
5.1 降级预案 / 93
5.2 自动开关降级 / 95
5.2.1 超时降级 / 95
5.2.2 统计失败次数降级 / 95
5.2.3 故障降级 / 95
5.2.4 限流降级 / 95
5.3 人工开关降级 / 96
5.4 读服务降级 / 96
5.5 写服务降级 / 97
5.6 多级降级 / 98
5.7 配置中心 / 100
5.7.1 应用层API封装 / 100
5.7.2 配置文件实现开关配置 / 101
5.7.3 配置中心实现开关配置 / 102
5.8 使用Hystrix实现降级 / 106
5.9 使用Hystrix实现熔断 / 108
5.9.1 熔断机制实现 / 108
5.9.2 配置示例 / 112
5.9.3 采样统计 / 113
6 超时与重试机制 / 117
6.1 简介 / 117
6.2 代理层超时与重试 / 119
6.2.1 Nginx / 119
6.2.2 Twemproxy / 126
6.3 Web容器超时 / 127
6.4 中间件客户端超时与重试 / 127
6.5 数据库客户端超时 / 131
6.6 NoSQL客户端超时 / 134
6.7 业务超时 / 135
6.8 前端Ajax超时 / 135
6.9 总结 / 136
6.10 参考资料 / 137
7 回滚机制 / 139
7.1 事务回滚 / 139
7.2 代码库回滚 / 140
7.3 部署版本回滚 / 141
7.4 数据版本回滚 / 142
7.5 静态资源版本回滚 / 143
8 压测与预案 / 145
8.1 系统压测 / 145
8.1.1 线下压测 / 146
8.1.2 线上压测 / 146
8.2 系统优化和容灾 / 147
8.3 应急预案 / 148
第3部分 高并发 / 153
9 应用级缓存 / 154
9.1 缓存简介 / 154
9.2 缓存命中率 / 155
9.3 缓存回收策略 / 155
9.3.1 基于空间 / 155
9.3.2 基于容量 / 155
9.3.3 基于时间 / 155
9.3.4 基于Java对象引用 / 156
9.3.5 回收算法 / 156
9.4 Java缓存类型 / 156
9.4.1 堆缓存 / 158
9.4.2 堆外缓存 / 162
9.4.3 磁盘缓存 / 162
9.4.4 分布式缓存 / 164
9.4.5 多级缓存 / 166
9.5 应用级缓存示例 / 167
9.5.1 多级缓存API封装 / 167
9.5.2 NULL Cache / 170
9.5.3 强制获取最新数据 / 170
9.5.4 失败统计 / 171
9.5.5 延迟报警 / 171
9.6 缓存使用模式实践 / 172
9.6.1 Cache-Aside / 173
9.6.2 Cache-As-SoR / 174
9.6.3 Read-Through / 174
9.6.4 Write-Through / 176
9.6.5 Write-Behind / 177
9.6.6 Copy Pattern / 181
9.7 性能测试 / 181
9.8 参考资料 / 182
10 HTTP缓存 / 183
10.1 简介 / 183
10.2 HTTP缓存 / 184
10.2.1 Last-Modified / 184
10.2.2 ETag / 190
10.2.3 总结 / 192
10.3 HttpClient客户端缓存 / 192
10.3.1 主流程 / 195
10.3.2 清除无效缓存 / 195
10.3.3 查找缓存 / 196
10.3.4 缓存未命中 / 198
10.3.5 缓存命中 / 198
10.3.6 缓存内容陈旧需重新验证 / 202
10.3.7 缓存内容无效需重新执行请求 / 205
10.3.8 缓存响应 / 206
10.3.9 缓存头总结 / 207
10.4 Nginx HTTP缓存设置 / 208
10.4.1 expires / 208
10.4.2 if-modified-since / 209
10.4.3 nginx proxy_pass / 209
10.5 Nginx代理层缓存 / 212
10.5.1 Nginx代理层缓存配置 / 212
10.5.2 清理缓存 / 215
10.6 一些经验 / 216
参考资料 / 217
11 多级缓存 / 218
11.1 多级缓存介绍 / 218
11.2 如何缓存数据 / 220
11.2.1 过期与不过期 / 220
11.2.2 维度化缓存与增量缓存 / 221
11.2.3 大Value缓存 / 221
11.2.4 热点缓存 / 221
11.3 分布式缓存与应用负载均衡 / 222
11.3.1 缓存分布式 / 222
11.3.2 应用负载均衡 / 222
11.4 热点数据与更新缓存 / 223
11.4.1 单机全量缓存+主从 / 223
11.4.2 分布式缓存+应用本地热点 / 224
11.5 更新缓存与原子性 / 225
11.6 缓存崩溃与快速修复 / 226
11.6.1 取模 / 226
11.6.2 一致性哈希 / 226
11.6.3 快速恢复 / 226
12 连接池线程池详解 / 227
12.1 数据库连接池 / 227
12.1.1 DBCP连接池配置 / 228
12.1.2 DBCP配置建议 / 233
12.1.3 数据库驱动超时实现 / 234
12.1.4 连接池使用的一些建议 / 235
12.2 HttpClient连接池 / 236
12.2.1 HttpClient 4.5.2配置 / 236
12.2.2 HttpClient连接池源码分析 / 240
12.2.3 HttpClient 4.2.3配置 / 241
12.2.4 问题示例 / 243
12.3 线程池 / 244
12.3.1 Java线程池 / 245
12.3.2 Tomcat线程池配置 / 248
13 异步并发实战 / 250
13.1 同步阻塞调用 / 251
13.2 异步Future / 252
13.3 异步Callback / 253
13.4 异步编排CompletableFuture / 254
13.5 异步Web服务实现 / 257
13.6 请求缓存 / 259
13.7 请求合并 / 261
14 如何扩容 / 266
14.1 单体应用垂直扩容 / 267
14.2 单体应用水平扩容 / 267
14.3 应用拆分 / 268
14.4 数据库拆分 / 271
14.5 数据库分库分表示例 / 275
14.5.1 应用层还是中间件层 / 275
14.5.2 分库分表策略 / 277
14.5.3 使用sharding-jdbc分库分表 / 279
14.5.4 sharding-jdbc分库分表配置 / 279
14.5.5 使用sharding-jdbc读写分离 / 283
14.6 数据异构 / 284
14.6.1 查询维度异构 / 284
14.6.2 聚合数据异构 / 285
14.7 任务系统扩容 / 285
14.7.1 简单任务 / 285
14.7.2 分布式任务 / 287
14.7.3 Elastic-Job简介 / 287
14.7.4 Elastic-Job-Lite功能与架构 / 287
14.7.5 Elastic-Job-Lite示例 / 288
15 队列术 / 295
15.1 应用场景 / 295
15.2 缓冲队列 / 296
15.3 任务队列 / 297
15.4 消息队列 / 297
15.5 请求队列 / 299
15.6 数据总线队列 / 300
15.7 混合队列 / 301
15.8 其他队列 / 302
15.9 Disruptor+Redis队列 / 303
15.10 下单系统水平可扩展架构 / 311
第4部分 案例 / 323
16 构建需求响应式亿级商品详情页 / 324
16.1 商品详情页是什么 / 324
16.2 商品详情页前端结构 / 325
16.3 我们的性能数据 / 327
16.4 单品页流量特点 / 327
16.5 单品页技术架构发展 / 327
16.5.1 架构1.0 / 328
16.5.2 架构2.0 / 328
16.5.3 架构3.0 / 330
16.6 详情页架构设计原则 / 332
16.7 遇到的一些坑和问题 / 339
16.8 其他 / 347
17 京东商品详情页服务闭环实践 / 348
17.1 为什么需要统一服务 / 348
17.2 整体架构 / 349
17.3 一些架构思路和总结 / 350
17.4 引入Nginx接入层 / 354
17.5 前端业务逻辑后置 / 356
17.6 前端接口服务端聚合 / 357
17.7 服务隔离 / 359
18 使用OpenResty开发高性能Web应用 / 360
18.1 OpenResty简介 / 361
18.1.1 Nginx优点 / 361
18.1.2 Lua的优点 / 361
18.1.3 什么是ngx_lua / 361
18.1.4 开发环境 / 362
18.1.5 OpenResty生态 / 362
18.1.6 场景 / 362
18.2 基于OpenResty的常用架构模式 / 363
18.3 如何使用OpenResty开发Web应用 / 371
18.4 基于OpenResty的常用功能总结 / 375
18.5 一些问题 / 376
19 应用数据静态化架构高性能单页Web应用 / 377
19.1 整体架构 / 378
19.2 数据和模板动态化 / 381
19.3 多版本机制 / 381
19.4 异常问题 / 382
20 使用OpenResty开发Web服务 / 383
20.1 架构 / 383
20.2 单DB架构 / 384
20.3 实现 / 387
21 使用OpenResty开发商品详情页 / 405
21.1 技术选型 / 407
21.2 核心流程 / 408
21.3 项目搭建 / 408
21.4 数据存储实现 / 410
21.5 动态服务实现 / 422
21.6 前端展示实现 / 430

