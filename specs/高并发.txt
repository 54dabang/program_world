
对于ThreadLocal感兴趣是从一个问题开始的：ThreadLocal在何种情况下会发生内存泄露？对于这个问题的思考不得不去了解ThreadLocal本身的实现以及一些细节问题等。接下去依次介绍ThreadLocal的功能，实现细节，使用场景以及一些使用建议。

##概述
ThreadLocal不是用来解决对象共享访问问题的，而主要提供了线程保持对象的方法和避免参数传递的方便的对象访问方式。一般情况下，通过ThreadLocal.set()到线程中的对象是该线程自己使用的对象，其他线程是不需要访问的，也访问不到的。各个线程中访问的是不同的对象。

ThreadLocal使用场合主要解决多线程中数据因并发产生不一致的问题。ThreadLocal为每个线程的中并发访问的数据提供一个副本，通过访问副本来运行业务，这样的结果是耗费了内存，但大大减少了线程同步所带来的线程消耗，也介绍了线程并发控制的复杂度。

另外，说ThreadLocal使得各线程能够保持各自独立的一个对象，并不是通过ThreadLocal.set()来实现的，而是通过每个线程中的new对象的操作来创建的对象，每个线程创建一个，不是什么对象的拷贝或副本。通过ThreadLocal.set()将这个新创建的对象的引用保存到各线程的自己的一个map(Thread类中的ThreadLocal.ThreadLocalMap的变量)中，每个线程都有这样一个map，执行ThreadLocal.get()时，各线程从自己的map中取出放进去的对象，因此取出来的是各自自己线程中的对象，ThreadLocal实例是作为map的key来使用的。
【代码1】

    /* ThreadLocal values pertaining to this thread. This map is maintained
     * by the ThreadLocal class. */
    ThreadLocal.ThreadLocalMap threadLocals = null;

    /*
     * InheritableThreadLocal values pertaining to this thread. This map is
     * maintained by the InheritableThreadLocal class.
     */
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
1
2
3
4
5
6
7
8
9
很多人会有这样的无解：感觉这个ThreadLocal对象建立了一个类似于全局的map，然后每个线程作为map的key来存取对应的线程本地的value。其实是ThreadLocal类中有一个ThreadLocalMap静态内部类，可以简单的理解为一个map，这个map为每个线程复制一个变量的“拷贝”存储其中。下面是ThreadLocalMap的部分源码：
【代码2】

static class ThreadLocalMap {
        static class Entry extends WeakReference<ThreadLocal> {
            Object value;
            Entry(ThreadLocal k, Object v) {
                super(k);
                value = v;
            }
        }
        private static final int INITIAL_CAPACITY = 16;
        private Entry[] table;
        private int size = 0;
        private int threshold; // Default to 0
        //部分省略
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
ThreadLocal类中一共有4个方法：

T get()
protected T initialValue()
void remove()
void set(T value)
就以get()方法为例
【代码3】

    public T get() {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null) {
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null)
                return (T)e.value;
        }
        return setInitialValue();
    }
    ThreadLocalMap getMap(Thread t) {
        return t.threadLocals;
    }
1
2
3
4
5
6
7
8
9
10
11
12
13
get()方法的源码如上所示，可以看到map中真正的key是线程ThreadLocal实例本身（ThreadLocalMap.Entry e = map.getEntry(this);中的this）。可以看一下getEntry(ThreadLocal key)的源码.
【代码4】

        private Entry getEntry(ThreadLocal key) {
            int i = key.threadLocalHashCode & (table.length - 1);
            Entry e = table[i];
            if (e != null && e.get() == key)
                return e;
            else
                return getEntryAfterMiss(key, i, e);
        }
1
2
3
4
5
6
7
8
那么map中的value是什么呢？我们继续来看源码：
【代码5】

    private T setInitialValue() {
        T value = initialValue();
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
        return value;
    }
    protected T initialValue() {
        return null;
    }
1
2
3
4
5
6
7
8
9
10
11
12
13
代码5中只能够观察到通过[protected T initialValue()]方法设置了一个初始值，当然也可以通过set方法来赋值，继续看源码：
【代码6】

    public void set(T value) {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
    }
1
2
3
4
5
6
7
8
ThreadLocal设置值有两种方案：1. Override其initialValue方法；2. 通过set设置。

关于重写initialValue方法可以参考下面这个例子简便的实现：
【代码7】

    private static final ThreadLocal<Long> TIME_THREADLOCAL = new ThreadLocal<Long>(){
        @Override
        protected Long initialValue()
        {
            return System.currentTimeMillis();
        }
    };
1
2
3
4
5
6
7
##内存泄露
通过代码1和代码2的片段可以看出，在Thread类中保有ThreadLocal.ThreadLocalMap的引用，即在一个Java线程栈中指向了堆内存中的一个ThreadLocal.ThreadLocalMap的对象，此对象中保存了若干个Entry，每个Entry的key(ThreadLocal实例)是弱引用，value是强引用（这点类似于WeakHashMap）。

用到弱引用的只是key，每个key都弱引用指向threadLocal，当把threadLocal实例置为null以后，没有任何强引用指向threadLocal实例，所以threadLocal将会被gc回收，但是value却不能被回收，因为其还存在于ThreadLocal.ThreadLocalMap的对象的Entry之中。只有当前Thread结束之后，所有与当前线程有关的资源才会被GC回收。所以，如果在线程池中使用ThreadLocal，由于线程会复用，而又没有显示的调用remove的话的确是会有可能发生内存泄露的问题。

其实在ThreadLocal.ThreadLocalMap的get或者set方法中会探测其中的key是否被回收（调用expungeStaleEntry方法），然后将其value设置为null，这个功能几乎和WeakHashMap中的expungeStaleEntries()方法一样。因此value在key被gc后可能还会存活一段时间，但最终也会被回收，但是若不再调用get或者set方法时，那么这个value就在线程存活期间无法被释放。
【代码8】

        private int expungeStaleEntry(int staleSlot) {
            Entry[] tab = table;
            int len = tab.length;

            // expunge entry at staleSlot
            tab[staleSlot].value = null;
            tab[staleSlot] = null;
            size--;

            // Rehash until we encounter null
            Entry e;
            int i;
            for (i = nextIndex(staleSlot, len);
                 (e = tab[i]) != null;
                 i = nextIndex(i, len)) {
                ThreadLocal k = e.get();
                if (k == null) {
                    e.value = null;
                    tab[i] = null;
                    size--;
                } else {
                    int h = k.threadLocalHashCode & (len - 1);
                    if (h != i) {
                        tab[i] = null;

                        // Unlike Knuth 6.4 Algorithm R, we must scan until
                        // null because multiple entries could have been stale.
                        while (tab[h] != null)
                            h = nextIndex(h, len);
                        tab[h] = e;
                    }
                }
            }
            return i;
        }
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
其实ThreadLocal本身可以看成是没有内存泄露问题的，通过显示的调用remove方法即可。

##使用场景及方式
ThreadLocal的应用场景，最适合的是按线程多实例（每个线程对应一个实例）的对象的访问，并且这个对象很多地方都要用到。

对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，比如定义一个static变量，同步访问，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。

在多线程的开发中，经常会考虑到的策略是对一些需要公开访问的属性通过设置同步的方式来访问。这样每次能保证只有一个线程访问它，不会有冲突。但是这样做的结果会使得性能和对高并发的支持不够。在某些情况下，如果我们不一定非要对一个变量共享不可，而是给每个线程一个这样的资源副本，让他们可以独立都各自跑各自的，这样不是可以大幅度的提高并行度和性能了吗？

还有的情况是有的数据本身不是线程安全的，或者说它只能被一个线程使用，不能被其它线程同时使用。如果等一个线程使用完了再给另一个线程使用就根本不现实。这样的情况下，我们也可以考虑用ThreadLocal。

ThreadLocal建议：

ThreadLocal类变量因为本身定位为要被多个线程来访问，它通常被定义为static变量。
能够通过值传递的参数，不要通过ThreadLocal存储，以免造成ThreadLocal的滥用。
在线程池的情况下，在ThreadLocal业务周期处理完成时，最好显示的调用remove()方法，清空“线程局部变量”中的值。
在正常情况下使用ThreadLocal不会造成OOM, 弱引用的知识ThreadLocal,保存值依然是强引用，如果ThreadLocal依然被其他对象应用，线程局部变量将无法回收。
##InheritableThreadLocal
InheritableThreadLocal是ThreadLocal的子类，代码量很少，可以看一下：
【代码9】

public class InheritableThreadLocal<T> extends ThreadLocal<T> {
    protected T childValue(T parentValue) {
        return parentValue;
    }
    ThreadLocalMap getMap(Thread t) {
       return t.inheritableThreadLocals;
    }
    void createMap(Thread t, T firstValue) {
        t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);
    }
}
1
2
3
4
5
6
7
8
9
10
11
这里主要的还是一个childValue这个方法。
在代码7中示范了ThreadLocal的方法，而使用类InheritableThreadLocal可以在子线程中取得父线程继承下来的值。可以采用重写childValue（Object parentValue）方法来更改继承的值。
查看案例：
【代码10】

public class InheriableThreadLocal
{
    public static final InheritableThreadLocal<?> itl = new InheritableThreadLocal<Object>(){
        @Override protected Object initialValue()
        {
            return new Date().getTime();
        }

        @Override protected Object childValue(Object parentValue)
        {
            return parentValue+" which plus in subThread.";
        }
    };

    public static void main(String[] args)
    {
        System.out.println("Main: get value = "+itl.get());
        Thread a = new Thread(new Runnable(){
            @Override public void run()
            {
                System.out.println(Thread.currentThread().getName()+": get value = "+itl.get());
            }
        });
        a.start();
    }
}

运行结果：

Main: get value = 1467100984858
Thread-0: get value = 1467100984858 which plus in subThread.
1
2
如果去掉@Override protected Object childValue(Object parentValue)方法运行结果：

Main: get value = 1461585396073
Thread-0: get value = 1461585396073







==================
1. interrupted与isInterrupted的区别
interrupted()：测试当前线程是否已经是中断状态，执行后具有状态标志清除为false的功能。
isInterrupted()：测试线程Thread对象是否已经是中断状态，但不清除状态标志。
方法：

    public static boolean interrupted() {
        return currentThread().isInterrupted(true);
    }
    public boolean isInterrupted() {
        return isInterrupted(false);
    }
    private native boolean isInterrupted(boolean ClearInterrupted);

2. 终止正在运行的线程的三种方法：
使用退出标志，是线程正常退出，也就是当run方法完成后线程终止；
使用stop方法强行终止线程，但是不推荐使用这个方法，因为stop和suspend及resume一样都是作废过期的方法，使用它们可能产生不可预料的结果；
使用interrupt方法中断线程；（推荐）
3. yield方法
yield()方法的作用是放弃当前的CPU资源，将它让给其他的任务去占用CPU执行时间。但放弃时间不确定，有可能刚刚放弃，马上又获得CPU时间片。这里需要注意的是yield()方法和sleep方法一样，线程并不会让出锁，和wait不同。

4. 线程的优先级
Java中线程的优先级分为1-10这10个等级，如果小于1或大于10则JDK抛出IllegalArgumentException()的异常，默认优先级是5。在Java中线程的优先级具有继承性，比如A线程启动B线程，则B线程的优先级与A是一样的。注意程序正确性不能依赖线程的优先级高低，因为操作系统可以完全不理会Java线程对于优先级的决定。

5. Java中线程的状态
New, Runnable, Blocked, Waiting, Time_waiting, Terminated.

6. 守护线程
Java中有两种线程，一种是用户线程，另一种是守护线程。当进程中不存在非守护线程了，则守护线程自动销毁。通过setDaemon(true)设置线程为后台线程。注意thread.setDaemon(true)必须在thread.start()之前设置，否则会报IllegalThreadStateException异常；在Daemon线程中产生的新线程也是Daemon的；在使用ExecutorSerice等多线程框架时，会把守护线程转换为用户线程，并且也会把优先级设置为Thread.NORM_PRIORITY。在构建Daemon线程时，不能依靠finally块中的内容来确保执行关闭或清理资源的逻辑。更多详细内容可参考《Java守护线程概述》

7. synchronized的类锁与对象锁
类锁：在方法上加上static synchronized的锁，或者synchronized(xxx.class)的锁。如下代码中的method1和method2：
对象锁：参考method4, method5,method6.

public class LockStrategy
{
    public Object object1 = new Object();

    public static synchronized void method1(){}
    public void method2(){
        synchronized(LockStrategy.class){}
    }

    public synchronized void method4(){}
    public void method5()
    {
        synchronized(this){}
    }
    public void method6()
    {
        synchronized(object1){}
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
注意方法method4和method5中的同步块也是互斥的。
下面做一道习题来加深一下对对象锁和类锁的理解：
有一个类这样定义

public class SynchronizedTest
{
    public synchronized void method1(){}
    public synchronized void method2(){}
    public static synchronized void method3(){}
    public static synchronized void method4(){}
}
1
2
3
4
5
6
7
那么，有SynchronizedTest的两个实例a和b，对于一下的几个选项有哪些能被一个以上的线程同时访问呢？
A. a.method1() vs. a.method2()
B. a.method1() vs. b.method1()
C. a.method3() vs. b.method4()
D. a.method3() vs. b.method3()
E. a.method1() vs. a.method3()
答案是什么呢？BE
有关Java中的锁的详细信息，可以参考《Java中的锁》

8. 同步不具备继承性
当一个线程执行的代码出现异常时，其所持有的锁会自动释放。同步不具有继承性（声明为synchronized的父类方法A，在子类中重写之后并不具备synchronized的特性）。

9. wait, notify, notifyAll用法
只能在同步方法或者同步块中使用wait()方法。在执行wait()方法后，当前线程释放锁（这点与sleep和yield方法不同）。调用了wait函数的线程会一直等待，知道有其他线程调用了同一个对象的notify或者notifyAll方法才能被唤醒，需要注意的是：被唤醒并不代表立刻获得对象的锁，要等待执行notify()方法的线程执行完，即退出synchronized代码块后，当前线程才会释放锁，而呈wait状态的线程才可以获取该对象锁。

如果调用wait()方法时没有持有适当的锁，则抛出IllegalMonitorStateException，它是RuntimeException的一个子类，因此，不需要try-catch语句进行捕获异常。

notify方法只会（随机）唤醒一个正在等待的线程，而notifyAll方法会唤醒所有正在等待的线程。如果一个对象之前没有调用wait方法，那么调用notify方法是没有任何影响的。
详细可以参考《JAVA线程间协作：wait.notify.notifyAll》

带参数的wait(long timeout)或者wait(long timeout, int nanos)方法的功能是等待某一时间内是否有线程对锁进行唤醒，如果超过这个时间则自动唤醒。

10. 管道
在Java中提供了各种各样的输入/输出流Stream，使我们能够很方便地对数据进行操作，其中管道流（pipeStream)是一种特殊的流，用于在不同线程间直接传送数据。一个线程发送数据到输出管道，另一个线程从输入管道中读数据，通过使用管道，实现不同线程间的通信，而无须借助类似临时文件之类的东西。在JDK中使用4个类来使线程间可以进行通信：PipedInputStream, PipedOutputStream, PipedReader, PipedWriter。使用代码类似inputStream.connect(outputStream)或outputStream.connect(inputStream)使两个Stream之间产生通信连接。

几种进程间的通信方式

管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
有名管道 (named pipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
套接字( socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。
11. join方法
如果一个线程A执行了thread.join()语句，其含义是：当前线程A等待thread线程终止之后才从thread.join()返回。join与synchronized的区别是：join在内部使用wait()方法进行等待，而synchronized关键字使用的是“对象监视器”做为同步。
join提供了另外两种实现方法：join(long millis)和join(long millis, int nanos)，至多等待多长时间而退出等待(释放锁)，退出等待之后还可以继续运行。内部是通过wait方法来实现的。

可以参考一下一个例子：

        System.out.println("method main begin-----");
        Thread t = new Thread(new Runnable(){
            int i = 0;
            @Override
            public void run()
            {
                while(true)
                {
                    System.out.println(i++);
                    try
                    {
                        TimeUnit.MILLISECONDS.sleep(100);
                    }
                    catch (InterruptedException e)
                    {
                        e.printStackTrace();
                    }
                }
            }
        });
        t.start();
        t.join(2000);
        System.out.println("method main end-----");
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
运行结果：

method main begin-----
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
method main end-----
19
20
21
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
12.ThreadLocal
ThreadLocal可以实现每个线程绑定自己的值，即每个线程有各自独立的副本而互相不受影响。一共有四个方法：get, set, remove, initialValue。可以重写initialValue()方法来为ThreadLocal赋初值。如下：

    private static final ThreadLocal<Long> TIME_THREADLOCAL = new ThreadLocal<Long>(){
        @Override
        protected Long initialValue()
        {
            return System.currentTimeMillis();
        }
    };
1
2
3
4
5
6
7
ThreadLocal建议设置为static类型的。
使用类InheritableThreadLocal可以在子线程中取得父线程继承下来的值。可以采用重写childValue（Object parentValue）方法来更改继承的值。
查看案例：

public class InheriableThreadLocal
{
    public static final InheritableThreadLocal<?> itl = new InheritableThreadLocal<Object>(){
        @Override protected Object initialValue()
        {
            return new Date().getTime();
        }

        @Override protected Object childValue(Object parentValue)
        {
            return parentValue+" which plus in subThread.";
        }
    };

    public static void main(String[] args)
    {
        System.out.println("Main: get value = "+itl.get());
        Thread a = new Thread(new Runnable(){
            @Override public void run()
            {
                System.out.println(Thread.currentThread().getName()+": get value = "+itl.get());
            }
        });
        a.start();
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
运行结果：

Main: get value = 1461585405704
Thread-0: get value = 1461585405704 which plus in subThread.

1
2
3
如果去掉@Override protected Object childValue(Object parentValue)方法运行结果：

Main: get value = 1461585396073
Thread-0: get value = 1461585396073
1
2
注意：在线程池的情况下，在ThreadLocal业务周期处理完成时，最好显式的调用remove()方法，清空”线程局部变量”中的值。正常情况下使用ThreadLocal不会造成内存溢出，弱引用的只是threadLocal，保存的值依然是强引用的，如果threadLocal依然被其他对象强引用，”线程局部变量”是无法回收的。

13. ReentrantLock
ReentrantLock提供了tryLock方法，tryLock调用的时候，如果锁被其他线程持有，那么tryLock会立即返回，返回结果为false；如果锁没有被其他线程持有，那么当前调用线程会持有锁，并且tryLock返回的结果为true。

boolean tryLock()
boolean tryLock(long timeout, TimeUnit unit)
1
2
可以在构造ReentranLock时使用公平锁，公平锁是指多个线程在等待同一个锁时，必须按照申请锁的先后顺序来一次获得锁。synchronized中的锁时非公平的，默认情况下ReentrantLock也是非公平的，但是可以在构造函数中指定使用公平锁。

ReentrantLock()
ReentrantLock(boolean fair)
1
2
对于ReentrantLock来说，还有一个十分实用的特性，它可以同时绑定多个Condition条件，以实现更精细化的同步控制。
ReentrantLock使用方式如下：

    Lock lock = new ReentrantLock();
    lock.lock();
    try{
    }finally{
        lock.unlock();
    }
1
2
3
4
5
6
14. ReentrantLock中的其余方法
int getHoldCount()：查询当前线程保持此锁定的个数，也就是调用lock()方法的次数。
int getQueueLength()：返回正等待获取此锁定的线程估计数。比如有5个线程，1个线程首先执行await()方法，那么在调用getQueueLength方法后返回值是4，说明有4个线程在等待lock的释放。
int getWaitQueueLength(Condition condition)：返回等待此锁定相关的给定条件Condition的线程估计数。比如有5个线程，每个线程都执行了同一个condition对象的await方法，则调用getWaitQueueLength(Condition condition)方法时返回的int值是5。
boolean hasQueuedThread(Thread thread)：查询指定线程是否正在等待获取此锁定。
boolean hasQueuedThreads()：查询是否有线程正在等待获取此锁定。
boolean hasWaiters(Condition condition)：查询是否有线程正在等待与此锁定有关的condition条件。
boolean isFair()：判断是不是公平锁。
boolean isHeldByCurrentThread()：查询当前线程是否保持此锁定。
boolean isLocked()：查询此锁定是否由任意线程保持。
void lockInterruptibly()：如果当前线程未被中断，则获取锁定，如果已经被中断则出现异常。
15. Condition
一个Condition和一个Lock关联在一起，就想一个条件队列和一个内置锁相关联一样。要创建一个Condition，可以在相关联的Lock上调用Lock.newCondition方法。正如Lock比内置加锁提供了更为丰富的功能，Condition同样比内置条件队列提供了更丰富的功能：在每个锁上可存在多个等待、条件等待可以是可中断的或者不可中断的、基于时限的等待，以及公平的或非公平的队列操作。与内置条件队列不同的是，对于每个Lock，可以有任意数量的Condition对象。Condition对象继承了相关的Lock对象的公平性，对于公平的锁，线程会依照FIFO顺序从Condition.await中释放。

注意：在Condition对象中，与wait,notify和notifyAll方法对于的分别是await,signal,signalAll。但是，Condition对Object进行了扩展，因而它也包含wait和notify方法。一定要确保使用的版本——await和signal.

详细可参考《JAVA线程间协作：Condition》

16. 读写锁ReentrantReadWriteLock
读写锁表示也有两个锁，一个是读操作相关的锁，也称为共享锁；另一个是写操作相关的锁，也叫排它锁。也就是多个读锁之间不互斥，读锁与写锁互斥，写锁与写锁互斥。在没有Thread进行写操作时，进行读取操作的多个Thread都可以获取读锁，而进行写入操作的Thread只有在获取写锁后才能进行写入操作。即多个Thread可以同时进行读取操作，但是同一时刻只允许一个Thread进行写入操作。(lock.readlock.lock(), lock.readlock.unlock, lock.writelock.lock, lock.writelock.unlock)

17. Timer的使用
JDK中的Timer类主要负责计划任务的功能，也就是在指定时间开始执行某一任务。Timer类的主要作用就是设置计划任务，但封装任务的类却是TimerTask类（public abstract class TimerTask extends Object implements Runnable）。可以通过new Timer(true)设置为后台线程。

有以下几个方法：

void schedule(TimerTask task, Date time)：在指定的日期执行某一次任务。如果执行任务的时间早于当前时间则立刻执行。
void schedule(TimerTask task, Date firstTime, long period)：在指定的日期之后，按指定的间隔周期性地无限循环地执行某一任务。如果执行任务的时间早于当前时间则立刻执行。
void schedule(TimerTask task, long delay)：以当前时间为参考时间，在此基础上延迟指定的毫秒数后执行一次TimerTask任务。
void schedule(TimerTask task, long delay, long period）：以当前时间为参考时间，在此基础上延迟指定的毫秒数，再以某一间隔无限次数地执行某一任务。
void scheduleAtFixedRate(TimerTask task, Date firstTime, long period)：下次执行任务时间参考上次任务的结束时间，且具有“追赶性”。
TimerTask是以队列的方式一个一个被顺序执行的，所以执行的时间有可能和预期的时间不一致，因为前面的任务有可能消耗的时间较长，则后面的任务运行时间也会被延迟。
TimerTask类中的cancel方法的作用是将自身从任务队列中清除。
Timer类中的cancel方法的作用是将任务队列中的全部任务清空，并且进程被销毁。

Timer的缺陷：Timer支持基于绝对时间而不是相对时间的调度机制，因此任务的执行对系统时钟变化很敏感，而ScheduledThreadPoolExecutor只支持相对时间的调度。Timer在执行所有定时任务时只会创建一个线程。如果某个任务的执行时间过长，那么将破坏其他TimerTask的定时精确性。Timer的另一个问题是，如果TimerTask抛出了一个未检查的异常，那么Timer将表现出糟糕的行为。Timer线程并不波或异常，因此当TimerTask抛出为检测的异常时将终止定时线程。

JDK5或者更高的JDK中已经很少使用Timer.

18. 线程安全的单例模式
建议不要采用DCL的写法，建议使用下面这种写法：

public class LazyInitHolderSingleton {
        private LazyInitHolderSingleton() {
        }

        private static class SingletonHolder {
                private static final LazyInitHolderSingleton INSTANCE = new LazyInitHolderSingleton();
        }

        public static LazyInitHolderSingleton getInstance() {
                return SingletonHolder.INSTANCE;
        }
}
1
2
3
4
5
6
7
8
9
10
11
12
或者这种：

public enum SingletonClass
{
    INSTANCE;
}
1
2
3
4
19. 线程组ThreadGroup
为了有效地对一些线程进行组织管理，通常的情况下事创建一个线程组，然后再将部分线程归属到该组中，这样可以对零散的线程对象进行有效的组织和规划。参考以下案例：

        ThreadGroup tgroup = new ThreadGroup("mavelous zzh");
        new Thread(tgroup, new Runnable(){
            @Override
            public void run()
            {
                System.out.println("A: Begin: "+Thread.currentThread().getName());
                while(!Thread.currentThread().isInterrupted())
                {

                }
                System.out.println("A: DEAD: "+Thread.currentThread().getName());
            }}).start();;
        new Thread(tgroup, new Runnable(){
            @Override
            public void run()
            {
                System.out.println("B: Begin: "+Thread.currentThread().getName());
                while(!Thread.currentThread().isInterrupted())
                {

                }
                System.out.println("B: DEAD: "+Thread.currentThread().getName());
            }}).start();;
        System.out.println(tgroup.activeCount());
        System.out.println(tgroup.getName());
        System.out.println(tgroup.getMaxPriority());
        System.out.println(tgroup.getParent());
        TimeUnit.SECONDS.sleep(5);
        tgroup.interrupt();
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
输出：

A: Begin: Thread-0
2
mavelous zzh
10
B: Begin: Thread-1
java.lang.ThreadGroup[name=main,maxpri=10]
B: DEAD: Thread-1
A: DEAD: Thread-0
1
2
3
4
5
6
7
8
20. 多线程的异常捕获UncaughtExceptionHandler
setUncaughtExceptionHandler()的作用是对指定线程对象设置默认的异常处理器。

        Thread thread = new Thread(new Runnable(){
            @Override
            public void run()
            {
                int a=1/0;
            }
        });
        thread.setUncaughtExceptionHandler(new UncaughtExceptionHandler(){
            @Override
            public void uncaughtException(Thread t, Throwable e)
            {
                System.out.println("线程："+t.getName()+" 出现了异常："+e.getMessage());
            }
        });
        thread.start();
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
输出：线程：Thread-0 出现了异常：/ by zero
setDefaultUncaughtExceptionHandler()方法对所有线程对象设置异常处理器。

        Thread thread = new Thread(new Runnable(){
            @Override
            public void run()
            {
                int a=1/0;
            }
        });
        Thread.setDefaultUncaughtExceptionHandler(new UncaughtExceptionHandler(){
            @Override
            public void uncaughtException(Thread t, Throwable e)
            {
                System.out.println("线程："+t.getName()+" 出现了异常："+e.getMessage());
            }
        });
        thread.start();
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
输出同上，注意两者之间的区别。如果既包含setUncaughtExceptionHandler又包含setDefaultUncaughtExceptionHandler那么会被setUncaughtExceptionHandler处理，setDefaultUncaughtExceptionHandler则忽略。更多详细信息参考《JAVA多线程之UncaughtExceptionHandler——处理非正常的线程中止》

21.ReentrantLock与synchonized区别
ReentrantLock可以中断地获取锁（void lockInterruptibly() throws InterruptedException）
ReentrantLock可以尝试非阻塞地获取锁（boolean tryLock()）
ReentrantLock可以超时获取锁。通过tryLock(timeout, unit)，可以尝试获得锁，并且指定等待的时间。
ReentrantLock可以实现公平锁。通过new ReentrantLock(true)实现。
ReentrantLock对象可以同时绑定多个Condition对象，而在synchronized中，锁对象的的wait(), notify(), notifyAll()方法可以实现一个隐含条件，如果要和多于一个的条件关联的对象，就不得不额外地添加一个锁，而ReentrantLock则无需这样做，只需要多次调用newCondition()方法即可。
22. 使用多线程的优势
更多的处理器核心；更快的响应时间；更好的编程模型。

23. 构造线程
一个新构造的线程对象是由其parent线程来进行空间分配的，而child线程继承了parent线程的：是否为Daemon、优先级、加载资源的contextClassLoader以及InheritableThreadLocal(参考第12条)，同时还会分配一个唯一的ID来标志这个child线程。

24. 使用多线程的方式
extends Thread 或者implements Runnable

25. 读写锁
读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排它锁有了很大的提升。Java中使用ReentrantReadWriteLock实现读写锁，读写锁的一般写法如下(修改自JDK7中的示例)：

    class RWDictionary {
    private final Map<String, Object> m = new TreeMap<String, Object>();
    private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
    private final Lock r = rwl.readLock();
    private final Lock w = rwl.writeLock();

    public Object get(String key)
    {
        r.lock();
        try
        {
            return m.get(key);
        }
        finally
        {
            r.unlock();
        }
    }

    public String[] allKeys()
    {
        r.lock();
        try
        {
            return (String[]) m.keySet().toArray();
        }
        finally
        {
            r.unlock();
        }
    }

    public Object put(String key, Object value)
    {
        w.lock();
        try
        {
            return m.put(key, value);
        }
        finally
        {
            w.unlock();
        }
    }

    public void clear()
    {
        w.lock();
        try
        {
            m.clear();
        }
        finally
        {
            w.unlock();
        }
    }
 }

26.锁降级
锁降级是指写锁降级成读锁。如果当前线程拥有写锁，然后将其释放，最后获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住（当前拥有的）写锁，再获取到读锁，最后释放（先前拥有的）写锁的过程。参考下面的示例：

    private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
    private final Lock r = rwl.readLock();
    private final Lock w = rwl.writeLock();
    private volatile static boolean update = false;

    public void processData()
    {
        r.lock();
        if(!update)
        {
            //必须先释放读锁
            r.unlock();
            //锁降级从写锁获取到开始
            w.lock();
            try
            {
                if(!update)
                {
                    //准备数据的流程（略）
                    update = true;
                }
                r.lock();
            }
            finally
            {
                w.unlock();
            }
            //锁降级完成，写锁降级为读锁
        }

        try
        {
            //使用数据的流程（略）
        }
        finally
        {
            r.unlock();
        }
    }

锁降级中的读锁是否有必要呢？答案是必要。主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。


27. ConcurrentHashMap
ConcurrentHashMap是线程安全的HashMap，内部采用分段锁来实现，默认初始容量为16，装载因子为0.75f，分段16，每个段的HashEntry<K,V>[]大小为2。**键值都不能为null。**每次扩容为原来容量的2倍，ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容。在获取size操作的时候，不是直接把所有segment的count相加就可以可到整个ConcurrentHashMap大小，也不是在统计size的时候把所有的segment的put, remove, clean方法全部锁住，这种方法太低效。在累加count操作过程中，之前累加过的count发生变化的几率非常小，所有ConcurrentHashMap的做法是先尝试2（RETRIES_BEFORE_LOCK）次通过不锁住Segment的方式统计各个Segment大小，如果统计的过程中，容器的count发生了变化，再采用加锁的方式来统计所有的Segment的大小。

28. 线程安全的非阻塞队列
非阻塞队列有ConcurrentLinkedQueue, ConcurrentLinkedDeque。**元素不能为null。**以ConcurrentLinkedQueue为例，有头head和尾tail两个指针，遵循FIFO的原则进行入队和出队，方法有add(E e), peek()取出不删除, poll()取出删除, remove(Object o)，size(), contains(Object o), addAll(Collection c), isEmpty()。ConcurrentLinkedDeque是双向队列，可以在头和尾两个方向进行相应的操作。

29. 阻塞队列
阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。
支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。
支持阻塞的移除方法：意思是队列为空时，获取元素的线程会等待队列变为非空。
任何阻塞队列中的元素都不能为null.

30. 阻塞队列的插入和移除操作处理方式：
方法-处理方法	抛出异常	返回特殊值	可能阻塞等待	可设定等待时间
入队	add(e)	offer(e)	put(e)	offer(e,timeout,unit)
出队	remove()	poll()	take()	poll(timeout,unit)
查看	element()	peek()	无	无
如果是无界队列，队列不可能出现满的情况，所以使用put或offer方法永远不会被阻塞，而且使用offer方法时，该方法永远返回true.

31. Java里的阻塞队列
ArrayBlockingQueue:一个由数组结构组成的有界阻塞队列。
LinkedeBlockingQueue:一个有链表结构组成的有界阻塞队列。
PriorityBlockingQueue:一个支持优先级排序的无界阻塞队列
DelayQueue:一个使用优先级队列实现的无界阻塞队列。
SynchronousQueue:一个不存储元素的阻塞队列。
LinkedTransferQueue:一个由链表结构组成的无界阻塞队列。
LinkedBlockingDeque:一个由链表结构组成的双向阻塞队列。

###32. ArrayBlockingQueue
此队列按照FIFO的原则对元素进行排序，可以设定为公平ArrayBlockingQueue(int capacity, boolean fair)，默认为不公平。初始化时必须设定容量大小ArrayBlockingQueue(int capactiy)。

33. LinkedBlockingQueue
与ArrayBlockingQueue一样，按照FIFO原则进行排序，与ArrayBlockingQueue不同的是内部实现是一个链表结构，且不能设置为公平的。默认和最大长度为Integer.MAX_VALUE。

34. PriorityBlockingQueue
是一个支持优先级的无界阻塞队列，默认初始容量为11，默认情况下采用自然顺序升序排列，不能保证同优先级元素的顺序。内部元素要么实现Comparable接口，要么在初始化的时候指定构造函数的Comparator来对元素进行排序，有关Comparable与Comparator的细节可以参考：Comparable与Comparator浅析。

35. DelayQueue
DelayQueue是一个支持延时获取元素的无界阻塞队列。内部包含一个PriorityQueue来实现，队列中的元素必须实现Delay接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。
DelayQueue非常有用，可以将DelayQueue运用在下面应用场景。

缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue,一旦能从DelayQueue中获取元素时，表示缓存有效期到了。
定时任务调度：使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，比如TimerQueue就是使用DelayQueue实现的。
36. SynchronousQueue
是一个不存储元素的阻塞队列，每一个put操作必须等待一个take操作，否则不能继续添加元素，非常适合传递性场景。支持公平访问队列。默认情况下线程采用非公平策略访问队列。

37. LinkedTransferQueue
是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，LinkedTransferQueue多了tryTransfer和transfer方法。
transfer方法：如果当前有消费者正在等待接收元素（消费者使用take()或者带时间限制的poll方法时），transfer方法可以把生产者传入的元素立刻transfer给消费者，如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。
tryTransfer方法：用来试探生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立刻返回，而transfer方法是必须等到消费者消费了才返回。

38. LinkedBlockingDeque
LinkedBlockingDeque是一个由链表结构组成的双向阻塞队列。所谓双向队列是指可以从队列的两端插入和移除元素。双向队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相对其他的阻塞队列，LinkedBlockingDeque多了addFirst, addLast, offerFirst, offerLast, peekFirst, peekLast等方法。

39. Fork/Join框架
Fork/Join框架是JDK7提供的一个用于并行执行任务的框架，是一个把大任务切分为若干子任务并行的执行，最终汇总每个小任务后得到大任务结果的框架。我们再通过Fork和Join来理解下Fork/Join框架。Fork就是把一个大任务划分成为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。

使用Fork/Join框架时，首先需要创建一个ForkJoin任务，它提供在任务中执行fork()和join操作的机制。通常情况下，我们不需要直接继承ForkJoinTask，只需要继承它的子类，Fork/Join框架提供了两个子类：RecursiveAction用于没有返回结果的任务；RecursiveTask用于有返回结果的任务。ForkJoinTask需要通过ForkJoinPool来执行。

任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。（工作窃取算法work-stealing）

示例：计算1+2+3+…+100的结果。

import java.util.concurrent.ExecutionException;
import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.Future;
import java.util.concurrent.RecursiveTask;

public class CountTask extends RecursiveTask<Integer>
{
    private static final int THRESHOLD = 10;
    private int start;
    private int end;

    public CountTask(int start, int end)
    {
        super();
        this.start = start;
        this.end = end;
    }

    @Override
    protected Integer compute()
    {
        int sum = 0;
        boolean canCompute = (end-start) <= THRESHOLD;
        if(canCompute)
        {
            for(int i=start;i<=end;i++)
            {
                sum += i;
            }
        }
        else
        {
            int middle = (start+end)/2;
            CountTask leftTask = new CountTask(start,middle);
            CountTask rightTask = new CountTask(middle+1,end);
            leftTask.fork();
            rightTask.fork();
            int leftResult = leftTask.join();
            int rightResult = rightTask.join();
            sum = leftResult+rightResult;
        }

        return sum;
    }

    public static void main(String[] args)
    {
        ForkJoinPool forkJoinPool = new ForkJoinPool();
        CountTask task = new CountTask(1,100);
        Future<Integer> result = forkJoinPool.submit(task);
        try
        {
            System.out.println(result.get());
        }
        catch (InterruptedException | ExecutionException e)
        {
            e.printStackTrace();
        }

        if(task.isCompletedAbnormally()){
            System.out.println(task.getException());
        }
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
40. 原子类
Java中Atomic包里一共提供了12个类，属于4种类型的原子更新方式，分别是原子更新基本类型、原子更新数组、原子更新引用、原子更新属性（字段）。Atomic包里的类基本都是使用Unsafe实现的包装类。
1）原子更新基本类型：AtomicBoolean，AtomicInteger, AtomicLong.
2）原子更新数组：AtomicIntegerArray，AtomicLongArray, AtomicReferenceArray.
3）原子更新引用类型：AtomicReference, AtomicStampedReference, AtomicMarkableReference.
4 ) 原子更新字段类型：AtomicReferenceFieldUpdater, AtomicIntegerFieldUpdater, AtomicLongFieldUpdater.

41. 原子更新基本类型
AtomicBoolean，AtomicInteger, AtomicLong三个类提供的方法类似，以AtomicInteger为例：有int addAndGet(int delta), boolean compareAndSet(int expect, int update), int getAndIncrement(), void lazySet(int newValue)，int getAndSet(int newValue)。其中大多数的方法都是调用compareAndSet方法实现的，譬如getAndIncrement():

    public final int getAndIncrement() {
        for (;;) {
            int current = get();
            int next = current + 1;
            if (compareAndSet(current, next))
                return current;
        }
    }
    public final boolean compareAndSet(int expect, int update) {
        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
    }


sun.misc.Unsafe只提供三种CAS方法：compareAndSwapObject, compareAndSwapInt和compareAndSwapLong，再看AtomicBoolean源码，发现它是先把Boolean转换成整形，再使用compareAndSwapInt进行CAS，原子更新char,float,double变量也可以用类似的思路来实现。

42. 原子更新数组
以AtomicIntegerArray为例，此类主要提供原子的方式更新数组里的整形，常用方法如下：
int addAndGet(int i, int delta)：以原子的方式将输入值与数组中索引i的元素相加。
boolean compareAndSet(int i, int expect, int update)：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。
AtomicIntegerArray的两个构造方法：
AtomicIntegerArray(int length)：指定数组的大小，并初始化为0
AtomicIntegerArray(int [] array)：对给定的数组进行拷贝。
案例：

        int value[] = new int[]{1,2,3};
        AtomicIntegerArray aia = new AtomicIntegerArray(value);
        System.out.println(aia.getAndSet(1, 9));
        System.out.println(aia.get(1));
        System.out.println(value[1]);
1
2
3
4
5
运行结果：2 9 2

43. CountDownLatch
CountDownLatch允许一个或多个线程等待其他线程完成操作。CountDownLatch的构造函数接收一个int类型的参数作为计数器，如果你想等待N个点完成，这里就传入N（CountDownLatch(int count)）。
CountDownLatch的方法有：await(), await(long timeout, TimeUnit unit), countDown(), getCount()等。

计数器必须大于等于0，只是等于0的时候，计数器就是零，调用await方法时不会阻塞当前线程。CountDownLatch不可能重新初始化或者修改CountDownLatch对象的内部计数器的值。一个线程调用countDown方法happens-before另一个线程调用的await()方法。

44. CyclicBarrier
让一组线程达到一个屏障时被阻塞，知道最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。CyclicBarrier默认的构造方法是CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经达到了屏障，然后当前线程被阻塞。CyclicBarrier还提供了一个更高级的构造函数CyclicBarrier(int parties, Runnable barrierAction)用于在线程达到屏障时，优先执行barrierAction，方便处理更复杂的业务场景，举例如下。

import java.util.concurrent.BrokenBarrierException;
import java.util.concurrent.CyclicBarrier;

public class CyclicBarrierTest
{
    static CyclicBarrier c = new CyclicBarrier(2,new A());

    public static void main(String[] args)
    {
        new Thread(new Runnable(){
            @Override
            public void run()
            {
                try
                {
                    System.out.println(1);
                    c.await();
                }
                catch (InterruptedException | BrokenBarrierException e)
                {
                    e.printStackTrace();
                }
                System.out.println(2);
            }
        }).start();

        try
        {
            System.out.println(3);
            c.await();
        }
        catch (InterruptedException | BrokenBarrierException e)
        {
            e.printStackTrace();
        }
        System.out.println(4);
    }

    static class A implements Runnable
    {
        @Override
        public void run()
        {
            System.out.println(5);
        }
    }
}

输出结果：3 1 5 2 4

45. CyclicBarrier和CountDownLatch的区别
CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。

46. Semaphore
Semaphore(信号量)是用来控制同事访问特定资源的线程数量，它协调各个线程，以保证合理的使用公共资源。Semaphore有两个构造函数：Semaphore(int permits)默认是非公平的，Semaphore(int permits, boolean fair)可以设置为公平的。应用案例如下：

public class SemaphoreTest
{
    private static final int THREAD_COUNT=30;
    private static ExecutorService threadPool = Executors.newFixedThreadPool(30);
    private static Semaphore s = new Semaphore(10);

    public static void main(String[] args)
    {
        for(int i=0;i<THREAD_COUNT;i++)
        {
            final int a = i;
            threadPool.execute(new Runnable(){
                @Override
                public void run()
                {
                    try
                    {
                        s.acquire();
                        System.out.println("do something...."+a);
                        s.release();
                    }
                    catch (InterruptedException e)
                    {
                        e.printStackTrace();
                    }
                }
            });
        }
        threadPool.shutdown();
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
由上例可以看出Semaphore的用法非常的简单，首先线程使用Semaphore的acquire()方法获取一个许可证，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。Semaphore还提供了一些其他方法： int availablePermits()返回此信号量中当前可用的许可证数；int getQueueLength()返回正在等待获取许可证的线程数；boolean hasQueuedThreads()是否有线程正在等待获取许可证；void reducePermits(int reduction)减少reduction个许可证，是个protected方法；Collection<Thread> getQueuedThreads()返回所有等待获取许可证的线程集合，也是一个protected方法。

47. 线程间交换数据的Exchanger
Exchanger是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法。当两个线程都到达同步点时，这两个线程就可以交换数据，将本现场生产出来的数据传递给对方。

import java.util.concurrent.Exchanger;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class ExchangerTest
{
    private static final Exchanger<String> exchanger = new Exchanger<>();
    private static ExecutorService threadPool = Executors.newFixedThreadPool(2);

    public static void main(String[] args)
    {
        threadPool.execute(new Runnable(){
            @Override
            public void run()
            {
                String A = "I'm A!";
                try
                {
                    String B = exchanger.exchange(A);
                    System.out.println("In 1-"+Thread.currentThread().getName()+": "+B);
                }
                catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
            }
        });

        threadPool.execute(new Runnable(){
            @Override
            public void run()
            {
                try
                {
                    String B="I'm B!";
                    String A = exchanger.exchange(B);
                    System.out.println("In 2-"+Thread.currentThread().getName()+": "+A);
                }
                catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
            }
        });
        threadPool.shutdown();
    }
}

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
输出结果：

In 2-pool-1-thread-2: I'm A!
In 1-pool-1-thread-1: I'm B!
1
2
如果两个线程有一个没有执行exchange(V x)方法，则会一直等待，如果担心有特殊情况发生，避免一直等待，可以使用exchange(V x, long timeout, TimeUnit unit)设置最大等待时长。

48. Java中的线程池ThreadPoolExecutor
可以通过ThreadPoolExecutor来创建一个线程池：

ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)
1
corePoolSize（线程池基本大小）：当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会通过创建一个新线程来执行该任务，直到已创建的线程数大于或等于corePoolSize时，才会根据是否存在空闲线程，来决定是否需要创建新的线程。除了利用提交新任务来创建和启动线程（按需构造），也可以通过 prestartCoreThread() 或 prestartAllCoreThreads() 方法来提前启动线程池中的基本线程。
maximumPoolSize（线程池最大大小）：线程池所允许的最大线程个数。当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。另外，对于无界队列，可忽略该参数。
keepAliveTime（线程存活保持时间）：默认情况下，当线程池的线程个数多于corePoolSize时，线程的空闲时间超过keepAliveTime则会终止。但只要keepAliveTime大于0，allowCoreThreadTimeOut(boolean) 方法也可将此超时策略应用于核心线程。另外，也可以使用setKeepAliveTime()动态地更改参数。
unit（存活时间的单位）：时间单位，分为7类，从细到粗顺序：NANOSECONDS（纳秒），MICROSECONDS（微妙），MILLISECONDS（毫秒），SECONDS（秒），MINUTES（分），HOURS（小时），DAYS（天）；
workQueue（任务队列）：用于传输和保存等待执行任务的阻塞队列。可以使用此队列与线程池进行交互：
如果运行的线程数少于 corePoolSize，则 Executor 始终首选添加新的线程，而不进行排队。
如果运行的线程数等于或多于 corePoolSize，则 Executor 始终首选将请求加入队列，而不添加新的线程。
如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。
threadFactory（线程工厂）：用于创建新线程。由同一个threadFactory创建的线程，属于同一个ThreadGroup，创建的线程优先级都为Thread.NORM_PRIORITY，以及是非守护进程状态。threadFactory创建的线程也是采用new Thread()方式，threadFactory创建的线程名都具有统一的风格：pool-m-thread-n（m为线程池的编号，n为线程池内的线程编号）;
handler（线程饱和策略）：当线程池和队列都满了，则表明该线程池已达饱和状态。
ThreadPoolExecutor.AbortPolicy：处理程序遭到拒绝，则直接抛出运行时异常 RejectedExecutionException。(默认策略)
ThreadPoolExecutor.CallerRunsPolicy：调用者所在线程来运行该任务，此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。
ThreadPoolExecutor.DiscardPolicy：无法执行的任务将被删除。
ThreadPoolExecutor.DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重新尝试执行任务（如果再次失败，则重复此过程）。
可以使用两个方法向线程池提交任务，分别为execute()和submit()方法。execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。submit()方法用于提交需要返回值的任务，线程池会返回一个Future类型的对象，通过这个对象可以判断任务是否执行成功。如Future<Object> future = executor.submit(task);

利用线程池提供的参数进行监控，参数如下：

getTaskCount()：线程池需要执行的任务数量。
getCompletedTaskCount()：线程池在运行过程中已完成的任务数量，小于或等于taskCount。
getLargestPoolSize()：线程池曾经创建过的最大线程数量，通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。
getPoolSize()：线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不减。
getActiveCount()：获取活动的线程数。
49. shutdown和shutdownNow
可以调用线程池的shutdown或者shutdownNow方法来关闭线程池。他们的原理是遍历线程池的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法停止。

区别：shutdown方法将执行平缓的关闭过程：不在接收新的任务，同时等待已提交的任务执行完成——包括哪些还未开始执行的任务。shutdownNow方法将执行粗暴的关闭过程：它将尝试取消所有运行中的任务，并且不再启动队列中尚未开始执行的任务。

只要调用了这两个关闭方法中的任意一个,isShutdown方法就会返回true，当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminated方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。

50. 扩展ThreadPoolExecutor
可以通过继承线程池来自定义线程池，重写线程池的beforeExecute, afterExecute和terminated方法。在执行任务的线程中将调用beforeExecute和afterExecute等方法，在这些方法中还可以添加日志、计时、监视或者统计信息收集的功能。无论任务是从run中正常返回，还是抛出一个异常而返回，afterExecute都会被调用。如果任务在完成后带有一个Error，那么就不会调用afterExecute。如果beforeExecute抛出一个RuntimeException，那么任务将不被执行，并且afterExecute也不会被调用。在线程池完成关闭时调用terminated，也就是在所有任务都已经完成并且所有工作者线程也已经关闭后，terminated可以用来释放Executor在其生命周期里分配的各种资源，此外还可以执行发送通知、记录日志或者手机finalize统计等操作。详细可以参考《JAVA多线程之扩展ThreadPoolExecutor》

============

###51. SimpleDateFormat非线程安全
当多个线程共享一个SimpleDateFormat实例的时候，就会出现难以预料的异常。

主要原因是parse()方法使用calendar来生成返回的Date实例，而每次parse之前，都会把calendar里的相关属性清除掉。问题是这个calendar是个全局变量，也就是线程共享的。因此就会出现一个线程刚把calendar设置好，另一个线程就把它给清空了，这时第一个线程再parse的话就会有问题了。

解决方案:1. 每次使用时创建一个新的SimpleDateFormat实例；2. 创建一个共享的SimpleDateFormat实例变量，并对这个变量进行同步；3. 使用ThreadLocal为每个线程都创建一个独享的SimpleDateFormat实例变量。

###52. CopyOnWriteArrayList
在每次修改时，都会创建并重新发布一个新的容器副本，从而实现可变现。CopyOnWriteArrayList的迭代器保留一个指向底层基础数组的引用，这个数组当前位于迭代器的起始位置，由于它不会被修改，因此在对其进行同步时只需确保数组内容的可见性。因此，多个线程可以同时对这个容器进行迭代，而不会彼此干扰或者与修改容器的线程相互干扰。“写时复制”容器返回的迭代器不会抛出ConcurrentModificationException并且返回的元素与迭代器创建时的元素完全一致，而不必考虑之后修改操作所带来的影响。显然，每当修改容器时都会复制底层数组，这需要一定的开销，特别是当容器的规模较大时，仅当迭代操作远远多于修改操作时，才应该使用“写入时赋值”容器。

###53. 工作窃取算法（work-stealing）
工作窃取算法是指某个线程从其他队列里窃取任务来执行。在生产-消费者设计中，所有消费者有一个共享的工作队列，而在work-stealing设计中，每个消费者都有各自的双端队列，如果一个消费者完成了自己双端队列中的全部任务，那么它可以从其他消费者双端队列末尾秘密地获取工作。

优点：充分利用线程进行并行计算，减少了线程间的竞争。
缺点：在某些情况下还是存在竞争，比如双端队列（Deque）里只有一个任务时。并且该算法会消耗了更多的系统资源，比如创建多个线程和多个双端队列。

###54. Future & FutureTask
FutureTask表示的计算是通过Callable来实现的，相当于一种可生产结果的Runnable，并且可以处于一下3种状态：等待运行，正在运行和运行完成。运行表示计算的所有可能结束方式，包括正常结束、由于取消而结束和由于异常而结束等。当FutureTask进入完成状态后，它会永远停止在这个状态上。Future.get的行为取决于任务的状态，如果任务已经完成，那么get会立刻返回结果，否则get将阻塞知道任务进入完成状态，然后返回结果或者异常。FutureTask的使用方式如下：

public class Preloader
{
    //method1
    private final static FutureTask<Object> future = new FutureTask<Object>(new Callable<Object>(){
        @Override
        public Object call() throws Exception
        {
            return "yes";
        }
    });

    //method2
    static ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());
    private static final Future<Object> futureExecutor = executor.submit(new Callable<Object>(){
        @Override
        public Object call() throws Exception
        {
            return "no";
        }
    });

    public static void main(String[] args) throws InterruptedException, ExecutionException
    {
        executor.shutdown();
        future.run();
        System.out.println(future.get());
        System.out.println(futureExecutor.get());
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
运行结果：yes no
Callable表示的任务可以抛出受检查或未受检查的异常，并且任何代码都可能抛出一个Error.无论任务代码抛出什么异常，都会被封装到一个ExecutionException中，并在Future.get中被重新抛出。

###55. Executors
newFixedThreadPool：创建一个固定长度的线程池，每当提交一个任务时就创建一个线程，直到达到线程池的最大数量，这时线程池的规模将不再变化（如果某个线程由于发生了未预期的Exception而结束，那么线程池会补充一个新的线程）。（LinkedBlockingQueue）
newCachedThreadPool：创建一个可换成的线程池，如果线程池的当前规模超过了处理需求时，那么将回收空闲的线程，而当需求增加时，则可以添加新的线程，线程池的规模不存在任何限制。（SynchronousQueue）
newSingleThreadExecutor：是一个单线程的Executor，它创建单个工作者线程来执行任务，如果这个线程异常结束，会创建另一个线程来替代。能确保一组任务在队列中的顺序来串行执行。（LinkedBlockingQueue）
newScheduledThreadPool：创建了一个固定长度的线程池，而且以延迟或者定时的方式来执行任务，类似于Timer。

###56. ScheduledThreadPoolExecutor替代Timer
由第17项可知Timer有两个缺陷，在JDK5开始就很少使用Timer了，取而代之的可以使用ScheduledThreadPoolExecutor。使用实例如下：

import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.TimeUnit;

public class ScheduleThreadPoolTest
{
    private static ScheduledExecutorService exec = Executors.newScheduledThreadPool(2);

    public static void method1()
    {
        exec.schedule(new Runnable(){
            @Override
            public void run()
            {
                System.out.println("1");
            }}, 2, TimeUnit.SECONDS);
    }

    public static void method2()
    {
        ScheduledFuture<String> future = exec.schedule(new Callable<String>(){
            @Override
            public String call() throws Exception
            {
                return "Callable";
            }}, 4, TimeUnit.SECONDS);
        try
        {
            System.out.println(future.get());
        }
        catch (InterruptedException | ExecutionException e)
        {
            e.printStackTrace();
        }
    }

    public static void main(String[] args)
    {
        method1();
        method2();
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
运行结果：1 Callable

###57. Callable & Runnable
Executor框架使用Runnable作为基本的任务表示形式。Runnable是一种有很大局限的抽象，虽然run能写入到日志文件或者将结果放入某个共享的数据结构，但它不能返回一个值或抛出一个受检查的异常。

许多任务实际上都是存在延迟的计算——执行数据库查询，从网络上获取资源，或者计算某个复杂的功能。对于这些任务，Callable是一种更好的抽象：它认为主入口点（call()）将返回一个值，并可能抛出一个异常。

Runnable和Callable描述的都是抽象的计算任务。这些任务通常是有范围的，即都有一个明确的起始点，并且最终会结束。

###58. CompletionService
如果想Executor提交了一组计算任务，并且希望在计算完成后获得结果，那么可以保留与每个任务关联的Future，然后反复使用get方法，同事将参数timeout指定为0，从而通过轮询来判断任务是否完成。这种方法虽然可行，但却有些繁琐。幸运的是，还有一种更好的方法：CompletionService。CompletionService将Executor和BlockingQueue的功能融合在一起。你可以将Callable任务提交给它来执行，然后使用类似于队列操作的take和poll等方法来获得已完成的结果，而这些结果会在完成时被封装为Future。ExecutorCompletionService实现了CompletionService,并将计算部分委托到一个Executor。代码示例如下：

        int coreNum = Runtime.getRuntime().availableProcessors();
        ExecutorService executor = Executors.newFixedThreadPool(coreNum);
        CompletionService<Object> completionService = new ExecutorCompletionService<Object>(executor);

        for(int i=0;i<coreNum;i++)
        {
            completionService.submit( new Callable<Object>(){
                @Override
                public Object call() throws Exception
                {
                    return Thread.currentThread().getName();
                }});
        }

        for(int i=0;i<coreNum;i++)
        {
            try
            {
                Future<Object> future = completionService.take();
                System.out.println(future.get());
            }
            catch (InterruptedException | ExecutionException e)
            {
                e.printStackTrace();
            }
        }
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
运行结果：

pool-1-thread-1
pool-1-thread-2
pool-1-thread-3
pool-1-thread-4
1
2
3
4
可以通过ExecutorCompletionService(Executor executor, BlockingQueue<Future<V>> completionQueue)构造函数指定特定的BlockingQueue（如下代码剪辑），默认为LinkedBlockingQueue。

        BlockingQueue<Future<Object>> bq = new LinkedBlockingQueue<Future<Object>>();
        CompletionService<Object> completionService = new ExecutorCompletionService<Object>(executor,bq);
1
2
ExecutorCompletionService的JDK源码只有100行左右，有兴趣的朋友可以看看。

###59. 通过Future来实现取消
ExecutorService.submit将返回一个Future来描述任务。Future拥有一个cancel方法，该方法带有一个boolean类型的参数mayInterruptIfRunning，表示取消操作是否成功。如果mayInterruptIfRunning为true并且任务当前正在某个线程运行，那么这个线程能被中断。如果这个参数为false，那么意味着“若任务还没启动，就不要运行它”，这种方式应该用于那些不处理中断的任务中。当Future.get抛出InterruptedException或TimeoutException时，如果你知道不再需要结果，那么就可以调用Futuure.cancel来取消任务。

###60. 处理不可中断的阻塞
对于一下几种情况，中断请求只能设置线程的中断状态，除此之外没有其他任何作用。

Java.io包中的同步Socket I/O：虽然InputStream和OutputStream中的read和write等方法都不会响应中断，但通过关闭底层的套接字，可以使得由于执行read或write等方法而被阻塞的线程抛出一个SocketException。
Java.io包中的同步I/O：当中断一个在InterruptibleChannel上等待的线程时会抛出ClosedByInterrptException并关闭链路。当关闭一个InterruptibleChannel时，将导致所有在链路操作上阻塞的线程都抛出AsynchronousCloseException。
Selector的异步I/O：如果一个线程在调用Selector.select方法时阻塞了，那么调用close或wakeup方法会使线程抛出ClosedSelectorException并提前返回。
获得某个锁：如果一个线程由于等待某个内置锁而阻塞，那么将无法响应中断，因为线程认为它肯定会获得锁，所以将不会理会中断请求，但是在Lock类中提供了lockInterruptibly方法，该方法允许在等待一个锁的同时仍能响应中断。
###61. 关闭钩子
JVM既可以正常关闭也可以强制关闭，或者说非正常关闭。关闭钩子可以在JVM关闭时执行一些特定的操作，譬如可以用于实现服务或应用程序的清理工作。关闭钩子可以在一下几种场景中应用：1. 程序正常退出（这里指一个JVM实例）；2.使用System.exit()；3.终端使用Ctrl+C触发的中断；4. 系统关闭；5. OutOfMemory宕机；6.使用Kill pid命令干掉进程（注：在使用kill -9 pid时，是不会被调用的）。使用方法（Runtime.getRuntime().addShutdownHook(Thread hook)）。更多内容可以参考JAVA虚拟机关闭钩子(Shutdown Hook)

###62. 终结器finalize
终结器finalize：在回收器释放它们后，调用它们的finalize方法，从而保证一些持久化的资源被释放。在大多数情况下，通过使用finally代码块和显示的close方法，能够比使用终结器更好地管理资源。唯一例外情况在于：当需要管理对象，并且该对象持有的资源是通过本地方法获得的。但是基于一些原因（譬如对象复活），我们要尽量避免编写或者使用包含终结器的类。

###63. 线程工厂ThreadFactory
每当线程池（ThreadPoolExecutor）需要创建一个线程时，都是通过线程功夫方法来完成的。默认的线程工厂方法将创建一个新的、非守护的线程，并且不包含特殊的配置信息。通过指定一个线程工厂方法，可以定制线程池的配置信息。在ThreadFactory中只定义了一个方法newThread，每当线程池需要创建一个新线程时都会调用这个方法。默认的线程工厂(DefaultThreadFactory 是Executors的内部类)如下：

    static class DefaultThreadFactory implements ThreadFactory {
        private static final AtomicInteger poolNumber = new AtomicInteger(1);
        private final ThreadGroup group;
        private final AtomicInteger threadNumber = new AtomicInteger(1);
        private final String namePrefix;

        DefaultThreadFactory() {
            SecurityManager s = System.getSecurityManager();
            group = (s != null) ? s.getThreadGroup() :
                                  Thread.currentThread().getThreadGroup();
            namePrefix = "pool-" +
                          poolNumber.getAndIncrement() +
                         "-thread-";
        }

        public Thread newThread(Runnable r) {
            Thread t = new Thread(group, r,
                                  namePrefix + threadNumber.getAndIncrement(),
                                  0);
            if (t.isDaemon())
                t.setDaemon(false);
            if (t.getPriority() != Thread.NORM_PRIORITY)
                t.setPriority(Thread.NORM_PRIORITY);
            return t;
        }
    }

通过implements ThreadFactory可以定制线程工厂。譬如，你希望为线程池中的线程指定一个UncaughtExceptionHandler，或者实例化一个定制的Thread类用于执行调试信息的记录。

###64. synchronized与ReentrantLock之间进行选择
由第21条可知ReentrantLock与synchronized想必提供了许多功能：定时的锁等待，可中断的锁等待、公平锁、非阻塞的获取锁等，而且从性能上来说ReentrantLock比synchronized略有胜出（JDK6起），在JDK5中是远远胜出，为嘛不放弃synchronized呢？ReentrantLock的危险性要比同步机制高，如果忘记在finnally块中调用unlock，那么虽然代码表面上能正常运行，但实际上已经埋下了一颗定时炸弹，并很可能伤及其他代码。仅当内置锁不能满足需求时，才可以考虑使用ReentrantLock.

###65. Happens-Before规则
程序顺序规则：如果程序中操作A在操作B之前，那么在线程中A操作将在B操作之前。
监视器锁规则：一个unlock操作现行发生于后面对同一个锁的lock操作。
volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。
线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。
线程终止规则：线程的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值等于段检测到线程已经终止执行。
线程中断规则：线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。
终结器规则：对象的构造函数必须在启动该对象的终结器之前执行完成。
传递性：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。

注意：如果两个操作之间存在happens-before关系，并不意味着java平台的具体实现必须要按照Happens-Before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法。

###66. as-if-serial
不管怎么重排序，程序执行结果不能被改变。

###67. ABA问题
ABA问题发生在类似这样的场景：线程1转变使用CAS将变量A的值替换为C，在此时，线程2将变量的值由A替换为C，又由C替换为A，然后线程1执行CAS时发现变量的值仍为A，所以CAS成功。但实际上这时的现场已经和最初的不同了。大多数情况下ABA问题不会产生什么影响。如果有特殊情况下由于ABA问题导致，可用采用AtomicStampedReference来解决，原理：乐观锁+version。可以参考下面的案例来了解其中的不同。

public class ABAQuestion
{
    private static AtomicInteger atomicInt = new AtomicInteger(100);
    private static AtomicStampedReference<Integer> atomicStampedRef = new AtomicStampedReference<Integer>(100,0);

    public static void main(String[] args) throws InterruptedException
    {
        Thread thread1 = new Thread(new Runnable(){
            @Override
            public void run()
            {
                atomicInt.compareAndSet(100, 101);
                atomicInt.compareAndSet(101, 100);
            }
        });

        Thread thread2 = new Thread(new Runnable(){
            @Override
            public void run()
            {
                try
                {
                    TimeUnit.SECONDS.sleep(1);
                }
                catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
                boolean c3 = atomicInt.compareAndSet(100, 101);
                System.out.println(c3);
            }
        });

        thread1.start();
        thread2.start();
        thread1.join();
        thread2.join();

        Thread thread3 = new Thread(new Runnable(){
            @Override
            public void run()
            {
                try
                {
                    TimeUnit.SECONDS.sleep(1);
                }
                catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
                atomicStampedRef.compareAndSet(100, 101, atomicStampedRef.getStamp(), atomicStampedRef.getStamp()+1);
                atomicStampedRef.compareAndSet(101, 100, atomicStampedRef.getStamp(), atomicStampedRef.getStamp()+1);
            }
        });

        Thread thread4 = new Thread(new Runnable(){
            @Override
            public void run()
            {
                int stamp = atomicStampedRef.getStamp();
                try
                {
                    TimeUnit.SECONDS.sleep(2);
                }
                catch (InterruptedException e)
                {
                    e.printStackTrace();
                }
                boolean c3 = atomicStampedRef.compareAndSet(100, 101, stamp, stamp+1);
                System.out.println(c3);
            }
        });
        thread3.start();
        thread4.start();
    }
}
输出结果：true false
=======================

###68. 如何避免死锁
死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，他们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足一下4个条件：
互斥条件：一个资源每次只能被一个进程使用。
请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。
循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。
避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序做操作来避免死锁。

###69. 怎么检测一个线程是否拥有锁
java.lang.Thread中有一个方法：public static native boolean holdsLock(Object obj). 当且仅当当前线程拥有某个具体对象的锁时返回true

###70. 如何查看线程快照？
jstack命令用来生成虚拟机当前的线程快照信息，线程快照就是当前虚拟机每一个线程正在执行的方法堆栈的集合。生成线程快照的目的主要是为了定位线程长时间没有响应的原因，如线程死锁、网络请求没有设置超时时间而长时间没有返回、死循环、信号量没有释放等，都有可能导致线程长时间停顿。这是如果能够dump出当前JVM的线程快照，就能够看出没有响应的线程究竟在做什么事情，从而定位问题。
语法：

稍加翻译一下：
-F 用来在输出不被响应时强制生成线程的快照
-m用来答应出包含Java和native代码的所有堆栈信息
-l 打印出锁的附加信息
可以配合jps命令找出pid

###71. JAVA中的线程调度算法
抢占式。一个线程用完CPU之后，操作系统会根据现场优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。

###72. Thread.sleep(0)有什么作用？
由于Java采用抢占式的线程调度算法，因此可能会出现某条线程尝尝获取到CPU控制权的情况，为了让某些优先级比较低的线程能获取到CPU控制权，可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡CPU控制权的一种操作。

###73. CAS
全称CompareAndSwap。假设有三个操作数：内存值V，旧的预期值A，要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要配合volatile变量，这样才能保证每次拿到的遍历是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功。

###74. AQS
全称AbstractQueuedSynchronizer。如果说JUC(java.util.concurrent)的基础是CAS的话，那么AQS就是整个JAVA并发包的核心了，ReentrantLock, ReentrantReadWriteLock, CountDownLatch, Semaphore等都用到了它。

###75.合理地配置线程池
需要针对具体情况而具体处理，不同的任务类别应采用不同规模的线程池，任务类别可划分为CPU密集型任务、IO密集型任务和混合型任务。

对于CPU密集型任务：线程池中线程个数应尽量少，不应大于CPU核心数；
对于IO密集型任务：由于IO操作速度远低于CPU速度，那么在运行这类任务时，CPU绝大多数时间处于空闲状态，那么线程池可以配置尽量多些的线程，以提高CPU利用率；
对于混合型任务：可以拆分为CPU密集型任务和IO密集型任务，当这两类任务执行时间相差无几时，通过拆分再执行的吞吐率高于串行执行的吞吐率，但若这两类任务执行时间有数据级的差距，那么没有拆分的意义。
76. 多线程三大定律
Amdahl 定律
–Gene Amdahl 发现在计算机体系架构设计过程中，某个部件的优化对整个架构的优化和改善是有上限的。这个发现后来成为知名的Amdahl 定律。
比如：即使你有10个老婆，也不能一个月把孩子生下来。
Gustafson 定律
–Gustafson假设随着处理器个数的增加，并行与串行的计算总量也是可以增加的。Gustafson定律认为加速系数几乎跟处理器个数成正比，如果现实情况符合Gustafson定律的假设前提的话，那么软件的性能将可以随着处理个数的增加而增加。
比如：当你有10个老婆，就会要生更多的孩子。
Sun-Ni 定律
–充分利用存储空间等计算资源，尽量增大问题规模以产生更好/更精确的解。
比如：你要设法让每个老婆都在干活，别让她们闲着。
###77. 进程间通信方式

管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
有名管道 (named pipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
套接字( socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。
持续更新中~
博主呕心沥血整理发布，跪求一赞。

=======================


1、在java中守护线程和本地线程区别？

java中的线程分为两种：守护线程（Daemon）和用户线程（User）。

任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。

两者的区别：
唯一的区别是判断虚拟机(JVM)何时离开，Daemon是为其他线程提供服务，如果全部的User Thread已经撤离，Daemon 没有可服务的线程，JVM撤离。也可以理解为守护线程是JVM自动创建的线程（但不一定），用户线程是程序创建的线程；比如JVM的垃圾回收线程是一个守护线程，当所有线程已经撤离，不再产生垃圾，守护线程自然就没事可干了，当垃圾回收线程是Java虚拟机上仅剩的线程时，Java虚拟机会自动离开。

扩展：Thread Dump打印出来的线程信息，含有daemon字样的线程即为守护进程，可能会有：服务守护进程、编译守护进程、windows下的监听Ctrl+break的守护进程、Finalizer守护进程、引用处理守护进程、GC守护进程。

2、线程与进程的区别？

进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。

一个程序至少有一个进程,一个进程至少有一个线程。

3、什么是多线程中的上下文切换？

多线程会共同使用一组计算机上的CPU，而线程数大于给程序分配的CPU数量时，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换。

4、死锁与活锁的区别，死锁与饥饿的区别？

死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。

产生死锁的必要条件：

互斥条件：所谓互斥就是进程在某一时间内独占资源。

请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

不剥夺条件:进程已获得资源，在末使用完之前，不能强行剥夺。

循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。

活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；


活锁有可能自行解开，死锁则不能。

饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。

Java中导致饥饿的原因：

高优先级线程吞噬所有的低优先级线程的CPU时间。

线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。

线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的wait方法)，因为其他线程总是被持续地获得唤醒。

5、Java中用到的线程调度算法是什么？

采用时间片轮转的方式。可以设置线程的优先级，会映射到下层的系统上面的优先级上，如非特别需要，尽量不要用，防止线程饥饿。

6、什么是线程组，为什么在Java中不推荐使用？

ThreadGroup类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。

为什么不推荐使用？因为使用有很多的安全隐患吧，没有具体追究，如果需要使用，推荐使用线程池。

7、为什么使用Executor框架？

每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。

调用 new Thread()创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。

接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。

8、在Java中Executor和Executors的区别？

Executors 工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。

Executor 接口对象能执行我们的线程任务。

ExecutorService接口继承了Executor接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。

使用ThreadPoolExecutor 可以创建自定义线程池。

Future 表示异步计算的结果，他提供了检查计算是否完成的方法，以等待计算的完成，并可以使用get()方法获取计算的结果。

9、什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)？

原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。

处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。

在Java中可以通过锁和循环CAS的方式来实现原子操作。 CAS操作——Compare & Set，或是 Compare & Swap，现在几乎所有的CPU指令都支持CAS的原子操作。

原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。

int++并不是一个原子操作，所以当一个线程读取它的值并加1时，另外一个线程有可能会读到之前的值，这就会引发错误。

为了解决这个问题，必须保证增加操作是原子的，在JDK1.5之前我们可以使用同步技术来做到这一点。到JDK1.5，java.util.concurrent.atomic包提供了int和long类型的原子包装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。

java.util.concurrent这个包里面提供了一组原子类。其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。

原子类：AtomicBoolean，AtomicInteger，

AtomicLong，AtomicReference

原子数组：AtomicIntegerArray,

AtomicLongArray，AtomicReferenceArray

原子属性更新器：

AtomicLongFieldUpdater,

AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater

解决ABA问题的原子类：

AtomicMarkableReference

(通过引入一个boolean来反映中间有没有变过）AtomicStampedReference

（通过引入一个int来累加来反映中间有没有变过）

10、Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？

Lock接口比同步方法和同步块提供了更具扩展性的锁操作。

他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。

它的优势有：

可以使锁更公平

可以使线程在等待锁的时候响应中断

可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间

可以在不同的范围，以不同的顺序获取和释放锁

整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的(tryLock方法)、定时的(tryLock带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition方法)锁操作。另外Lock的实现类基本都支持非公平锁(默认)和公平锁，synchronized只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。

11、什么是Executors框架？

Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。

无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。利用Executors框架可以非常方便的创建一个线程池。

12、什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？

阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。

这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。

阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

JDK7提供了7个阻塞队列。分别是：

ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。

LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。

PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。

DelayQueue：一个使用优先级队列实现的无界阻塞队列。

SynchronousQueue：一个不存储元素的阻塞队列。

LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。

LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。

Java 5之前实现同步存取时，可以使用普通的一个集合，然后在使用线程的协作和线程同步可以实现生产者，消费者模式，主要的技术就是用好，wait ,notify,notifyAll,sychronized这些关键字。而在java 5之后，可以使用阻塞队列来实现，此方式大大简少了代码量，使得多线程编程更加容易，安全方面也有保障。

BlockingQueue接口是Queue的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工具，因此他具有一个很明显的特性，当生产者线程试图向BlockingQueue放入元素时，如果队列已满，则线程被阻塞，当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞，正是因为它所具有这个特性，所以在程序中多个线程交替向BlockingQueue中放入元素，取出元素，它可以很好的控制线程之间的通信。

阻塞队列使用最经典的场景就是socket客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析。

13、什么是Callable和Future?

Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说，Future可以拿到异步执行任务的返回值。

可以认为是带有回调的Runnable。

Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。

14、什么是FutureTask?

使用ExecutorService启动任务。

在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。

15、什么是并发容器的实现？

何为同步容器：可以简单地理解为通过synchronized来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如Vector，Hashtable，以及Collections.synchronizedSet，synchronizedList等方法返回的容器。

可以通过查看Vector，Hashtable等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字synchronized。

并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在ConcurrentHashMap中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的线程和写操作的线程也可以并发的访问map，同时允许一定数量的写操作线程并发地修改map，所以它可以在并发环境下实现更高的吞吐量。

16、多线程同步和互斥有几种实现方法，都是什么？

线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。

线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。

线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。

用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。

17、什么是竞争条件？你怎样发现和解决竞争？

当多个进程都企图对共享数据进行某种处理，而最后的结果又取决于进程运行的顺序时，则我们认为这发生了竞争条件（race condition）。

18、你将如何使用thread dump？你将如何分析Thread dump？



新建状态（New）

用new语句创建的线程处于新建状态，此时它和其他Java对象一样，仅仅在堆区中被分配了内存。

就绪状态（Runnable）

当一个线程对象创建后，其他线程调用它的start()方法，该线程就进入就绪状态，Java虚拟机会为它创建方法调用栈和程序计数器。处于这个状态的线程位于可运行池中，等待获得CPU的使用权。

运行状态（Running）

处于这个状态的线程占用CPU，执行程序代码。只有处于就绪状态的线程才有机会转到运行状态。

阻塞状态（Blocked）

阻塞状态是指线程因为某些原因放弃CPU，暂时停止运行。当线程处于阻塞状态时，Java虚拟机不会给线程分配CPU。直到线程重新进入就绪状态，它才有机会转到运行状态。

阻塞状态可分为以下3种：

① 位于对象等待池中的阻塞状态（Blocked in object’s wait pool）：当线程处于运行状态时，如果执行了某个对象的wait()方法，Java虚拟机就会把线程放到这个对象的等待池中，这涉及到“线程通信”的内容。

② 位于对象锁池中的阻塞状态（Blocked in object’s lock pool）：当线程处于运行状态时，试图获得某个对象的同步锁时，如果该对象的同步锁已经被其他线程占用，Java虚拟机就会把这个线程放到这个对象的锁池中，这涉及到“线程同步”的内容。

③ 其他阻塞状态（Otherwise Blocked）：当前线程执行了sleep()方法，或者调用了其他线程的join()方法，或者发出了I/O请求时，就会进入这个状态。

死亡状态（Dead）

当线程退出run()方法时，就进入死亡状态，该线程结束生命周期。

我们运行之前的那个死锁代码SimpleDeadLock.java，然后尝试输出信息(/*这是注释，作者自己加的*/)：

/* 时间，jvm信息 */
2017-11-01 17:36:28
Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.144-b01 mixed mode):

/* 线程名称：DestroyJavaVM
编号：#13
优先级：5
系统优先级：0
jvm内部线程id：0x0000000001c88800
对应系统线程id（NativeThread ID）：0x1c18
线程状态： waiting on condition [0x0000000000000000]  （等待某个条件）
线程详细状态：java.lang.Thread.State: RUNNABLE  及之后所有*/
"DestroyJavaVM" #13 prio=5 os_prio=0 tid=0x0000000001c88800 nid=0x1c18 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"Thread-1" #12 prio=5 os_prio=0 tid=0x0000000018d49000 nid=0x17b8 waiting for monitor entry [0x0000000019d7f000]
/* 线程状态：阻塞（在对象同步上）
    代码位置：at com.leo.interview.SimpleDeadLock$B.run(SimpleDeadLock.java:56)
    等待锁：0x00000000d629b4d8
    已经获得锁：0x00000000d629b4e8*/
   java.lang.Thread.State: BLOCKED (on object monitor)
    at com.leo.interview.SimpleDeadLock$B.run(SimpleDeadLock.java:56)
    - waiting to lock <0x00000000d629b4d8> (a java.lang.Object)
    - locked <0x00000000d629b4e8> (a java.lang.Object)

"Thread-0" #11 prio=5 os_prio=0 tid=0x0000000018d44000 nid=0x1ebc waiting for monitor entry [0x000000001907f000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at com.leo.interview.SimpleDeadLock$A.run(SimpleDeadLock.java:34)
    - waiting to lock <0x00000000d629b4e8> (a java.lang.Object)
    - locked <0x00000000d629b4d8> (a java.lang.Object)

"Service Thread" #10 daemon prio=9 os_prio=0 tid=0x0000000018ca5000 nid=0x1264 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"C1 CompilerThread2" #9 daemon prio=9 os_prio=2 tid=0x0000000018c46000 nid=0xb8c waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"C2 CompilerThread1" #8 daemon prio=9 os_prio=2 tid=0x0000000018be4800 nid=0x1db4 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"C2 CompilerThread0" #7 daemon prio=9 os_prio=2 tid=0x0000000018be3800 nid=0x810 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"Monitor Ctrl-Break" #6 daemon prio=5 os_prio=0 tid=0x0000000018bcc800 nid=0x1c24 runnable [0x00000000193ce000]
   java.lang.Thread.State: RUNNABLE
    at java.net.SocketInputStream.socketRead0(Native Method)
    at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
    at java.net.SocketInputStream.read(SocketInputStream.java:171)
    at java.net.SocketInputStream.read(SocketInputStream.java:141)
    at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
    at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
    at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
    - locked <0x00000000d632b928> (a java.io.InputStreamReader)
    at java.io.InputStreamReader.read(InputStreamReader.java:184)
    at java.io.BufferedReader.fill(BufferedReader.java:161)
    at java.io.BufferedReader.readLine(BufferedReader.java:324)
    - locked <0x00000000d632b928> (a java.io.InputStreamReader)
    at java.io.BufferedReader.readLine(BufferedReader.java:389)
    at com.intellij.rt.execution.application.AppMainV2$1.run(AppMainV2.java:64)

"Attach Listener" #5 daemon prio=5 os_prio=2 tid=0x0000000017781800 nid=0x524 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"Signal Dispatcher" #4 daemon prio=9 os_prio=2 tid=0x000000001778f800 nid=0x1b08 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"Finalizer" #3 daemon prio=8 os_prio=1 tid=0x000000001776a800 nid=0xdac in Object.wait() [0x0000000018b6f000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00000000d6108ec8> (a java.lang.ref.ReferenceQueue$Lock)
    at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
    - locked <0x00000000d6108ec8> (a java.lang.ref.ReferenceQueue$Lock)
    at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
    at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

"Reference Handler" #2 daemon prio=10 os_prio=2 tid=0x0000000017723800 nid=0x1670 in Object.wait() [0x00000000189ef000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    - waiting on <0x00000000d6106b68> (a java.lang.ref.Reference$Lock)
    at java.lang.Object.wait(Object.java:502)
    at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
    - locked <0x00000000d6106b68> (a java.lang.ref.Reference$Lock)
    at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)

"VM Thread" os_prio=2 tid=0x000000001771b800 nid=0x604 runnable

"GC task thread#0 (ParallelGC)" os_prio=0 tid=0x0000000001c9d800 nid=0x9f0 runnable

"GC task thread#1 (ParallelGC)" os_prio=0 tid=0x0000000001c9f000 nid=0x154c runnable

"GC task thread#2 (ParallelGC)" os_prio=0 tid=0x0000000001ca0800 nid=0xcd0 runnable

"GC task thread#3 (ParallelGC)" os_prio=0 tid=0x0000000001ca2000 nid=0x1e58 runnable

"VM Periodic Task Thread" os_prio=2 tid=0x0000000018c5a000 nid=0x1b58 waiting on condition

JNI global references: 33


/* 此处可以看待死锁的相关信息！ */
Found one Java-level deadlock:
=============================
"Thread-1":
  waiting to lock monitor 0x0000000017729fc8 (object 0x00000000d629b4d8, a java.lang.Object),
  which is held by "Thread-0"
"Thread-0":
  waiting to lock monitor 0x0000000017727738 (object 0x00000000d629b4e8, a java.lang.Object),
  which is held by "Thread-1"

Java stack information for the threads listed above:
===================================================
"Thread-1":
    at com.leo.interview.SimpleDeadLock$B.run(SimpleDeadLock.java:56)
    - waiting to lock <0x00000000d629b4d8> (a java.lang.Object)
    - locked <0x00000000d629b4e8> (a java.lang.Object)
"Thread-0":
    at com.leo.interview.SimpleDeadLock$A.run(SimpleDeadLock.java:34)
    - waiting to lock <0x00000000d629b4e8> (a java.lang.Object)
    - locked <0x00000000d629b4d8> (a java.lang.Object)

Found 1 deadlock.

/* 内存使用状况，详情得看JVM方面的书 */
Heap
 PSYoungGen      total 37888K, used 4590K [0x00000000d6100000, 0x00000000d8b00000, 0x0000000100000000)
  eden space 32768K, 14% used [0x00000000d6100000,0x00000000d657b968,0x00000000d8100000)
  from space 5120K, 0% used [0x00000000d8600000,0x00000000d8600000,0x00000000d8b00000)
  to   space 5120K, 0% used [0x00000000d8100000,0x00000000d8100000,0x00000000d8600000)
 ParOldGen       total 86016K, used 0K [0x0000000082200000, 0x0000000087600000, 0x00000000d6100000)
  object space 86016K, 0% used [0x0000000082200000,0x0000000082200000,0x0000000087600000)
 Metaspace       used 3474K, capacity 4500K, committed 4864K, reserved 1056768K
  class space    used 382K, capacity 388K, committed 512K, reserved 1048576K

19、为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？

当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。

但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码，只会把run方法当作普通方法去执行。

20、Java中你怎样唤醒一个阻塞的线程？

在Java发展史上曾经使用suspend()、resume()方法对于线程进行阻塞唤醒，但随之出现很多问题，比较典型的还是死锁问题。

解决方案可以使用以对象为目标的阻塞，即利用Object类的wait()和notify()方法实现线程阻塞。

首先，wait、notify方法是针对对象的，调用任意对象的wait()方法都将导致线程阻塞，阻塞的同时也将释放该对象的锁，相应地，调用任意对象的notify()方法则将随机解除该对象阻塞的线程，但它需要重新获取改对象的锁，直到获取成功才能往下执行；其次，wait、notify方法必须在synchronized块或方法中被调用，并且要保证同步块或方法的锁对象与调用wait、notify方法的对象是同一个，如此一来在调用wait之前当前线程就已经成功获取某对象的锁，执行wait阻塞后当前线程就将之前获取的对象锁释放。

21、在Java中CycliBarriar和

CountdownLatch有什么区别？

CyclicBarrier可以重复使用，而CountdownLatch不能重复使用。

Java的concurrent包里面的CountDownLatch其实可以把它看作一个计数器，只不过这个计数器的操作是原子操作，同时只能有一个线程去操作这个计数器，也就是同时只能有一个线程去减这个计数器里面的值。

你可以向CountDownLatch对象设置一个初始的数字作为计数值，任何调用这个对象上的await()方法都会阻塞，直到这个计数器的计数值被其他的线程减为0为止。

所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。如果需要重置计数，请考虑使用 CyclicBarrier。

CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止

CyclicBarrier一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。

22、什么是不可变对象，它对写并发应用有什么帮助？

不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。

不可变对象的类即为不可变类(Immutable Class)。Java平台类库中包含许多不可变类，如String、基本类型的包装类、BigInteger和BigDecimal等。

不可变对象天生是线程安全的。它们的常量（域）是在构造函数中创建的。既然它们的状态无法修改，这些常量永远不会变。

不可变对象永远是线程安全的。

只有满足如下状态，一个对象才是不可变的；

它的状态不能在创建后再被修改；

所有域都是final类型；并且，

它被正确创建（创建期间没有发生this引用的逸出）。

23、什么是多线程中的上下文切换？

在上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。从这个角度来看，上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。在程序中，上下文切换过程中的“页码”信息是保存在进程控制块（PCB）中的。PCB还经常被称作“切换桢”（switchframe）。“页码”信息会一直保存到CPU的内存中，直到他们被再次使用。
上下文切换是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。上下文切换是多任务操作系统和多线程环境的基本特征。

24、Java中用到的线程调度算法是什么？

计算机通常只有一个CPU,在任意时刻只能执行一条机器指令,每个线程只有获得CPU的使用权才能执行指令.所谓多线程的并发运行,其实是指从宏观上看,各个线程轮流获得CPU的使用权,分别执行各自的任务.在运行池中,会有多个处于就绪状态的线程在等待CPU,JAVA虚拟机的一项任务就是负责线程的调度,线程调度是指按照特定机制为多个线程分配CPU的使用权.

有两种调度模型：分时调度模型和抢占式调度模型。

分时调度模型是指让所有的线程轮流获得cpu的使用权,并且平均分配每个线程占用的CPU的时间片这个也比较好理解。

java虚拟机采用抢占式调度模型，是指优先让可运行池中优先级高的线程占用CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。处于运行状态的线程会一直运行，直至它不得不放弃CPU。

25、什么是线程组，为什么在Java中不推荐使用？

线程组和线程池是两个不同的概念，他们的作用完全不同，前者是为了方便线程的管理，后者是为了管理线程的生命周期，复用线程，减少创建销毁线程的开销。

26、为什么使用Executor框架比使用应用创建和管理线程好？

为什么要使用Executor线程池框架

每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。

调用 new Thread()创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。

直接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。

使用Executor线程池框架的优点

能复用已存在并空闲的线程从而减少线程对象的创建从而减少了消亡线程的开销。

可有效控制最大并发线程数，提高系统资源使用率，同时避免过多资源竞争。

框架中已经有定时、定期、单线程、并发数控制等功能。

综上所述使用线程池框架Executor能更好的管理线程、提供系统资源使用率。

27、java中有几种方法可以实现一个线程？

继承 Thread 类

实现 Runnable 接口

实现 Callable 接口，需要实现的是 call() 方法

28、如何停止一个正在运行的线程？

使用共享变量的方式

在这种方式中，之所以引入共享变量，是因为该变量可以被多个执行相同任务的线程用来作为是否中断的信号，通知中断线程的执行。

使用interrupt方法终止线程

如果一个线程由于等待某些事件的发生而被阻塞，又该怎样停止该线程呢？这种情况经常会发生，比如当一个线程由于需要等候键盘输入而被阻塞，或者调用Thread.join()方法，或者Thread.sleep()方法，在网络中调用ServerSocket.accept()方法，或者调用了DatagramSocket.receive()方法时，都有可能导致线程阻塞，使线程处于处于不可运行状态时，即使主程序中将该线程的共享变量设置为true，但该线程此时根本无法检查循环标志，当然也就无法立即中断。这里我们给出的建议是，不要使用stop()方法，而是使用Thread提供的interrupt()方法，因为该方法虽然不会中断一个正在运行的线程，但是它可以使一个被阻塞的线程抛出一个中断异常，从而使线程提前结束阻塞状态，退出堵塞代码。

29、notify()和notifyAll()有什么区别？

当一个线程进入wait之后，就必须等其他线程notify/notifyall,使用notifyall,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。

如果没把握，建议notifyAll，防止notigy因为信号丢失而造成程序异常。

30、什么是Daemon线程？它有什么意义？

所谓后台(daemon)线程，是指在程序运行的时候在后台提供一种通用服务的线程，并且这个线程并不属于程序中不可或缺的部分。因此，当所有的非后台线程结束时，程序也就终止了，同时会杀死进程中的所有后台线程。

反过来说， 只要有任何非后台线程还在运行，程序就不会终止。必须在线程启动之前调用setDaemon()方法，才能把它设置为后台线程。注意：后台进程在不执行finally子句的情况下就会终止其run()方法。

比如：JVM的垃圾回收线程就是Daemon线程，Finalizer也是守护线程。

31、java如何实现多线程之间的通讯和协作？

中断和共享变量

32、什么是可重入锁（ReentrantLock）？

举例来说明锁的可重入性

public class UnReentrant{
    Lock lock = new Lock();
    public void outer(){
        lock.lock();
        inner();
        lock.unlock();
    }
    public void inner(){
        lock.lock();
        //do something
        lock.unlock();
    }
}

outer中调用了inner，outer先锁住了lock，这样inner就不能再获取lock。其实调用outer的线程已经获取了lock锁，但是不能在inner中重复利用已经获取的锁资源，这种锁即称之为 不可重入可重入就意味着：线程可以进入任何一个它已经拥有的锁所同步着的代码块。

synchronized、ReentrantLock都是可重入的锁，可重入锁相对来说简化了并发编程的开发。

33、当一个线程进入某个对象的一个synchronized的实例方法后，其它线程是否可进入此对象的其它方法？

如果其他方法没有synchronized的话，其他线程是可以进入的。

所以要开放一个线程安全的对象时，得保证每个方法都是线程安全的。

34、乐观锁和悲观锁的理解及如何实现，有哪些实现方式？

悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。

乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。

乐观锁的实现方式：

使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。

java中的Compare and Swap即CAS ，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。　CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。

CAS缺点：

ABA问题：

比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。

循环时间长开销大：

对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。

只能保证一个共享变量的原子操作：

当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。

35、SynchronizedMap和ConcurrentHashMap有什么区别？

SynchronizedMap一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为map。

ConcurrentHashMap使用分段锁来保证在多线程下的性能。ConcurrentHashMap中则是一次锁住一个桶。ConcurrentHashMap默认将hash表分为16个桶，诸如get,put,remove等常用操作只锁当前需要用到的桶。这样，原来只能一个线程进入，现在却能同时有16个写线程执行，并发性能的提升是显而易见的。

另外ConcurrentHashMap使用了一种不同的迭代方式。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数据 ，iterator完成后再将头指针替换为新的数据 ，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变。

36、CopyOnWriteArrayList可以用于什么应用场景？

CopyOnWriteArrayList(免锁容器)的好处之一是当多个迭代器同时遍历和修改这个列表时，不会抛出ConcurrentModificationException。在CopyOnWriteArrayList中，写入将导致创建整个底层数组的副本，而源数组将保留在原地，使得复制的数组在被修改时，读取操作可以安全地执行。

由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致young gc或者full gc；

不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的,虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求；

CopyOnWriteArrayList透露的思想

读写分离，读和写分开

最终一致性

使用另外开辟空间的思路，来解决并发冲突

37、什么叫线程安全？servlet是线程安全吗?

线程安全是编程中的术语，指某个函数、函数库在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。

Servlet不是线程安全的，servlet是单实例多线程的，当多个线程同时访问同一个方法，是不能保证共享变量的线程安全性的。

Struts2的action是多实例多线程的，是线程安全的，每个请求过来都会new一个新的action分配给这个请求，请求完成后销毁。

SpringMVC的Controller是线程安全的吗？不是的，和Servlet类似的处理流程

Struts2好处是不用考虑线程安全问题；Servlet和SpringMVC需要考虑线程安全问题，但是性能可以提升不用处理太多的gc，可以使用ThreadLocal来处理多线程的问题。

38、volatile有什么用？能否用一句话说明下volatile的应用场景？

volatile保证内存可见性和禁止指令重排。

volatile用于多线程环境下的单次操作(单次读或者单次写)。

39、为什么代码会重排序？

在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，不是你想怎么排序就怎么排序，它需要满足以下两个条件：

在单线程环境下不能改变程序运行的结果；

存在数据依赖关系的不允许重排序

需要注意的是：重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。

40、在java中wait和sleep方法的不同？

最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。

直接了解的深入一点吧：



在Java中线程的状态一共被分成6种：

初始态：NEW

创建一个Thread对象，但还未调用start()启动线程时，线程处于初始态。

运行态：RUNNABLE

在Java中，运行态包括就绪态和运行态。

就绪态该状态下的线程已经获得执行所需的所有资源，只要CPU分配执行权就能运行。所有就绪态的线程存放在就绪队列中。

运行态获得CPU执行权，正在执行的线程。由于一个CPU同一时刻只能执行一条线程，因此每个CPU每个时刻只有一条运行态的线程。

阻塞态

当一条正在执行的线程请求某一资源失败时，就会进入阻塞态。而在Java中，阻塞态专指请求锁失败时进入的状态。由一个阻塞队列存放所有阻塞态的线程。处于阻塞态的线程会不断请求资源，一旦请求成功，就会进入就绪队列，等待执行。PS：锁、IO、Socket等都资源。

等待态

当前线程中调用wait、join、park函数时，当前线程就会进入等待态。也有一个等待队列存放所有等待态的线程。线程处于等待态表示它需要等待其他线程的指示才能继续运行。进入等待态的线程会释放CPU执行权，并释放资源（如：锁）

超时等待态

当运行中的线程调用sleep(time)、wait、join、parkNanos、parkUntil时，就会进入该状态；它和等待态一样，并不是因为请求不到资源，而是主动进入，并且进入后需要其他线程唤醒；进入该状态后释放CPU执行权 和 占有的资源。与等待态的区别：到了超时时间后自动进入阻塞队列，开始竞争锁。

终止态

线程执行结束后的状态。

注意：

wait()方法会释放CPU执行权 和 占有的锁。

sleep(long)方法仅释放CPU使用权，锁仍然占用；线程被放入超时等待队列，与yield相比，它会使线程较长时间得不到运行。

yield()方法仅释放CPU执行权，锁仍然占用，线程会被放入就绪队列，会在短时间内再次执行。

wait和notify必须配套使用，即必须使用同一把锁调用；

wait和notify必须放在一个同步块中调用wait和notify的对象必须是他们所处同步块的锁对象。

41、一个线程运行时发生异常会怎样？

如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。

42、如何在两个线程间共享数据？

在两个线程间共享变量即可实现共享。

一般来说，共享变量要求变量本身是线程安全的，然后在线程内使用的时候，如果有对共享变量的复合操作，那么也得保证复合操作的线程安全性。

43、Java中notify 和 notifyAll有什么区别？

notify() 方法不能唤醒某个具体的线程，所以只有一个线程在等待的时候它才有用武之地。而notifyAll()唤醒所有线程并允许他们争夺锁确保了至少有一个线程能继续运行。

44、为什么wait, notify 和 notifyAll这些方法不在thread类里面？

一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。

45、什么是ThreadLocal变量？

ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。

46、Java中interrupted 和 isInterrupted方法的区别？

interrupt

interrupt方法用于中断线程。调用该方法的线程的状态为将被置为”中断”状态。
注意：线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。支持线程中断的方法（也就是线程中断后会抛出interruptedException的方法）就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常。

interrupted

查询当前线程的中断状态，并且清除原状态。如果一个线程被中断了，第一次调用interrupted则返回true，第二次和后面的就返回false了。

isInterrupted

仅仅是查询当前线程的中断状态

47、为什么wait和notify方法要在同步块中调用？

Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。还有一个原因是为了避免wait和notify之间产生竞态条件。

48、为什么你应该在循环中检查等待条件?

处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。

49、Java中的同步集合与并发集合有什么区别？

同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在Java1.5之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。

50、什么是线程池？ 为什么要使用它？

创建线程要花费昂贵的资源和时间，如果任务来了才创建线程那么响应时间会变长，而且一个进程能创建的线程数有限。为了避免这些问题，在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫工作线程。从JDK1.5开始，Java API提供了Executor框架让你可以创建不同的线程池。

51、怎么检测一个线程是否拥有锁？

在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。

52、你如何在Java中获取线程堆栈？

kill -3 [java pid]

不会在当前终端输出，它会输出到代码执行的或指定的地方去。比如，kill -3 tomcat pid, 输出堆栈到log目录下。

Jstack [java pid]

这个比较简单，在当前终端显示，也可以重定向到指定文件中。

-JvisualVM：Thread Dump

不做说明，打开JvisualVM后，都是界面操作，过程还是很简单的。

53、JVM中哪个参数是用来控制线程的栈堆栈小的?

-Xss 每个线程的栈大小

54、Thread类中的yield方法有什么作用？

使当前线程从执行状态（运行状态）变为可执行态（就绪状态）。

当前线程到了就绪状态，那么接下来哪个线程会从就绪状态变成执行状态呢？可能是当前线程，也可能是其他线程，看系统的分配了。

55、Java中ConcurrentHashMap的并发度是什么？

ConcurrentHashMap把实际map划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是ConcurrentHashMap类构造函数的一个可选参数，默认值为16，这样在多线程情况下就能避免争用。

在JDK8后，它摒弃了Segment（锁段）的概念，而是启用了一种全新的方式实现,利用CAS算法。同时加入了更多的辅助变量来提高并发度，具体内容还是查看源码吧。

56、Java中Semaphore是什么？

Java中的Semaphore是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动。信号量常常用于多线程的代码中，比如数据库连接池。

57、Java线程池中submit() 和 execute()方法有什么区别？

两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中。

而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。

58、什么是阻塞式方法？

阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。

59、Java中的ReadWriteLock是什么？

读写锁是用来提升并发程序性能的锁分离技术的成果。

60、volatile 变量和 atomic 变量有什么不同？

Volatile变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰count变量那么 count++ 操作就不是原子性的。

而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。

61、可以直接调用Thread类的run ()方法么？

当然可以。但是如果我们调用了Thread的run()方法，它的行为就会和普通的方法一样，会在当前线程中执行。为了在新的线程中执行我们的代码，必须使用Thread.start()方法。

62、如何让正在运行的线程暂停一段时间？

我们可以使用Thread类的Sleep()方法让线程暂停一段时间。需要注意的是，这并不会让线程终止，一旦从休眠中唤醒线程，线程的状态将会被改变为Runnable，并且根据线程调度，它将得到执行。

63、你对线程优先级的理解是什么？

每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。

java的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。

64、什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing )？

线程调度器是一个操作系统服务，它负责为Runnable状态的线程分配CPU时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。
同上一个问题，线程调度并不受到Java虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。

时间分片是指将可用的CPU时间分配给可用的Runnable线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。

65、你如何确保main()方法所在的线程是Java 程序最后结束的线程？

我们可以使用Thread类的join()方法来确保所有程序创建的线程在main()方法退出前结束。

66、线程之间是如何通信的？

当线程间是可以共享资源时，线程间通信是协调它们的重要的手段。Object类中wait() otify() otifyAll()方法可以用于线程间通信关于资源的锁的状态。

67、为什么线程通信的方法wait(), notify()和notifyAll()被定义在Object 类里？

Java的每个对象中都有一个锁(monitor，也可以成为监视器) 并且wait()，notify()等方法用于等待对象的锁或者通知其他线程对象的监视器可用。在Java的线程中并没有可供任何对象使用的锁和同步器。这就是为什么这些方法是Object类的一部分，这样Java的每一个类都有用于线程间通信的基本方法。

68、为什么wait(), notify()和notifyAll ()必须在同步方法或者同步块中被调用？

当一个线程需要调用对象的wait()方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对象锁并进入等待状态直到其他线程调用这个对象上的notify()方法。同样的，当一个线程需要调用对象的notify()方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中被调用。

69、为什么Thread类的sleep()和yield ()方法是静态的？

Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。

70、如何确保线程安全？

在Java中可以有很多方法来保证线程安全——同步，使用原子类(atomic concurrent classes)，实现并发锁，使用volatile关键字，使用不变类和线程安全类。

71、同步方法和同步块，哪个是更好的选择？

同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。

同步块更要符合开放调用的原则，只在需要锁住的代码块锁住相应的对象，这样从侧面来说也可以避免死锁。

72、如何创建守护线程？

使用Thread类的setDaemon(true)方法可以将线程设置为守护线程，需要注意的是，需要在调用start()方法前调用这个方法，否则会抛出IllegalThreadStateException异常。

73、什么是Java Timer 类？如何创建一个有特定时间间隔的任务？

java.util.Timer是一个工具类，可以用于安排一个线程在未来的某个特定时间执行。Timer类可以用安排一次性任务或者周期任务。

java.util.TimerTask是一个实现了Runnable接口的抽象类，我们需要去继承这个类来创建我们自己的定时任务并使用Timer去安排它的执行。

目前有开源的Qurtz可以用来创建定时任务。

==============================






第1章　并发编程的挑战 1
1.1　上下文切换 1
1.1.1　多线程一定快吗 1
1.1.2　测试上下文切换次数和时长 3
1.1.3　如何减少上下文切换 3
1.1.4　减少上下文切换实战 4
1.2　死锁 5
1.3　资源限制的挑战 6
1.4　本章小结 7

第2章　Java并发机制的底层实现原理 8
2.1　volatile的应用 8
2.2　synchronized的实现原理与应用 11
2.2.1　Java对象头 12
2.2.2　锁的升级与对比 13
2.3　原子操作的实现原理 16
2.4　本章小结 20

第3章　Java内存模型 21
3.1　Java内存模型的基础 21
3.1.1　并发编程模型的两个关键问题 21
3.1.2　Java内存模型的抽象结构 22
3.1.3　从源代码到指令序列的重排序 23
3.1.4　并发编程模型的分类 24
3.1.5　happens-before简介 26

3.2　重排序 27
3.2.1　数据依赖性 28
3.2.2　as-if-serial语义 28
3.2.3　程序顺序规则 29
3.2.4　重排序对多线程的影响 29
3.3　顺序一致性 31
3.3.1　数据竞争与顺序一致性 31
3.3.2　顺序一致性内存模型 32
3.3.3　同步程序的顺序一致性效果 34
3.3.4　未同步程序的执行特性 35
3.4　volatile的内存语义 38
3.4.1　volatile的特性 38
3.4.2　volatile写-读建立的happens-before关系 39
3.4.3　volatile写-读的内存语义 40
3.4.4　volatile内存语义的实现 42
3.4.5　JSR-133为什么要增强volatile的内存语义 46
3.5　锁的内存语义 47
3.5.1　锁的释放-获取建立的
　　　happens-before关系 47
3.5.2　锁的释放和获取的内存语义 48
3.5.3　锁内存语义的实现 50
3.5.4　concurrent包的实现 54
3.6　final域的内存语义 55
3.6.1　final域的重排序规则 55
3.6.2　写final域的重排序规则 56
3.6.3　读final域的重排序规则 57
3.6.4　final域为引用类型 58
3.6.5　为什么final引用不能从构造函数内“溢出” 59
3.6.6　final语义在处理器中的实现 61
3.6.7　JSR-133为什么要增强f?inal的语义 62
3.7　happens-before 62
3.7.1　JMM的设计 62
3.7.2　happens-before的定义 64
3.7.3　happens-before规则 65
3.8　双重检查锁定与延迟初始化 67
3.8.1　双重检查锁定的由来 67
3.8.2　问题的根源 69
3.8.3　基于volatile的解决方案 71
3.8.4　基于类初始化的解决方案 72
3.9　Java内存模型综述 78
3.9.1　处理器的内存模型 78
3.9.2　各种内存模型之间的关系 80
3.9.3　JMM的内存可见性保证 80
3.9.4　JSR-133对旧内存模型的修补 81
3.10　本章小结 82
第4章　Java并发编程基础 83
4.1　线程简介 83
4.1.1　什么是线程 83
4.1.2　为什么要使用多线程 84
4.1.3　线程优先级 85
4.1.4　线程的状态 87
4.1.5　Daemon线程 90
4.2　启动和终止线程 91
4.2.1　构造线程 91
4.2.2　启动线程 92
4.2.3　理解中断 92
4.2.4　过期的suspend()、resume()和stop() 93
4.2.5　安全地终止线程 95
4.3　线程间通信 96
4.3.1　volatile和synchronized关键字 96
4.3.2　等待/通知机制 98
4.3.3　等待/通知的经典范式 101
4.3.4　管道输入/输出流 102
4.3.5　Thread.join()的使用 103
4.3.6　ThreadLocal的使用 105
4.4　线程应用实例 106
4.4.1　等待超时模式 106
4.4.2　一个简单的数据库连接池示例 106
4.4.3　线程池技术及其示例 110
4.4.4　一个基于线程池技术的简单Web服务器 114

第5章　Java中的锁 119
5.1　Lock接口 119
5.2　队列同步器 121
5.2.1　队列同步器的接口与示例 121
5.2.2　队列同步器的实现分析 124
5.3　重入锁 136
5.4　读写锁 140
5.4.1　读写锁的接口与示例 141
5.4.2　读写锁的实现分析 142
5.5　LockSupport工具 146
5.6　Condition接口 147
5.6.1　Condition接口与示例 148
5.6.2　Condition的实现分析 150
5.7　本章小结 154
第6章　Java并发容器和框架 155
6.1　ConcurrentHashMap的实现原理与使用 155
6.1.1　为什么要使用ConcurrentHashMap 155
6.1.2　ConcurrentHashMap的结构 156
6.1.3　ConcurrentHashMap的初始化 157
6.1.4　定位Segment 159
6.1.5　ConcurrentHashMap的操作 160
6.2　ConcurrentLinkedQueue 161
6.2.1　ConcurrentLinkedQueue的结构 162
6.2.2　入队列 162
6.2.3　出队列 165
6.3　Java中的阻塞队列 167
6.3.1　什么是阻塞队列 167
6.3.2　Java里的阻塞队列 168
6.3.3　阻塞队列的实现原理 172
6.4　Fork/Join框架 175
6.4.1　什么是Fork/Join框架 175
6.4.2　工作窃取算法 176
6.4.3　Fork/Join框架的设计 177
6.4.4　使用Fork/Join框架 177
6.4.5　Fork/Join框架的异常处理 179
6.4.6　Fork/Join框架的实现原理 179
6.5　本章小结 181
第7章　Java中的13个原子操作类 182
7.1　原子更新基本类型类 182
7.2　原子更新数组 184
7.3　原子更新引用类型 185
7.4　原子更新字段类 187
7.5　本章小结 188
第8章　Java中的并发工具类 189
8.1　等待多线程完成的CountDownLatch 189
8.2　同步屏障CyclicBarrier 191
8.2.1　CyclicBarrier简介 191
8.2.2　CyclicBarrier的应用场景 193
8.2.3　CyclicBarrier和CountDownLatch的区别 195
8.3　控制并发线程数的Semaphore 196
8.4　线程间交换数据的Exchanger 198
8.5　本章小结 199
第9章　Java中的线程池 200
9.1　线程池的实现原理 200
9.2　线程池的使用 203
9.2.1　线程池的创建 203
9.2.2　向线程池提交任务 205
9.2.3　关闭线程池 205
9.2.4　合理地配置线程池 206
9.2.5　线程池的监控 206
9.3　本章小结 207
第10章　Executor框架 208
10.1　Executor框架简介 208
10.1.1　Executor框架的两级调度模型 208
10.1.2　Executor框架的结构与成员 208
10.2　ThreadPoolExecutor详解 213
10.2.1　FixedThreadPool详解 213
10.2.2　SingleThreadExecutor详解 214
10.2.3　CachedThreadPool详解 215
10.3　ScheduledThreadPoolExecutor详解 217
10.3.1　ScheduledThreadPoolExecutor的运行机制 217
10.3.2　ScheduledThreadPoolExecutor的实现 218
10.4　FutureTask详解 221
10.4.1　FutureTask简介 222
10.4.2　FutureTask的使用 222
10.4.3　FutureTask的实现 224

第11章　Java并发编程实践 228
11.1　生产者和消费者模式 228
11.1.1　生产者消费者模式实战 229
11.1.2　多生产者和多消费者场景 231
11.1.3　线程池与生产消费者模式 234
11.2　线上问题定位 234
11.3　性能测试 236
11.4　异步任务池 238

1.1　并发简史
1.2　线程的优势
1.2.1　发挥多处理器的强大能力
1.2.2　建模的简单性
1.2.3　异步事件的简化处理
1.2.4　响应更灵敏的用户界面
1.3　线程带来的风险
1.3.1　安全性问题
1.3.2　活跃性问题
1.3.3　性能问题
1.4　线程无处不在

第一部分　基础知识
第2章　线程安全性
2.1　什么是线程安全性
2.2　原子性
2.2.1　竞态条件
2.2.2　示例：延迟初始化中的竞态条件
2.2.3　复合操作
2.3　加锁机制
2.3.1　内置锁
2.3.2　重入
2.4　用锁来保护状态
2.5　活跃性与性能
第3章　对象的共享
3.1　可见性
3.1.1　失效数据
3.1.2　非原子的64位操作
3.1.3　加锁与可见性
3.1.4　Volatile变量
3.2　发布与逸出
3.3　线程封闭
3.3.1　Ad-hoc线程封闭
3.3.2　栈封闭
3.3.3　ThreadLocal类
3.4　不变性
3.4.1　Final域
3.4.2　示例：使用Volatile类型来发布不可变对象
3.5　安全发布
3.5.1　不正确的发布：正确的对象被破坏
3.5.2 　不可变对象与初始化安全性
3.5.3　安全发布的常用模式
3.5.4　事实不可变对象
3.5.5　可变对象
3.5.6　安全地共享对象
第4章　对象的组合
4.1　设计线程安全的类
4.1.1　收集同步需求
4.1.2　依赖状态的操作
4.1.3　状态的所有权
4.2　实例封闭
4.2.1　Java监视器模式
4.2.2　示例：车辆追踪
4.3　线程安全性的委托
4.3.1　示例：基于委托的车辆追踪器
4.3.2　独立的状态变量
4.3.3　当委托失效时
4.3.4　发布底层的状态变量
4.3.5　示例：发布状态的车辆追踪器
4.4　在现有的线程安全类中添加功能
4.4.1　客户端加锁机制
4.4.2　组合
4.5　将同步策略文档化
第5章　基础构建模块
5.1　同步容器类
5.1.1　同步容器类的问题
5.1.2　迭代器与Concurrent-ModificationException
5.1.3　隐藏迭代器
5.2　并发容器
5.2.1　ConcurrentHashMap
5.2.2　额外的原子Map操作
5.2.3　CopyOnWriteArrayList
5.3　阻塞队列和生产者-消费者模式
5.3.1　示例：桌面搜索
5.3.2　串行线程封闭
5.3.3　双端队列与工作密取
5.4　阻塞方法与中断方法
5.5　同步工具类
5.5.1　闭锁
5.5.2　FutureTask
5.5.3　信号量
5.5.4　栅栏
5.6　构建高效且可伸缩的结果缓存
第二部分　结构化并发应用程序
第6章　任务执行
6.1　在线程中执行任务
6.1.1　串行地执行任务
6.1.2　显式地为任务创建线程
6.1.3　无限制创建线程的不足
6.2　Executor框架
6.2.1　示例：基于Executor的Web服务器
6.2.2　执行策略
6.2.3　线程池
6.2.4　Executor的生命周期
6.2.5　延迟任务与周期任务
6.3　找出可利用的并行性
6.3.1　示例：串行的页面渲染器
6.3.2　携带结果的任务Callable与Future
6.3.3　示例：使用Future实现页面渲染器
6.3.4　在异构任务并行化中存在的局限
6.3.5　CompletionService:Executor与BlockingQueue
6.3.6　示例：使用CompletionService实现页面渲染器
6.3.7　为任务设置时限
6.3.8　示例：旅行预定门户网站
第7章　取消与关闭
第8章　线程池的使用
第9章　图形用户界面应用程序
第三部分　活跃性、性能与测试
第10章　避免活跃性危险
第11章　性能与可伸缩性
第12章　并发程序的测试
第四部分　高级主题
第13章　显式锁
第14章　构建自定义的同步工具
第15章　原子变量与非阻塞同步机制
第16章　Java内存模型
附录A　并发性标注

第1章：快速认识线程 22
1.1 线程的介绍 22
1.2 快速创建并启动一个线程 22
1.2.1 尝试并行运行 23
1.2.2 并发运行交替输出 24
1.2.3 使用Jconsole观察线程 25
1.3 线程的生命周期详解 26
1.3.1 线程的NEW状态 27
1.3.2 线程的RUNNABLE状态 28
1.3.3 线程的 RUNNING状态 28
1.3.4 线程的BLOCKED状态 29
1.3.5 线程的TERMINATED状态 29
1.4 线程的start方法剖析--模板设计模式在Thread中的应用 30
1.4.1 Thread start方法源码分析以及注意事项 30
1.4.2 模板设计模式在Thread中的应用 33
1.4.3 Thread模拟营业大厅叫号机程序 34
1.5 Runnable接口的引入以及策略模式在Thread中的使用 39
1.5.1 Runnable的职责 39
1.5.2 策略模式在Thread中的应用 40
1.5.3 模拟营业大厅叫号机程序 42
1.6 本章总结 43
第2章：深入理解Thread构造函数 45
2.1 线程的命名 45
2.1.1 线程的默认命名 45
2.1.2 命名线程 46
2.1.3 修改线程的名字 47
2.2 线程的父子关系 48
2.3 Thread与ThreadGroup 48
2.4 Thread与Runnable 50
2.5 Thread与JVM虚拟机栈 50
2.5.1 Thread与Stacksize 51
2.5.2 JVM内存结构 53
2.5.3 Thread与虚拟机栈 58
2.6 守护线程 62
2.6.1 什么是守护线程 62
2.6.2 守护线程的作用 64
2.7 本章总结 64
第3章：Thread API的详细介绍 66
3.1 线程sleep 66
3.1.1 sleep方法介绍 66
3.1.2 使用TimeUnit替代Thread.sleep 67
3.2 线程yield 68
3.2.1 yield方法介绍 68
3.2.2 yield vs sleep 69
3.3 设置线程的优先级 69
3.3.1 线程优先级介绍 70
3.3.2 线程优先级源码分析 71
3.3.3 关于优先级的一些总结 72
3.4 获取线程ID 73
3.5 获取当前线程 73
3.6 设置线程上下文类加载器 74
3.7 线程interrupt 75
3.7.1 interrupt 75
3.7.2 isInterrupted 77
3.7.3 interrupted 79
3.7.4 interrupt注意事项 81
3.8 线程join 82
3.8.1 线程join方法详解 83
3.8.2 join方法结合实战 85
3.9 如何关闭一个线程 90
3.9.1 正常关闭 90
3.9.2 异常退出 94
3.9.3 进程假死 94
3.10 本章总结 95
第4章：线程安全与数据同步 97
4.1 数据同步 97
4.1.1 数据不一致问题的引入 97
4.1.2 数据不一致问题原因分析 99
4.2 初识 synchronized关键字 101
4.2.1 什么是synchronized 102
4.2.2 synchronized关键字的用法 103
4.3 深入synchronized关键字 105
4.3.1 线程堆栈分析 105
4.3.2 JVM指令分析 108
4.3.3 使用synchronized需要注意的问题 112
4.4 This Monitor和Class Monitor的详细介绍 114
4.4.1 this monitor 114
4.4.2 class monitor 117

4.5 程序死锁的原因以及如何诊断 120
4.5.1 程序死锁 120
4.5.2 程序死锁举例 121
4.5.3 死锁诊断 124
4.6 本章总结 126

第5章：线程间通信 127
5.1 同步阻塞与异步非阻塞 127
5.1.1 同步阻塞消息处理 127
5.1.2 异步非阻塞消息处理 128
5.2 单线程间通信 129
5.2.1 初识wait和notify 129
5.2.2 wait和notify方法详解 133
5.2.3 wait和notify注意事项 135
5.2.4 wait vs sleep 137
5.3 多线程间通信 137
5.3.1 生产者消费者 137
5.3.2 线程休息室wait set 140
5.4 自定义显式锁BooleanLock 141
5.4.1 synchronized关键字的缺陷 142
5.4.2 显式锁BooleanLock 143
5.5 本章总结 153
第6章：ThreadGroup详细讲解 155
6.1 ThreadGroup与Thread 155
6.2 创建Thread Group 155
6.3 拷贝Thread数组和ThreadGroup数组 157
6.3.1 拷贝Thread数组 157
6.3.2 拷贝ThreadGroup数组 159
6.4 ThreadGroup操作 160
6.4.1 ThreadGroup的基本操作 161
6.4.2 ThreadGroup的interrupt 164
6.4.3 ThreadGroup的destroy 166
6.4.4 守护ThreadGroup 168
6.5 本章总结 169
第7章：Hook线程以及捕获线程执行异常 170
7.1 获取线程运行时异常 170
7.1.1 UncaughtExceptionHandler介绍 170
7.1.2 UncaughtExceptionHandler实例 171
7.1.3 UncaughtExceptionHandler源码分析 173
7.2 注入钩子线程（Hook） 175
7.2.1 Hook线程介绍 175
7.2.2 Hook线程实战 177
7.2.3 Hook线程应用场景以及注意事项 179
7.3 本章总结 179
第8章：线程池原理以及自定义线程池 180
8.1 线程池原理 180
8.2 线程池实现 181
8.2.1 线程池接口定义 182
8.2.2 线程池详细实现 188
8.3 线程池应用 198
8.4 本章总结 202
第二部分：Java ClassLoader 204
第9章 类的加载过程 205
9.1 类的加载过程介绍 205
9.2 类的主动使用和被动使用 206
9.3 类加载过程详解 209
9.3.1 类的加载阶段 210
9.3.2 类的连接阶段 212
9.3.3 类的初始化阶段 219
9.4 本章总结 221
第10章 JVM类加载器 224
10.1 JVM内置三大类加载器 224
10.1.1 根类加载器介绍 225
10.1.2 扩展类加载器介绍 226
10.1.3 系统类加载器介绍 227
10.2 自定义类加载器 227
10.2.1 自定义类加载器，问候世界 228
10.2.2 双亲委托机制详细介绍 233
10.2.3 破坏双亲委托机制 236
10.2.4 类加载器命名空间，运行时包，类的卸载等 239
10.3 本章总结 246
第11章 线程上下文类加载器 249
11.1 为什么需要线程上下文类加载器 249
11.2 数据库驱动的初始化源码分析 250
第三部分 深入理解volatile关键字 254
第12章 volatile关键字的介绍 255
12.1 初识volatile关键字 255
12.2 机器硬件CPU 257
12.3 Java 内存模型 262
第13章 深入volatile关键字 265
13.1 并发编程的三个重要特性 265
13.1.1 原子性 265
13.1.2 可见性 266
13.1.3 有序性 266
13.2 JMM如何保证三大特性 268
13.2.1 JMM与原子性 269
13.2.2 JMM与可见性 271
13.2.3 JMM与有序性 272
13.3 volatile关键字深入解析 273
13.3.1 volatile关键字的语义 274
13.3.2 volatile的原理和实现机制 277
13.3.3 volatile的使用场景 278

第1 章 并发编程线程基础 2

1.1 什么是线程 2

1.2 线程创建与运行 3

1.3 线程通知与等待 6

1.4 等待线程执行终止的join 方法 16

1.5 让线程睡眠的sleep 方法 19

1.6 让出CPU 执行权的yield 方法 23

1.7 线程中断 24

1.8 理解线程上下文切换 30

1.9 线程死锁 30

1.9.1 什么是线程死锁 30

1.9.2 如何避免线程死锁 33

1.10 守护线程与用户线程 35

1.11 ThreadLocal 39

1.11.1 ThreadLocal 使用示例 40

1.11.2 ThreadLocal 的实现原理 42

1.11.3 ThreadLocal 不支持继承性 45

1.11.4 InheritableThreadLocal 类 46

第2 章 并发编程的其他基础知识 50

2.1 什么是多线程并发编程 50

2.2 为什么要进行多线程并发编程 51

2.3 Java 中的线程安全问题 51

?2.4 Java 中共享变量的内存可见性问题 52

2.5 Java 中的synchronized 关键字 54

2.5.1 synchronized 关键字介绍 54

2.5.2 synchronized 的内存语义 55

2.6 Java 中的volatile 关键字 55

2.7 Java 中的原子性操作 57

2.8 Java 中的CAS 操作 59

2.9 Unsafe 类 59

2.9.1 Unsafe 类中的重要方法 59

2.9.2 如何使用Unsafe 类 61

2.10 Java 指令重排序 65

2.11 伪共享 67

2.11.1 什么是伪共享 67

2.11.2 为何会出现伪共享 68

2.11.3 如何避免伪共享 70

2.11.4 小结 72

2.12 锁的概述 72

2.12.1 乐观锁与悲观锁 72

2.12.2 公平锁与非公平锁 75

2.12.3 独占锁与共享锁 75

2.12.4 什么是可重入锁 76

2.12.5 自旋锁 77

2.13 总结 77

第二部分 Java 并发编程高级篇

第3 章 Java 并发包中ThreadLocalRandom 类原理剖析 80

3.1 Random 类及其局限性 80

3.2 ThreadLocalRandom 82

3.3 源码分析 84

3.4 总结 87

第4 章 Java 并发包中原子操作类原理剖析 88

4.1 原子变量操作类 88

4.2 JDK 8 新增的原子操作类LongAdder 93

4.2.1 LongAdder 简单介绍 93

4.2.2 LongAdder 代码分析 95

4.2.3 小结 101

4.3 LongAccumulator 类原理探究 102

4.4 总结 104

第5 章 Java 并发包中并发List 源码剖析 105

5.1 介绍 105

5.2 主要方法源码解析 106

5.2.1 初始化 106

5.2.2 添加元素 106

5.2.3 获取指定位置元素 108

5.2.4 修改指定元素 109

5.2.5 删除元素 110

5.2.6 弱一致性的迭代器 111

5.3 总结 114

第6 章 Java 并发包中锁原理剖析 115

6.1 LockSupport 工具类 115

6.2 抽象同步队列AQS 概述 122

6.2.1 AQS——锁的底层支持 122

6.2.2 AQS——条件变量的支持 128

6.2.3 基于AQS 实现自定义同步器 131

6.3 独占锁ReentrantLock 的原理 136

6.3.1 类图结构 136

6.3.2 获取锁 137

6.3.3 释放锁 142

6.3.4 案例介绍 143

6.3.5 小结 145

?6.4 读写锁ReentrantReadWriteLock 的原理 145

6.4.1 类图结构 145

6.4.2 写锁的获取与释放 147

6.4.3 读锁的获取与释放 151

6.4.4 案例介绍 156

6.4.5 小结 158

6.5 JDK 8 中新增的StampedLock 锁探究 158

6.5.1 概述 158

6.5.2 案例介绍 160

6.5.3 小结 164

第7 章 Java 并发包中并发队列原理剖析 165

7.1 ConcurrentLinkedQueue 原理探究 165

7.1.1 类图结构 165

7.1.2 ConcurrentLinkedQueue 原理介绍 166

7.1.3 小结 181

7.2 LinkedBlockingQueue 原理探究 182

7.2.1 类图结构 182

7.2.2 LinkedBlockingQueue 原理介绍 185

7.2.3 小结 194

7.3 ArrayBlockingQueue 原理探究 195

7.3.1 类图结构 195

7.3.2 ArrayBlockingQueue 原理介绍 197

7.3.3 小结 202

7.4 PriorityBlockingQueue 原理探究 203

7.4.1 介绍 203

7.4.2 PriorityBlockingQueue 类图结构 203

7.4.3 原理介绍 205

7.4.4 案例介绍 214

7.4.5 小结 216

7.5 DelayQueue 原理探究 217

7.5.1 DelayQueue 类图结构 217

7.5.2 主要函数原理讲解 219

7.5.3 案例介绍 222

7.5.4 小结 224

第8 章 Java 并发包中线程池ThreadPoolExecutor 原理探究 225

8.1 介绍 225

8.2 类图介绍 225

8.3 源码分析 230

8.3.1 public void execute(Runnable command) 230

8.3.2 工作线程Worker 的执行 235

8.3.3 shutdown 操作 238

8.3.4 shutdownNow 操作 240

8.3.5 awaitTermination 操作 241

8.4 总结 242

第9 章 Java 并发包中ScheduledThreadPoolExecutor 原理探究 243

9.1 介绍 243

9.2 类图介绍 243

9.3 原理剖析 245

9.3.1 schedule(Runnable command, long delay,TimeUnit unit) 方法 246

9.3.2 scheduleWithFixedDelay(Runnable command,long initialDelay, long delay,TimeUnit unit) 方法 252

9.3.3 scheduleAtFixedRate(Runnable command,long initialDelay,long period,TimeUnit unit) 方法 254

9.4 总结 255

第10 章 Java 并发包中线程同步器原理剖析 256

10.1 CountDownLatch 原理剖析 256

10.1.1 案例介绍 256

10.1.2 实现原理探究 259

10.1.3 小结 263

10.2 回环屏障CyclicBarrier 原理探究 264

10.2.1 案例介绍 264

10.2.2 实现原理探究 268

10.2.3 小结 272

?10.3 信号量Semaphore 原理探究 272

10.3.1 案例介绍 272

10.3.2 实现原理探究 276

10.3.3 小结 281

10.4 总结 281

第三部分 Java 并发编程实践篇

第11 章 并发编程实践 284

11.1 ArrayBlockingQueue 的使用 284

11.1.1 异步日志打印模型概述 284

11.1.2 异步日志与具体实现 285

11.1.3 小结 293

11.2 Tomcat 的NioEndPoint 中ConcurrentLinkedQueue 的使用 293

11.2.1 生产者——Acceptor 线程 294

11.2.2 消费者——Poller 线程 298

11.2.3 小结 300

11.3 并发组件ConcurrentHashMap 使用注意事项 300

11.4 SimpleDateFormat 是线程不安全的 304

11.4.1 问题复现 304

11.4.2 问题分析 305

11.4.3 小结 309

11.5 使用Timer 时需要注意的事情 309

11.5.1 问题的产生 309

11.5.2 Timer 实现原理分析 310

11.5.3 小结 313

11.6 对需要复用但是会被下游修改的参数要进行深复制 314

11.6.1 问题的产生 314

11.6.2 问题分析 316

11.6.3 小结 318

11.7 创建线程和线程池时要指定与业务相关的名称 319

11.7.1 创建线程需要有线程名 319

11.7.2 创建线程池时也需要指定线程池的名称 321

11.7.3 小结 325

11.8 使用线程池的情况下当程序结束时记得调用shutdown 关闭线程池 325

11.8.1 问题复现 325

11.8.2 问题分析 327

11.8.3 小结 329

11.9 线程池使用FutureTask 时需要注意的事情 329

11.9.1 问题复现 329

11.9.2 问题分析 332

11.9.3 小结 335

11.10 使用ThreadLocal 不当可能会导致内存泄漏 336

11.10.1 为何会出现内存泄漏 336

11.10.2 在线程池中使用ThreadLocal 导致的内存泄漏 339

11.10.3 在Tomcat 的Servlet 中使用ThreadLocal 导致内存泄漏 341

第 1 章 第 一步：并发设计原理 　　 1
1．1　基本的并发概念　1
1．1．1　并发与并行　1
1．1．2　同步　2
1．1．3　不可变对象　2
1．1．4　原子操作和原子变量　3
1．1．5　共享内存与消息传递　3
1．2　并发应用程序中可能出现的问题　3
1．2．1　数据竞争　3
1．2．2　死锁　4
1．2．3　活锁　4
1．2．4　资源不足　4
1．2．5　优先权反转　5
1．3　设计并发算法的方法论　5
1．3．1　起点：算法的一个串行版本　5
1．3．2　第 1 步：分析　5
1．3．3　第 2 步：设计　5
1．3．4　第3 步：实现　6
1．3．5　第4 步：测试　6
1．3．6　第5 步：调整　6
1．3．7　结论　7
1．4　Java 并发API　8
1．4．1　基本并发类　8
1．4．2　同步机制　8
1．4．3　执行器　9
1．4．4　Fork/Join 框架　9
1．4．5　并行流　9
1．4．6　并发数据结构　9
1．5　并发设计模式　10
1．5．1　信号模式　10
1．5．2　会合模式　11
1．5．3　互斥模式　11
1．5．4　多元复用模式　12
1．5．5　栅栏模式　12
1．5．6　双重检查锁定模式　12
1．5．7　读 写锁模式　13
1．5．8　线程池模式　14
1．5．9　线程局部存储模式　14
1．6　设计并发算法的提示和技巧　14
1．6．1　正确识别独立任务　14
1．6．2　在尽可能高的层面上实施并发处理　15
1．6．3　考虑伸缩性　15
1．6．4　使用线程安全API　15
1．6．5　绝不要假定执行顺序　16
1．6．6　在静态和共享场合尽可能使用局部线程变量　16
1．6．7　寻找更易于并行处理的算法版本　17
1．6．8　尽可能使用不可变对象　17
1．6．9　通过对锁排序来避免死锁　17
1．6．10　使用原子变量代替同步　18
1．6．11　占有锁的时间尽可能短　19
1．6．12　谨慎使用延迟初始化　19
1．6．13　避免在临界段中使用阻塞操作　19
1．7　小结　20
第　2 章 使用基本元素：Thread 和Runnable　21
2．1　Java 中的线程　21
2．1．1　Java 中的线程：特征和状态　22
2．1．2　Thread 类和Runnable 接口　23
2．2　第 一个例子：矩阵乘法　24
2．2．1　公共类　24
2．2．2　串行版本　25
2．2．3　并行版本　25
2．3　第二个例子：文件搜索　32
2．3．1　公共类　32
2．3．2　串行版本　32
2．3．3　并发版本　33
2．3．4　对比解决方案　37
2．4　小结　38
第3　章 管理大量线程：执行器　39
3．1　执行器简介　39
3．1．1　执行器的基本特征　39
3．1．2　执行器框架的基本组件　40
3．2　第 一个例子：k-最近邻算法　40
3．2．1　k-最近邻算法：串行版本　41
3．2．2　k-最近邻算法：细粒度并发版本　42
3．2．3　k-最近邻算法：粗粒度并发版本　45
3．2．4　对比解决方案　46
3．3　第二个例子：客户端/服务器环境下的并发处理　48
3．3．1　客户端/服务器：串行版　48
3．3．2　客户端/服务器：并行版本　51
3．3．3　额外的并发服务器组件　54
3．3．4　对比两种解决方案　59
3．3．5　其他重要方法　61
3．4　小结　62
第4　章 充分利用执行器　63
4．1　执行器的高级特性　63
4．1．1　任务的撤销　63
4．1．2　任务执行调度　64
4．1．3　重载执行器方法　64
4．1．4　更改一些初始化参数　64
4．2　第 一个例子：高级服务器应用程序　65
4．2．1　ServerExecutor 类　65
4．2．2　命令类　70
4．2．3　服务器部件　72
4．2．4　客户端部件　78
4．3　第二个例子：执行周期性任务　79
4．3．1　公共部件　79
4．3．2　基础阅读器　81
4．3．3　高级阅读器　84
4．4　有关执行器的其他信息　87
4．5　小结　87
第5　章 从任务获取数据：Callable接口与Future 接口　88
5．1　Callable 接口和Future 接口简介　88
5．1．1　Callable 接口　88
5．1．2　Future 接口　89
5．2　第 一个例子：单词最佳匹配算法　89
5．2．1　公共类　90
5．2．2　最佳匹配算法：串行版本　91
5．2．3　最佳匹配算法：第 一个并发版本　92
5．2．4　最佳匹配算法：第二个并发版本　95
5．2．5　单词存在算法：串行版本　96
5．2．6　单词存在算法：并行版本　98
5．2．7　对比解决方案　100
5．3　第二个例子：为文档集创建倒排索引　102
5．3．1　公共类　103
5．3．2　串行版本　104
5．3．3　第 一个并发版本：每个文档一个任务　105
5．3．4　第二个并发版本：每个任务多个文档　109
5．3．5　对比解决方案　112
5．3．6　其他相关方法　113
5．4　小结　113
第6　章 运行分为多阶段的任务：Phaser 类　115
6．1　Phaser 类简介　115
6．1．1　参与者的注册与注销　116
6．1．2　同步阶段变更　116
6．1．3　其他功能　116
6．2　第 一个例子：关键字抽取算法　117
6．2．1　公共类　118
6．2．2　串行版本　121
6．2．3　并发版本　123
6．2．4　对比两种解决方案　128
6．3　第二个例子：遗传算法　129
6．3．1　公共类　130
6．3．2　串行版本　132
6．3．3　并发版本　134
6．3．4　对比两种解决方案　139
6．4　小结　141
第7　章 优化分治解决方案：
Fork/Join　框架　142
7．1　Fork/Join 框架简介　142
7．1．1　Fork/Join 框架的基本特征　143
7．1．2　Fork/Join 框架的局限性　143
7．1．3　Fork/Join 框架的组件　144
7．2　第 一个例子：k-means 聚类算法　144
7．2．1　公共类　145
7．2．2　串行版本　149
7．2．3　并发版本　151
7．2．4　对比解决方案　155
7．3　第二个例子：数据筛选算法　157
7．3．1　公共特性　157
7．3．2　串行版　157
7．3．3　并发版本　159
7．3．4　对比两个版本　165
7．4　第三个例子：归并排序算法　166
7．4．1　共享类　166
7．4．2　串行版本　167
7．4．3　并发版本　169
7．4．4　对比两个版本　172
7．5　Fork/Join 框架的其他方法　172
7．6　小结　173
第8　章 使用并行流处理大规模数据集：MapReduce 模型　174
8．1　流的简介　174
8．1．1　流的基本特征　174
8．1．2　流的组成部分　175
8．1．3　MapReduce 与MapCollect　177
8．2　第 一个例子：数值综合分析应用程序　178
8．2．1　并发版本　178
8．2．2　串行版本　185
8．2．3　对比两个版本　186
8．3　第二个例子：信息检索工具　186
8．3．1　约简操作简介　187
8．3．2　第 一种方式：全文档查询　188
8．3．3　第二种方式：约简的文档查询　191
8．3．4　第三种方式：生成一个含有结果的HTML 文件　191
8．3．5　第四种方式：预先载入倒排索引　194
8．3．6　第五种方式：使用我们的执行器　195
8．3．7　从倒排索引获取数据：ConcurrentData 类　196
8．3．8　获取文件中的单词数　196
8．3．9　获取文件的平均tfxidf 值　196
8．3．10　获取索引中的最大tfxidf值和最小tfxidf 值　197
8．3．11　ConcurrentMain 类　198
8．3．12　串行版　199
8．3．13　对比两种解决方案　199
8．4　小结　202
第9　章 使用并行流处理大规模数据集：MapCollect 模型　203
9．1　使用流收集数据　203
9．2　第 一个例子：无索引条件下的数据搜索　205
9．2．1　基本类　205
9．2．2　第 一种方式：基本搜索　207
9．2．3　第二种方式：高级搜索　209
9．2．4　本例的串行实现　211
9．2．5　对比实现方案　211
9．3　第二个例子：推荐系统　212
9．3．1　公共类　212
9．3．2　推荐系统：主类　213
9．3．3　ConcurrentLoaderAccumulator 类　215
9．3．4　串行版　216
9．3．5　对比两个版本　216
9．4　第三个例子：社交网络中的共同联系人　217
9．4．1　基本类　218
9．4．2　并发版本　219
9．4．3　串行版本　223
9．4．4　对比两个版本　223
9．5　小结　224
第　10 章 异步流处理：反应流　225
10．1　Java 反应流简介　225
10．1．1　Flow．Publisher 接口　226
10．1．2　Flow．Subscriber 接口　226
10．1．3　Flow．Subscription 接口　226
10．1．4　SubmissionPublisher 类　226
10．2　第 一个例子：面向事件通知的集中式系统　227
10．2．1　Event 类　227
10．2．2　Producer 类　227
10．2．3　Consumer 类　228
10．2．4　Main 类　230
10．3　第二个例子：新闻系统　231
10．3．1　News 类　232
10．3．2　发布者相关的类　232
10．3．3　Consumer 类　235
10．3．4　Main 类　236
10．4　小结　238
第　11 章 探究并发数据结构和同步工具　240
11．1　并发数据结构　240
11．1．1　阻塞型数据结构和非阻塞型数据结构　241
11．1．2　并发数据结构　241
11．1．3　使用新特性　244
11．1．4　原子变量　251
11．1．5　变量句柄　252
11．2　同步机制　254
11．2．1　CommonTask 类　255
11．2．2　Lock 接口　255
11．2．3　Semaphore 类　256
11．2．4　CountDownLatch 类　258
11．2．5　CyclicBarrier 类　259
11．2．6　CompletableFuture 类　261
11．3　小结　268
第　12 章 测试与监视并发应用程序　269
12．1　监视并发对象　269
12．1．1　监视线程　269
12．1．2　监视锁　270
12．1．3　监视执行器　272
12．1．4　监视Fork/Join 框架　273
12．1．5　监视Phaser　274
12．1．6　监视流API　275
12．2　监视并发应用程序　276
12．2．1　Overview 选项卡　278
12．2．2　Memory 选项卡　279
12．2．3　Threads 选项卡　280
12．2．4　Classes 选项卡　280
12．2．5　VM Summary 选项卡　281
12．2．6　MBeans 选项卡　283
12．2．7　About 选项卡　284
12．3　测试并发应用程序　284
12．3．1　使用MultithreadedTC 测试并发应用程序　285
12．3．2　使用Java Pathfinder 测试并发应用程序　288
12．4　小结　293
第　13 章 JVM 中的并发处理：Clojure、带有GPars 库的Groovy 以及Scala　294
13．1　Clojure 的并发处理　294
13．1．1　使用Java 元素　295
13．1．2　引用类型　295
13．1．3　Ref 对象　298
13．1．4　Delay　299
13．1．5　Future　300
13．1．6　Promise　301
13．2　Groovy 及其GPars 库的并发处理　302
13．3　软件事务性内存　302
13．3．1　使用Java 元素　302
13．3．2　数据并行处理　303
13．3．3　Fork/Join 处理　307
13．3．4　Actor　308
13．3．5　Agent　315
13．3．6　Dataf low　316
13．4　Scala 的并发处理　322
13．4．1　Scala 中的Future 对象　322
13．4．2　Promise　328

第1章　概述　　1

1.1 并发还是并行？ 　　1

1.2 并行架构　　3

1.3 并发：不只是多核　　5

1.4 七个模型　　6

第2章　线程与锁　　7

2.1 简单粗暴　　7

2.2 第一天：互斥和内存模型　　8

2.3 第二天：超越内置锁　　17

2.4 第三天：站在巨人的肩膀上　　27

2.5 复习　　38

第3章　函数式编程　　41

3.1 若不爽，就另辟蹊径　　41

3.2 第一天：抛弃可变状态　　42

3.3 第二天：函数式并行　　51

3.4 第三天：函数式并发　　61

3.5 复习　　70

第4章　Clojure 之道——分离标识与状态　　73

4.1 混搭的力量　　73

4.2 第一天：原子变量与持久数据结构　　73

4.3 第二天：代理和软件事务内存　　84

4.4 第三天：深入学习　　92

4.5 复习　　98

第5章　Actor　　100

5.1 更加面向对象　　100

5.2 第一天：消息和信箱　　101

5.3 第二天：错误处理和容错性　　111

5.4 第三天：分布式　　120

5.5 复习　　132

第6章　通信顺序进程　　135

6.1 万物皆通信　　135

6.2 第一天：channel 和go 块　　136

6.3 第二天：多个channel 与IO　　146

6.4 第三天：客户端CSP　　157

6.5 复习　　164

第7章　数据并行　　167

7.1 隐藏在笔记本电脑中的超级计算机　　167

7.2 第一天：GPGPU编程　　167

7.3 第二天：多维空间与工作组　　177

7.4 第三天：OpenCL和OpenGL——全部在GPU 上运行　　187

7.5 复习　　194

第8章　Lambda架构　　196

8.1 并行计算搞定大数据　　196

8.2 第一天：MapReduce　　197

8.3 第二天：批处理层　　208

8.4 第三天：加速层　　218

8.5 复习　　229

第9章　圆满结束　　231

9.1 君欲何往　　231

9.2 未尽之路　　232

9.3 越过山丘　　234

第1部分 概述 / 1
1 交易型系统设计的一些原则 / 2
1.1 高并发原则 / 3
1.1.1 无状态 / 3
1.1.2 拆分 / 3
1.1.3 服务化 / 4
1.1.4 消息队列 / 4
1.1.5 数据异构 / 6
1.1.6 缓存银弹 / 7
1.1.7 并发化 / 9
1.2 高可用原则 / 10
1.2.1 降级 / 10
1.2.2 限流 / 11
1.2.3 切流量 / 12
1.2.4 可回滚 / 12
1.3 业务设计原则 / 12
1.3.1 防重设计 / 13
1.3.2 幂等设计 / 13
1.3.3 流程可定义 / 13
1.3.4 状态与状态机 / 13
1.3.5 后台系统操作可反馈 / 14
1.3.6 后台系统审批化 / 14
1.3.7 文档和注释 / 14
1.3.8 备份 / 14
1.4 总结 / 14
第2部分 高可用 / 17
2 负载均衡与反向代理 / 18
2.1 upstream配置 / 20
2.2 负载均衡算法 / 21
2.3 失败重试 / 23
2.4 健康检查 / 24
2.4.1 TCP心跳检查 / 24
2.4.2 HTTP心跳检查 / 25
2.5 其他配置 / 25
2.5.1 域名上游服务器 / 25
2.5.2 备份上游服务器 / 26
2.5.3 不可用上游服务器 / 26
2.6 长连接 / 26
2.7 HTTP反向代理示例 / 29
2.8 HTTP动态负载均衡 / 30
2.8.1 Consul+Consul-template / 31
2.8.2 Consul+OpenResty / 35
2.9 Nginx四层负载均衡 / 39
2.9.1 静态负载均衡 / 39
2.9.2 动态负载均衡 / 41
参考资料 / 42
3 隔离术 / 43
3.1 线程隔离 / 43
3.2 进程隔离 / 45
3.3 集群隔离 / 45
3.4 机房隔离 / 46
3.5 读写隔离 / 47
3.6 动静隔离 / 48
3.7 爬虫隔离 / 49
3.8 热点隔离 / 50
3.9 资源隔离 / 50
3.10 使用Hystrix实现隔离 / 51
3.10.1 Hystrix简介 / 51
3.10.2 隔离示例 / 52
3.11 基于Servlet 3实现请求隔离 / 56
3.11.1 请求解析和业务处理线程池分离 / 57
3.11.2 业务线程池隔离 / 58
3.11.3 业务线程池监控/运维/降级 / 58
3.11.4 如何使用Servlet 3异步化 / 59
3.11.5 一些Servlet 3异步化压测数据 / 64
4 限流详解 / 66
4.1 限流算法 / 67
4.1.1 令牌桶算法 / 67
4.1.2 漏桶算法 / 68
4.2 应用级限流 / 69
4.2.1 限流总并发/连接/请求数 / 69
4.2.2 限流总资源数 / 70
4.2.3 限流某个接口的总并发/请求数 / 70
4.2.4 限流某个接口的时间窗请求数 / 70
4.2.5 平滑限流某个接口的请求数 / 71
4.3 分布式限流 / 75
4.3.1 Redis+Lua实现 / 76
4.3.2 Nginx+Lua实现 / 77
4.4 接入层限流 / 78
4.4.1 ngx_http_limit_conn_module / 78
4.4.2 ngx_http_limit_req_module / 80
4.4.3 lua-resty-limit-traffic / 88
4.5 节流 / 90
4.5.1 throttleFirst/throttleLast / 90
4.5.2 throttleWithTimeout / 91
参考资料 / 92
5 降级特技 / 93
5.1 降级预案 / 93
5.2 自动开关降级 / 95
5.2.1 超时降级 / 95
5.2.2 统计失败次数降级 / 95
5.2.3 故障降级 / 95
5.2.4 限流降级 / 95
5.3 人工开关降级 / 96
5.4 读服务降级 / 96
5.5 写服务降级 / 97
5.6 多级降级 / 98
5.7 配置中心 / 100
5.7.1 应用层API封装 / 100
5.7.2 配置文件实现开关配置 / 101
5.7.3 配置中心实现开关配置 / 102
5.8 使用Hystrix实现降级 / 106
5.9 使用Hystrix实现熔断 / 108
5.9.1 熔断机制实现 / 108
5.9.2 配置示例 / 112
5.9.3 采样统计 / 113
6 超时与重试机制 / 117
6.1 简介 / 117
6.2 代理层超时与重试 / 119
6.2.1 Nginx / 119
6.2.2 Twemproxy / 126
6.3 Web容器超时 / 127
6.4 中间件客户端超时与重试 / 127
6.5 数据库客户端超时 / 131
6.6 NoSQL客户端超时 / 134
6.7 业务超时 / 135
6.8 前端Ajax超时 / 135
6.9 总结 / 136
6.10 参考资料 / 137
7 回滚机制 / 139
7.1 事务回滚 / 139
7.2 代码库回滚 / 140
7.3 部署版本回滚 / 141
7.4 数据版本回滚 / 142
7.5 静态资源版本回滚 / 143
8 压测与预案 / 145
8.1 系统压测 / 145
8.1.1 线下压测 / 146
8.1.2 线上压测 / 146
8.2 系统优化和容灾 / 147
8.3 应急预案 / 148
第3部分 高并发 / 153
9 应用级缓存 / 154
9.1 缓存简介 / 154
9.2 缓存命中率 / 155
9.3 缓存回收策略 / 155
9.3.1 基于空间 / 155
9.3.2 基于容量 / 155
9.3.3 基于时间 / 155
9.3.4 基于Java对象引用 / 156
9.3.5 回收算法 / 156
9.4 Java缓存类型 / 156
9.4.1 堆缓存 / 158
9.4.2 堆外缓存 / 162
9.4.3 磁盘缓存 / 162
9.4.4 分布式缓存 / 164
9.4.5 多级缓存 / 166
9.5 应用级缓存示例 / 167
9.5.1 多级缓存API封装 / 167
9.5.2 NULL Cache / 170
9.5.3 强制获取最新数据 / 170
9.5.4 失败统计 / 171
9.5.5 延迟报警 / 171
9.6 缓存使用模式实践 / 172
9.6.1 Cache-Aside / 173
9.6.2 Cache-As-SoR / 174
9.6.3 Read-Through / 174
9.6.4 Write-Through / 176
9.6.5 Write-Behind / 177
9.6.6 Copy Pattern / 181
9.7 性能测试 / 181
9.8 参考资料 / 182
10 HTTP缓存 / 183
10.1 简介 / 183
10.2 HTTP缓存 / 184
10.2.1 Last-Modified / 184
10.2.2 ETag / 190
10.2.3 总结 / 192
10.3 HttpClient客户端缓存 / 192
10.3.1 主流程 / 195
10.3.2 清除无效缓存 / 195
10.3.3 查找缓存 / 196
10.3.4 缓存未命中 / 198
10.3.5 缓存命中 / 198
10.3.6 缓存内容陈旧需重新验证 / 202
10.3.7 缓存内容无效需重新执行请求 / 205
10.3.8 缓存响应 / 206
10.3.9 缓存头总结 / 207
10.4 Nginx HTTP缓存设置 / 208
10.4.1 expires / 208
10.4.2 if-modified-since / 209
10.4.3 nginx proxy_pass / 209
10.5 Nginx代理层缓存 / 212
10.5.1 Nginx代理层缓存配置 / 212
10.5.2 清理缓存 / 215
10.6 一些经验 / 216
参考资料 / 217
11 多级缓存 / 218
11.1 多级缓存介绍 / 218
11.2 如何缓存数据 / 220
11.2.1 过期与不过期 / 220
11.2.2 维度化缓存与增量缓存 / 221
11.2.3 大Value缓存 / 221
11.2.4 热点缓存 / 221
11.3 分布式缓存与应用负载均衡 / 222
11.3.1 缓存分布式 / 222
11.3.2 应用负载均衡 / 222
11.4 热点数据与更新缓存 / 223
11.4.1 单机全量缓存+主从 / 223
11.4.2 分布式缓存+应用本地热点 / 224
11.5 更新缓存与原子性 / 225
11.6 缓存崩溃与快速修复 / 226
11.6.1 取模 / 226
11.6.2 一致性哈希 / 226
11.6.3 快速恢复 / 226
12 连接池线程池详解 / 227
12.1 数据库连接池 / 227
12.1.1 DBCP连接池配置 / 228
12.1.2 DBCP配置建议 / 233
12.1.3 数据库驱动超时实现 / 234
12.1.4 连接池使用的一些建议 / 235
12.2 HttpClient连接池 / 236
12.2.1 HttpClient 4.5.2配置 / 236
12.2.2 HttpClient连接池源码分析 / 240
12.2.3 HttpClient 4.2.3配置 / 241
12.2.4 问题示例 / 243
12.3 线程池 / 244
12.3.1 Java线程池 / 245
12.3.2 Tomcat线程池配置 / 248
13 异步并发实战 / 250
13.1 同步阻塞调用 / 251
13.2 异步Future / 252
13.3 异步Callback / 253
13.4 异步编排CompletableFuture / 254
13.5 异步Web服务实现 / 257
13.6 请求缓存 / 259
13.7 请求合并 / 261
14 如何扩容 / 266
14.1 单体应用垂直扩容 / 267
14.2 单体应用水平扩容 / 267
14.3 应用拆分 / 268
14.4 数据库拆分 / 271
14.5 数据库分库分表示例 / 275
14.5.1 应用层还是中间件层 / 275
14.5.2 分库分表策略 / 277
14.5.3 使用sharding-jdbc分库分表 / 279
14.5.4 sharding-jdbc分库分表配置 / 279
14.5.5 使用sharding-jdbc读写分离 / 283
14.6 数据异构 / 284
14.6.1 查询维度异构 / 284
14.6.2 聚合数据异构 / 285
14.7 任务系统扩容 / 285
14.7.1 简单任务 / 285
14.7.2 分布式任务 / 287
14.7.3 Elastic-Job简介 / 287
14.7.4 Elastic-Job-Lite功能与架构 / 287
14.7.5 Elastic-Job-Lite示例 / 288
15 队列术 / 295
15.1 应用场景 / 295
15.2 缓冲队列 / 296
15.3 任务队列 / 297
15.4 消息队列 / 297
15.5 请求队列 / 299
15.6 数据总线队列 / 300
15.7 混合队列 / 301
15.8 其他队列 / 302
15.9 Disruptor+Redis队列 / 303
15.10 下单系统水平可扩展架构 / 311
第4部分 案例 / 323
16 构建需求响应式亿级商品详情页 / 324
16.1 商品详情页是什么 / 324
16.2 商品详情页前端结构 / 325
16.3 我们的性能数据 / 327
16.4 单品页流量特点 / 327
16.5 单品页技术架构发展 / 327
16.5.1 架构1.0 / 328
16.5.2 架构2.0 / 328
16.5.3 架构3.0 / 330
16.6 详情页架构设计原则 / 332
16.7 遇到的一些坑和问题 / 339
16.8 其他 / 347
17 京东商品详情页服务闭环实践 / 348
17.1 为什么需要统一服务 / 348
17.2 整体架构 / 349
17.3 一些架构思路和总结 / 350
17.4 引入Nginx接入层 / 354
17.5 前端业务逻辑后置 / 356
17.6 前端接口服务端聚合 / 357
17.7 服务隔离 / 359
18 使用OpenResty开发高性能Web应用 / 360
18.1 OpenResty简介 / 361
18.1.1 Nginx优点 / 361
18.1.2 Lua的优点 / 361
18.1.3 什么是ngx_lua / 361
18.1.4 开发环境 / 362
18.1.5 OpenResty生态 / 362
18.1.6 场景 / 362
18.2 基于OpenResty的常用架构模式 / 363
18.3 如何使用OpenResty开发Web应用 / 371
18.4 基于OpenResty的常用功能总结 / 375
18.5 一些问题 / 376
19 应用数据静态化架构高性能单页Web应用 / 377
19.1 整体架构 / 378
19.2 数据和模板动态化 / 381
19.3 多版本机制 / 381
19.4 异常问题 / 382
20 使用OpenResty开发Web服务 / 383
20.1 架构 / 383
20.2 单DB架构 / 384
20.3 实现 / 387
21 使用OpenResty开发商品详情页 / 405
21.1 技术选型 / 407
21.2 核心流程 / 408
21.3 项目搭建 / 408
21.4 数据存储实现 / 410
21.5 动态服务实现 / 422
21.6 前端展示实现 / 430

第1章　走入并行世界 1
1．1　何去何从的并行计算 1
1．1．1　忘掉那该死的并行 2
1．1．2　可怕的现实：摩尔定律的失效 4
1．1．3　柳暗花明：不断地前进 5
1．1．4　光明或是黑暗 6
1．2　你必须知道的几个概念 6
1．2．1　同步（Synchronous）和异步（Asynchronous） 7
1．2．2　并发（Concurrency）和并行（Parallelism） 8
1．2．3　临界区 9
1．2．4　阻塞（Blocking）和非阻塞（Non-Blocking） 9
1．2．5　死锁（Deadlock）、饥饿（Starvation）和活锁（Livelock） 9
1．3　并发级别 11
1．3．1　阻塞（Blocking） 11
1．3．2　无饥饿（Starvation-Free） 11
1．3．3　无障碍（Obstruction-Free） 12
1．3．4　无锁（Lock-Free） 12
1．3．5　无等待（Wait-Free） 13
1．4　有关并行的两个重要定律 13
1．4．1　Amdahl定律 13
1．4．2　Gustafson定律 16
1．4．3　Amdahl定律和Gustafson定律是否相互矛盾 16
1．5　回到Java：JMM 17
1．5．1　原子性（Atomicity） 18
1．5．2　可见性（Visibility） 20
1．5．3　有序性（Ordering） 22
1．5．4　哪些指令不能重排：Happen-Before规则 27
1．6　参考文献 27
第2章　Java并行程序基础 29
2．1　有关线程你必须知道的事 29
2．2　初始线程：线程的基本操作 32
2．2．1　新建线程 32
2．2．2　终止线程 34
2．2．3　线程中断 38
2．2．4　等待（wait）和通知（notify） 41
2．2．5　挂起（suspend）和继续执行（resume）线程 44
2．2．6　等待线程结束（join）和谦让（yield） 48
2．3　volatile与Java内存模型（JMM） 50
2．4　分门别类的管理：线程组 52
2．5　驻守后台：守护线程（Daemon） 54
2．6　先干重要的事：线程优先级 55
2．7　线程安全的概念与synchronized 57
2．8　程序中的幽灵：隐蔽的错误 61
2．8．1　无提示的错误案例 61
2．8．2　并发下的ArrayList 62
2．8．3　并发下诡异的HashMap 63
2．8．4　初学者常见问题：错误的加锁 66
2．9　参考文献 68
第3章　JDK并发包 70
3．1　多线程的团队协作：同步控制 70
3．1．1　synchronized的功能扩展：重入锁 71
3．1．2　重入锁的好搭档：Condition条件 80
3．1．3　允许多个线程同时访问：信号量（Semaphore） 83
3．1．4　ReadWriteLock读写锁 85
3．1．5　倒计时器：CountDownLatch 87
3．1．6　循环栅栏：CyclicBarrier 89
3．1．7　线程阻塞工具类：LockSupport 92
3．2　线程复用：线程池 95
3．2．1　什么是线程池 96
3．2．2　不要重复发明轮子：JDK对线程池的支持 97
3．2．3　刨根究底：核心线程池的内部实现 102
3．2．4　超负载了怎么办：拒绝策略 106
3．2．5　自定义线程创建：ThreadFactory 109
3．2．6　我的应用我做主：扩展线程池 110
3．2．7　合理的选择：优化线程池线程数量 112
3．2．8　堆栈去哪里了：在线程池中寻找堆栈 113
3．2．9　分而治之：Fork/Join框架 117
3．3　不要重复发明轮子：JDK的并发容器 121
3．3．1　超好用的工具类：并发集合简介 121
3．3．2　线程安全的HashMap 122
3．3．3　有关List的线程安全 123
3．3．4　高效读写的队列：深度剖析ConcurrentLinkedQueue 123
3．3．5　高效读取：不变模式下的CopyOnWriteArrayList 129
3．3．6　数据共享通道：BlockingQueue 130
3．3．7　随机数据结构：跳表（SkipList） 134
3．4　参考资料 136

第4章　锁的优化及注意事项 138
4．1　有助于提高“锁”性能的几点建议 139
4．1．1　减小锁持有时间 139
4．1．2　减小锁粒度 140
4．1．3　读写分离锁来替换独占锁 142
4．1．4　锁分离 142
4．1．5　锁粗化 144
4．2　Java虚拟机对锁优化所做的努力 146
4．2．1　锁偏向 146
4．2．2　轻量级锁 146
4．2．3　自旋锁 146
4．2．4　锁消除 146
4．3　人手一支笔：ThreadLocal 147
4．3．1　ThreadLocal的简单使用 148
4．3．2　ThreadLocal的实现原理 149
4．3．3　对性能有何帮助 155
4．4　无锁 157
4．4．1　与众不同的并发策略：比较交换（CAS） 158
4．4．2　无锁的线程安全整数：AtomicInteger 159
4．4．3　Java中的指针：Unsafe类 161
4．4．4　无锁的对象引用：AtomicReference 162
4．4．5　带有时间戳的对象引用：AtomicStampedReference 165
4．4．6　数组也能无锁：AtomicIntegerArray 168
4．4．7　让普通变量也享受原子操作：AtomicIntegerFieldUpdater 169
4．4．8　挑战无锁算法：无锁的Vector实现 171
4．4．9　让线程之间互相帮助：细看SynchronousQueue的实现 176
4．5　有关死锁的问题 179
4．6　参考文献 183

第5章　并行模式与算法 184
5．1　探讨单例模式 184
5．2　不变模式 187
5．3　生产者-消费者模式 190
5．4　高性能的生产者-消费者：无锁的实现 194
5．4．1　无锁的缓存框架：Disruptor 195
5．4．2　用Disruptor实现生产者-消费者案例 196
5．4．3　提高消费者的响应时间：选择合适的策略 199
5．4．4　CPU Cache的优化：解决伪共享问题 200
5．5　Future模式 204
5．5．1　Future模式的主要角色 206
5．5．2　Future模式的简单实现 207
5．5．3　JDK中的Future模式 210
5．6　并行流水线 212
5．7　并行搜索 216
5．8　并行排序 218
5．8．1　分离数据相关性：奇偶交换排序 218
5．8．2　改进的插入排序：希尔排序 221
5．9　并行算法：矩阵乘法 226
5．10　准备好了再通知我：网络NIO 230
5．10．1　基于Socket的服务端的多线程模式 230
5．10．2　使用NIO进行网络编程 235
5．10．3　使用NIO来实现客户端 243
5．11　读完了再通知我：AIO 245
5．11．1　AIO EchoServer的实现 245
5．11．2　AIO Echo客户端实现 248
5．12　参考文献 249

第6章　Java 8与并发 251
6．1　Java 8的函数式编程简介 251
6．1．1　函数作为一等公民 252
6．1．2　无副作用 252
6．1．3　申明式的（Declarative） 253
6．1．4　不变的对象 254
6．1．5　易于并行 254
6．1．6　更少的代码 254
6．2　函数式编程基础 255
6．2．1　FunctionalInterface注释 255
6．2．2　接口默认方法 256
6．2．3　lambda表达式 259
6．2．4　方法引用 260
6．3　一步一步走入函数式编程 263
6．4　并行流与并行排序 267
6．4．1　使用并行流过滤数据 267
6．4．2　从集合得到并行流 268
6．4．3　并行排序 268
6．5　增强的Future：CompletableFuture 269
6．5．1　完成了就通知我 269
6．5．2　异步执行任务 270
6．5．3　流式调用 272
6．5．4　CompletableFuture中的异常处理 272
6．5．5　组合多个CompletableFuture 273

6．6　读写锁的改进：StampedLock 274
6．6．1　StampedLock使用示例 275
6．6．2　StampedLock的小陷阱 276
6．6．3　有关StampedLock的实现思想 278
6．7　原子类的增强 281
6．7．1　更快的原子类：LongAdder 281
6．7．2　LongAdder的功能增强版：LongAccumulator 287

第7章　使用Akka构建高并发程序 289
7．1　新并发模型：Actor 290
7．2　Akka之Hello World 290
7．3　有关消息投递的一些说明 293
7．4　Actor的生命周期 295
7．5　监督策略 298
7．6　选择Actor 303
7．7　消息收件箱（Inbox） 303
7．8　消息路由 305

7．9　Actor的内置状态转换 308
7．10　询问模式：Actor中的Future 311
7．11　多个Actor同时修改数据：Agent 313
7．12　像数据库一样操作内存数据：软件事务内存 316
7．13　一个有趣的例子：并发粒子群的实现 319
7．13．1　什么是粒子群算法 320
7．13．2　粒子群算法的计算过程 320
7．13．3　粒子群算法能做什么 322
7．13．4　使用Akka实现粒子群 323
7．14　参考文献 330

第8章　并行程序调试 331
8．1　准备实验样本 331
8．2　正式起航 332
8．3　挂起整个虚拟机 334
8．4　调试进入ArrayList内部 336


CLH锁是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋，获得锁。
* @author EX-ZHANGYONGTIAN001
* @version 1.0.0
* @date 2019-3-13  13:46
*/
public class CLHLock {

    /**
     * 定义一个节点，默认的lock状态为true
     */
    public static class CLHNode {
        private volatile boolean isLocked = true;
    }
    /**
     * 尾部节点,只用一个节点即可
     */
    private volatile CLHNode tail;
    private static final ThreadLocal<CLHNode> LOCAL = new ThreadLocal<CLHNode>();
    private static final AtomicReferenceFieldUpdater<CLHLock, CLHNode> UPDATER = AtomicReferenceFieldUpdater.newUpdater(CLHLock.class, CLHNode.class,
            "tail");
    public void lock() {
        // 新建节点并将节点与当前线程保存起来
        CLHNode node = new CLHNode();
        LOCAL.set(node);
        // 将新建的节点设置为尾部节点，并返回旧的节点（原子操作），这里旧的节点实际上就是当前节点的前驱节点
        CLHNode preNode = UPDATER.getAndSet(this, node);
        if (preNode != null) {
            // 前驱节点不为null表示当锁被其他线程占用，通过不断轮询判断前驱节点的锁标志位等待前驱节点释放锁
            while (preNode.isLocked) {
            }
            preNode = null;
            LOCAL.set(node);
        }
        // 如果不存在前驱节点，表示该锁没有被其他线程占用，则当前线程获得锁
    }
    public void unlock() {
        // 获取当前线程对应的节点
        CLHNode node = LOCAL.get();
        // 如果tail节点等于node，则将tail节点更新为null，同时将node的lock状态职位false，表示当前线程释放了锁
        if (!UPDATER.compareAndSet(this, node, null)) {
            node.isLocked = false;
        }
        node = null;
    }


}




提到 JAVA 加锁，我们通常会想到 synchronized 关键字或者是 Java Concurrent Util（后面简称JCU）包下面的 Lock，今天就来扒一扒 Lock 是如何实现的，比如我们可以先提出一些问题：当我们通实例化一个 ReentrantLock 并且调用它的 lock 或 unlock 的时候，这其中发生了什么？如果多个线程同时对同一个锁实例进行 lock 或 unlcok 操作，这其中又发生了什么？

什么是可重入锁？

ReentrantLock 是可重入锁，什么是可重入锁呢？可重入锁就是当前持有该锁的线程能够多次获取该锁，无需等待。可重入锁是如何实现的呢？这要从 ReentrantLock 的一个内部类 Sync 的父类说起，Sync 的父类是 AbstractQueuedSynchronizer（后面简称AQS）。

什么是AQS？

AQS 是 JDK1.5 提供的一个基于 FIFO 等待队列实现的一个用于实现同步器的基础框架，这个基础框架的重要性可以这么说，JCU 包里面几乎所有的有关锁、多线程并发以及线程同步器等重要组件的实现都是基于 AQS 这个框架。AQS 的核心思想是基于 volatile int state 这样的一个属性同时配合 Unsafe 工具对其原子性的操作来实现对当前锁的状态进行修改。当 state 的值为 0 的时候，标识改 Lock 不被任何线程所占有。

ReentrantLock 锁的架构

ReentrantLock 的架构相对简单，主要包括一个 Sync 的内部抽象类以及 Sync 抽象类的两个实现类。上面已经说过了 Sync 继承自 AQS，他们的结构示意图如下：



上图除了 AQS 之外，我把 AQS 的父类 AbstractOwnableSynchronizer（后面简称AOS）也画了进来，可以稍微提一下，AOS 主要提供一个 exclusiveOwnerThread 属性，用于关联当前持有该所的线程。另外、Sync 的两个实现类分别是 NonfairSync 和 FairSync，由名字大概可以猜到，一个是用于实现公平锁、一个是用于实现非公平锁。那么 Sync 为什么要被设计成内部类呢？我们可以看看 AQS 主要提供了哪些 protect 的方法用于修改 state 的状态，我们发现 Sync 被设计成为安全的外部不可访问的内部类。ReentrantLock 中所有涉及对 AQS 的访问都要经过 Sync，其实，Sync 被设计成为内部类主要是为了安全性考虑，这也是作者在 AQS 的 comments 上强调的一点。

AQS 的等待队列

作为 AQS 的核心实现的一部分，举个例子来描述一下这个队列长什么样子，我们假设目前有三个线程 Thread1、Thread2、Thread3 同时去竞争锁，如果结果是 Thread1 获取了锁，Thread2 和 Thread3 进入了等待队列，那么他们的样子如下：



AQS 的等待队列基于一个双向链表实现的，HEAD 节点不关联线程，后面两个节点分别关联 Thread2 和 Thread3，他们将会按照先后顺序被串联在这个队列上。这个时候如果后面再有线程进来的话将会被当做队列的 TAIL。

1）入队列

我们来看看，当这三个线程同时去竞争锁的时候发生了什么？代码：

public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
解读：三个线程同时进来，他们会首先会通过 CAS 去修改 state 的状态，如果修改成功，那么竞争成功，因此这个时候三个线程只有一个 CAS 成功，其他两个线程失败，也就是 tryAcquire 返回 false。接下来，addWaiter 会把将当前线程关联的 EXCLUSIVE 类型的节点入队列：

private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);
    return node;
}
解读：如果队尾节点不为 null，则说明队列中已经有线程在等待了，那么直接入队尾。对于我们举的例子，这边的逻辑应该是走 enq，也就是开始队尾是 null，其实这个时候整个队列都是 null 的。代码：

private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
解读：如果 Thread2 和 Thread3 同时进入了 enq，同时 t==null，则进行 CAS 操作对队列进行初始化，这个时候只有一个线程能够成功，然后他们继续进入循环，第二次都进入了 else 代码块，这个时候又要进行 CAS 操作，将自己放在队尾，因此这个时候又是只有一个线程成功，我们假设是 Thread2 成功，哈哈，Thread2 开心的返回了，Thread3 失落的再进行下一次的循环，最终入队列成功，返回自己。

2）并发问题

基于上面两段代码，他们是如何实现不进行加锁，当有多个线程，或者说很多很多的线程同时执行的时候，怎么能保证最终他们都能够乖乖的入队列而不会出现并发问题的呢？这也是这部分代码的经典之处，多线程竞争，热点、单点在队列尾部，多个线程都通过【CAS+死循环】这个free-lock黄金搭档来对队列进行修改，每次能够保证只有一个成功，如果失败下次重试，如果是N个线程，那么每个线程最多 loop N 次，最终都能够成功。

3）挂起等待线程

上面只是 addWaiter 的实现部分，那么节点入队列之后会继续发生什么呢？那就要看看 acquireQueued 是怎么实现的了，为保证文章整洁，代码我就不贴了，同志们自行查阅，我们还是以上面的例子来看看，Thread2 和 Thread3 已经被放入队列了，进入 acquireQueued 之后：

对于 Thread2 来说，它的 prev 指向 HEAD，因此会首先再尝试获取锁一次，如果失败，则会将 HEAD 的 waitStatus 值为 SIGNAL，下次循环的时候再去尝试获取锁，如果还是失败，且这个时候 prev 节点的 waitStatus 已经是 SIGNAL，则这个时候线程会被通过 LockSupport 挂起。

对于 Thread3 来说，它的 prev 指向 Thread2，因此直接看看 Thread2 对应的节点的 waitStatus 是否为 SIGNAL，如果不是则将它设置为 SIGNAL，再给自己一次去看看自己有没有资格获取锁，如果 Thread2 还是挡在前面，且它的 waitStatus 是 SIGNAL，则将自己挂起。

如果 Thread1 死死的握住锁不放，那么 Thread2 和 Thread3 现在的状态就是挂起状态啦，而且 HEAD，以及 Thread 的 waitStatus 都是 SIGNAL，尽管他们在整个过程中曾经数次去尝试获取锁，但是都失败了，失败了不能死循环呀，所以就被挂起了。当前状态如下：



锁释放-等待线程唤起

我们来看看当 Thread1 这个时候终于做完了事情，调用了 unlock 准备释放锁，这个时候发生了什么。代码：

public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}
解读：首先，Thread1 会修改AQS的state状态，加入之前是 1，则变为 0，注意这个时候对于非公平锁来说是个很好的插入机会，举个例子，如果锁是公平锁，这个时候来了 Thread4，那么这个锁将会被 Thread4 抢去。。。

我们继续走常规路线来分析，当 Thread1 修改完状态了，判断队列是否为 null，以及队头的 waitStatus 是否为 0，如果 waitStatus 为 0，说明队列无等待线程，按照我们的例子来说，队头的 waitStatus 为 SIGNAL=-1，因此这个时候要通知队列的等待线程，可以来拿锁啦，这也是 unparkSuccessor 做的事情，unparkSuccessor 主要做三件事情：

将队头的 waitStatus 设置为 0。

通过从队列尾部向队列头部移动，找到最后一个 waitStatus<=0 的那个节点，也就是离队头最近的没有被cancelled的那个节点，队头这个时候指向这个节点。

将这个节点唤醒，其实这个时候 Thread1 已经出队列了。

还记得线程在哪里挂起的么，上面说过了，在 acquireQueued 里面，我没有贴代码，自己去看哦。这里我们也大概能理解 AQS 的这个队列为什么叫 FIFO 队列了，因此每次唤醒仅仅唤醒队头等待线程，让队头等待线程先出。

羊群效应

这里说一下羊群效应，当有多个线程去竞争同一个锁的时候，假设锁被某个线程占用，那么如果有成千上万个线程在等待锁，有一种做法是同时唤醒这成千上万个线程去去竞争锁，这个时候就发生了羊群效应，海量的竞争必然造成资源的剧增和浪费，因此终究只能有一个线程竞争成功，其他线程还是要老老实实的回去等待。AQS 的 FIFO 的等待队列给解决在锁竞争方面的羊群效应问题提供了一个思路：保持一个 FIFO 队列，队列每个节点只关心其前一个节点的状态，线程唤醒也只唤醒队头等待线程。其实这个思路已经被应用到了分布式锁的实践中，见：Zookeeper 分布式锁的改进实现方案。

==========

线程池的设计原理是什么？
无敌码农  Java技术江湖  昨天
点击关注上方“Java技术江湖”，设为“置顶或星标”，第一时间送达技术干货。





作者：无敌码农

文章来源：无敌码农





导读





线程池相关的知识点是面试中非常高频的问题，掌握线程及线程池相关的知识点也是程序员向高段位进阶的必由之路。由于线程池涉及线程、并发、编程语言内存模型等多方面的知识，历来也不是一块特别好掌握的内容。因此，小码哥决定好好梳理下这方面的知识，希望能够对你有所帮助。在本文中，作者将以JAVA语言中的线程池设计为基础，从原理分析及代码实践两个方面来进行梳理。



线程的概念





在了解线程池的相关的知识之前，我们有必要再次深入理解下线程的基本概念。在这里，也许会有很多同学质疑，线程的基本概念我们都懂，为什么还需要重复提起呢？



在回答这个问题之前，我们还是先回到实际的编程语言中来看看线程到底是什么？以JAVA为例，在JAVA中如何实现一个线程呢？



public class ThreadDemo01 {
    public static void main(String args[]) {
        //通过匿名内部类的方式创建线程，并且重写其中的run方法
        new Thread() {
            public void run() {
                while (true) {
                    System.out.println("线程->" + Thread.currentThread().getName() + " 运行中！");
                    try {
                        sleep(100);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }.start();
    }
}




通过上面的代码示例，我们知道在JAVA中要实现一个线程可以通过构造Thread类来实现。之后，通过重写run()方法来让线程执行我们想要让它执行的逻辑。然而，为了让线程生效，我们还需要通过调用start()方法来启动它。那么为什么我们重写了run()方法，但是却还需要调用start()方法呢？run()方法和start()方法有什么关系？到底那个方法才是真正代表了线程这个存在呢？



要搞清楚这个问题，需要我们明确“线程的执行单元”与“线程”是两个不同的概念。在JAVA中通过Thread类重写的run()方法是线程的执行单元，而通过调用start()方法才是真正启动了一个线程。这一点对后面我们理解线程池的作用会比较有用，因为只有从概念上剥离线程的执行单元与线程本身才能更深入的理解线程池存在的意义。



为了更加深入的说明这一点，我们可以来具体分析下上面例子中start()方法在JDK中的源码：



 public synchronized void start() {
        group.add(this);
        boolean started = false;
        try {
            start0();
            started = true;
        } finally {
            try {
                if (!started) {
                    group.threadStartFailed(this);
                }
            } catch (Throwable ignore) {
            }
        }
    }



在start()方法的源码中，最核心的部分其实就是start0()这个JNI本地方法：



private native void start0();




也就是说在start方法中会调用start0这个本地方法，但是从源码上这么看又看不出start0的具体逻辑。为此，作者特地翻了下JDK的官方文档，其中关于start方法的说明如下：

Causes this thread to begin execution; the Java Virtual Machine calls the run method of this thread.

上面这句话的意思是：在开始执行这个线程的时候，JVM将会调用该线程的run方法，而实际上run方法是被本地方法start0()调用的。也就是说，在JAVA中由于语言的约定，我们需要在使用线程时重写线程中的执行单元方法来实现业务逻辑，而真正开启线程资源的则是start方法。



在不少关于JAVA线程的软文或者书籍中，经常会提到，创建线程有两种方式：第一种是构造一个Thread；第二种是实现Runnable接口。通过上面的分析，这种说法其实是不严谨的。在JDK中代表线程的只有Thread类，而Runnable接口只是简单定义了一个无参数返回值的run方法。而我们知道run方法只是定义了线程的执行单元，而并非直接开启了线程资源，只有Thread方法的start()方法才可以启动一个线程。



所以，如果面试中有人问你在JAVA中实现线程的方式有哪些？应该告诉他准确答案：“在JAVA中创建线程只有一种方式，那就是构造Thread类。而实现线程的执行单元则有两种方式，第一种是重写Thread类的run方法；第二种是实现Runnable接口的run方法，并且将Runnable实例用作构造Thread的参数”。



接下来让我们再来回顾下线程的定义：“线程是一种轻量级的进程，是由进程派生出来的子任务，它是程序执行的一个路径；每个线程都有自己的局部变量表、程序计数器（指向真正执行的指令指针）以及各自的生命周期”。例如，当启动了一个JVM时，从操作系统开始就会创建一个新的JVM进程，之后JVM进程中将会派生或者创建很多线程。



线程知识涉及编程语言特性的面非常广泛，以JAVA语言为例，作者梳理了一份有关线程的知识图谱，如下：





要掌握JAVA中的线程，需要我们理解线程的生命周期、Thread类提供的方法细节、线程安全问题等多方面的知识点。而其中线程安全相关的问题又涉及JVM的内存模型、线程同步及锁相关的知识。由于篇幅的关系，这里作者也只能给出一个大致的提纲，更细节的内容在后面有时间再和大家一起细化同步。



以上就是在具体讲述线程池之前有关线程知识的回顾了，接下来就让我们进入本篇文章的主题“线程池”相关的内容吧！



线程池原理





在上节关于线程知识的回顾中，我们知道创建一个线程Thread其实是比较耗费操作系统资源的，况且系统中可创建的线程数量也是有限的，如果创建的线程资源数量不能够很好的加以限制，反而会导致系统性能的下降。因此我们在进行多线程编程时，对线程资源的重复利将是一种非常好的程序设计习惯。



那么我们在编程时如何才能实现线程资源的重复利用呢？答案就是使用线程池！所谓的线程池，通俗的理解就是有一个池子，里面存放着已经创建好的线程资源，当有任务提交给线程池执行时，池中的某个线程就会主动执行该任务，执行完任务后该线程就会继续回到池子中等待下次任务的执行。下面我们就来看一下线程池的基本原理图，如下：







线程池中的线程资源是Thread类代表的，而具体的执行任务是由实现Runnable接口的线程执行单元类组成。线程的执行单元逻辑随业务的变化而有所不同，而线程则是一个公共资源，所以可以复用，这一点也是我们在前面内容中特别强调的，因为如果我们将线程的执行单元中的逻辑与线程本身混在一起理解的话就很容易产生疑惑。



那么如何实现一个线程池呢？一个完整的线程池应该具备如下要素：

任务队列：用于缓存提交的任务。

线程数量管理功能：一个线程池必须能够很好地管理和控制线程的数量。大致会有三个参数，创建线程池时的初始线程数量init；自动扩充时的最大线程数量max；在线程池空闲时需要释放资源但是也要维持一定数量的核心线程数量core。通过这三个基本参数维持好线程池中数量的合理范围，一般来说它们之间的关系是“init<=core<=max”。

任务拒绝策略：如果线程数量已达到上限且任务队列已满，则需要有相应的拒绝策略来通知任务的提交者。

线程工厂：主要用于个性化定制线程，如设置线程的名称或者将线程设置为守护线程等。

QueueSize：任务队列主要存放提交的Runnable,但是为了防止内存溢出，需要有limit数量对其进行限制。

Keepedalive时间：该时间主要决定线程各个重要参数自动维护的时间间隔。


通过上面对线程池组成部分及原理的分析，为了更加深刻地理解下线程池，下面我们手工实现一个线程池！UML类图如下：







ThreadPool（接口）：主要定义一个线程池应该具备的基本操作和方法。

RunnableQueue（接口）：定义存放提交的线程执行单元Runnable的队列。

ThreadFactory（接口）：定义创建线程的接口，便于个性化地定制Thread。

DenyPolicy（接口）：拒绝策略接口，主要用于Queue中当runnable达到limit上限后所采用的拒绝策略。

Internaltask（类）：Runnable的实现，用于线程池内部，该类通过沦陷RunnableQueue队列，不断从队列中取出任务进行执行。

LinkedRunnableQueue（类）：队列接口的具体实现。

BasicThreadPool（类）：线程池的核心实现类。

手工编写完线程池后，我们看看怎么使用：



public class ThreadPoolTest
    public static void main(String args[]) throws InterruptedException {
        //定义线程池，初始化线程数为2，核心线程数为4，最大线程数为6，任务队列最多允许1000个任务
        final ThreadPool threadPool = new BasicThreadPool(2, 6, 4, 1000);
        //定义20个任务并提交给线程池
        for (int i = 0; i < 20; i++) {
            threadPool.execute(() -> {
                try {
                    TimeUnit.SECONDS.sleep(10);
                    System.out.println(Thread.currentThread().getName() + " is running and done.");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            });
        }
    }
}


以上测试代码，我们通过初始化2个线程、核心线程数为4，最大为6，然后向该线程池提交20个任务，执行结果如下：



thread-pool-0 is running and done.
thread-pool--1 is running and done.
thread-pool--2 is running and done.
thread-pool--3 is running and done.
thread-pool-0 is running and done.
thread-pool--1 is running and done.
thread-pool--2 is running and done.
thread-pool--3 is running and done.
thread-pool--1 is running and done.
thread-pool-0 is running and done.
thread-pool--3 is running and done.
thread-pool--2 is running and done.
thread-pool--1 is running and done.
thread-pool-0 is running and done.
thread-pool--3 is running and done.
thread-pool--2 is running and done.
thread-pool-0 is running and done.
thread-pool--1 is running and done.
thread-pool--2 is running and done.
thread-pool--3 is running and done.


从运行结果看，由于提交速度比较快，线程池扩容到了其核心线程的数量，总共4个线程，然后这些线程逐步完成了20个任务的执行，从而实现了线程的重复使用。



以上代码的github地址如下：

https://github.com/manongwudi/java-thread.git。

通过手工编写线程池的目的只是为了让大家更好地理解线程池的实现原理，实际上在JDK1.5以后在"java.util.concurrent(简称JUC)"中已经提供了多种版本的线程池实现，所以在JAVA中使用线程池时，我们只需要选择合适的线程池类型即可，而这些线程池的实现也基本上与我们手工编写的线程池原理类似。



Java自带线程池





在Java中通过Executor框架提供线程池支持，通过该框架我们可以创建出如下几类线程池：





按照线程池的核心实现类的不同派生，Java中共提供了5种现成的线程池。



1、newSingleThreadExecutor



是单个工作线程的Executor，它的corePoolSize和maximumPoolSize被设置为1。采用的是无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Interger.MAX_VALUE）。由于使用了无界队列，如果请求过多会导致OOM，在并发请求量比较大的系统中，使用此线程池需要注意。



public class SingleThreadExecutorDemo {

    public static void main(String args[]) {
        ExecutorService pool = Executors.newSingleThreadExecutor();
        for (int i = 0; i <= 20; i++) {
            pool.execute(() -> System.out.println(Thread.currentThread().getName() + "[running done]"));
        }
    }
}


2、newFixedThreadPool



被称为可重用固定线程数线程池。与SingleThreadExecutor一样它也使用了无界队列作为工作队列，如果没有执行方法shutdown()的话也是不会拒绝任务的。



public class FixThreadPoolDemo {
    public static void main(String args[]) {
        ExecutorService pool = Executors.newFixedThreadPool(10);
        for (int i = 0; i <= 100; i++) {
            pool.execute(() -> {
                try {
                    Thread.sleep(10);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + "[runing done]");
            });
        }
    }
}


3、newCachedThreadPool



是一个会根据需要创建新线程的线程池。它的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为Integer.MAX_VALUE,即maximumPool是无界的，正因为如此，如果主线程提交任务的速度高于线程池中线程处理任务的速度的话，线程池就会不断创建新的线程，极端情况下就可能导致线程创建过多而耗尽CPU和内存资源。



public class CacheThreadPoolDemo {
    public static void main(String args[]) {
        ExecutorService pool = Executors.newCachedThreadPool();
        for (int i = 0; i <= 20; i++) {
            pool.execute(() -> {
                System.out.println(Thread.currentThread().getName() + "[runing done]");
            });
        }
    }
}


4、newScheduledThreadPool



用于实现多个线程的周期性任务，它会把待调度的任务放到延迟队列DelayQueue中。与CacheThreadPool一样，它允许创建的最大线程数也是Interger.MAX_VALUE。



public class ScheduledThreadPoolExecutorDemo {
    public static void main(String args[]) {
        ScheduledExecutorService pool = Executors.newScheduledThreadPool(10);
        for (int i = 0; i <= 20; i++) {
            pool.schedule(() -> {
                System.out.println(Thread.currentThread().getName() + "[runing done]");
            }, 10, TimeUnit.SECONDS);
        }
    }
}
以上逻辑实现的是：延迟10秒后开始执行任务。



5、newSingleThreadScheduledExecutor



只包含一个线程的ThreadScheduleExecutor。



public class SingleThreadScheduledExecutorDemo {
    public static void main(String args[]) {
        ScheduledExecutorService pool = Executors.newSingleThreadScheduledExecutor();
        for (int i = 0; i <= 20; i++) {
            pool.scheduleAtFixedRate(() -> {
                System.out.println(Thread.currentThread().getName() + "[runing done]");
            }, 1, 1, TimeUnit.SECONDS);
        }
    }
}
以上逻辑实现的是：每一秒钟执行一次任务。



6、newWorkStealingPool



该线程池是jdk1.8以后新增的，底层采用ForkJoinPool来实现，类似于Fork-Join框架所支持的功能。



public class WorkStealingPoolDemo {
    public static void main(String args[]) {
        ExecutorService pool = Executors.newWorkStealingPool(10);
        for (int i = 0; i <= 20; i++) {
            pool.execute(() -> {
                System.out.println(Thread.currentThread().getName() + "[running done]");
            });
        }
    }
}


JDK自带的线程池大家可以根据场景选用，在阿里的开发手册中要求在实现线程池时明确的通过ThreadPoolExecutor去自行创建，并要求使用有界队列作为线程池的工作队列，同时对线程池允许创建的最大线程数也要限制，因为以上几个线程池都存在对资源使用没有限制的问题，所以大家还是根据实际情况来判断吧！


==========
【干货走一波】千万级用户的大型网站，应该如何设计其高并发架构？
原创： 原子弹大侠  狸猫技术窝  前天
目录

（1）单块架构

（2）初步的高可用架构

（3）千万级用户量的压力预估

（4）服务器压力预估

（5）业务垂直拆分

（6）用分布式缓存抗下读请求

（7）基于数据库主从架构做读写分离

（8）总结

本文将会从一个大型的网站发展历程出发，一步一步的探索这个网站的架构是如何从单体架构，演化到分布式架构，然后演化到高并发架构的。






（1）单块架构



一般一个网站刚开始建立的时候，用户量是很少的，大概可能就几万或者几十万的用户量，每天活跃的用户可能就几百或者几千个。



这个时候一般网站架构都是采用单体架构来设计的，总共就部署3台服务器，1台应用服务器，1台数据库服务器，1台图片服务器。



研发团队通常都在10人以内，就是在一个单块应用里写代码，然后写好之后合并代码，接着就是直接在线上的应用服务器上发布。很可能就是手动把应用服务器上的Tomcat给关掉，然后替换系统的代码war包，接着重新启动Tomcat。



数据库一般就部署在一台独立的服务器上，存放网站的全部核心数据。



然后在另外一台独立的服务器上部署NFS作为图片服务器，存放网站的全部图片。应用服务器上的代码会连接以及操作数据库以及图片服务器。如下图所示：







（2）初步的高可用架构



但是这种纯单块系统架构下，有高可用问题存在，最大的问题就是应用服务器可能会故障，或者是数据库可能会故障



所以在这个时期，一般稍微预算充足一点的公司，都会做一个初步的高可用架构出来。



对于应用服务器而言，一般会集群化部署。当然所谓的集群化部署，在初期用户量很少的情况下，其实一般也就是部署两台应用服务器而已，然后前面会放一台服务器部署负载均衡设备，比如说LVS，均匀的把用户请求打到两台应用服务器上去。



如果此时某台应用服务器故障了，还有另外一台应用服务器是可以使用的，这样就避免了单点故障问题。如下图所示：



对于数据库服务器而言，此时一般也会使用主从架构，部署一台从库来从主库同步数据，这样一旦主库出现问题，可以迅速使用从库继续提供数据库服务，避免数据库故障导致整个系统都彻底故障不可用。如下图：







（3）千万级用户量的压力预估



这个假设这个网站预估的用户数是1000万，那么根据28法则，每天会来访问这个网站的用户占到20%，也就是200万用户每天会过来访问。



通常假设平均每个用户每次过来会有30次的点击，那么总共就有6000万的点击（PV）。



每天24小时，根据28法则，每天大部分用户最活跃的时间集中在（24小时 * 0.2）≈ 5小时内，而大部分用户指的是（6000万点击 * 0.8 ≈ 5000万点击）



也就是说，在5小时内会有5000万点击进来。



换算下来，在那5小时的活跃访问期内，大概每秒钟会有3000左右的请求量，然后这5小时中可能又会出现大量用户集中访问的高峰时间段。



比如在集中半个小时内大量用户涌入形成高峰访问。根据线上经验，一般高峰访问是活跃访问的2~3倍。假设我们按照3倍来计算，那么5小时内可能有短暂的峰值会出现每秒有10000左右的请求。







（4）服务器压力预估



大概知道了高峰期每秒钟可能会有1万左右的请求量之后，来看一下系统中各个服务器的压力预估。



一般来说一台虚拟机部署的应用服务器，上面放一个Tomcat，也就支撑最多每秒几百的请求。



按每秒支撑500的请求来计算，那么支撑高峰期的每秒1万访问量，需要部署20台应用服务。



而且应用服务器对数据库的访问量又是要翻几倍的，因为假设一秒钟应用服务器接收到1万个请求，但是应用服务器为了处理每个请求可能要涉及到平均3~5次数据库的访问。



按照3次数据库访问来算，那么每秒会对数据库形成3万次的请求。



按照一台数据库服务器最高支撑每秒5000左右的请求量，此时需要通过6台数据库服务器才能支撑每秒3万左右的请求。



图片服务器的压力同样会很大，因为需要大量的读取图片展示页面，这个不太好估算，但是大致可以推算出来每秒至少也会有几千次请求，因此也需要多台图片服务器来支撑图片访问的请求。







（5）业务垂直拆分



一般来说在这个阶段要做的第一件事儿就是业务的垂直拆分



因为如果所有业务代码都混合在一起部署，会导致多人协作开发时难以维护。在网站到了千万级用户的时候，研发团队一般都有几十人甚至上百人。



所以这时如果还是在一个单块系统里做开发，是一件非常痛苦的事情，此时需要做的就是进行业务的垂直拆分，把一个单块系统拆分为多个业务系统，然后一个小团队10个人左右就专门负责维护一个业务系统。如下图







（6）分布式缓存扛下读请求



这个时候应用服务器层面一般没什么大问题，因为无非就是加机器就可以抗住更高的并发请求。



现在估算出来每秒钟是1万左右的请求，部署个二三十台机器就没问题了。



但是目前上述系统架构中压力最大的，其实是数据库层面 ，因为估算出来可能高峰期对数据库的读写并发会有3万左右的请求。



此时就需要引入分布式缓存来抗下对数据库的读请求压力了，也就是引入Redis集群。



一般来说对数据库的读写请求也大致遵循28法则，所以每秒3万的读写请求中，大概有2.4万左右是读请求



这些读请求基本上90%都可以通过分布式缓存集群来抗下来，也就是大概2万左右的读请求可以通过 Redis集群来抗住。



我们完全可以把热点的、常见的数据都在Redis集群里放一份作为缓存，然后对外提供缓存服务。



在读数据的时候优先从缓存里读，如果缓存里没有，再从数据库里读取。这样2万读请求就落到Redis上了，1万读写请求继续落在数据库上。



Redis一般单台服务器抗每秒几万请求是没问题的，所以Redis集群一般就部署3台机器，抗下每秒2万读请求是绝对没问题的。如下图所示：





（7）基于数据库主从架构做读写分离



此时数据库服务器还是存在每秒1万的请求，对于单台服务器来说压力还是过大。



但是数据库一般都支持主从架构，也就是有一个从库一直从主库同步数据过去。此时可以基于主从架构做读写分离。



也就是说，每秒大概6000写请求是进入主库，大概还有4000个读请求是在从库上去读，这样就可以把1万读写请求压力分摊到两台服务器上去。

这么分摊过后，主库每秒最多6000写请求，从库每秒最多4000读请求，基本上可以勉强把压力给抗住。如下图：


（8）总结



本文主要是探讨在千万级用户场景下的大型网站的高并发架构设计，也就是预估出了千万级用户的访问压力以及对应的后台系统为了要抗住高并发，在业务系统、缓存、数据库几个层面的架构设计以及抗高并发的分析。


MQ、CDN、静态化、分库分表、NoSQL、搜索、分布式文件系统、反向代理，



为什么我如此注重并发？



因为随着公司发展，并发量及数据量肯定会增加，高性能、高并发的问题就避免不了。而且工作中，你总是绕不开并发编程的任务，比如说，你想写个程序，一边从文件中读取数据，一边还要做实时计算.....



另外，并发编程是Java语言中最为晦涩的知识点，它涉及操作系统、内存、CPU、编程语言等多方面的基础能力，而这些知识点看上去非常的零散、独立，可实则关联性又比较强，更为考验一个程序员的内功。



甚至可以说，只要你想进大厂，并发是必须跨过的一道“坎”。



不过，因为网上学习资料非常零散，也很少有人能系统讲清楚并发，所以想掌握并发，只能靠“自学”，却往往不得要领。



说到这里，我想给你推荐一张“并发编程”全景图。是由京东资深架构师王宝令凝聚他十几年经验制成的，从三个核心问题：分工、互斥、协作，全面且系统地涵盖了Java并发编程的技术难点。



我认为，这个全景图是回到并发的源头思考来问题，根据这个思路，可以举一反三，融会贯通。



并发编程全景图



这张全景图，出自宝令老师《Java并发编程实战》专栏，我也一直在跟着学习，让我觉得很厉害的是，他把并发编程涉及到的Java内存模型、管程、多线程等关键性问题讲得通俗易懂、深入浅出，时常让你有种“原来如此”的豁然开朗。甚至即使你是初学者，也能看懂每篇内容的逻辑及要点。



而且，每篇文章下的留言也特别精彩，有些是总结笔记，有些是提问，还有一些是课后作业的回答代码，跟着大家一起查缺补漏，我也收获良多。




其实，这个专栏上新的时候，我就推荐过了。有好的学习资料，我希望可以让粉丝中想想好好并发的用户知道。特意给大伙争取了《Java并发编程实战》专栏的24小时限时福利，参团价仅79元，原价99元，立省20元。








👆👆👆

扫描上方二维码，立即参团

立省20元，限时24小时





另外，这个专栏不断有用户呼吁涨价，据运营小姐姐说，涨价时间不确定，但这个拼团价格绝对是最低了。





也截了一些留言，供你参考。






第二个推荐的硬核课程：《深入拆解Java虚拟机》，原价99，限时优惠79，立省20。



JVM也是大厂常见的面试题之一，而且如果你想进阶资深Java程序员，虚拟机必然是你要深耕的一块内容。



郑雨迪这个专栏，我看到很多Java领域大神都推荐过，比如你假笨、江南白衣、开涛等等，自己也在跟着学，确实很硬核。



我记得，这个专栏上线不到3天，专栏订阅量都已经破1W订阅了，异常火爆。目前为止，这个专栏订阅量一直稳居极客时间 top 5，现在快2.5w+订阅。大概原因，我总结了两点：

1、Java虚拟机确实是面试大题；

2、作者是郑雨迪，Oracle Labs高级研究员，专攻Graal编译器，也在研究HotSpot虚拟机项目。



既然你要学JVM，那跟着Oracle内部专家学，是我想到最高效的方式。想认真进阶Java的同学，请不要错过这次的福利，也是专栏最优惠的时候了。



雨迪从底层出发，通过揭秘 Java虚拟机的工作原理，掌握诊断手法和调优方式。通过这个专栏的学习，你将了解如何编写高效的代码，如何对Bug达到最优处理，以及如何针对自己的应用调整虚拟机的运营参数。



如何模拟超过 5 万的并发用户
程序猿DD  1周前


来源：http://t.cn/ES7KBkW



本文将从负载测试的角度，描述了做一次流畅的5万用户并发测试需要做的事情.

你可以在本文的结尾部分看到讨论的记录.

快速的步骤概要

编写你的脚本

使用JMeter进行本地测试

BlazeMeter沙箱测试

使用一个控制台和一个引擎设置Users-per-Engine的数量

设置并测试你的集合 (1个控制台和10-14 引擎)

使用 Master / Slave 特性来达成你的最大CC目标



步骤1 : 编写你的脚本
开始之前，请确定从JMeter的Apache社区jmeter.apache.org 获得了最新的版本.

你也会要下载这些附加的插件 ，因为它们可以让你的工作更轻松.

有许多方法可以获得脚本:

使用 BlazeMeter 的 Chrome 扩展 来记录你的方案

使用 JMeter HTTP(S) 测试脚本记录器 来设置一个代理，那样你就可以运行你的测试并记录下所有的东西

从头开始全部手工构建(可能是功能/QA测试)

如果你的脚本是一份记录的结果(像步骤1&2), 请牢记:

你需要改变诸如Username & Password这样的特定参数，或者你也许会想要设置一个CSV文件，有了里面的值每个用户就可以是不同的.

为了完成诸如“添加到购物车”，“登录”还有其它这样的请求，你也许要使用正则表达式，JSON路径提取器，XPath提取器，来提取诸如Token字符串，表单构建ID还有其它要素

保持你的脚本参数化，并使用配置元素，诸如默认HTTP请求，来使得在环境之间切换时你的工作更轻松.

步骤2 : 使用JMeter进行本地测试
在1个线程的1个迭代中使用查看结果树要素，调试样本，虚拟样本还有打开的日志查看器（一些JMeter的错误会在里面报告），来调试你的脚本.

遍历所有的场景(包括True 或者 False的回应) 来确保脚本行为确如预期...

在成功使用一个线程测试之后——将其提高到10分钟10到20个线程继续测试:

如果你想要每个用户独立——是那样的么?

有没有收到错误?

如果你在做一个注册过程，那就看看你的后台 - 账户是不是照你的模板创建好了? 它们是不是独立的呢?

从总结报告中，你可以看到对测试的统计 - 它们有点用么? (平均响应时间, 错误, 每秒命中率)

一旦你准备好了脚本:

通过移除任何调试和虚拟样本来清理脚本，并删除你的脚本侦听器

如果你使用了侦听器(诸如 "将响应保存到一个文件")，请确保你没有使用任何路径! , 而如果他是一个侦听器或者一个CSV数据集配置——请确保你没有使用你在本地使用的路径 - 而只要文件名(就好像跟你的脚本在同一个文件夹)

如果你使用了自己专有的JAR文件，请确保它也被上传了.

如果你使用了超过一个线程组（不是默认的那个) - 请确保在将其上传到BlazeMeter之前设置了这个值.

步骤3 : BlazeMeter沙箱测试
如果那时你的第一个测试——你应该温习一下 这篇 有关如何在BlazeMeter中创建测试的文章.

将沙箱的测试配置设置成，用户300，1个控制台, 时间50分钟.

对沙箱进行这样的配置让你可以在后台测试你的脚本，并确保上的BlazeMeter的一切都运行完好.

为此，先按下灰色的按钮: 告诉JMeter引擎我想要完全控制! - 来获得对你的测试参数的完全控制

通常你将会遇到的问题:

防火墙 - 确保你的环境对BlazeMeter的CIDR 列表 (它们会实时更新)开发，并把它们放入白名单中

确保你所有的测试文件, 比如: CSVs, JAR, JSON, User.properties 等等.. 都可以使用

确保你没有使用任何路径

如果仍然有问题，那就看看错误日志吧(你应该可以把整个日志都下载下来).

一个沙箱的配置可以是这样的:

引擎: 是能使控制台(1 个控制台 , 0 个引擎)

线程: 50-300

产能提升: 20 分钟

迭代: 一直测试下去

时间: 30-50 分钟

这可以让你在产能提升期间获得足够多的数据(以防你遇到问题) ，而你将可以对结果进行分析，以确保脚本的执行确如预期.

你应该观察下Waterfall / WebDriver 选项卡来看看请求是否正常，你不应该在这一点上出任何问题（除非你是故意的).

你应该盯着监控选项卡，观察期内存和CPU消耗 - 这对你在步骤4中尝试设置每一个引擎的用户数量.

步骤4 : 使用1个控制台和1个引擎来设置每个引擎用户的数量
现在我们可以肯定脚本能在BlazeMeter中完美运行了——我们需要计算出要多少用户放到一个引擎中.

如果你能用户沙箱中的数据来做这个决定，那就太棒了!

在这里，我会给出一种不用回头去查看沙箱测试数据就能计算出这个数的方法.

设置你的测试配置:

线程数: 500

产能提升：40 分钟

迭代: 永久

时长: 50 分钟

使用一个控制台和一个引擎.

运行测试并(通过监视选项卡)对你的测试引擎进行监视.

如果你的引擎对于75%的CPI使用率和85%的内存使用率都没有达到(一次性的峰值可以忽略) 的话:

将线程数调整到700在测试一次

提交线程的数量直到线程数达到1000或者60%的CPU或内存使用

如果你的引擎过了75%的CPU使用率或者85%的内存使用率(一次性的峰值可以忽略 :

看看你第一次达到75%的点，在那个点有多少并发用户.

在运行一次测试, 而不是提高你之前500个用户数量的产能

这一次将产能提升放到真实的测试中(5-15 分钟是一个好的开始) 并将时长设置为50分钟.

确保整个测试过程中没有超过75%的CPU使用率或者85%的内存使用率...

为安全起见，你可以把每个引擎的线程数降低10%的.

步骤5：安装并测试集群
我们现在知道了从一个引擎中我们得到了多少线程，在该章节的最后，我们将会知道一个集群能给我们提供多少用户。

一个集群是指具有一个控制台（仅有一个）和0-14个引擎的逻辑容器。

即使你可以创建一个使用超过14个引擎的测试案例——但实际上是创建了两个集群（你可以注意到控制台的数量增加了），并且克隆了你的测试案例……

每个集群具有最多14个引擎，是基于BlazeMeter自己本身的测试，以确保控制台可以控制这14台引擎对新建的大量数据处理的压力。

所以在这一步骤中，我们会用步骤4种的测试，并且仅仅修改引擎数量，将其增加到14.

将该测试按照最终测试的全部时长运行。当测试在运行时，打开监听标签，并且检验：



没有一个引擎超过CPU75%的占有率和内存85%占有率的上限；





定位你的控制台标签（你可以通过一次点击Logs Tab->Network Information，查看控制台私有IP地址来找到它的名字）——它不应该达到CPU75%占有率和内存85%占有率的上限。



如果你的控制台达到了该上限——减少引擎数量并重新运行直到控制台在该上限之下。

在这个步骤的最后，你会发现：

每个集群的用户数量；

每个集群的命中率。

查看Aggretate Table中的其他统计信息，并找到本地结果统计图来获得有关你集群吞吐量的更多信息。

步骤 6 : 使用 Master / Slave 特性来达成你的最大CC目标
我们到了最后一步了。

我们知道脚本正在运行，我们也知道一个引擎可以支持多少用户以及一个集群可以支持多少用户。

让我们做一下假设：

一个引擎支持500用户

一个集群可以用户12个引擎

我们的目标是5万用户测试

因此为了完成这些，我们需要8.3 个集群..

我们可以用8个12台引擎的集群和一个4太引擎的集群 - 但是像下面这样分散负载应该会更好：

每个集群我们用10台引擎而不是12，那么每个集群可以支持 10*500 = 5K 用户并且我们需要10个集群来支持5万用户。

这样可以得到如下好处：

不用维护两个不同的测试类型

我们可以通过简单的复制现有集群来增加5K用户（5K比6K更常见）

只要需要我们可以一直增加

现在，我们已经准备好创建最终的5万用户级别的Master / Slave测试了：

将测试的名称从"My prod test" 改为"My prod test - slave 1"。

我们回到步骤5，将高级测试属性(Advanced Test Properties)下的Standalone修改为Slave。

按保存按钮——现在我们有了一个Master和9个Slave中的一个。

返回你的 "My prod test -slave 1".

按复制按钮

接下来重复步骤1-5直到你创建了9个slave。

回到你的 "My prod test -salve 9" 并按复制按钮.

将测试的名称改为 "My prod test -Master".

将高级测试属性(Advanced Test Properties) 下的Slave改为Master。

检查我们刚才创建的所有的Slave(My prod test -salve 1..9)并按保存。

你的5万用户级别的Master-Slave测试已经准备好了。通过按master上的开始按钮来运行10个测试，每个测试5千用户。

你可以修改任意一个测试（salve或master），让它们来自不同的区域，有不同的脚本/csv/以及其他文件，使用不同的网络模拟器，不同的参数等。

你可以在一个叫“Master load results”的master报告中的一个新tab页中找到生成的聚合结果的报告，你还可以通过打开单个的报告来独立的查看每一个测试结果。



90%的Java工程师都不了解的线程池细节问题！
crossoverJie  石杉的架构笔记  5天前
公众号后台回复 “资料”

获取作者独家秘制学习资料

线程池的工作原理
首先复习下线程池的基本原理,我认为线程池它就是一个调度任务的工具。



众所周知，在初始化线程池会给定线程池的大小，假设现在我们有 1000 个线程任务需要运行，而线程池的大小为 10~20。



在真正运行任务的过程中他肯定不会创建这1000个线程同时运行，而是充分利用线程池里这 10~20 个线程来调度这1000个任务。



而这里的 10~20 个线程最后会由线程池封装为 ThreadPoolExecutor.Worker 对象，而这个 Worker 是实现了 Runnable 接口的，所以他自己本身就是一个线程。



深入分析


这里我们来做一个模拟，创建了一个核心线程、最大线程数、阻塞队列都为2的线程池。



这里假设线程池已经完成了预热，也就是线程池内部已经创建好了两个线程 Worker。



当我们往一个线程池丢一个任务会发生什么事呢？



第一步是生产者，也就是任务提供者他执行了一个 execute() 方法，本质上就是往这个内部队列里放了一个任务。


之前已经创建好了的 Worker 线程会执行一个 while 循环 ---> 不停的从这个 内部队列里获取任务。(这一步是竞争的关系，都会抢着从队列里获取任务，由这个队列内部实现了线程安全)


获取得到一个任务后，其实也就是拿到了一个 Runnable 对象(也就是 execute(Runnabletask) 这里所提交的任务)，接着执行这个 Runnable 的 run() 方法，而不是 start()。这点需要注意。后文分析原因。



结合源码来看：



从图中其实就对应了刚才提到的二三两步：

while 循环，从 getTask() 方法中一直不停的获取任务。

拿到任务后，执行它的 run() 方法。


这样一个线程就调度完毕，然后再次进入循环从队列里取任务并不断的进行调度。



再次解释之前的问题
接下来回顾一下以前提到的问题：导致一个线程没有运行的根本原因是？

在单个线程的线程池中一旦抛出了未被捕获的异常时，线程池会回收当前的线程，并创建一个新的 Worker



它也会一直不断的从队列里获取任务来执行，但由于这是一个消费线程，根本没有生产者往里边丢任务，因此它会一直 waiting 在从队列里获取任务处。



所以也就造成了线上的队列没有消费，业务线程池没有执行的问题。



结合之前的那张图来看：



这里大家问的最多的一个点是，为什么会没有生产者往里面丢任务？图中不是明明画的有一个 product 嘛？



这里确实是有些不太清楚，再次强调一次：图中的 product 是往内部队列里写消息的生产者，并不是往这个 Consumer 所在的线程池中写任务的生产者。



因为即便 Consumer 是一个单线程的线程池，它依然具有一个常规线程池所具备的所有条件：

Worker 调度线程，也就是线程池运行的线程；虽然只有一个。

内部的阻塞队列；虽然长度只有1。


再次结合图来看：



所以之前提到的【没有生产者往里边丢任务】是指右图放大后的那一块，也就是内部队列并没有其他线程往里边丢任务执行 execute() 方法。



而一旦发生未捕获的异常后， Worker1 被回收，顺带的它所调度的线程 task1（这个task1 也就是在执行一个 while 循环消费左图中的那个队列） 也会被回收掉。



新创建的 Worker2 会取代 Worker1 继续执行 while 循环从内部队列里获取任务，但此时这个队列就一直会是空的，所以也就是处于 Waiting 状态。



为什是 run() 而不是 start() ？

问题搞清楚后来想想为什么线程池在调度的时候执行的是 Runnable 的 run() 方法，而不是 start() 方法呢？



我相信大部分没有看过源码的同学心中第一个印象就应该是执行的 start() 方法；



因为不管是学校老师，还是网上大牛讲的都是只有执行了 start() 方法后操作系统才会给我们创建一个独立的线程来运行，而 run() 方法只是一个普通的方法调用。



而在线程池这个场景中却恰好就是要利用它只是一个普通方法调用。



回到我在文初中所提到的：我认为线程池它就是一个调度任务的工具。



假设这里是调用的 Runnable 的 start 方法，那会发生什么事情？



如果我们往一个核心、最大线程数为 2 的线程池里丢了 1000 个任务，那么它会额外的创建 1000 个线程，同时每个任务都是异步执行的，一下子就执行完毕了。



这样就没法做到由这两个 Worker 线程来调度这 1000 个任务，而只有当做一个同步阻塞的 run() 方法调用时才能满足这个要求。






迄今为止把同步/异步/阻塞/非阻塞/BIO/NIO/AIO讲的这么清楚的好文章
编程新说李新杰  Java团长  前天


来源：编程新说

网上有很多讲同步/异步/阻塞/非阻塞/BIO/NIO/AIO的文章，但是都没有达到我的心里预期，于是自己写一篇出来。






常规的误区


假设有一个展示用户详情的需求，分两步，先调用一个HTTP接口拿到详情数据，然后使用适合的视图展示详情数据。

如果网速很慢，代码发起一个HTTP请求后，就卡住不动了，直到十几秒后才拿到HTTP响应，然后继续往下执行。

这个时候你问别人，刚刚代码发起的这个请求是不是一个同步请求，对方一定回答是。这是对的，它确实是。

但你要问它为什么是呢？对方一定是这样回答的，“因为发起请求后，代码就卡住不动了，直到拿到响应后才可以继续往下执行”。

我相信很多人也都是这样认为的，其实这是不对的，是把因果关系搞反了：

不是因为代码卡住不动了才叫同步请求，而是因为它是同步请求所以代码才卡住不动了。

至于为什么能卡住不动，这是由操作系统和CPU决定的：

因为内核空间里的对应函数会卡住不动，造成用户空间发起的系统调用卡住不动，继而使程序里的用户代码卡住不动了。

因此卡住不动了只是同步请求的一个副作用，并不能用它来定义同步请求，那该如何定义呢？


同步和异步


所谓同步，指的是协同步调。既然叫协同，所以至少要有2个以上的事物存在。协同的结果就是：

多个事物不能同时进行，必须一个一个的来，上一个事物结束后，下一个事物才开始。

那当一个事物正在进行时，其它事物都在干嘛呢？

严格来讲这个并没有要求，但一般都是处于一种“等待”的状态，因为通常后面事物的正常进行都需要依赖前面事物的结果或前面事物正在使用的资源。

因此，可以认为，同步更希望关注的是从宏观整体来看，多个事物是一种逐个逐个的串行化关系，绝对不会出现交叉的情况。

所以，自然也不太会去关注某个瞬间某个具体事物是处于一个什么状态。

把这个理论应用的出神入化的非“排队”莫属。凡是在资源少需求多的场景下都会用到排队。

比如排队买火车票这件事：

其实售票大厅更在意的是旅客一个一个的到窗口去买票，因为一次只能卖一张票。

即使大家一窝蜂的都围上去，还是一次只能卖一张票，何必呢？挤在一起又不安全。

只是有些人素质太差，非要往上挤，售票大厅迫不得已，采用排队这种形式来达到自己的目的，即一个一个的买票。

至于每个旅客排队时的状态，是看手机呀还是说话呀，根本不用去在意。


除了这种由于资源导致的同步外，还存在一种由于逻辑上的先后顺序导致的同步。

比如，先更新代码，然后再编译，接着再打包。这些操作由于后一步要使用上一步的结果，所以只能按照这种顺序一个一个的执行。

关于同步还需知道两个小的点：

一是范围，并不需要在全局范围内都去同步，只需要在某些关键的点执行同步即可。

比如食堂只有一个卖饭窗口，肯定是同步的，一个人买完，下一个人再买。但吃饭的时候也是一个人吃完，下一个人才开始吃吗？当然不是啦。

二是粒度，并不是只有大粒度的事物才有同步，小粒度的事物也有同步。



只不过小粒度的事物同步通常是天然支持的，而大粒度的事物同步往往需要手工处理。

比如两个线程的同步就需要手工处理，但一个线程里的两个语句天然就是同步的。

所谓异步，就是步调各异。既然是各异，那就是都不相同。所以结果就是：

多个事物可以你进行你的、我进行我的，谁都不用管谁，所有的事物都在同时进行中。



一言以蔽之，同步就是多个事物不能同时开工，异步就是多个事物可以同时开工。



注：一定要去体会“多个事物”，多个线程是多个事物，多个方法是多个事物，多个语句是多个事物，多个CPU指令是多个事物。等等等等。





阻塞和非阻塞





所谓阻塞，指的是阻碍堵塞。它的本意可以理解为由于遇到了障碍而造成的动弹不得。



所谓非阻塞，自然是和阻塞相对，可以理解为由于没有遇到障碍而继续畅通无阻。

对这两个词最好的诠释就是，当今中国一大交通难题，堵车：

汽车可以正常通行时，就是非阻塞。一旦堵上了，全部趴窝，一动不动，就是阻塞。



因此阻塞关注的是不能动，非阻塞关注的是可以动。



不能动的结果就是只能等待，可以动的结果就是继续前行。

因此和阻塞搭配的词一定是等待，和非阻塞搭配的词一定是进行。

回到程序里，阻塞同样意味着停下来等待，非阻塞表明可以继续向下执行。


阻塞和等待





等待只是阻塞的一个副作用而已，表明随着时间的流逝，没有任何有意义的事物发生或进行。



阻塞的真正含义是你关心的事物由于某些原因无法继续进行，因此让你等待。但没必要干等，你可以做一些其它无关的事物，因为这并不影响你对相关事物的等待。

在堵车时，你可以干等。也可以玩手机、和别人聊天，或者打牌、甚至先去吃饭都行。因为这些事物并不影响你对堵车的等待。不过你的车必须呆在原地。

在计算机里，是没有人这么灵活的，一般在阻塞时，选在干等，因为这最容易实现，只需要挂起线程，让出CPU即可。在条件满足时，会重新调度该线程。


两两组合


所谓同步/异步，关注的是能不能同时开工。

所谓阻塞/非阻塞，关注的是能不能动。

通过推理进行组合：

同步阻塞，不能同时开工，也不能动。只有一条小道，一次只能过一辆车，可悲的是还TMD的堵上了。

同步非阻塞，不能同时开工，但可以动。只有一条小道，一次只能过一辆车，幸运的是可以正常通行。

异步阻塞，可以同时开工，但不可以动。有多条路，每条路都可以跑车，可气的是全都TMD的堵上了。

异步非阻塞，可以工时开工，也可以动。有多条路，每条路都可以跑车，很爽的是全都可以正常通行。

是不是很容易理解啊。其实它们的关注点是不同的，只要搞明白了这点，组合起来也不是事儿。

回到程序里，把它们和线程关联起来：

同步阻塞，相当于一个线程在等待。

同步非阻塞，相当于一个线程在正常运行。

异步阻塞，相当于多个线程都在等待。

异步非阻塞，相当于多个线程都在正常运行。





I/O





IO指的就是读入/写出数据的过程，和等待读入/写出数据的过程。一旦拿到数据后就变成了数据操作了，就不是IO了。

拿网络IO来说，等待的过程就是数据从网络到网卡再到内核空间。读写的过程就是内核空间和用户空间的相互拷贝。



所以IO就包括两个过程，一个是等待数据的过程，一个是读写（拷贝）数据的过程。而且还要明白，一定不能包括操作数据的过程。





阻塞IO和非阻塞IO





应用程序都是运行在用户空间的，所以它们能操作的数据也都在用户空间。按照这样子来理解，只要数据没有到达用户空间，用户线程就操作不了。



如果此时用户线程已经参与，那它一定会被阻塞在IO上。这就是常说的阻塞IO。用户线程被阻塞在等待数据上或拷贝数据上。



非阻塞IO就是用户线程不参与以上两个过程，即数据已经拷贝到用户空间后，才去通知用户线程，一上来就可以直接操作数据了。



用户线程没有因为IO的事情出现阻塞，这就是常说的非阻塞IO。





同步IO和同步阻塞IO





按照上文中对同步的理解，同步IO是指发起IO请求后，必须拿到IO的数据才可以继续执行。

按照程序的表现形式又分为两种：

在等待数据的过程中，和拷贝数据的过程中，线程都在阻塞，这就是同步阻塞IO。

在等待数据的过程中，线程采用死循环式轮询，在拷贝数据的过程中，线程在阻塞，这其实还是同步阻塞IO。



网上很多文章把第二种归为同步非阻塞IO，这肯定是错误的，它一定是阻塞IO，因为拷贝数据的过程，线程是阻塞的。

严格来讲，在IO的概念上，同步和非阻塞是不可能搭配的，因为它们是一对相悖的概念。

同步IO意味着必须拿到IO的数据，才可以继续执行。因为后续操作依赖IO数据，所以它必须是阻塞的。

非阻塞IO意味着发起IO请求后，可以继续往下执行。说明后续执行不依赖于IO数据，所以它肯定不是同步的。

因此，在IO上，同步和非阻塞是互斥的，所以不存在同步非阻塞IO。但同步非阻塞是存在的，那不叫IO，叫操作数据了。



所以，同步IO一定是阻塞IO，同步IO也就是同步阻塞IO。





异步IO和异步阻塞/非阻塞IO




按照上文中对异步的理解，异步IO是指发起IO请求后，不用拿到IO的数据就可以继续执行。



用户线程的继续执行，和操作系统准备IO数据的过程是同时进行的，因此才叫做异步IO。

按照IO数据的两个过程，又可以分为两种：

在等待数据的过程中，用户线程继续执行，在拷贝数据的过程中，线程在阻塞，这就是异步阻塞IO。

在等待数据的过程中，和拷贝数据的过程中，用户线程都在继续执行，这就是异步非阻塞IO。



第一种情况是，用户线程没有参与数据等待的过程，所以它是异步的。但用户线程参与了数据拷贝的过程，所以它又是阻塞的。合起来就是异步阻塞IO。

第二种情况是，用户线程既没有参与等待过程也没有参与拷贝过程，所以它是异步的。当它接到通知时，数据已经准备好了，它没有因为IO数据而阻塞过，所以它又是非阻塞的。合起来就是异步非阻塞IO。



PS：聪明的你或许发现了我没有提多路复用IO，因为它值得专门撰文一篇。

======================

java并发编程系列：wait/notify机制
小孩子4919  程序员小灰  今天
本文转载自公众号  我们都是小青蛙



如果一个线程从头到尾执行完也不和别的线程打交道的话，那就不会有各种安全性问题了。但是协作越来越成为社会发展的大势，一个大任务拆成若干个小任务之后，各个小任务之间可能也需要相互协作最终才能执行完整个大任务。所以各个线程在执行过程中可以相互通信，所谓通信就是指相互交换一些数据或者发送一些控制指令，比如一个线程给另一个暂停执行的线程发送一个恢复执行的指令，下边详细看都有哪些通信方式。



volatile和synchronized


可变共享变量是天然的通信媒介，也就是说一个线程如果想和另一个线程通信的话，可以修改某个在多线程间共享的变量，另一个线程通过读取这个共享变量来获取通信的内容。



由于原子性操作、内存可见性和指令重排序的存在，java提供了volatile和synchronized的同步手段来保证通信内容的正确性，假如没有这些同步手段，一个线程的写入不能被另一个线程立即观测到，那这种通信就是不靠谱的～



wait/notify机制


故事背景


也不知道是那个遭天杀的给我们学校厕所的坑里塞了个塑料瓶，导致楼道里如黄河泛滥一般，臭味熏天。更加悲催的是整个楼只有这么一个厕所，比这个更悲催的是这个厕所里只有一个坑！！！！！好吧，让我们用java来描述一下这个厕所：



public class Washroom {

    private volatile boolean isAvailable = false;    //表示厕所是否是可用的状态

    private Object lock = new Object(); //厕所门的锁

    public boolean isAvailable() {
        return isAvailable;
    }

    public void setAvailable(boolean available) {
        this.isAvailable = available;
    }

    public Object getLock() {
        return lock;
    }
}


isAvailable字段代表厕所是否可用，由于厕所损坏，默认是false的，lock字段代表这个厕所门的锁。需要注意的是isAvailable字段被volatile修饰，也就是说有一个线程修改了它的值，它可以立即对别的线程可见～



由于厕所资源宝贵，英明的学校领导立即拟定了一个修复任务：



public class RepairTask implements Runnable {

    private Washroom washroom;

    public RepairTask(Washroom washroom) {
        this.washroom = washroom;
    }

    @Override
    public void run() {

        synchronized (washroom.getLock()) {
            System.out.println("维修工 获取了厕所的锁");
            System.out.println("厕所维修中，维修厕所是一件辛苦活，需要很长时间。。。");

            try {
                Thread.sleep(5000L);    //用线程sleep表示维修的过程
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
            washroom.setAvailable(true);        //维修结束把厕所置为可用状态
            System.out.println("维修工把厕所修好了，准备释放锁了");
        }
    }
}


这个维修计划的内容就是当维修工进入厕所之后，先把门锁上，然后开始维修，维修结束之后把Washroom的isAvailable字段设置为true，以表示厕所可用。



与此同时，一群急得像热锅上的蚂蚁的家伙在厕所门前打转转，他们想做神马不用我明说了吧😏😏：



public class ShitTask implements Runnable {

    private Washroom washroom;

    private String name;

    public ShitTask(Washroom washroom, String name) {
        this.washroom = washroom;
        this.name = name;
    }

    @Override
    public void run() {
        synchronized (washroom.getLock()) {
            System.out.println(name + " 获取了厕所的锁");
            while (!washroom.isAvailable()) {
                // 一直等
            }
            System.out.println(name + " 上完了厕所");
        }
    }
}


这个ShitTask描述了上厕所的一个流程，先获取到厕所的锁，然后判断厕所是否可用，如果不可用，则在一个死循环里不断的判断厕所是否可用，直到厕所可用为止，然后上完厕所释放锁走人。



然后我们看看现实世界都发生了什么吧：



public class Test {
    public static void main(String[] args) {
        Washroom washroom = new Washroom();
        new Thread(new RepairTask(washroom), "REPAIR-THREAD").start();

        try {
            Thread.sleep(1000L);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }

        new Thread(new ShitTask(washroom, "狗哥"), "BROTHER-DOG-THREAD").start();
        new Thread(new ShitTask(washroom, "猫爷"), "GRANDPA-CAT-THREAD").start();
        new Thread(new ShitTask(washroom, "王尼妹"), "WANG-NI-MEI-THREAD").start();
    }
}


学校先让维修工进入厕所维修，然后包括狗哥、猫爷、王尼妹在内的上厕所大军就开始围着厕所打转转的旅程，我们看一下执行结果：



维修工 获取了厕所的锁
厕所维修中，维修厕所是一件辛苦活，需要很长时间。。。
维修工把厕所修好了，准备释放锁了
王尼妹 获取了厕所的锁
王尼妹 上完了厕所
猫爷 获取了厕所的锁
猫爷 上完了厕所
狗哥 获取了厕所的锁
狗哥 上完了厕所


看起来没有神马问题，但是再回头看看代码，发现有两处特别别扭的地方：



在main线程开启REPAIR-THREAD线程后，必须调用sleep方法等待一段时间才允许上厕所线程开启。



如果REPAIR-THREAD线程和其他上厕所线程一块儿开启的话，就有可能上厕所的人，比如狗哥先获取到厕所的锁，然后维修工压根儿连厕所也进不去。但是真实情况可能真的这样的，狗哥先到了厕所，然后维修工才到。不过狗哥的处理应该不是一直待在厕所里，而是先出来等着，啥时候维修工说修好了他再进去。所以这点有些别扭～



在一个上厕所的人获取到厕所的锁的时候，必须不断判断Washroom的isAvailable字段是否为true。



如果一个人进入到厕所发现厕所仍然处在不可用状态的话，那它应该在某个地方休息，啥时候维修工把厕所修好了，再叫一下等着上厕所的人就好了嘛，没必要自己不停的去检查厕所是否被修好了。



总结一下，就是一个线程在获取到锁之后，如果指定条件不满足的话，应该主动让出锁，然后到专门的等待区等待，直到某个线程完成了指定的条件，再通知一下在等待这个条件完成的线程，让它们继续执行。



如果你觉得上边这句话比较绕的话，我来给你翻译一下：当上狗哥获取到厕所门锁之后，如果厕所处于不可用状态，那就主动让出锁，然后到等待上厕所的队伍里排队`等待`，直到维修工把厕所修理好，把厕所的状态置为可用后，维修工再通知需要上厕所的人，然他们正常上厕所。


具体使用方式


为了实现这个构想，java里提出了一套叫wait/notify的机制。当一个线程获取到锁之后，如果发现条件不满足，那就主动让出锁，然后把这个线程放到一个等待队列里等待去，等到某个线程把这个条件完成后，就通知等待队列里的线程他们等待的条件满足了，可以继续运行啦！



如果不同线程有不同的等待条件肿么办，总不能都塞到同一个等待队列里吧？是的，java里规定了每一个锁都对应了一个等待队列，也就是说如果一个线程在获取到锁之后发现某个条件不满足，就主动让出锁然后把这个线程放到与它获取到的锁对应的那个等待队列里，另一个线程在完成对应条件时需要获取同一个锁，在条件完成后通知它获取的锁对应的等待队列。这个过程意味着锁和等待队列建立了一对一关联。



怎么让出锁并且把线程放到与锁关联的等待队列中以及怎么通知等待队列中的线程相关条件已经完成java已经为我们规定好了。我们知道，锁其实就是个对象而已，在所有对象的老祖宗类Object中定义了这么几个方法：



public final void wait() throws InterruptedException
public final void wait(long timeout) throws InterruptedException
public final void wait(long timeout, int nanos) throws InterruptedException

public final void notify();
public final void notifyAll();

各个方法的详细说明如下：



方法名	说明
wait()	在线程获取到锁后，调用锁对象的本方法，线程释放锁并且把该线程放置到与锁对象关联的等待队列
wait(long timeout)	与wait()方法相似，只不过等待指定的毫秒数，如果超过指定时间则自动把该线程从等待队列中移出
wait(long timeout, int nanos)	与上边的一样，只不过超时时间粒度更小，即指定的毫秒数加纳秒数
notify()	通知一个在与该锁对象关联的等待队列的线程，使它从wait()方法中返回继续往下执行
notifyAll()	与上边的类似，只不过通知该等待队列中的所有线程


了解了这些方法的意思以后我们再来改写一下ShitTask：



public class ShitTask implements Runnable {

    // ... 为节省篇幅，省略相关字段和构造方法

    @Override
    public void run() {
        synchronized (washroom.getLock()) {
            System.out.println(name + " 获取了厕所的锁");
            while (!washroom.isAvailable()) {
                try {
                    washroom.getLock().wait();  //调用锁对象的wait()方法，让出锁，并把当前线程放到与锁关联的等待队列
                } catch (InterruptedException e) {
                    throw new RuntimeException(e);
                }
            }
            System.out.println(name + " 上完了厕所");
        }
    }
}


看，原来我们在判断厕所是否可用的死循环里加了这么一段代码：



washroom.getLock().wait();


这段代码的意思就是让出厕所的锁，并且把当前线程放到与厕所的锁相关联的等待队列里。



然后我们也需要修改一下维修任务：



public class RepairTask implements Runnable {

    // ... 为节省篇幅，省略相关字段和构造方法

    @Override
    public void run() {

        synchronized (washroom.getLock()) {
            System.out.println("维修工 获取了厕所的锁");
            System.out.println("厕所维修中，维修厕所是一件辛苦活，需要很长时间。。。");

            try {
                Thread.sleep(5000L);    //用线程sleep表示维修的过程
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
            washroom.setAvailable(true);    //维修结束把厕所置为可用状态

            washroom.getLock().notifyAll(); //通知所有在与锁对象关联的等待队列里的线程，它们可以继续执行了
            System.out.println("维修工把厕所修好了，准备释放锁了");
        }
    }
}


大家可以看出来，我们在维修结束后加了这么一行代码：



washroom.getLock().notifyAll();


这个代码表示将通知所有在与锁对象关联的等待队列里的线程，它们可以继续执行了。



在使用java的wait/notify机制修改了ShitTask和RepairTask后，我们在复原一下整个现实场景：



public class Test {
    public static void main(String[] args) {
        Washroom washroom = new Washroom();
        new Thread(new ShitTask(washroom, "狗哥"), "BROTHER-DOG-THREAD").start();
        new Thread(new ShitTask(washroom, "猫爷"), "GRANDPA-CAT-THREAD").start();
        new Thread(new ShitTask(washroom, "王尼妹"), "WANG-NI-MEI-THREAD").start();

        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }

        new Thread(new RepairTask(washroom), "REPAIR-THREAD").start();
    }
}


在这个场景中，我们可以刻意让着急上厕所的先到达了厕所，维修工最后抵达厕所，来看一下加了wait/notify机制的代码的执行结果是：



狗哥 获取了厕所的锁
猫爷 获取了厕所的锁
王尼妹 获取了厕所的锁
维修工 获取了厕所的锁
厕所维修中，维修厕所是一件辛苦活，需要很长时间。。。
维修工把厕所修好了，准备释放锁了
王尼妹 上完了厕所
猫爷 上完了厕所
狗哥 上完了厕所


从执行结果可以看出来，狗哥、猫爷、王尼妹虽然先到达了厕所并且获取到锁，但是由于厕所处于不可用状态，所以都先调用wait()方法让出了自己获得的锁，然后躲到与这个锁关联的等待队列里，直到维修工修完了厕所，通知了在等待队列中的狗哥、猫爷、王尼妹，他们才又开始继续执行上厕所的程序～



通用模式


经过上边的厕所案例，大家应该对wait/notify机制有了大致了解，下边我们总结一下这个机制的通用模式。首先看一下等待线程的通用模式：

获取对象锁。

如果某个条件不满足的话，调用锁对象的wait方法，被通知后仍要检查条件是否满足。

条件满足则继续执行代码。



通用的代码如下：



synchronized (对象) {
    处理逻辑（可选）
    while(条件不满足) {
        对象.wait();
    }
    处理逻辑（可选）
}


除了判断条件是否满足和调用wait方法以外的代码，其他的处理逻辑是可选的。



下边再来看通知线程的通用模式：

获得对象的锁。

完成条件。

通知在等待队列中的等待线程。



synchronized (对象) {
    完成条件
    对象.notifyAll();、
}
小贴士：别忘了同步方法也是使用锁的喔，静态同步方法的锁对象是该类的`Class对象`，成员同步方法的锁对象是`this对象`。所以如果没有刻意强调，下边所说的同步代码块也包含同步方法。



了解了wait/notify的通用模式之后，使用的时候需要特别小心，需要注意下边这些方面：



必须在同步代码块中调用wait、 notify或者notifyAll方法。



有的童鞋会有疑问，为啥wait/notify机制的这些方法必须都放在同步代码块中才能调用呢？wait方法的意思只是让当前线程停止执行，把当前线程放在等待队列里，notify方法的意思只是从等待队列里移除一个线程而已，跟加锁有什么关系？



答：因为wait方法是运行在等待线程里的，notify或者notifyAll是运行在通知线程里的。而执行wait方法前需要判断一下某个条件是否满足，如果不满足才会执行wait方法，这是一个先检查后执行的操作，不是一个原子性操作，所以如果不加锁的话，在多线程环境下等待线程和通知线程的执行顺序可能是这样的：


也就是说当等待线程已经判断条件不满足，正要执行wait方法，此时通知线程抢先把条件完成并且调用了notify方法，之后等待线程才执行到wait方法，这会导致等待线程永远停留在等待队列而没有人再去notify它。所以等待线程中的判断条件是否满足、调用wait方法和通知线程中完成条件、调用notify方法都应该是原子性操作，彼此之间是互斥的，所以用同一个锁来对这两个原子性操作进行同步，从而避免出现等待线程永久等待的尴尬局面。



如果不在同步代码块中调用wait、notify或者notifyAll方法，也就是说没有获取锁就调用wait方法，就像这样：



对象.wait();


是会抛出IllegalMonitorStateException异常的。



在同步代码块中，必须调用获取的锁对象的wait、 notify或者notifyAll方法。



也就是说不能随便调用一个对象的wait、notify或者notifyAll方法。比如等待线程中的代码是这样的：




synchronized (对象1) {
    while(条件不满足) {
        对象2.wait();    //随便调用一个对象的wait方法
    }
}


通知线程中的代码是这样的：





synchronized (对象1) {
    完成条件
    对象2.notifyAll();
}


对于代码对象2.wait()，表示让出当前线程持有的对象2的锁，而当前线程持有的是对象1的锁，所以这么写是错误的，也会抛出IllegalMonitorStateException异常的。意思就是如果当前线程不持有某个对象的锁，那它就不能调用该对象的wait方法来让出该锁。所以如果想让等待线程让出当前持有的锁，只能调用对象1.wait()。然后这个线程就被放置到与对象1相关联的等待队列中，在通知线程中只能调用对象1.notifyAll()来通知这些等待的线程了。



在等待线程判断条件是否满足时，应该使用while，而不是if。



也就是说在判断条件是否满足的时候要使用while：


while(条件不满足) { //正确✅
    对象.wait();
}


而不是使用if：





if(条件不满足) { //错误❌
    对象.wait();
}


这个是因为在多线程条件下，可能在一个线程调用notify之后立即又有一个线程把条件改成了不满足的状态，比如在维修工把厕所修好之后通知大家上厕所吧的瞬间，有一个小屁孩以迅雷不及掩耳之势又给厕所坑里塞了个瓶子，厕所又被置为不可用状态，等待上厕所的还是需要再判断一下条件是否满足才能继续执行。



在调用完锁对象的notify或者notifyAll方法后，等待线程并不会立即从wait()方法返回，需要调用notify()或者notifyAll()的线程释放锁之后，等待线程才从wait()返回继续执行。






也就是说如果通知线程在调用完锁对象的notify或者notifyAll方法后还有需要执行的代码，就像这样：



synchronized (对象) {
    完成条件
    对象.notifyAll();
    ... 通知后的处理逻辑
}


需要把通知后的处理逻辑执行完成后，把锁释放掉，其他线程才可以从wait状态恢复过来，重新竞争锁来执行代码。比方说在维修工修好厕所并通知了等待上厕所的人们之后，他还没有从厕所出来，而是在厕所的墙上写了 "XXX到此一游"之类的话之后才从厕所出来，从厕所出来才代表着释放了锁，狗哥、猫爷、王尼妹才开始争抢进入厕所的机会。



notify方法只会将等待队列中的一个线程移出，而notifyAll方法会将等待队列中的所有线程移出。



大家可以把上边代码中的notifyAll方法替换称notify方法，看看执行结果～


wait和sleep的区别


眼尖的小伙伴肯定发现，wait和sleep这两个方法都可以让线程暂停执行，而且都有InterruptedException的异常说明，那么它们的区别是啥呢？



wait是Object的成员方法，而sleep是Thread的静态方法。



只要是作为锁的对象都可以在同步代码块中调用自己的wait方法，sleep是Thread的静态方法，表示的是让当前线程休眠指定的时间。



调用wait方法需要先获得锁，而调用sleep方法是不需要的。



再一次强调，一定要在同步代码块中调用锁对象的wait方法，前提是要获得锁！前提是要获得锁！前提是要获得锁！而sleep方法随时调用～



调用wait方法的线程需要用notify来唤醒，而sleep必须设置超时值。



线程在调用wait方法之后会先释放锁，而sleep不会释放锁。



这一点可能是最重要的一点不同点了吧，狗哥、猫爷、王尼妹这些线程一开始是获取到厕所的锁了，但是调用了wait方法之后主动把锁让出，从而让维修工得以进入厕所维修。如果狗哥在发现厕所是不可用的条件时选择调用sleep方法的话，线程是不会释放锁的，也就是说维修工无法获得厕所的锁，也就修不了厕所了～ 大家一定要谨记这一点啊！



总结


线程间需要通过通信才能协作解决某个复杂的问题。



可变共享变量是天然的通信媒介，但是使用的时候一定要保证线程安全性，通常使用volatile变量或synchronized来保证线程安全性。



一个线程在获取到锁之后，如果指定条件不满足的话，应该主动让出锁，然后到专门的等待区等待，直到某个线程完成了指定的条件，再通知一下在等待这个条件完成的线程，让它们继续执行。这个机制就是wait/notify机制。



等待线程的通用模式：





synchronized (对象) {
    处理逻辑（可选）
    while(条件不满足) {
        对象.wait();
    }
    处理逻辑（可选）
}




可以分为下边几个步骤：



获取对象锁。

如果某个条件不满足的话，调用锁对象的wait方法，被通知后仍要检查条件是否满足。

条件满足则继续执行代码。







通知线程的通用模式：





synchronized (对象) {
    完成条件
    对象.notifyAll();、
}




可以分为下边几个步骤：

获得对象的锁。

完成条件。

通知在等待队列中的等待线程。



wait和sleep的区别

wait是Object的成员方法，而sleep是Thread的静态方法。

调用wait方法需要先获得锁，而调用sleep方法是不需要的。

调用wait方法的线程需要用notify来唤醒，而sleep必须设置超时值。

线程在调用wait方法之后会先释放锁，而sleep不会释放锁。






优雅的使用 ThreadLocal
码匠笔记  JAVA葵花宝典  4月18日
来源：码匠笔记
前言
在我们日常 Web 开发中难免遇到需要把一个参数层层的传递到最内层，然后中间层根本不需要使用这个参数，或者是仅仅在特定的工具类中使用，这样我们完全没有必要在每一个方法里面都传递这样一个 通用的参数。如果有一个办法能够在任何一个类里面想用的时候直接拿来使用就太好了。Java的 Web项目大部分都是基于 Tomcat，每次访问都是一个新的线程，这样让我们联想到了 ThreadLocal，每一个线程都独享一个 ThreadLocal，在接收请求的时候 set特定内容，在需要的时候 get这个值。下面我们就进入主题。

ThreadLocal
维持线程封闭性的一种更规范的方法就是使用 ThreadLocal，这个类能使线程中的某个值与保存的值的对象关联起来。ThreadLocal提供 get和 set等接口或方法，这些方法为每一个使用这个变量的线程都存有一份独立的副本，因此 get总是返回由当前线程在调用 set时设置的最新值。ThreadLocal有如下方法

public
 T get() { }

public

void
 set(T value) { }

public

void
 remove() { }

protected
 T initialValue() { }

get()方法是用来获取 ThreadLocal在当前线程中保存的变量副本
set()用来设置当前线程中变量的副本
remove()用来移除当前线程中变量的副本
initialValue()是一个 protected方法，一般是用来在使用时进行重写的，如果在没有set的时候就调用 get，会调用 initialValue方法初始化内容。为了使用的更放心，我们简单的看一下具体的实现:

set方法
public

void
 set(T value) {


Thread
 t =
Thread
.currentThread();


ThreadLocalMap
 map = getMap(t);


if
 (map !=
null
)

            map.set(
this
, value);


else

            createMap(t, value);

    }

set方法会获取当前的线程，通过当前线程获取 ThreadLocalMap对象。然后把需要存储的值放到这个 map里面。如果没有就调用 createMap创建对象。

getMap方法

ThreadLocalMap
 getMap(
Thread
 t) {


return
 t.threadLocals;

    }

getMap方法直接返回当前 Thread的 threadLocals变量，这样说明了之所以说 ThreadLocal是 线程局部变量就是因为它只是通过 ThreadLocal把 变量存在了 Thread本身而已。

createMap方法
void
 createMap(
Thread
 t, T firstValue) {

        t.threadLocals =
new

ThreadLocalMap
(
this
, firstValue);

    }

在 set的时候如果不存在 threadLocals，直接创建对象。由上看出，放入 map的 key是当前的 ThreadLocal， value是需要存放的内容，所以我们设置属性的时候需要注意存放和获取的是一个 ThreadLocal。

get方法
public
 T get() {


Thread
 t =
Thread
.currentThread();


ThreadLocalMap
 map = getMap(t);


if
 (map !=
null
) {


ThreadLocalMap
.
Entry
 e = map.getEntry(
this
);


if
 (e !=
null
)


return
 (T)e.value;

        }


return
 setInitialValue();

    }

get方法就比较简单，获取当前线程，尝试获取当前线程里面的 threadLocals，如果没有获取到就调用 setInitialValue方法， setInitialValue基本和 set是一样的，就不累累述了。

场景
本文应用 ThreadLocal的场景：在调用API接口的时候传递了一些公共参数，这些公共参数携带了一些设备信息，服务端接口根据不同的信息组装不同的格式数据返回给客户端。假定服务器端需要通过设备类型(device)来下发下载地址，当然接口也有同样的其他逻辑，我们只要在返回数据的时候判断好是什么类型的客户端就好了。如下:

场景一
请求

GET api/users?device=android

返回

    {

        user : {

        },

        link :
"https://play.google.com/store/apps/details?id=***"

    }

场景二
请求

GET api/users?device=ios

返回

    {

        user : {

        },

        link :
"https://itunes.apple.com/us/app/**"

    }

实现
首先准备一个 BaseSigntureRequest类用来存放公共参数

public

class

BaseSignatureRequest
 {


private

String
 device;



public

String
 getDevice() {


return
 device;

    }



public

void
 setDevice(
String
 device) {


this
.device = device;

    }

}

然后准备一个 static的 ThreadLocal类用来存放 ThreadLocal，以便存储和获取时候的 ThreadLocal一致。

public

class

ThreadLocalCache
 {


public

static

ThreadLocal
<
BaseSignatureRequest
>

        baseSignatureRequestThreadLocal =
new

ThreadLocal
<>();

}

然后编写一个 Interceptor，在请求的时候获取 device参数，存入当前线程的 ThreadLocal中。这里需要注意的是，重写了 afterCompletion方法，当请求结束的时候把 ThreadLocal remove，移除不必须要键值对。

public

class

ParameterInterceptor

implements

HandlerInterceptor
 {


@Override


public

boolean
 preHandle(
HttpServletRequest
 request,
HttpServletResponse
 response,


Object
 handler)
throws

Exception
 {


String
 device = request.getParameter(
"device"
);


BaseSignatureRequest
 baseSignatureRequest =
new

BaseSignatureRequest
();

        baseSignatureRequest.setDevice(device);


ThreadLocalCache
.baseSignatureRequestThreadLocal.set(baseSignatureRequest);


return

true
;

    }



@Override


public

void
 afterCompletion(
HttpServletRequest
 request,
HttpServletResponse
 response,


Object
 handler,
Exception
 ex)
throws

Exception
 {


ThreadLocalCache
.baseSignatureRequestThreadLocal.remove();

    }



@Override


public

void
 postHandle(
HttpServletRequest
 httpServletRequest,


HttpServletResponse
 httpServletResponse,


Object
 o,
ModelAndView
 modelAndView)
throws

Exception
 {


    }

}

当然需要在 spring里面配置 interceptor


<mvc:interceptors>


<mvc:interceptor>


<mvc:mapping

path
=
"/api/**"
/>


<bean

class
=
"life.majiang.ParameterInterceptor"
></bean>


</mvc:interceptor>


</mvc:interceptors>

最后在 Converter里面转换实体的时候直接使用即可，这样就大功告成了。

public

class

UserConverter
 {


public

static

ResultDO
 toDO(
User
 user) {


ResultDO
 resultDO =
new

ResultDO
();

        resultDO.setUser(user);


BaseSignatureRequest
 baseSignatureRequest =
ThreadLocalCache
.baseSignatureRequestThreadLocal.get();


String
 device = baseSignatureRequest.getDevice();


if
 (
StringUtils
.equals(device,
"ios"
)) {

            resultDO.setLink(
"https://itunes.apple.com/us/app/**"
);

        }
else
 {

            resultDO.setLink(
"https://play.google.com/store/apps/details?id=***"
);

        }


return
 resultDO;

    }

总结
这种机制很方便，因为他避免了在调用每一个方法时都要传递执行上下文信息，合理的使用 ThreadLocal可以起到事倍功半的效果，但是需要避免滥用，例如将所有的全局变量作为 ThreadLocal对象， ThreadLocal类似全局变量，他能降低代码的可重用性，并在类之间引入隐含的耦合性，所以再使用前需要格外小心。

====================================================

面试官：如何模拟超过 5 万的并发用户?

来自：http://t.cn/ES7KBkW

本文将从负载测试的角度，描述了做一次流畅的5万用户并发测试需要做的事情.

你可以在本文的结尾部分看到讨论的记录.

快速的步骤概要

编写你的脚本

使用JMeter进行本地测试

BlazeMeter沙箱测试

使用一个控制台和一个引擎设置Users-per-Engine的数量

设置并测试你的集合 (1个控制台和10-14 引擎)

使用 Master / Slave 特性来达成你的最大CC目标



步骤1 : 编写你的脚本
开始之前，请确定从JMeter的Apache社区jmeter.apache.org 获得了最新的版本.

你也会要下载这些附加的插件 ，因为它们可以让你的工作更轻松.

有许多方法可以获得脚本:

使用 BlazeMeter 的 Chrome 扩展 来记录你的方案

使用 JMeter HTTP(S) 测试脚本记录器 来设置一个代理，那样你就可以运行你的测试并记录下所有的东西

从头开始全部手工构建(可能是功能/QA测试)

如果你的脚本是一份记录的结果(像步骤1&2), 请牢记:

你需要改变诸如Username & Password这样的特定参数，或者你也许会想要设置一个CSV文件，有了里面的值每个用户就可以是不同的.

为了完成诸如“添加到购物车”，“登录”还有其它这样的请求，你也许要使用正则表达式，JSON路径提取器，XPath提取器，来提取诸如Token字符串，表单构建ID还有其它要素

保持你的脚本参数化，并使用配置元素，诸如默认HTTP请求，来使得在环境之间切换时你的工作更轻松.

步骤2 : 使用JMeter进行本地测试
在1个线程的1个迭代中使用查看结果树要素，调试样本，虚拟样本还有打开的日志查看器（一些JMeter的错误会在里面报告），来调试你的脚本.

遍历所有的场景(包括True 或者 False的回应) 来确保脚本行为确如预期...

在成功使用一个线程测试之后——将其提高到10分钟10到20个线程继续测试:

如果你想要每个用户独立——是那样的么?

有没有收到错误?

如果你在做一个注册过程，那就看看你的后台 - 账户是不是照你的模板创建好了? 它们是不是独立的呢?

从总结报告中，你可以看到对测试的统计 - 它们有点用么? (平均响应时间, 错误, 每秒命中率)

一旦你准备好了脚本:

通过移除任何调试和虚拟样本来清理脚本，并删除你的脚本侦听器

如果你使用了侦听器(诸如 "将响应保存到一个文件")，请确保你没有使用任何路径! , 而如果他是一个侦听器或者一个CSV数据集配置——请确保你没有使用你在本地使用的路径 - 而只要文件名(就好像跟你的脚本在同一个文件夹)

如果你使用了自己专有的JAR文件，请确保它也被上传了.

如果你使用了超过一个线程组（不是默认的那个) - 请确保在将其上传到BlazeMeter之前设置了这个值.

步骤3 : BlazeMeter沙箱测试
如果那时你的第一个测试——你应该温习一下 这篇 有关如何在BlazeMeter中创建测试的文章.

将沙箱的测试配置设置成，用户300，1个控制台, 时间50分钟.

对沙箱进行这样的配置让你可以在后台测试你的脚本，并确保上的BlazeMeter的一切都运行完好.

为此，先按下灰色的按钮: 告诉JMeter引擎我想要完全控制! - 来获得对你的测试参数的完全控制

通常你将会遇到的问题:

防火墙 - 确保你的环境对BlazeMeter的CIDR 列表 (它们会实时更新)开发，并把它们放入白名单中

确保你所有的测试文件, 比如: CSVs, JAR, JSON, User.properties 等等.. 都可以使用

确保你没有使用任何路径

如果仍然有问题，那就看看错误日志吧(你应该可以把整个日志都下载下来).

一个沙箱的配置可以是这样的:

引擎: 是能使控制台(1 个控制台 , 0 个引擎)

线程: 50-300

产能提升: 20 分钟

迭代: 一直测试下去

时间: 30-50 分钟

这可以让你在产能提升期间获得足够多的数据(以防你遇到问题) ，而你将可以对结果进行分析，以确保脚本的执行确如预期.

你应该观察下Waterfall / WebDriver 选项卡来看看请求是否正常，你不应该在这一点上出任何问题（除非你是故意的).

你应该盯着监控选项卡，观察期内存和CPU消耗 - 这对你在步骤4中尝试设置每一个引擎的用户数量.

步骤4 : 使用1个控制台和1个引擎来设置每个引擎用户的数量
现在我们可以肯定脚本能在BlazeMeter中完美运行了——我们需要计算出要多少用户放到一个引擎中.

如果你能用户沙箱中的数据来做这个决定，那就太棒了!

在这里，我会给出一种不用回头去查看沙箱测试数据就能计算出这个数的方法.

设置你的测试配置:

线程数: 500

产能提升：40 分钟

迭代: 永久

时长: 50 分钟

使用一个控制台和一个引擎.

运行测试并(通过监视选项卡)对你的测试引擎进行监视.

如果你的引擎对于75%的CPI使用率和85%的内存使用率都没有达到(一次性的峰值可以忽略) 的话:

将线程数调整到700在测试一次

提交线程的数量直到线程数达到1000或者60%的CPU或内存使用

如果你的引擎过了75%的CPU使用率或者85%的内存使用率(一次性的峰值可以忽略 :

看看你第一次达到75%的点，在那个点有多少并发用户.

在运行一次测试, 而不是提高你之前500个用户数量的产能

这一次将产能提升放到真实的测试中(5-15 分钟是一个好的开始) 并将时长设置为50分钟.

确保整个测试过程中没有超过75%的CPU使用率或者85%的内存使用率...

为安全起见，你可以把每个引擎的线程数降低10%的.

步骤5：安装并测试集群
我们现在知道了从一个引擎中我们得到了多少线程，在该章节的最后，我们将会知道一个集群能给我们提供多少用户。

一个集群是指具有一个控制台（仅有一个）和0-14个引擎的逻辑容器。

即使你可以创建一个使用超过14个引擎的测试案例——但实际上是创建了两个集群（你可以注意到控制台的数量增加了），并且克隆了你的测试案例……

每个集群具有最多14个引擎，是基于BlazeMeter自己本身的测试，以确保控制台可以控制这14台引擎对新建的大量数据处理的压力。

所以在这一步骤中，我们会用步骤4种的测试，并且仅仅修改引擎数量，将其增加到14.

将该测试按照最终测试的全部时长运行。当测试在运行时，打开监听标签，并且检验：

1，没有一个引擎超过CPU75%的占有率和内存85%占有率的上限；

2，定位你的控制台标签（你可以通过一次点击Logs Tab->Network Information，查看控制台私有IP地址来找到它的名字）——它不应该达到CPU75%占有率和内存85%占有率的上限。

如果你的控制台达到了该上限——减少引擎数量并重新运行直到控制台在该上限之下。

在这个步骤的最后，你会发现：

每个集群的用户数量；

每个集群的命中率。

查看Aggretate Table中的其他统计信息，并找到本地结果统计图来获得有关你集群吞吐量的更多信息。

步骤 6 : 使用 Master / Slave 特性来达成你的最大CC目标
我们到了最后一步了。

我们知道脚本正在运行，我们也知道一个引擎可以支持多少用户以及一个集群可以支持多少用户。

让我们做一下假设：

一个引擎支持500用户

一个集群可以用户12个引擎

我们的目标是5万用户测试

因此为了完成这些，我们需要8.3 个集群..

我们可以用8个12台引擎的集群和一个4太引擎的集群 - 但是像下面这样分散负载应该会更好：

每个集群我们用10台引擎而不是12，那么每个集群可以支持 10*500 = 5K 用户并且我们需要10个集群来支持5万用户。

这样可以得到如下好处：

不用维护两个不同的测试类型

我们可以通过简单的复制现有集群来增加5K用户（5K比6K更常见）

只要需要我们可以一直增加

现在，我们已经准备好创建最终的5万用户级别的Master / Slave测试了：

将测试的名称从"My prod test" 改为"My prod test - slave 1"。

我们回到步骤5，将高级测试属性(Advanced Test Properties)下的Standalone修改为Slave。

按保存按钮——现在我们有了一个Master和9个Slave中的一个。

返回你的 "My prod test -slave 1".

接下来重复步骤1-5直到你创建了9个slave。

回到你的 "My prod test -salve 9" 并按复制按钮.

将测试的名称改为 "My prod test -Master".

将高级测试属性(Advanced Test Properties) 下的Slave改为Master。

检查我们刚才创建的所有的Slave(My prod test -salve 1..9)并按保存。

你的5万用户级别的Master-Slave测试已经准备好了。通过按master上的开始按钮来运行10个测试，每个测试5千用户。

你可以修改任意一个测试（salve或master），让它们来自不同的区域，有不同的脚本/csv/以及其他文件，使用不同的网络模拟器，不同的参数等。

你可以在一个叫“Master load results”的master报告中的一个新tab页中找到生成的聚合结果的报告，你还可以通过打开单个的报告来独立的查看每一个测试结果

==================

技术经理：求求你，别再乱改数据库连接池的大小了！

犬小哈  JAVA葵花宝典  昨天

文章翻译整理自: https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing

如何正确设置数据库连接池大小

目录
一、笔者前言

二、正菜开始

三、假设你的服务有1万并发的访问

四、为啥有这种效果?

五、其他应该考虑到的因素

六、连接数计算公式

七、结论：你需要的是一个小连接池，和一个等待连接的线程队列

八、额外需要注意的点

一、前言
基本上来说，大部分项目都需要跟数据库做交互，那么，数据库连接池的大小设置成多大合适呢？

一些开发老鸟可能还会告诉你：没关系，尽量设置的大些，比如设置成 200，这样数据库性能会高些，吞吐量也会大些！

你也许会点头称是，真的是这样吗？看完这篇文章，也许会颠覆你的认知哦！

你不要骗我

二、正菜开始

可以很直接的说，关于数据库连接池大小的设置，每个开发者都可能在一环节掉进坑里，事实上呢，大部分程序员可能都会依靠自己的直觉去设置它的大小，设置成 100 ？思量许久后，自顾自想，应该差不多吧？

三、假设你的服务有1万并发的访问
不妨意淫一下，你手里有个网站，并发压力虽然还没到 Facebook 那个级别，但是呢？也有个1万上下的并发量！也就是说差不多2万左右的 TPS。

那么问题来了！这个网站的数据库连接池应该设置成多大合适呢？

其实这个问法本身就是有问题的，我们需要反过来问，正确问法应该是：

“这个网站的数据库连接池应该设置成多小合适呢？”

PS: 这里有一个 Oracle 性能小组发布的简短视频，链接地址为 http://www.dailymotion.com/video/x2s8uec，友情提示，需要科学上网才能访问哦！

oracle性能测试视频

口述一下，视频中对 Oracle 数据库进行了压力测试，模拟 9600 个并发线程来操作数据库，每两次数据库操作之间 sleep 550ms，注意，视频中刚开始设置的线程池大小为 2048。

让我们来看看数据库连接池的大小为 2048 性能测试结果的鬼样子：

每个请求要在连接池队列里等待 33ms，获得连接之后，执行SQL需要耗时77ms, CPU 消耗维持在 95% 左右；

接下来，我们将连接池的大小改小点，设置成 1024，其他测试参数不变，结果咋样？

"这里，获取连接等待时长基本不变，但是 SQL 的执行耗时降低了！"

哎呦，有长进哦！

接下来，我们再设置小些，连接池的大小降低到 96，并发数等其他参数不变，看看结果如何：

每个请求在连接池队列中的平均等待时间为 1ms, SQL 执行耗时为 2ms.

我去！什么鬼？

我们没调整任何东西，仅仅只是将数据库连接池的大小降低了，这样，就能把之前平均 100ms 响应时间缩短到了 3ms。吞吐量指数级上升啊！


四、为啥有这种效果?

我们不妨想一下，为啥 Nginx 内部仅仅使用了 4 个线程，其性能就大大超越了 100 个进程的 Apache HTTPD 呢？追究其原因的话，回想一下计算机科学的基础知识，答案其实非常明显。

要知道，即使是单核 CPU 的计算机也能“同时”运行着数百个线程。但我们其实都知道，这只不过是操作系统快速切换时间片，跟我们玩的一个小把戏罢了。

一核 CPU同一时刻只能执行一个线程，然后操作系统切换上下文，CPU 核心快速调度，执行另一个线程的代码，不停反复，给我们造成了所有进程同时运行假象。

其实，在一核 CPU 的机器上，顺序执行A和B永远比通过时间分片切换“同时”执行A和B要快，


一旦线程的数量超过了 CPU 核心的数量，再增加线程数系统就只会更慢，而不是更快，因为这里涉及到上下文切换耗费的额外的性能。

五、其他应该考虑到的因素

上小节中说到了主要原因，但其实没有这么简单，我们还需要考虑到一些其他的因素。

当我们在寻找数据库的性能瓶颈时，大致可归为三类：

CPU

磁盘 IO

网络 IO

也许你会说，还有内存这一因素？内存的确是需要考虑的，但是比起磁盘IO和网络IO，稍显微不足道，这里就不加了。

假设我们不考虑磁盘 IO 和网络 IO，就很好定论了，在一个 8 核的服务器上，数据库连接数/线程数设置为 8 能够提供最优的性能，如果再增加连接数，反而会因为上下文切换导致性能下降。

大家都知道，数据库通常把数据存储在磁盘上，而磁盘呢，通常是由一些旋转着的金属碟片和一个装在步进马达上的读写头组成的。读/写头同一时刻只能出现在一个位置，当它需要再次执行读写操作时，它必须“寻址”到另外一个位置才能完成任务。所以呢？这里就有了寻址的耗时，此外还有旋转耗时，读写头需要等待磁盘碟片上的目标数据“旋转到位”才能进行读写操作。使用缓存当然是能够提升性能的，但上述原理仍然适用。

在这段（"I/O等待"）时间内，线程是处于“阻塞”等待状态，也就是说没干啥正事！此时操作系统可以将这个空闲的CPU 核心用于服务其他线程。

这里我们可以总结一下，当你的线程处理的是 I/O 密集型业务时，便可以让线程/连接数设置的比 CPU核心大一些，这样就能够在同样的时间内，完成更多的工作，提升吞吐量。

那么问题又来了？

大小设置成多少合适呢？

这要取决于磁盘，如果你使用的是 SSD 固态硬盘，它不需要寻址，也不需要旋转碟片。打住打住！！！你千万可别理所当然的认为：“既然SSD速度更快，我们把线程数的大小设置的大些吧！！”

结论正好相反！无需寻址和没有旋回耗时的确意味着更少的阻塞，所以更少的线程（更接近于CPU核心数）会发挥出更高的性能。只有当阻塞密集时，更多的线程数才能发挥出更好的性能。

上面我们已经说过了磁盘 IO, 接下来我们谈谈网络 IO！

网络 IO 其实也是非常相似的。通过以太网接口读写数据时也会造成阻塞，10G带宽会比1G带宽的阻塞耗时少一些，而 1G 带宽又会比 100M 带宽的阻塞少一些。通常情况下，我们把网络 IO 放在第三顺位来考虑，然而有些人会在性能计算中忽略网络 IO 带来的影响。

PostgreSQL的benchmark数据

上图是 PostgreSQL 的基准性能测试数据，从图中我们可以看到，TPS 在连接数达到 50 时开始变缓。回过头来想下，在上面 Oracle 的性能测试视频中，测试人员们将连接数从 2048 降到了 96，实际上 96 还是太高了，除非你的服务器 CPU 核心数有 16 或 32。

六、连接数计算公式
下面公式由 PostgreSQL 提供，不过底层原理是不变的，它适用于市面上绝大部分数据库产品。还有，你应该模拟预期的访问量，并通过下面的公式先设置一个偏合理的值，然后在实际的测试中，通过微调，来寻找最合适的连接数大小。

连接数 = ((核心数 * 2) + 有效磁盘数)

核心数不应包含超线程(hyper thread)，即使打开了超线程也是如此，如果热点数据全被缓存了，那么有效磁盘数实际是0，随着缓存命中率的下降，有效磁盘数也逐渐趋近于实际的磁盘数。另外需要注意，这一公式作用于SSD 的效果如何，尚未明了。

好了，按照这个公式，如果说你的服务器 CPU 是 4核 i7 的，连接池大小应该为 ((4*2)+1)=9。

取个整, 我们就设置为 10 吧。你这个行不行啊？10 也太小了吧！

行不行啊

你要是觉得不太行的话，可以跑个性能测试看看，我们可以保证，它能轻松支撑 3000 用户以 6000 TPS 的速率并发执行简单查询的场景。你还可以将连接池大小超过 10，那时，你会看到响应时长开始增加，TPS 开始下降。

七、结论：你需要的是一个小连接池，和一个等待连接的线程队列
假设说你有 10000 个并发访问，而你设置了连接池大小为 10000，你怕是石乐志哦。

改成 1000，太高？改成 100？还是太多了。

你仅仅需要一个大小为 10 数据库连接池，然后让剩下的业务线程都在队列里等待就可以了。

连接池中的连接数量大小应该设置成：数据库能够有效同时进行的查询任务数（通常情况下来说不会高于 2*CPU核心数）。

你应该经常会看到一些用户量不是很大的 web 应用中，为应付大约十来个的并发，却将数据库连接池设置成 100， 200 的情况。请不要过度配置您的数据库连接池的大小。

八、额外需要注意的点
实际上，连接池的大小的设置还是要结合实际的业务场景来说事。

比如说，你的系统同时混合了长事务和短事务，这时，根据上面的公式来计算就很难办了。正确的做法应该是创建两个连接池，一个服务于长事务，一个服务于"实时"查询，也就是短事务。

还有一种情况，比方说一个系统执行一个任务队列，业务上要求同一时间内只允许执行一定数量的任务，这时，我们就应该让并发任务数去适配连接池连接数，而不是连接数大小去适配并发任务数。

Ref
https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing


Java 线程池详解
CarpenterLee  Java基基  昨天
点击上方“Java基基”，选择“设为星标”

做积极的人，而不是积极废人！

源码精品专栏


中文详细注释的开源项目

RPC 框架 Dubbo 源码解析

网络应用框架 Netty 源码解析

消息中间件 RocketMQ 源码解析

数据库中间件 Sharding-JDBC 和 MyCAT 源码解析

作业调度中间件 Elastic-Job 源码解析

分布式事务中间件 TCC-Transaction 源码解析

Eureka 和 Hystrix 源码解析

Java 并发源码

来源：http://t.cn/EKjdY9A

基础知识

如何正确使用线程池

线程池的常用场景

线程池和装修公司

总结

参考

构造一个线程池为什么需要几个参数？如果避免线程池出现OOM？Runnable和Callable的区别是什么？本文将对这些问题一一解答，同时还将给出使用线程池的常见场景和代码片段。

基础知识
Executors创建线程池
Java中创建线程池很简单，只需要调用Executors中相应的便捷方法即可，比如Executors.newFixedThreadPool(int nThreads)，但是便捷不仅隐藏了复杂性，也为我们埋下了潜在的隐患（OOM，线程耗尽）。

Executors创建线程池便捷方法列表：

img
img
小程序使用这些快捷方法没什么问题，对于服务端需要长期运行的程序，创建线程池应该直接使用ThreadPoolExecutor的构造方法。没错，上述Executors方法创建的线程池就是ThreadPoolExecutor。

ThreadPoolExecutor构造方法
Executors中创建线程池的快捷方法，实际上是调用了ThreadPoolExecutor的构造方法（定时任务使用的是ScheduledThreadPoolExecutor），该类构造方法参数列表如下：

// Java线程池的完整构造函数
public ThreadPoolExecutor(
  int corePoolSize, // 线程池长期维持的线程数，即使线程处于Idle状态，也不会回收。
  int maximumPoolSize, // 线程数的上限
  long keepAliveTime, TimeUnit unit, // 超过corePoolSize的线程的idle时长，
                                     // 超过这个时间，多余的线程会被回收。
  BlockingQueue<Runnable> workQueue, // 任务的排队队列
  ThreadFactory threadFactory, // 新线程的产生方式
  RejectedExecutionHandler handler) // 拒绝策略
竟然有7个参数，很无奈，构造一个线程池确实需要这么多参数。这些参数中，比较容易引起问题的有corePoolSize, maximumPoolSize, workQueue以及handler：

corePoolSize和maximumPoolSize设置不当会影响效率，甚至耗尽线程；
workQueue设置不当容易导致OOM；
handler设置不当会导致提交任务时抛出异常。
正确的参数设置方式会在下文给出。

线程池的工作顺序
If fewer than corePoolSize threads are running, the Executor always prefers adding a new thread rather than queuing.
If corePoolSize or more threads are running, the Executor always prefers queuing a request rather than adding a new thread.
If a request cannot be queued, a new thread is created unless this would exceed maximumPoolSize, in which case, the task will be rejected.

corePoolSize -> 任务队列 -> maximumPoolSize -> 拒绝策略

Runnable和Callable
可以向线程池提交的任务有两种：Runnable和Callable，二者的区别如下：

方法签名不同，void Runnable.run(), V Callable.call() throws Exception
是否允许有返回值，Callable允许有返回值
是否允许抛出异常，Callable允许抛出异常。
Callable是JDK1.5时加入的接口，作为Runnable的一种补充，允许有返回值，允许抛出异常。

三种提交任务的方式：
img
img
如何正确使用线程池
避免使用无界队列
不要使用Executors.newXXXThreadPool()快捷方法创建线程池，因为这种方式会使用无界的任务队列，为避免OOM，我们应该使用ThreadPoolExecutor的构造方法手动指定队列的最大长度：

ExecutorService executorService = new ThreadPoolExecutor(2, 2,
                0, TimeUnit.SECONDS,
                new ArrayBlockingQueue<>(512), // 使用有界队列，避免OOM
                new ThreadPoolExecutor.DiscardPolicy());
明确拒绝任务时的行为
任务队列总有占满的时候，这是再submit()提交新的任务会怎么样呢？RejectedExecutionHandler接口为我们提供了控制方式，接口定义如下：

public interface RejectedExecutionHandler {
    void rejectedExecution(Runnable r, ThreadPoolExecutor executor);
}
线程池给我们提供了几种常见的拒绝策略：

img
img
img
img
线程池默认的拒绝行为是AbortPolicy，也就是抛出RejectedExecutionHandler异常，该异常是非受检异常，很容易忘记捕获。如果不关心任务被拒绝的事件，可以将拒绝策略设置成DiscardPolicy，这样多余的任务会悄悄的被忽略。

ExecutorService executorService = new ThreadPoolExecutor(2, 2,
                0, TimeUnit.SECONDS,
                new ArrayBlockingQueue<>(512),
                new ThreadPoolExecutor.DiscardPolicy());// 指定拒绝策略
获取处理结果和异常
线程池的处理结果、以及处理过程中的异常都被包装到Future中，并在调用Future.get()方法时获取，执行过程中的异常会被包装成ExecutionException，submit()方法本身不会传递结果和任务执行过程中的异常。获取执行结果的代码可以这样写：

ExecutorService executorService = Executors.newFixedThreadPool(4);
Future<Object> future = executorService.submit(new Callable<Object>() {
        @Override
        public Object call() throws Exception {
            throw new RuntimeException("exception in call~");// 该异常会在调用Future.get()时传递给调用者
        }
    });

try {
  Object result = future.get();
} catch (InterruptedException e) {
  // interrupt
} catch (ExecutionException e) {
  // exception in Callable.call()
  e.printStackTrace();
}
上述代码输出类似如下：

线程池的常用场景
正确构造线程池
int poolSize = Runtime.getRuntime().availableProcessors() * 2;
BlockingQueue<Runnable> queue = new ArrayBlockingQueue<>(512);
RejectedExecutionHandler policy = new ThreadPoolExecutor.DiscardPolicy();
executorService = new ThreadPoolExecutor(poolSize, poolSize,
    0, TimeUnit.SECONDS,
            queue,
            policy);
获取单个结果
过submit()向线程池提交任务后会返回一个Future，调用V Future.get()方法能够阻塞等待执行结果，V get(long timeout, TimeUnit unit)方法可以指定等待的超时时间。

获取多个结果
如果向线程池提交了多个任务，要获取这些任务的执行结果，可以依次调用Future.get()获得。但对于这种场景，我们更应该使用ExecutorCompletionService，该类的take()方法总是阻塞等待某一个任务完成，然后返回该任务的Future对象。向CompletionService批量提交任务后，只需调用相同次数的CompletionService.take()方法，就能获取所有任务的执行结果，获取顺序是任意的，取决于任务的完成顺序：

void solve(Executor executor, Collection<Callable<Result>> solvers)
   throws InterruptedException, ExecutionException {

   CompletionService<Result> ecs = new ExecutorCompletionService<Result>(executor);// 构造器

   for (Callable<Result> s : solvers)// 提交所有任务
       ecs.submit(s);

   int n = solvers.size();
   for (int i = 0; i < n; ++i) {// 获取每一个完成的任务
       Result r = ecs.take().get();
       if (r != null)
           use(r);
   }
}
单个任务的超时时间
V Future.get(long timeout, TimeUnit unit)
方法可以指定等待的超时时间，超时未完成会抛出TimeoutException。

多个任务的超时时间
等待多个任务完成，并设置最大等待时间，可以通过CountDownLatch完成：

public void testLatch(ExecutorService executorService, List<Runnable> tasks)
    throws InterruptedException{

    CountDownLatch latch = new CountDownLatch(tasks.size());
      for(Runnable r : tasks){
          executorService.submit(new Runnable() {
              @Override
              public void run() {
                  try{
                      r.run();
                  }finally {
                      latch.countDown();// countDown
                  }
              }
          });
      }
      latch.await(10, TimeUnit.SECONDS); // 指定超时时间
  }
线程池和装修公司
以运营一家装修公司做个比喻。公司在办公地点等待客户来提交装修请求；公司有固定数量的正式工以维持运转；旺季业务较多时，新来的客户请求会被排期，比如接单后告诉用户一个月后才能开始装修；当排期太多时，为避免用户等太久，公司会通过某些渠道（比如人才市场、熟人介绍等）雇佣一些临时工（注意，招聘临时工是在排期排满之后）；如果临时工也忙不过来，公司将决定不再接收新的客户，直接拒单。

线程池就是程序中的“装修公司”，代劳各种脏活累活。上面的过程对应到线程池上：

// Java线程池的完整构造函数
public ThreadPoolExecutor(
  int corePoolSize, // 正式工数量
  int maximumPoolSize, // 工人数量上限，包括正式工和临时工
  long keepAliveTime, TimeUnit unit, // 临时工游手好闲的最长时间，超过这个时间将被解雇
  BlockingQueue<Runnable> workQueue, // 排期队列
  ThreadFactory threadFactory, // 招人渠道
  RejectedExecutionHandler handler) // 拒单方式
总结
Executors为我们提供了构造线程池的便捷方法，对于服务器程序我们应该杜绝使用这些便捷方法，而是直接使用线程池ThreadPoolExecutor的构造方法，避免无界队列可能导致的OOM以及线程个数限制不当导致的线程数耗尽等问题。ExecutorCompletionService提供了等待所有任务执行结束的有效方式，如果要设置等待的超时时间，则可以通过CountDownLatch完成。

参考
ThreadPoolExecutor API Doc
https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadPoolExecutor.html




