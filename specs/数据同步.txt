读数据表
读取Maxcompute的表数据组件，默认读取本工程下的数据。若读取其他工程的表数据且拥有该工程的操作权限，只需在表名前添加工程名，格式：工程名.表名，如：tianchi_project.weibo_data。

读MaxCompute表的输入框：当输入表名后，会自动读取表的结构数据，可单击字段信息查看。


注意：MaxCompute表字段修改后，如果增加或删除某个字段，在算法平台中是无法感知的，需要用户重新设置一下MaxCompute源，重新加载这个表信息。

分区功能介绍。

若输入表是分区表，后台会自动勾选分区框，用户可选择或输入分区参数，目前仅支持输入单个分区。
不勾选分区框或勾选后不输入分区参数均默认为输入全表。
若输入表是非分区表，分区框不可勾选。
PAI的读数据组件包含读取分区表的功能，在日期定义上与大数据开发套件略有不同。
PAI在读取分区表时需要指定dt=@@{yyyyMMdd}，其中@@{yyyyMMdd}表示当前日期，@@{yyyyMMdd-1d}表示当前日期前一天。
写数据表
写入MaxCompute表的数据组件，同样支持写入其他工程的表数据。
写入表数据不支持分区操作。

Mysql数据同步
功能说明
同步Mysql数据到MaxCompute项目。

参数说明
参数名称	参数描述	取值范围	默认值/行为
实例名称	必填，RDS的实例名称	不涉及	不涉及
数据库	必填，RDS数据库名称	不涉及	不涉及
数据表	必填，欲同步的数据表	不涉及	不涉及
用户名	必填，RDS数据库的用户名	不涉及	不涉及
密码	必填，RDS数据库密码	不涉及	不涉及
同步的字段	选填，默认同步该数据库所有字段	不涉及	所有字段
允许脏数据阈值	选填，数据错误数，默认0容忍数据错误	不涉及	0
同步数据宽带	选填，数据同步带宽	单位 MB/s	1
注意：由于CDP服务是对外服务，不支持集团内部数据同步，集团内部数据同步请走数据同步中心或者DataX。

如何获取组件参数
使用主账号登录阿里云官网，切换到RDS控制台，如下图所示，获取RDS的实例名称。


添加白名单。由于RDS对访问的IP有限制，需要单击实例链接，选择数据安全性，添加白名单。其中 0.0.0.0/0 表示运行任意IP访问。


单击实例链接，可以查看实例的详细信息，比如账号信息（如果没有账号，可以新建一个账号）、数据库信息等。


在左侧的菜单栏中选择数据库连接，单击登录数据库。



登录后可以查看数据库database，数据库下对应的table和schema。
image

OSS数据同步
功能说明
同步OSS的文本到MaxCompute数据源。

说明：CDP服务不提供命令行执行语句。

参数说明
参数名称	参数描述	取值范围	默认值/行为
OSSendpoint	必填，OSS存储服务所在的 Endpoint	oss-cn-xxxx.aliyuncs.com	oss-cn-shanghai.aliyuncs.com
OSSaccessId	必填，OSS服务的 AccessId	不涉及	不涉及
OSSaccessKey	必填，OSS服务的 AccessKey	不涉及	不涉及
bucket	必填，OSS服务的 Bucket	不涉及	不涉及
object	必填，欲同步的 OSS object	不涉及	不涉及
OSScolumn映射	必填，同步的字段映射格式是 index:name，表示OSS第index列同步到Maxcompute字段名为name的字段中，字段类型默认string，比如0:label,1:s_width,2:s_length,3:v_width,4:v_length	不涉及	不涉及
OSS文本分隔符	必填，OSS object 的文本分隔符(列分隔符)	逗号	,
OSS文本压缩格式	选填，OSS 文本压缩格式	gzip，zip，bzip2	无
OSS文本编码	选填，OSS 文本的编码	utf-8	utf-8
同步数据带宽	选填，数据同步带宽	单位 MB/s	1
允许脏数据阈值	选填，数据错误数，默认0容忍数据错误	不涉及	0
注意：由于CDP服务是对外服务，不支持集团内部数据同步，集团内部数据同步请走数据同步中心或者DataX。

如何获取组件参数
使用主账号登录阿里云官网，切换到OSS控制台。单击界面右侧的Access key，获取 AccessId 和 AccessKey，如下图所示。


在OSS控制台，可以在左侧列表中搜索用户拥有的 Bucket，如果没有可以参考创建OSS存储空间创建 Bucket。

单击 Bucket 实例链接，进入概览页面，可以获取该 OSS Bucket 所在的 Endpoint。


单击文件管理可以获取 Bucket，Object 等信息。


DataWorks数据集成支持任意位置任意网络环境下的任意数据源之间的实时、离线数据互通，是一站式数据同步的全栈平台，并允许用户在各种云和本地数据存储中每天复制数十TB的数据。

速度超快的数据传输性能以及400+对异构数据源之间的数据互通是确保用户能专注于核心“大数据”问题的关键：构建高级分析解决方案并从所有数据获得深入洞察。

本文将为您介绍数据同步速度的影响因素，如何通过调整同步作业的DMU配置、并发配置来达到最大化同步速度，作业限速和不限速的区别，以及自定义资源组的注意事项。

数据同步速度的影响因素
影响数据同步速度的因素，可从以下几方面进行考虑：

来源端数据源

数据库的性能：CPU、内存、SSD 硬盘、网络、硬盘等。

并发数：如果数据源并发数高，数据库负载便高。

网络：网络的带宽（吞吐量），网速。一般来说，数据库的性能越好，其可承载的并发数越高，可为数据同步作业设置更高的并发进行数据的抽取。
数据集成的同步任务配置

传输速度：是否设置任务同步速度上限值
DMU：任务运行所需要的资源量
并发：从源并行读取或并行写入数据存储端的最大线程数
WAIT 资源
Bytes 的设置：单个线程的 Bytes = 1048576，在网速比较敏感时，会出现超时现象，建议设置小一些。
查询语句是否建索引。
关于同步任务配置的相关概念，下文有详细说明。

目的端数据源
性能：CPU、内存、SSD 硬盘、网络、硬盘。
负载：目的数据库负载过高会影响同步任务数据写入效率。
网络：网络的带宽（吞吐量），网速。
数据源端和目的端数据库的性能、负载和网络情况主要由用户自己关注和调优，下文重点介绍在数据集成产品中配置同步任务的核心概念。

DMU数据移动单位
概念&配置
数据移动单位 (DMU) 是数据集成消耗资源（包含 CPU、内存、网络等资源分配）的度量单位。一个DMU描述了一个数据集成作业最小运行能力，即在限定的CPU、内存、网络等资源情况下对于数据同步的处理能力。

一个同步任务可以在1个或多个DMU上运行，向导模式最高可选上限为20个DMU；

如果通过脚本模式配置DMU，示例如下：

"setting": {
      "speed": {
        "dmu": 10
      }
    }
注：脚本模式虽然可以配置超过20DMU，系统上仍然会进行一定的资源限制。

DMU与作业速度的关系
DMU代表了资源能力，给同步任务配置较高DMU，可以分配得到更多的资源占用，但并不等于同步任务的速度一定能得到提升；速度调优需要结合并发、DMU两者之间的配比调优。举例来说，一个同步任务，配置3个并发，所需3DMU，同步速度为10MB/s;此时3并发所需资源量为3DMU，任务无需使用更多的资源，因此增加DMU并不能同步增加同步任务的速度。

并发
概念&配置
可将此属性视为数据同步任务内，可从源并行读取或并行写入数据存储端的最大线程数。向导模式通过界面化配置并发数，指定任务所使用的并行度；脚本模式通过如下示例代码：

"setting": {
      "speed": {
        "concurrent": 10
      }
    }
并发与DMU的关系
并发是指同步任务读取或写入的并行度，并发配置的越大，则所需要的系统资源（DMU）越多，在网络状况和读写端数据源能力满足的情况下，同步速度可以呈线性增长。但需注意以下几点：

为了保障高并发状态下，任务可正常执行，在产品设计上，DMU和并发有联动关系：当DMU配置为10时，最高并发数不可超过10
配置高并发，需要考虑读写端数据源的能力，并发过高可能会对源端数据库造成性能影响，请注意调优
脚本模式中，并发值虽然可以设置较高，但单任务所分配数据移动单元（DMU）会有控制，请注意调优
限速
商业化之后，数据集成同步任务默认不限速，任务将在所配置的并发数、DMU数的限制上以最高能达到的速度进行同步。另一方面，考虑到速度过高可能对数据库造成过大的压力从而影响生产，数据集成同时提供了限速选项，用户可以按照实际情况调优配置（我们建议选择限速之后，最高速度上限不应超过30MB/s）。脚本模式通过如下示例代码配置限速：

"setting": {
      "speed": {
         "throttle": true // 限流
        "mbps": 1,　// 具体速率值
      }
    }
注：当throttle设置为false时，表示不限速，则mbps的配置无意义；

自定义资源组注意事项
自定义资源组指的是将用户的同步任务运行在用户自己的机器上，特别是在网络不通情况下解决数据传输问题，详见文档：https://help.aliyun.com/document_detail/60429.html

任务运行在用户自己机器的自定义资源组上与运行在阿里云机器上的运行机制相似，均需要配置任务所需占用的DMU、并发数以及是否限速等；所不同的是，数据集成不会针对自定义资源消耗的DMU收费，而仅针对任务运行时长收费，详见数据集成计量计费文档。

为了保障任务在自定义资源组上顺畅的运行，推荐的自定义资源组机器配置至少为：2GHz，4核，8GB RAM和80GB磁盘。

数据同步过慢的场景
同步任务使用公共调度（WAIT）资源时一直在等待状态
场景示例

在 DataWorks（数据工场，原大数据开发套件）中对任务运行测试时，出现任务一直等待的状态，或好多测试任务都处于等待状态，而且还提示了系统内部错误。示例如下：

比如一个数据同步任务执行完成，共等待了大概 800s，但是日志显示任务只运行了 18s，使用的是默认资源组，现在运行其他同步任务，也是 RDS 到 MaxCompute ，一共几百条数据，一直处于等待中 。

显示等待日志：

2017-01-03 07:16:54 : State: 2(WAIT) | Total: 0R 0B | Speed: 0R/s 0B/s | Error: 0R 0B | Stage: 0.0%
解决方法

因为您使用的是公共调度资源，公共资源能力是受限的有很多项目都在使用，不只是单个用户的 2-3 个任务，任务实际运行 10 秒，但是延长到 800 秒，是因为您的任务下发执行时，发现资源不足，需等待获取资源。

如果对于同步速度和等待时间比较敏感，建议在低峰期配置同步任务，一般晚上零点到 3 点同步任务比较多，这样可以避开零点到 3 点的时间段，便可相对减少等待资源的情况。

提高多个任务导入数据到同一张表的同步速度
场景示例

想要将多个数据源的表同步到一张表里，所以将同步任务设置成串行任务，但是最后发现同步时间很长。

解决方法

可以同时启动多个任务，同时往一个数据库进行写入，注意以下几方面：

确保目标数据库负载能力是能够承受，避免不能正常工作。

在配置工作流任务，可以选择单个任务节点，配置分库分表任务或者在一个工作流中设置多个节点同时执行。

如果任务执行时，出现等待资源（WAIT）情况，可以低峰期配置同步任务，这样任务有较高的执行优先级。

数据同步任务 where 条件没有索引，导致全表扫描同步变慢
场景示例

执行的 SQL 如下所示：

select bid,inviter,uid,createTime from `relatives` where createTime>='2016-10-2300:00:00'and reateTime<'2016-10-24 00:00:00';
从 2016-10-25 11:01:24.875 开始执行，到 2016-10-25 11:11:05.489 开始返回结果。同步程序在等待数据库返回 SQL 查询结果，MaxCompute 需等待很久才能执行。

分析原因

where 条件查询时，createTime 列没有索引，导致查询全表扫描。

解决方法

建议 where 条件使用有索引相关的列，提高性能，索引也可以补充添加。