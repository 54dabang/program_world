
　1.2　推荐系统的功能3



　1.3　数据和知识来源5



　1.4　推荐技术7



　1.5　推荐系统评估10



　1.6　推荐系统应用11



　1.7　推荐系统与人机交互13



　1.8　高级话题14



　1.9　挑战16



　　1.9.1　偏好获取与分析16



　　1.9.2　交互17



　　1.9.3　新的推荐任务18



　参考文献19



第一部分　推荐系统技术



第2章　基于邻域的推荐方法综述24



　2.1　简介24



　　2.1.1　基于邻域方法的优势25



　　2.1.2　目标和概要26



　2.2　问题定义和符号26



　2.3　基于邻域的推荐27



　　2.3.1　基于用户的评分预测28



　　2.3.2　基于用户的分类预测方法28



　　2.3.3　回归与分类29



　　2.3.4　基于物品的推荐29



　　2.3.5　基于用户和基于物品的推荐方法的比较30



　2.4　基于邻域方法的要素31



　　2.4.1　评分标准化31



　　2.4.2　相似度权重的计算33



　　2.4.3　邻域的选择37



　2.5　高级进阶技术37



　　2.5.1　基于图的方法38



　　2.5.2　基于学习的方法40



　2.6　总结44



　参考文献44



第3章　协同过滤方法进阶48



　3.1　简介48



　3.2　预备知识49



　　3.2.1　基准预测49



　　3.2.2　Netflix数据50



　　3.2.3　隐式反馈51



　3.3　矩阵分解模型51



　　3.3.1　SVD52



　　3.3.2　SVD++53



　　3.3.3　时间敏感的因子模型54



　　3.3.4　比较57



　　3.3.5　小结58



　3.4　基于邻域的模型59



　　3.4.1　相似度度量59



　　3.4.2　基于相似度的插值60



　　3.4.3　联合派生插值权重61



　　3.4.4　小结63



　3.5　增强的基于邻域的模型63



　　3.5.1　全局化的邻域模型64



　　3.5.2　因式分解的邻域模型67



　　3.5.3　基于邻域模型的动态时序71



　　3.5.4　小结72



　3.6　基于邻域的模型和因子分解模型的比较73



　参考文献75



第4章　基于内容的语义感知推荐系统77



　4.1　简介77



　4.2　基于内容的推荐系统概述77



　　4.2.1　基于关键词的向量空间模型79



　　4.2.2　用户特征学习的方法80



　　4.2.3　基于内容过滤的优缺点81



　4.3　自上而下的语义方法82



　　4.3.1　基于本体资源的方法83



　　4.3.2　基于非结构化或半结构化百科知识的方法84



　　4.3.3　基于关联开放数据的方法86



　4.4　自下而上的语义方法90



　　4.4.1　基于判别式模型的方法90



　4.5　方法比较与小结94



　4.6　总结与未来挑战95



　致谢96



　参考文献96



第5章　基于约束的推荐系统103



　5.1　简介103



　5.2　推荐知识库的开发105



　5.3　推荐过程中的用户导向作用108



　5.4　计算推荐结果113



　5.5　实际应用的经验114



　5.6　未来的研究方法116



　5.7　总结118



　参考文献118



第6章　情境感知推荐系统123



　6.1　简介和动机123



　6.2　推荐系统中的情境124



　　6.2.1　什么是情境124



　　6.2.2　推荐系统中模型化情境信息的表征性方法125



　　6.2.3　推荐系统中主要的情境信息建模方法127



　　6.2.4　获取情境信息130



　6.3　结合具有代表性情境的推荐系统范式131



　　6.3.1　情境预过滤133



　　6.3.2　情境后过滤136



　　6.3.3　情境建模137



　6.4　讨论和总结138



　致谢140



　参考文献140



第7章　推荐系统中的数据挖掘方法145



　7.1　简介145



　7.2　数据预处理146



　　7.2.1　相似度度量方法146



　　7.2.2　抽样147



　　7.2.3　降维148



　　7.2.4　去噪150



　7.3　监督学习150



　　7.3.1　分类150



　　7.3.2　分类器的集成157



　　7.3.3　评估分类器157



　7.4　无监督学习159



　　7.4.1　聚类分析159



　　7.4.2　关联规则挖掘161



　7.5　总结162



　参考文献163



第二部分　推荐系统评估



第8章　推荐系统的评估170



　8.1　简介170



　8.2　实验设置171



　　8.2.1　离线实验172



　　8.2.2　用户调查173



　　8.2.3　在线评估175



　　8.2.4　得出可靠结论176



　8.3　推荐系统属性178



　　8.3.1　用户偏好179



　　8.3.2　预测精度179



　　8.3.3　覆盖率186



　　8.3.4　置信度187



　　8.3.5　信任度188



　　8.3.6　新颖性188



　　8.3.7　惊喜度189



　　8.3.8　多样性190



　　8.3.9　效用191



　　8.3.10　风险191



　　8.3.11　健壮性192



　　8.3.12　隐私192



　　8.3.13　适应性193



　　8.3.14　可扩展性193



　8.4　结论193



　参考文献194



第9章　使用用户实验评估推荐系统198



　9.1　简介198



　9.2　理论基础与现有工作199



　　9.2.1　理论基础：Knijnenburg等人提出的评估框架199



　　9.2.2　现有以用户为中心的研究概览以及有前景的方向201



　9.3　实践指南203



　　9.3.1　研究模型203



　　9.3.2　参与者206



　　9.3.3　实验操控207



　　9.3.4　测量209



　　9.3.5　统计评估214



　9.4　结论219



　参考文献221



第10章　对推荐结果的解释：设计和评估228



　10.1　简介228



　10.2　推荐设计的呈现和交互229



　　10.2.1　推荐呈现229

========

方案一：基于Online Learning的流式算法推荐（免费邀测）

上手难度:        推荐效果:

应用产品：PAI Studio（Online Learning版 ）（申请免费测试）、PAI EAS

Online Learning的特点是可以实时对模型进行训练，是一种流式机器学习的方式。
PAI平台内置了FTRL流式推荐算法，可以在用户已有的离线模型基础上帮助用户实时更新推荐模型，达到最优效果，做到流批一体。[ 查看详情 ]

训练离线模型并将摸型接入流式算法

生成流式数据源

通过流式算法不断更新模型

将实时模型输出到PAI EAS供业务调用或直接拿到预测结果

方案二：基于深度学习模型Wide&Deep的推荐（限时5折）

上手难度:        推荐效果:

应用产品：PAI DSW（立享优惠）PAI EAS

Wide&Deep方法是一种专门针对推荐领域的结合常规机器学习以及深度学习的建模方法。PAI DSW是一款云端编程平台，可以基于深度学习框架在线做模型训练，目前Wide&Deep相关示例代码和数据已经内置PAI DSW。[ 查看详情 ]

1
上传数据至NAS，并将NAS挂载到PAI DSW

2
在DSW上基于Tensorflow实现Wide&Deep逻辑

3
训练模型不断调优

4
将Tensorflow模型部署到PAI EAS生成HTTP服务，供业务调用



方案三：基于协同过滤算法的推荐

上手难度:        推荐效果:

应用产品：PAI Studio
出名的尿布与啤酒的故事背后映射的就是协同过滤算法，协同过滤算法是比较基础的推荐算法，经过简单的学习就可以快速上手，门槛低，但是准确率的天花板也较低。[ 查看详情 ]
上传数据至MaxCompute
参照PAI Studio首页模板利用协同过滤算法建模
生成推荐匹配结果表
将推荐匹配结果表应用于用户自身推荐逻辑中



方案四：基于对象特征的推荐
上手难度:        推荐效果:
应用产品：PAI Studio、PAI EAS
基于对象特征的推荐建模需要用户充分理解自身的业务，通过特征工程的方式衍生更多特征，增强数据表现力。
另外需要了解二分类或多分类的算法原理，不断借助PAI的AutoML调参工具提升模型表现力。最终将生成的推荐模型通过PAI EAS部署成HTTP服务供调用。[ 查看详情 ]

上传数据至MaxCompute
利用特征工程法法进行数据建模，建立特征列以及目标列
选用分类算法生成模型，并用AutoML方法不断提升模型准确率
将模型部署到PAI EAS生成HTTP服务，供业务方调用

==============

示例背景
本示例主要介绍如何使用 DataWorks（数据工场，原大数据开发套件）完成一个完整的 MaxCompute SQl 工作流。您可以根据本示例，了解一个完整的工作流开发过程，包括：创建 MaxCompute 表、数据导入 MaxCompute 表、创建工作流、创建节点、测试运行工作流等过程。

示例介绍
本示例主要通过准备 用户 > 品牌特征 表为后期天猫品牌推荐模型做铺垫。在天猫，每天都会有数千万的用户通过品牌发现自己喜欢的商品，品牌推荐是链接商家和消费者的重要纽带。

本示例通过分析用户前三个月的的品牌购买情况以及最近3天、7天的用户偏好特征，得出下个月 用户 > 品牌特征，为后续品牌个性化推荐模型做准备。

 上一篇：步骤6：数据回流


 步骤1：数据准备
 更新时间：2017-11-07 11:49:22


 本页目录
 后续步骤
 本示例假设 用户 > 品牌信息（源数据表） 存储在业务方的 RDS 上，进而利用 DataWorks（数据工场，原大数据开发套件）进行数据同步、数据加工等操作，来详细阐述常见开发流程 数据产生 > 数据收集和存储 > 数据分析和计算。

 源数据 请参见 附件，数据说明如下：

 字段	字段说明	提取说明
 user_id	用户标识
 brand_id	品牌ID
 type	用户对品牌的行为类型	点击：0；购买：1；收藏：2；加入购物车：3
 visit_datetime	行为时间	格式：年月日（yyyymmdd）
 该数据主要记录 20150415-20150815 四个月的用户行为信息，本示例将以该数据作为源数据进行分析，产出目标表。

 本示例实现过程中，涉及到的 MaxCompute 表说明如下：

 序号	表名	说明
 1	s_user_brand_demo	用户-品牌行为信息源表
 2	b_cvr_demo	品牌转化率表，前3个月品牌的购买用户数/点击数
 3	ub_action_demo	用户偏好表，统计用户最近7天和最近3天的行为次数
 4	ub_features_demo	用户-品牌所有特征表
 经分析，源数据 visit_datetime 字段刚好是年月日，为了提高后续查询速度，源表 s_user_brand_demo 建为分区表，以字段 visit_datetime 为分区。

 用户数据每天都不断新增变化，本示例的表，都以年月日作为分区表。

 后续步骤
 现在，您已经对实验所需的数据做了一定的准备和了解，您可以继续学习下一个教程。在该教程中您将学习如何配置实验所需的 RDS 数据源。详情请参见 配置 RDS 数据源。

 由前文可知，原始数据在 RDS 上，那么需要把 RDS 数据导入到 MaxCompute 中。本示例通过数据同步任务来完成数据的导入，而数据同步任务必须事先创建好数据源。

 前提条件
 创建 RDS 数据源必须要清楚 RDS 的相关信息（可在 RDS 的基本信息页面中获取），此处数据源配置成通过 RDS 实例形式连接，所以需要提前知道的 RDS 信息包括：RDS 实例 ID，RDS 实例购买者 ID，数据库名，用户名和密码。

 操作步骤
 以项目管理员身份进入 DataWorks 管理控制台，单击对应项目操作栏中的 进入工作区。

 单击顶部菜单栏中的 数据集成，导航至 数据源 页面。

 单击 新增数据源。

 在新建数据源弹出框中，选择数据源类型为 RDS > MySQL。

 选择以 RDS 实例形配置该 MySQL 数据源。



 查看 RDS > MySQL 中的实例 ID，如下图所示：

 instance_id

 单击 测试连通性。

 测试连通性通过后，单击 确定。

 注意：

 若测试连通性失败，请参见 RDS 数据源测试连通性不通。

 后续步骤
 现在，您已经学习了如何配置 RDS 数据源，您可以继续学习下一个教程。在该教程中您将学习如何准备相关的 MaxCompute 表。详情请参见 创建 MaxCompute 表。

 步骤3：创建MaxCompute表
 更新时间：2017-11-08 15:31:56


 本页目录
 操作步骤
 建表语句
 后续步骤
 操作步骤
 以新建 s_user_brand_demo 数据表为例，具体操作如下：

 以开发者身份进入 DataWorks 管理控制台，单击对应项目操作栏中的 进入工作区。

 创建脚本文件。

 单击顶部菜单栏中的 数据开发，导航至 新建 > 新建脚本。

 1

 编辑建表语句。

 CREATE TABLE IF NOT EXISTS s_user_brand_demo (
  user_id STRING COMMENT '用户标识',
  brand_id STRING COMMENT '品牌ID',
  type STRING COMMENT '用户对品牌的行为类型，点击：0，购买：1，收藏：2，加入购物车：3'
  )
 PARTITIONED BY (
  dt STRING
  )
 LIFECYCLE 150;
 单击运行按钮 Run_Button 运行建表语句。

 语句运行成功，则建表成功。

 注意：

 您可以执行 desc tablename;，查看表是否真正创建成功。

 建表语句
 您可根据上述步骤，完成其他表的创建。需要创建的表和对应的建表语句，如下所示：

 b_cvr_demo（品牌转化率表）

 --品牌转化率表，品牌的购买用户数/点击数
 CREATE TABLE IF NOT EXISTS b_cvr_demo (
   brand_id STRING,
   cvr DOUBLE
 )
 PARTITIONED BY (
   dt STRING
 )
 LIFECYCLE 7;
 ub_action_demo（用户偏好表）

 --用户偏好表，这里统计用户最近 7 天和最近 3 天的行为次数
 CREATE TABLE IF NOT EXISTS ub_action_demo (
   user_id STRING,
   brand_id STRING,
   buy_cnt BIGINT,
   click_d7 BIGINT,
   collect_d7 BIGINT,
   shopping_cart_d7 BIGINT,
   click_d3 BIGINT,
   collect_d3 BIGINT,
   shopping_cart_d3 BIGINT
 )
 PARTITIONED BY (
   dt STRING
 )
 LIFECYCLE 7;
 ub_features_demo（用户-品牌所有特征表）

 --品牌-用户所有特征表
 CREATE TABLE IF NOT EXISTS ub_features_demo (
   user_id STRING,
   brand_id STRING,
   buy_cnt BIGINT,
   click_d7 BIGINT,
   collect_d7 BIGINT,
   shopping_cart_d7 BIGINT,
   click_d3 BIGINT,
   collect_d3 BIGINT,
   shopping_cart_d3 BIGINT,
   cvr DOUBLE
 )
 PARTITIONED BY (
   dt STRING
 )
 LIFECYCLE 7;
 后续步骤
 现在，您已经学习了如何创建 MaxCompute 表，您可以继续学习下一个教程。在该教程中您将学习如何创建工作流来对项目空间的数据进行进一步的计算与分析。详情请参见 创建工作流。


 步骤4：创建工作流
 更新时间：2017-11-08 15:32:55


 本页目录
 操作步骤
 后续步骤
 本示例中，数据的分析流程如下图所示：

 tm_demo_dataflow.JPG

 源表经过加工成为两个中间表，最后通过两个中间表加工得出目标表，一个工作流即可完成。同时，在 数据准备 中分析得出需要创建日分区表，也就是每日一分区。因此工作流需配置为周期性天调度。

 操作步骤
 以开发者身份进入 DataIDE 管理控制台，单击对应项目操作栏中的 进入工作区。

 单击顶部导航栏中的 数据开发，导航至 新建 > 新建任务。

 填写弹出框中的各配置项，指定任务类型为 工作流任务。如下图所示：

 1

 单击 创建。

 进入工作流页面后，单击右侧导航栏的 调度配置 进行配置。

 基本属性无需修改。

 1

 调度属性保留默认配置。

 因为工作流需要周期调度，且目前没有预设下线时间，因此所有配置项保留默认。

 1

 调度周期为天，具体时间为 0 点整，即每日 0 点调度服务开始调度当天示例时，即可开始调度此工作流。

 依赖属性保留默认配置。

 因为源头数据导入后，打算直接在本工作流中配置任务，没有必须依赖的上游工作流，所以此配置保持不变。

 跨周期依赖可根据自己的需求进行相应的配置。

 1

 后续步骤
 现在，您已经学习了如何创建工作流，您可以继续学习下一个教程。在该教程中您将学习如何通过创建同步任务来把数据导入到 MaxCompute 中。详情请参见 配置数据导入任务。

 步骤5：配置数据导入任务
 更新时间：2017-09-20 19:04:45


 本页目录
 操作步骤
 后续步骤
 原始数据在 RDS 数据库上，若想通过 MaxCompute 对数据进行加工、分析，需要先把数据导入到 MaxCompute 中。前文中已成功 配置 RDS 数据源 和 创建 MaxCompute 表，接下来即可开始创建数据导入任务。

 操作步骤
 打开创建的工作流（tmall_ub_features_demo），将数据同步节点组件拖拽至画布中。

 1

 名称：s_user_brand_demo。

 描述：RDS 上同步数据到表 s_user_brand_demo。

 双击该节点或右键查看节点内容进入任务配置界面。

 选择来源。

 1

 源头默认为单表，选择前面添加的数据源，和对应的原始数据表。

 选择目标。

 1

 目标选择本项目对应的 MaxCompute project，所以数据源为 odps_frist，目标表为 s_user_brand_demo 表。

 字段映射。

 选择要抽取的列，并映射到目标表字段。

 1

 选好源和目标表之后，列会先自动按照字段名对应匹配，匹配不到的目标字段留空，默认显示所有源表字段，数据同步任务执行的时候就按该字段配置顺序一一对应读写。

 通道控制。

 1

 完成以上配置后，单击 保存。

 配置节点参数。



 由于 ${bdp.system.bizdate} 为系统参数，因此参数配置中无需赋值。

 单击 保存。

 后续步骤
 现在，您已经学习了如何配置数据同步任务，您可以继续学习下一个教程。在该教程中您将学习如何配置 SQL 任务，产出结果表。详情请参见 配置 SQL 任务产出特征表。

 步骤6：配置SQL任务产出特征表
 更新时间：2017-09-25 11:00:27


 本页目录
 操作步骤
 后续步骤
 本示例为了更形象的说明工作流配置，一个 MaxCompute SQL 节点产出一个表。经分析需要创建 3 个 MaxCompute SQL 节点。

 操作步骤
 工作流（tmall_ub_features_demo）设计器的节点组件中向画布拖拽 3 个 MaxCompute SQL 节点组件，进行创建。

 节点名称分别为：b_cvr_demo、ub_action_demo、ub_features_demo。

 描述：对应上面的节点名称分别为：产出品牌转化率表、产出用户偏好表、产出用户-品牌所有特征表。

 此时看到工作流设计器上有 4 个 节点：1 个同步任务，3 个 MaxCompute SQL 任务，如下图所示：



 配置节点依赖。

 根据前面的数据分析，中间表数据来自同步任务产出的源表，最终特征表数据来自两个中间表，因此，节点的依赖关系如下图所示：



 编辑 MaxCompute SQL 节点代码，与参数配置（内置调度时间参数说明请参见 数据开发手册 > 系统调度参数）。

 分别双击 SQL 节点进入代码编辑页面进行代码编辑，代码如下：

 节点 b_cvr_demo 代码与参数配置

 --产出品牌转化率表,前3个月品牌的购买用户数/点击数
 INSERT OVERWRITE TABLE b_cvr_demo PARTITION (dt=${bdp.system.bizdate})
 SELECT brand_id
 , CASE
    WHEN click_cnt > 0 THEN buy_cnt / click_cnt
    ELSE 0
 END AS cvr
 FROM (
 SELECT brand_id
    , COUNT(DISTINCT CASE
        WHEN type = '1' THEN user_id
        ELSE NULL
    END) AS buy_cnt
    , COUNT(DISTINCT CASE
        WHEN type = '0' THEN user_id
        ELSE NULL
    END) AS click_cnt
 FROM s_user_brand_demo
 WHERE dt >= ${before3mont}
 GROUP BY brand_id
 ) t1;
 产出表分区表达式与前面数据同步任务分区表达式一致，每次运行读源表分区为前三个月分区，源表分区过滤条件 dt>=${before3mont}

 参数配置如下图：



 ${bdp.system.bizdate} 变量在调度的时候会自动替换成业务日期，所以不需要赋值。

 ${before3mont} 自定义变量需要在此赋值，因为是取前 3 个月的数据，所以可以去当前节点实例定时时间减 3 个月，即 $[add_months(YYYYMMDD,-3)]。

 节点 ub_action_demo 代码与参数配置

 --产出用户偏好表,这里统计用户最近7天和最近3天的行为次数
 INSERT OVERWRITE TABLE ub_action_demo PARTITION (dt=${bdp.system.bizdate})
 SELECT user_id
 , brand_id
 , SUM(CASE
    WHEN type = '1' THEN 1
    ELSE 0
 END) AS buy_cnt
 , SUM(CASE
    WHEN type = '0'
    AND dt > '${before7days}' THEN 1
    ELSE 0
 END) AS click_d7
 , SUM(CASE
    WHEN type = '2'
    AND dt > '${before7days}' THEN 1
    ELSE 0
 END) AS collect_d7
 , SUM(CASE
    WHEN type = '3'
    AND dt > '${before7days}' THEN 1
    ELSE 0
 END) AS shopping_cart_d7
 , SUM(CASE
    WHEN type = '0'
    AND dt > '${before3days}' THEN 1
    ELSE 0
 END) AS click_d3
 , SUM(CASE
    WHEN type = '2'
    AND dt > '${before3days}' THEN 1
    ELSE 0
 END) AS collect_d3
 , SUM(CASE
    WHEN type = '3'
    AND dt > '${before3days}' THEN 1
    ELSE 0
 END) AS shopping_cart_d3
 FROM s_user_brand_demo
 WHERE dt >= ${before7days}
 and dt <= ${bdp.system.bizdate}
 GROUP BY user_id,
 brand_id;
 参数配置如下图：



 ${bdp.system.bizdate} 变量在调度的时候会自动替换成业务日期，所以不需要赋值。

 ${before7days} 和 ${before3days} 需要的是业务日期的前7天和前3天，所以可以用调度时间参数 $[yyyymmdd-8] 和 $[yyyymmdd-4]，即当前节点实例定时时间年月日减 8 天/减 4 天。

 节点ub_features_demo代码与参数配置

 INSERT OVERWRITE TABLE ub_features_demo PARTITION (dt=${bdp.system.bizdate})
 SELECT t1.user_id
 , t1.brand_id
 , t1.buy_cnt
 , t1.click_d7
 , t1.collect_d7
 , t1.shopping_cart_d7
 , t1.click_d3
 , t1.collect_d3
 , t1.shopping_cart_d3
 , t2.cvr
 FROM ub_action_demo t1
 LEFT OUTER JOIN b_cvr_demo t2
 ON t1.brand_id = t2.brand_id
 AND t1.dt = ${bdp.system.bizdate}
 AND t2.dt = ${bdp.system.bizdate};
 ${bdp.system.bizdate}变量在调度的时候会自动替换成业务日期，所以不需要赋值,代码中没用到其他自定义变量名，所以不需要配置参数。

 返回工作流设置器页面，单击 保存。

 至此，已完成本示例的工作流配置，但要想让工作流根据配置每天自动调度，还需要把工作流提交到调度系统，即在工作流设计页面（整体视图页面）单击 提交，在变更节点列表中选择所有节点并单击 确定提交，提交成功则成功的把工作流提交到调度服务。

 后续步骤
 现在，您已经学习了如何通过 MaxCompute SQL 对数据进行加工处理，并产出最终目标表，您可以继续学习下一个教程。在该教程中您将学习如何测试工作流。详情请参见 测试任务。

 测试任务
 更新时间：2017-06-07 13:26:11


 工作流提交后，即可对整个工作流手动在调度上试运行一次，目的是看运行过程中代码、调度配置是否符合预期。（注意测试运行是真正的在跑任务，结果是真实的结果。）具体操作步骤如下：

 方式一：
 步骤1：紧接上个章节，在整体视图页面右击节点，点击“测试节点”，在弹出的业务日期选择框里选择业务日期，点击“生成并运行”。



 步骤2：前往运维中心查看工作流测试情况。



 点击“前往查看冒烟结果”会直接跳到运维中心>>任务运维>>测试页面中且定位到具体的工作流测试实例。

 1

 步骤3：查看任务具体运行日志。不管是执行成功还是失败，都应该去查看一次每个节点的运行日志，如查看真正运行的代码是什么，查看生产的节点实例的SKYNET_BIZDATE是否就是选择的测试业务日期，查看使用的调度参数是否正常替换等。

 方式二：
 步骤1：进入运维中心>>任务管理，搜索到本任务，选择后，在右边的DAG图里对工作流右键->测试节点。



 步骤2：选择需要测试的业务日期，点击“生成并运行”。



 点击后会直接跳到测试模块，且定位到具体的工作流测试实例。

 1

 步骤3：查看任务具体运行日志。不管是执行成功还是失败，都应该去查看一次每个节点的运行日志，如查看真正运行的代码是什么，查看生产的节点实例的SKYNET_BIZDATE是否就是选择的测试业务日期，查看使用的调度参数是否正常替换等。

 【注意】：由于本示例准备的数据仅仅是2015/04/15—2015/08/15 四个月的数据，而测试的时候只挑了1天的数据来测试，那么除了同步任务能看出具体结果外，3个sql类型节点由于是要加工前3个月或者前7/3天的数据，只跑一天的数据对于sql任务来说只能测试查看代码和调度配置是否正常而已，无法看最终结果表的结果是否符合预期，所以一般情况下工作流配置好后，我们会通过补数据方式把前面已有的数据都导入ODPS表中并进行加工处理，补数据操作请看后面小章节。


 补数据
 更新时间：2017-06-07 13:26:11


 补数据可以对工作流/节点操作执行发生在过去的一段时间的调度。如本示例中数据是2015/04/15—2015/08/15 四个月的时间，补数据的时候可以分1次或2次操作把这段时间的工作流实例全部生成好。具体操作如下：

 进入运维中心>>任务管理>>工作流管理>>定义页面，搜索到本工作流，选择后，在右边的DAG图里对工作流右键->补数据任务。

 这里分开两次操作，先补2015/04/15—2015/06/15业务日期，点击“运行选择工作流”后会生产补数据实例，页面跳到“补数据”模块，并定位到具体的工作流。

 生产好补数据实例后接下来就是等待运行结果并查看具体运行情况。






















