第1章 数据仓库、商业智能及维度建模初步
1.1 数据获取与数据分析的区别
1.2 数据仓库与商业智能的目标
1.3 维度建模简介
1.3.1 星型模式与OLAP多维数据库
1.3.2 用于度量的事实表
1.3.3 用于描述环境的维度表
1.3.4 星型模式中维度与事实的连接
1.4 Kimball的DW/BI架构
1.4.1 操作型源系统
1.4.2 获取.转换_加口载(ETL)系统
1.4.3 用于支持商业智能决策的展现区
1.4.4 商业智能应用
1.4.5 以餐厅为例描述Kimball架构
1.5 其他DW/BI架构
1.5.1 独立数据集市架构]
1.5.2 辐射状企业信息工厂Inmon架构
1.5.3 混合辐射状架构与Kimball架构
1.6 维度建模神话
1.6.1 神话1：维度模型仅包含汇总数据
1.6.2 神话2：维度模型是部门级而不是企业级的
1.6.3 神话3：维度模型是不可扩展的
1.6.4 神话4：维度模型仅用于预测
1.6.5 神话5：维度模型不能被集成
1.7 考虑使用维度模型的


------------------------------

第2章 Kimball维度建模技术概述
2.1 基本概念
2.1.1 收集业务需求与数据实现
2.1.2 协作维度建模研讨
2.1.3 4步骤维度设计过程
2.1.4 业务过程
2.1.5 粒度
2.1.6 描述环境的维度
2.1.7 用于度量的事实
2.1.8 星型模式与OLAP多维数据库
2.1.9 方便地扩展到维度模型
2.2 事实表技术基础
2.2.1 事实表结构
2.2.2 可加、半可加、不可加事实
2.2.3 事实表中的空值
2.2.4 一致性事实
2.2.5 事务事实表
2.2.6 周期快照事实表
2.2.7 累积快照事实表
2.2.8 无事实的事实表
2.2.9 聚集事实表或OLAP多维数据库
2.2.1 0合并事实表
2.3 维度表技术基础
2.3.1 维度表结构
2.3.2 维度代理键
2.3.3 自然键、持久键和超自然键
2.3.4 下钻
2.3.5 退化维度
2.3.6 非规范化扁平维度
2.3.7 多层次维度
2.3.8 文档属性的标识与指示器
2.3.9 维度表中的空值属性
2.3.10 日历日期维度
2.3.11 扮演角色的维度
2.3.12 杂项维度
2.3.13 雪花维度
2.3.14 支架维度
2.4 使用一致性维度集成
2.4.1 一致性维度
2.4.2 缩减维度
2.4.3 跨表钻取
2.4.4 价值链
2.4.5 企业数据仓库总线架构
2.4.6 企业数据仓库总线矩阵
2.4.7 总线矩阵实现细节
2.4.8 机会／利益相关方矩阵
2.5 处理缓慢变化维度属性
2.5.1 类型0：原样保留
2.5.2 类型1：重写
2.5.3 类型2：增加新行
2.5.4 类型3：增加新属性
2.5.5 类型4：增加微型维度
2.5.6 类型5：增加微型维度及类型1支架
2.5.7 类型6：增加类型1属性到类型2维度
2.5.8 类型7：双类型l和类型2维度
2.6 处理维度层次关系
2.6.1 固定深度位置的层次
2.6.2 轻微参差不齐／可变深度层次
2.6.3 具有层次桥接表的参差不齐／可变深度层次
2.6.4 具有路径字符属性的可变深度层次
2.7 高级事实表技术
2.7.1 事实表代理键
2.7.2 蜈蚣事实表
2.7.3 属性或事实的数字值
2.7.4 日志／持续时间事实
2.7.5 头／行事实表
2.7.6 分配的事实
2.7.7 利用分配建立利润与损失事实表
2.7.8 多种货币事实
2.7.9 多种度量事实单位
2.7.1 0年.日事实
2.7.1 1多遍SQL以避免事实表间的连接
2.7.1 2针对事实表的时间跟踪1
2.7.1 3迟到的事实
2.8 高级维度技术
2.8.1 维度表连接
2.8.2 多值维度与桥接表
2.8.3 随时间变化的多值桥接表
2.8.4 标签的时间序列行为
2.8.5 行为研究分组
2.8.6 聚集事实作为维度属性
2.8.7 动态值范围
2.8.8 文本注释维度
2.8.9 多时区
2.8.10 度量类型维度



第3章 零售业务
第4章 库存
第5章 采购
第6章 订单管理
第7章 会计
第8章 客户关系管理
第9章 人力资源管理
第10章 金融服务
第11章 电信
第12章 交通运输
第13章 教育
第14章 医疗卫生
第15章 电子商务
第16章 保险业务
第17章 KimballDW/BI生命周期概述
第18章 维度建模过程与任务
第19章 ETL子系统与技术
第20章 ETL系统设计与开发过程和任务
第21章 大数据分析



第1章 读本概览
1.1 抑制住立即开始编码的冲动
1.2 设置边界
1.3 数据争夺
1.4 流言终结者
1.5 划分数据世界
1.6 集成式企业数据仓库的必要步骤
1.6.1 集成式：EDW会交付什么
1.6.2 集成的终极试金石
1.6.3 组织挑战
1.6.4 一致化维度和事实
1.6.5 使用总线矩阵与管理层交流
1.6.6 管理集成式EDW的主干
1.6.7 维度管理器
1.6.8 事实提供者
1.6.9 配置商业智能（BI）工具
1.6.10 连带责任
1.7 钻取以寻求原因
1.8 渐变维度
1.8.1 渐变维度的三种原生类型
1.8.2 高级渐变维度
1.9 通过维度评价BI工具
1.10 事实表
1.10.1 忠实于粒度
1.10.2 从最低的可能粒度进行构建
1.10.3 三类事实表
1.11 开发利用事实表
1.11.1 前端：聚合导航
1.11.2 前端：钻取不同的粒度
1.11.3 前端：将约束暴露给不同的业务过程
1.11.4 后端：事实表代理键

第2章 深入研究之前
2.1 Ralph Kimball和施乐帕克研究中心（Xerox PARC）
2.2 数据库市场分化
2.3 提出超市概念（Kimball经典）
2.3.1 危机规划
2.3.2 具有架构的数据集市
2.3.3 一致化维度的重要性
2.3.4 设计一致化维度
2.3.5 做出承诺
2.3.6 允许的一致化维度变体
2.3.7 建立标准事实定义
2.3.8 粒度的重要性
2.3.9 更高级别的数据集市
2.3.10 解决烟囱问题
2.3.11 不需要一致化维度的情形
2.3.12 清晰视角
2.4 数据仓库的全新需求
2.5 应对全新需求
2.5.1 数据集市和维度建模
2.5.2 将数据集市插入数据仓库总线架构中
2.6 挑起事端
2.7 设计约束和不可避免的现实
2.7.1 设计约束
2.7.2 不可避免的现实
2.7.3 摆脱困境

第3章 项目/程序规划
第4章 需求定义
第5章 数据架构
第6章 维度建模基础
第7章 维度建模任务和职责
第8章 事实表核心概念
第9章 维度表核心概念
第10章 更多的维度模式和注意事项
第11章 后台ETL和数据质量
第12章 技术架构注意事项
第13章 前台商业智能应用程序
第14章 维护和发展的注意事项


第1章 决策支持系统的发展
1.1 演化
1.2 自然演化式体系结构的问题
1.3 开发生命周期
1.4 硬件利用模式
1.5 为重建工程创造条件
1.6 监控数据仓库环境
1.7 小结
第2章 数据仓库环境
2.1 数据仓库的结构
2.2 面向主题
2.3 第1天到第n天的现象
2.4 粒度
2.5 探查与数据挖掘
2.6 活样本数据库
2.7 分区设计方法
2.8 数据仓库中的数据组织
2.9 审计与数据仓库
2.10 数据的同构/异构
2.11 数据仓库中的数据清理
2.12 报表与体系结构化环境
2.13 各种环境中的操作型窗口
2.14 数据仓库中的错误数据
第3章 设计数据仓库
3.1 从操作型数据开始
3.2 数据/过程模型与体系结构化环境
3.3 数据仓库与数据模型
3.4 数据模型与迭代式开发
3.5 规范化/反向规范化
3.6 元数据
3.7 数据周期——时间间隔
3.8 转换和集成的复杂性
3.9 数据仓库记录的触发
3.10 概要记录
3.11 管理大量数据
3.12 创建多个概要记录
3.13 从数据仓库环境到操作型环境
3.14 数据仓库数据的直拉操作型访问
3.15 数据仓库数据的间接访问
3.16 数据仓库数据的间接使用
3.17 星形连接
3.18 支持操作型数据存储
3.19 需求和Zachman框架
第4章 数据仓库中的粒度
4.1 粗略估算
4.2 规划过程的输入
4.3 溢出存储器中的数据
4.4 确定粒度级别
4.5 一些反馈循环技巧
4.6 确定粒度级别的几个例子
4.7 填充数据集市
第5章 数据仓库和技术
5.1 管理大量数据
5.2 管理多种介质
5.3 索引和监控数据
5.4 多种技术的接口
5.5 程序员/设计者对数据存放位置的控制
5.6 数据的并行存储和管理
5.7 语言接口
5.8 数据的有效装裁
5.9 有效利用索引
5.10 数据压缩
5.11 复合主键
5.12 变长数据
5.13 加锁管理
5.14 只涉及索引的处理
5.15 快速恢复
5.16 其他的技术特征
5.17 DBMS类型和数据仓库
5.18 改变DBMS技术
5.19 多维DBMS和数据仓库
5.20 在多种存储介质上构建数据仓库
5.21 数据仓库环境中元数据的角色
5.22 上下文和内容
5.23 刷新数据仓库
5.24 测试问题
第6章 分布式数据仓库
第7章 主管信息系统和数据仓库
第8章 外部数据与数据仓库
第9章 迁移到体系结构化环境
第10章 数据仓库和Web
第11章 非结构化数据和数据仓库
第12章 大型数据仓库
第13章 关系模型和多维模型数据库设计基础
第14章 数据仓库高级话题
第15章 数据仓库的成本论证和投资回报
第16章 数据仓库和ODS
第17章 企业信息依从准则和数据仓库
第18章 最终用户社区
第19章 数据仓库设计的复查要目

第1章 数据仓库的概念与体系结构
1．1 数据仓库的兴起
1．1．1 数据管理技术的发展
1．1．2 数据仓库的萌芽
1．2 数据仓库的基本概念
1．2．1 元数据
1．2．2 数据粒度
1．2．3 数据模型
1．2．4 ETL
1．2．5 数据集市
1．3 数据仓库的特点与组成
1．3．1 数据仓库的特点
1．3．2 数据仓库的组成
1．4 数据仓库的体系结构
1．4．1 传统的数据仓库体系结构
1．4．2 传统数据仓库系统在大数据时代所面临的挑战
1．4．3 大数据时代的数据仓库
习题

第2章 数据
2．1 数据的概念与内容
2．2 数据属性与数据集
2．3 数据预处理
2．3．1 数据预处理概述
2．3．2 数据清洗
2．3．3 数据集成
2．3．4 数据变换
2．3．5 数据归约
习题

第3章 数据存储
3．1 数据仓库的数据模型
3．1．1 数据仓库的概念模型
3．1．2 数据仓库的逻辑模型
3．1．3 数据仓库的物理模型
3．2 元数据存储
3．2．1 元数据的概念
3．2．2 元数据的分类方法
3．2．3 元数据的管理
3．2．4 元数据的作用
3．3 数据集市
3．3．1 数据集市的概念
3．3．2 数据集市的类型
3．3．3 数据集市的建立
3．4 大数据存储技术
3．4．1 大数据的概念
3．4．2 传统数据库的局限
3．4．3 NoSQL数据库
3．4．4 几种主流的NoSQL数据库

第4章 OLAP与数据立方体
4．1 OLAP的概念4．1．1 OLAP的定义
4．1．2 OLAP的准则
4．1．3 OLAP的特征
4．2 多维分析的基本分析动作
4．2．1 切片
4．2．2 切块
4．2．3 钻取
4．2．4 旋转

第5章 数据挖掘基础
第6章 关联挖掘
第7章 聚类分析
第8章 分类
第9章 神经网络
第10章 统计分析
第11章 非结构化数据挖掘
第12章 知识图谱
第13章 大数据挖掘算法


第1章 实时数据仓库技术概述
1．1 数据仓库技术
1．1．1 数据仓库的定义
1．1．2 数据仓库的特点
1．1．3 数据仓库的体系结构
1．1．4 数据仓库的模型
1．2 实时数据仓库技术
1．2．1 实时数据仓库的定义
1．2．2 实时数据仓库的新挑战
1．2．3 实时数据仓库的体系结构
1．2．4 实时数据仓库与传统数据仓库的比较
1．3 MapReduce技术
1．3．1 MapReduce编程模式
1．3．2 MapReduce框架的实现
1．3．3 Hadoop

第2章 实时数据仓库体系结构
2．1 实时数据仓库体系结构的设计
2．2 ODS分区
2．3 双镜像交替分区
2．4 数据仓库副本分区
2．5 多级缓存分区机制
2．5．1 缓存的数据新鲜度
2．5．2 缓存的更新算法
2．5．3 多级缓存分区机制的查询
2．5．4 查询冲突问题的解决
2．6 几种实时数据存储区的比较

第3章 变化数据捕获
3．1 变化数据捕获方法
3．1．1 基于数据源表的时间戳标注
3．1．2 基于日志的被动数据变化的捕获
3．1．3 基于触发器的主动数据变化的捕获
3．2 基于LogMiner的变化数据捕获
3．2．1 Oracle日志简述
3．2．2 Oracle日志的两种模式
3．2．3 LogM：iner进行日志挖掘的基本流程
3．3 基于CDC的变化数据捕获
3．3．1 CDC工具捕获变化数据概述
3．3．2 CDC相关的数据库对象
3．3．3 对变化数据处理
3．3．4 CDC捕获模块流程设计

第4章 更新查询调度技术
4．1 更新查询调度技术概述
4．2 基于优先级的更新与查询平衡调度
4．2．1 系统模型
4．2．2 在线日志捕获数据
4．2．3 系统性能参数
4．2．4 PBBS调度算法
4．2．5 并行一致性控制策略
4．2．6 小结
4．3 支持Qos的更新和查询任务调度
4．3．1 概述
4．3．2 系统模型
4．3．3 查询任务的时间估算
4．3．4 调度算法
4．3．5 小结

第5章 实时数据仓库并行查询
5．1 概述
5．2 MapRecluee的基本流程
5．3 基于MapReclUee的并行关系运算
5．3．1 选择和投影运算
5．3．2 连接运算
5．3．3 除运算
5．3．4 聚集运算
5．4 基于分块结构的分布式数据库ChunkDB
5．4．1 ChunkDB的整体架构
5．4．2 ChunkDB分布式数据库
5．5 基于ChunkDB数据库的MapRecluee计算
5．5．1 基于ChunkDB的Maptleduee计算实现流程
5．5．2 DBInputFormat数据接口扩展
5．6 ChunkDB性能评估
5．6．1 评估环境
5．6．2 查询性能评价
5．6．3 集群规模的影响

第6章 实时数据立方技术
6．1 概述
6．2 基础知识
6．2．1 数据立方Cube
6．2．2 Dwarf数据立方
6．2．3 MapRedllice
6．3 基于MapReduee的数据立方构建
6．4 Dwarf立方的分割
6．4．1 Dwarf立方的基础划分
6．4．2 Dwarf立方的多维划分
6．5 并行Dwarf数据立方
6．5．1 并行Dwarf的建立
6．5．2 并行Dwarf的查询
6．5．3 并行Dwarf的更新
6．5．4 并行Dwarf的优化
6．6 并行Dwarf性能分析
6．6．1 评估环境
6．6．2 Dwarf的建立和存储性能
6．6．3 Dwarf立方的查询性能
6．6．4 Dwarf立方的更新性能
6．6．5 集群节点数量的影响

第7章 MR-RTDWH系统
7．1 MR．RTDWH概述
7．2 MR-RTDwH系统设计
7．2．1 系统设计目标
7．2．2 系统体系结构
7．2．3 传统ETL模块
7．2．4 实时ETL模块
7．2．5 实时数据仓库存储
7．2．6 更新查询调度模块
7．2．7 M印Reduce并行计算模块
7．2．8 MR-RTDWH系统实现


1.3　大数据的定义4
1.4　为什么需要大数据？为什么是现在4
1.5　大数据示例5
1.5.1　社交媒体的文章5
1.5.2　调查数据分析6
1.5.3　调查数据7
1.5.4　气象数据8
1.5.5　Twitter数据8
1.5.6　集成和分析8
1.5.7　附加数据的类型10

第2章　使用大数据12
2.1　引言12
2.2　数据爆炸12
2.3　数据体量13
2.3.1　机器数据14
2.3.2　应用日志14
2.3.3　点击流日志14
2.3.4　外部或第三方数据15
2.3.5　电子邮件15
2.3.6　合同15
2.3.7　地理信息系统和地理空间数据16
2.3.8　示例：Funshots公司17

2.4　数据速度19
2.4.1　Amazon、Facebook、Yahoo和Google19
2.4.2　传感器数据19
2.4.3　移动网络20
2.4.4　社交媒体20
2.5　数据多样性21


第3章　大数据处理架构23

3.2　再论数据处理23
3.3　数据处理技术24
3.4　数据处理基础设施的挑战25
3.4.1　存储25
3.4.2　传输25
3.4.3　处理26
3.4.4　速度或吞吐量26

3.5　全共享架构与无共享架构的比较26
3.5.1　全共享架构27
3.5.2　无共享架构27
3.5.3　OLTP与数据仓库28

3.6　大数据处理28
3.6.1　基础设施方面31
3.6.2　数据处理方面32

3.7　电信大数据研究32
3.7.1　基础设施34
3.7.2　数据处理34


第4章　大数据技术简介35

4.2　分布式数据处理36
4.3　大数据处理需求38
4.4　大数据处理技术39

4.5　Hadoop42
4.5.1　Hadoop核心组件43
4.5.2　Hadoop总结69

4.6　NoSQL69
4.6.1　CAP定理69
4.6.2　键-值对：Voldemort70
4.6.3　列簇存储：Cassandra70
4.6.4　文档数据库：Riak76
4.6.5　图数据库77
4.6.6　NoSQL小结78
4.7　文本ETL处理78


第5章　大数据驱动的商业价值80
5.1　引言80
5.2　案例研究1：传感器数据81
5.2.1　摘要81
5.2.2　Vestas81
5.2.3　概述81
5.2.4　利用风力发电81
5.2.5　把气候变成资本82
5.2.6　跟踪大数据的挑战83
5.2.7　维持数据中心的能源效率83
5.3　案例研究2：流数据84
5.3.1　摘要84
5.3.2　监控和安全：TerraEchos84
5.3.3　需求84
5.3.4　解决方案84
5.3.5　效益84
5.3.6　先进的光纤网结合实时流数据85
5.3.7　解决方案组件85
5.3.8　扩展安全边界创建战略优势85
5.3.9　关联传感器数据使得假阳性率为零86
5.4　案例研究3：通过大数据分析改善患者预后86
5.4.1　摘要86
5.4.2　业务目标87
5.4.3　挑战87
5.4.4　概述：给从业人员新的洞察以指导患者护理87
5.4.5　挑战：将传统数据仓库生态系统与大数据融合87
5.4.6　解决方案：为大数据分析做好准备88
5.4.7　结果：消除“数据陷阱”88
5.4.8　为什么是aster88
5.4.9　关于Aurora89
5.5　案例研究4：安大略大学技术学院—利用关键数据，提供积极的患者护理89
5.5.1　摘要89
5.5.2　概述89
5.5.3　商业上的收益90
5.5.4　更好地利用数据资源90
5.5.5　智慧医疗保健91
5.5.6　解决方案组件91
5.5.7　融合人类知识与技术92
5.5.8　扩大Artemis的影响92
5.6　案例研究5：微软SQL Server客户解决方案93
5.6.1　客户画像93
5.6.2　解决方案的亮点93
5.6.3　业务需求93
5.6.4　解决方案94
5.6.5　好处94
5.7　案例研究6：以客户为中心的数据集成95
5.7.1　概述95
5.7.2　解决方案设计98
5.7.3　促成更好的交叉销售和追加销售的机会99
5.8　总结100
第二部分　数据仓库
第6章　再论数据仓库102
6.1　引言102
6.2　传统的数据仓库或DW 1.0103
6.2.1　数据架构103
6.2.2　基础设施104
6.2.3　数据仓库的陷阱106
6.2.4　建立数据仓库的架构方法111
6.3　DW 2.0113
6.3.1　Inmon的DW 2.0概述114
6.3.2　DSS 2.0概述115
6.4　总结116
延伸阅读116
第7章　数据仓库的再造118
7.1　引言118
7.2　企业数据仓库平台118
7.2.1　事务型系统119
7.2.2　运营数据存储区119
7.2.3　分段区120
7.2.4　数据仓库120
7.2.5　数据集市120
7.2.6　分析型数据库121
7.2.7　数据仓库的问题121
7.3　再造数据仓库的选择122
7.3.1　平台再造122
7.3.2　平台工程123
7.3.3　数据工程124
7.4　使数据仓库现代化125
7.5　使数据仓库现代化的案例研究127
7.5.1　当前状态分析127
7.5.2　推荐127
7.5.3　现代化的业务收益128
7.5.4　一体机的选择过程128
7.6　总结132
第8章　数据仓库中的工作负载管理133
8.1　引言133
8.2　当前状态133
8.3　工作负载的定义134
8.4　了解工作负载135
8.4.1　数据仓库输出136
8.4.2　数据仓库输入137
8.5　查询分类138
8.5.1　宽/宽138
8.5.2　宽/窄139
8.5.3　窄/宽139
8.5.4　窄/窄139
8.5.5　非结构化/半结构化数据140
8.6　ETL和CDC的工作负载140
8.7　度量141
8.8　当前系统设计的局限142
8.9　新工作负载和大数据143
8.10　技术选择144
8.11　总结144
第9章　应用到数据仓库的新技术145




title	categories	tags	date
数据仓库的一些建议
随笔
数据仓库
2018/09/10 19:25:25
没有哪个胜利者信仰机遇。

0x00 概述
大数据时代，作为数据的掌握者，我们不仅要更好地使用数据，也要更好地管理数据。而数据仓库正是这样一套管理和组织数据的解决方案。

本文试图从一种经验的角度来描述在数据仓库建设中的会遇到的各种坑和需要注意的关键点，希望以此帮助踏上数据仓库之路的小伙伴们。

注意：本文不会详细地解释数据仓库的各个概念，亦不会给出各种示例代码来阐述数据仓库的建设细节。

0x01 正文
一、请理解数据仓库和数据平台的区别
当你开始建设数据仓库之前，需要明白数据仓库和数据平台是两个不同的概念，不要把搭建一套 Hadoop + Hive 的平台叫数据仓库，这是数据平台的范畴。

我们常说的数据仓库不仅仅是指数据接入、数据存储和数据计算，它也要包括数据治理、数据建模和数据挖掘。比如元数据管理、维度建模和 OLAP 分析，这些都是我们在建设数据仓库时候要考虑的内容。

二、提前规划你的数据仓库
数据仓库是公司数据体系的核心模块，数据仓库可以做的不好，但是不能不做。

因此，在数据体系设计的前期最好要有一定的规划，即使最简单的表和字段命名的规范也能带来很大的收益。

另外，从数据开发的角度出发，在做各种临时数据处理需求的时候也要有数据仓库的思维，多尝试抽象出来数据中间层，这样对公司和对自己的成长都是有帮助的。

三、实现轻量级的数据仓库
如果业务的快速发展不能留给你太多的时间来实现一个完善的数据仓库，那么可以考虑在前期实现一个轻量级的数据仓库，以尽可能小的成本带来最大收益。关于这个轻量级的数据仓库，建议优先考虑如下几个点：

明确数据分层

确定可执行的表和字段命名规范

定期抽象出常用的中间表

建设元数据管理系统，或者建设文档库，提供中间表的文档说明

四、不要脱离业务场景
做数据一定要记得贴近业务，虽说会有很多临时和重复需求，但却能切实地创造价值。

切记不要以为可以完全脱离业务去做一套数据仓库，我们可以在数据仓库的某个层次不以业务需求为导向来设计，但是最终面向业务的数据一定会是和业务理解有关。

五、文档！文档！
数据仓库建设的初期，要逐步沉淀出各种文档，比如模型设计文档、字段命名规范文档、SQL 开发规范文档。文档是数据仓库沉淀的最直观的一种体现，这也是技术积累的一部分。

最重要的是，如果元数据系统没有成型，那就要把数据仓库中间表的内容沉淀到文档中，尽量做到一表一文档。这样不管是从节约沟通成本的角度，亦或是增加团队积累，更或是完成 KPI 的角度考虑，都是有很大益处的。

六、尽早布局数据质量管理
请尽早布局数据质量管理的内容，不要等到发生严重的数据事故后才注意到数据质量问题。关于数据质量监控，如果没有足够的时间和精力做一套完整的系统，可以先从以下几个点入手，这样至少能对自己有一层基本的保护：

核心数据每日数据量级监控和告警
重要业务指标监控和告警
主要业务流程各阶段数据的监控和告警
七、多使用视图表
多使用视图表对外提供数据服务，它可以有效地屏蔽业务方对最底层表结构变更的感知，同时加强权限管理。

如下场景可以多考虑使用视图表：

该表经常会有加字段的需求
该表的计算口径会出现变化，需要并行跑多份数据，某个时间点进行表切换
该表可能会对不同人或部门提供服务，希望不同人或部门可读的字段不同
视图表主要是来晚上表结构变更、口径修改和权限管理的场景，不要滥用而增加维护成本。

八、考虑你的职业发展
不要一直埋着头搞 ETL，可以搞半年或一年来了解大致的业务和技能，但不能长期这样发展。现在开源平台相对成熟，长时间搞 ETL，会弱化自己的技术深度，如果再没有数据挖掘相关的项目经验，很容易在以后得面试中被淘汰。

因此，建议各位数据开发的小伙伴，如果你近一年的工作主要都是在用 SQL 做 ETL，那就要有一点危机意识，经常反思一下自己是否有成长，核心竞争力是否有所提现。

如果有些心虚，可以考虑在数据仓库、数据挖掘或者核心平台开发上下一些功夫。

0x00 前言
本篇聊一聊在做数据仓库的时候该如何确定 KPI。

0x01 思考角度
首先，要明确的一点是**数据最终是要服务于业务的！**但是，数据仓库一般又不直接对接于业务，而更多地对接数据分析系统、用户画像系统和推荐或广告系统等。因此不容易用业务指标来衡量数据仓库的效果。

那么我们可以换一个角度，从数据仓库要解决的问题来考虑。简单地讲，数据仓库要做的是提高数据能力、提高数据分析效率、提高数据质量的。

那么，怎样既体现了服务业务，又体现了提高了整体的数据服务能力呢？这就是下面要讨论的 KPI 怎么定。

0x02 怎样定 KPI
定 KPI 在某种程度上也可以理解为工作的评价标准。对于数据建设来讲，我们可以从工作内容是否可量化的角度来考虑。

个人认为真正价值最高的是那部分不可量化或者不容易量化的工作内容。这些工作可以是：一、数据仓库整体的设计（比如主题设计、通用维度的设计、数据分层的设计）；二、数据规范的设计（比如说表和字段命名规范、Sql 编写规范）。

对于这部分内容，居士建议可以通过写文档的形式体现，最终统计出这些工作带来的效果（KPI 之一）：

比如说需要写多少和数据仓库设计相关的文档
有哪些业务相关的表将会按照你的设计来卡发
优化了多少数据分析的流程
上面的内容更多的像是品牌影响力，不容易体现具体的工作产出。我们聊一下相对容易量化的工作内容。比如说中间表对业务方的支持情况，解决了多少业务的痛点，提高了多少的数据质量等等。

具体到点的话，大致可以总结出下面的一些内容（KPI 之二）：

将要解决哪些业务问题（多少业务、多少报表用了你的中间表）

将会替换多少原始表的使用频率（比如数据分析查询你的表的次数，以前都是查原始日志的）

将要解决了多少数据口径不一致，数据质量的问题（可以加上告警，统计出来提前发现了多少数据问题）

0x03 举个栗子
上面列了一些居士大致思考的一些点，在具体写 KPI 的时候，可以从中选三四条。

举个简单的栗子，仅供参考：

完成数据仓库的设计，包括主题设计、数据分层和表字段命名等内容，完成10篇以上 Wiki
完成店铺主题相关的中间表的设计和开发，满足90%的数据分析需求。
完成基本的数据监控功能，能够监控关键数据的数据迟到、掉零、环比等内容。

已完成数据仓库设计相关文档的编写，总计25篇 Wiki，总阅读量10w。
已完成店铺主题相关的中间表的设计和开发，共计15张中间表，日均访问次数400次，占店铺主题相关总任务数的98%。
完成基本的数据监控功能，共计监控380张业务表，提前发现了14起数据异常。
0xFF 总结
上面就是数据仓库相关的 KPI 该怎么定的内容，具体的内容要和现实的业务情况相结合，因此本文仅起到抛砖引玉的作用，希望读者朋友们看后能有一些启发。

不足之处多多指出，一起交流进步。

祝各位童鞋升职加薪，早日走向人生巅峰。

0x00 概述
半年前推荐过一波数据仓库相关的书单，现在应读者朋友们的要求，更新一波推荐的书单！

和以前一样，居士只会推荐自己认真读过的书，没仔细看过的书是不会放出来的。推荐图书的范围主要是和数据建设相关的，具体内容看下文即可知。每本书有一个推荐的星级，5星为最佳。

补充一下，推荐的这几本书，均可在各大网上商城买到，暂不推荐已经不再版的图书，所以不要再找居士要电子版了。

0x01 书单
一、《大数据之路：阿里巴巴大数据实践》 5星
阿里的大数据最佳实践，基本上讲了阿里在大数据实践上的方方面面，特别是数据模型的设计和实践，理论和实践结合的比较好，是我目前看到最好的一本书。

该书可作为整个数据体系建设的参考书，从数据平台到数据仓库到数据应用，都有比较不错的讲解。另外，本书的很多论述可以用作方案设计、老板汇报、晋升答辩等，值得反复看。

二、《数据仓库工具箱（第3版）：维度建模权威指南》 5星
英文名：《The DataWarehouse Toolkit-The Complete Guide to Dimensona Modeling》

还是有一些抽象的概念，零基础来读，可能要花点时间，毕竟经典的数据都需要一些上层次抽象的概念。

三、《数据驱动：从方法到实践》 4.5星
百度大神桑文锋出的书，现在是神策数据创始人兼CEO。

这本书内容很棒，个人感觉主要是从数据分析的视野来讲解整个数据体系，基本把数据相关的方法论讲了一遍，适合所有从事数据工作的童鞋看一下。

书中列出来很多实际工作中会遇到的坑，也都给出了一定的解决思路，但是个人感觉文中涉及到的技术比较少，更多的是各种思路和方法论。


四、《大数据日知录》 4.5星
这本书主要偏向于各种大数据系统的原理，是居士翻的最多的一本技术书了，基本上把现在流行的大数据组件都介绍了一遍，深度和广度都有，每章内容后面也都有相应的论文推荐。

推荐这本书的原因就在于现在大部分互联网公司的数据仓库都是基于这一套大数据框架来的，更准确的来讲，大家其实都是先工程，后理论，因此这本书可以作为对大数据生态的一览。

五、《数据挖掘：概念与技术（原书第3版）》 4星
这是一本数据挖掘的书，但是没关系，数据仓库本身就是和数据挖掘息息相关的，或者是说数据仓库是数据挖掘的支撑。这本书的前5章十分值得一读，它讲了其它书没有深入讲的OLAP和数据立方体技术，比如说Kylin构建Cube，其实看看这本书的第五章基本就知道是怎么回事了。

所以强烈推荐看了这本书，至少是前5五章。

六、《美团机器学习实践》4星
美团的技术公众号近段时间经常会更新一些干货文章，本书风格也是如此，相当干货，因此本书刚一面世就让美团的朋友送了一本。

这本书主要是关于机器学习实践的书，可读性很强，都是一些实际案例的讲解，个人认为本书和阿里的大数据之路很类似，都是实战性很强干货十足的书。

本书前面几部分包含了特征工程和用户画像的内容，特别是用户画像体系设计可以参考本书。

0x02 补充
前面推荐的都是居士认为很优秀并且自己看的频率比较高的书，下面几本也各有优点。

七、《数据仓库（原书第4版）》
范式是数据库逻辑模型设计的基本理论，一个关系模型可以从第一范式到第五范式进行无损分解。在数据仓库的模型设计中目前一般采用第三范式。范式模型由数据仓库之父 Inmon 提倡，而这本书就是 Inmon 所写。

这本书是我看的第二本数据仓库的书，个人感受是理论比较强，刚开始看基本就是一头雾水，然后当你做了一段时间后，再回头来看这本书会有很多理论指导，比如说元数据该怎么做，模型该怎么设计，参考性很强。

即使工作了一段时间后，来看这本书依旧感觉比较费劲儿，所以本书翻的比较少，只是偶尔想起来会看一下。

八、《数据架构 大数据 数据仓库以及Data Vault》
本书提出了Data Vault这种数据建模方式，但是Data Vault到底是什么，居士理解的也不深，毕竟在工作中没有具体设计过这种模型。但是值得一读，个人意见，前面的书读完之后可以来翻一下本书。

九、《数据天才：数据科学家修炼之道》
本书探讨来数据科学家是什么，会有很多示例以及分析。书的视角和前面几本都有所不同，个人感觉主要是从人的角度来规划数据科学家的发展道路。



0x00 概述
长期从事数据仓库的你，是否还记得数据库设计中的三大范式？在设计数据仓库的表时，是否考虑过规范化和反规范化之间的区别？是否想过数据仓库和数据库在设计中对范式考虑的侧重点是什么？

本文，将包含如下几个方面：

一起回顾数据库设计中经典的三大范式
聊一聊数据仓库和范式之间的关系
聊一聊数据仓库和数据库在范式设计中的侧重点
全文将会围绕一个订单表（假设一个订单中只有一种商品出现）设计的例子，既有数据库中表的设计，亦有数据仓库中表的设计，一个例子贯穿全文，有始有终，简单易懂。

0x01 三范式
首先回顾一下范式是什么：

设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。

目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。

数据库范式有这么多，但是在工作中常用到的一般是前三个范式，因此，本文将只举例分享第一、二、三范式。为了方便理解，先上一个关于各个范式核心点的图镇楼，后面的说明会参考该图来进行。

database-normalization

第零范式
我们暂且将第一种设计称为第零范式，它满足一个基本条件：无重复数据。

如下，是我们按照无范式设计的第一张订单表。虽说该设计将成为一个被挑毛病的坏孩子，但从设计上来看，仍是可被理解的。

database-normalization

如下表格，列几条数据作为例子，该设计的一个问题上字段“购买信息”里面包含了两部分内容：商品价格和购买数量。

用户ID	商品ID	用户地址（省）	用户地址（市）	用户地址（县）	商品名	购买信息（价格，数量）	总金额	购买日期
user_0001	product_0001	xx省	xx市	xx县	手机1号	200，5	1300	20181201
order_0002	product_0003	xx省	xx市	xx县	电脑1号	1000，1	1000	20181202
order_0003	product_0002	xx省	xx市	xx县	手机2号	100，5	500	20181204
第一范式
第一范式的核心在于 Atomic colums（cells have single value），即属性不可分。

该设计和第零范式的区别在于我们将“购买信息”这一个字段拆成了“购买单价”和“购买数量”两个字段，新表满足了第一范式。

database-normalization

第二范式
第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。即在第一范式的基础上满足属性完全依赖于主键。

以第一范式中的设计为例，商品数量、总金额和购买日期是完全依赖于（用户ID，商品ID）的，但是商品名和商品价格只依赖于商品ID，用户信息只依赖于用户ID，这属于部分依赖。

因此，将用户信息和商品信息单独拎出来后，我们的订单表设计就变成了如下三张表：订单表，商品表和用户表。

database-normalization

直观一点来理解第二范式的话，就是说一个数据表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。

第三范式
第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。即在第二范式的基础上满足属性只直接依赖主键。

以第二范式中的设计为例，现在订单表中的信息已经完全依赖于订单ID了，该设计是满足第二范式的。但是在用户表中，用户ID和地址信息是存在传递依赖的，即：用户ID决定地址ID，地址ID决定（省，市，县），这是传递依赖。

因此，我在地址信息表单独拎出来之后就可以设计出如下满足第三范式的表了。

database-normalization

0x02 数据仓库和三范式
以上，简单回顾了一下三范式的内容，下面将分析一下数据仓库中的数据建模和三范式之间的关系。

范式建模
范式建模是数据仓库之父 Bill lnmon 提出的建模方法是从全企业的高度设计一个第三范式的模型，用实体关系（Entity Relationship, ER）模型描述企业业务，在范式理论上符合第三范式。

因此我们可以认为数据仓库中的范式建模，在表的设计上和范式中的第三范式基本上一致的，具体到表的设计是可以如下内容。

database-normalization

维度建模
维度模型是数据仓库领域另一位大师 Ralph Kimball 所倡导，维度建模以分析决策的需求出发构建模型，构建的数据模型为分析需求服务，因此它重点解决用户如何更快速完成分析需求，同时还有较好的大规模复杂查询的响应性能。

维度建模的理论就不再细说，我们只介绍两个主要概念：事实表和维度表。

事实表：我们可以简单地将事实理解为现实中发生的一次操作型事件。比如订单表，我们就可以理解为一张事实表，我们每完成一个订单，就会在订单事实表中增加一条记录。

维度表：我们可以简单地理解维度表包含了事实表中指定属性的相关详细信息。比如商品维度表表和用户维度表。

那么用维度建模的方式进行设计的话，我们会设计如下三张表：订单事实表、商品维度表和用户维度表。这种设计，在范式理论上符合第二范式。

database-normalization

一般大家也会称维度建模是星星模型，可以将事实表当作是中间最大的一颗星星，维度表围绕在事实表周围。星星模型和雪花模型的主要区别在于维度表是否都和事实表直接相连。如下图，将我们的星星模型转换成了雪花模型，比如年维度表并不是直接连在订单事实表上，而是连在日期维度表上。

因此，简单点来讲，我们可以认为星星模型是将同一主题的维度信息冗余在了一张维表中。

database-normalization

有冗余的事实表
在维度建模中我们聊到了事实表的设计，它其实是符合第二范式的设计，但是在实际工作中我们经常会在事实表中存放更多的信息，以便更好地满足业务需求。

如下图，我们会将用户信息和商品信息都冗余到订单事实表中，在这种情况下，该事实表的设计在范式理论上符合第一范式。

database-normalization

0x03 数据仓库和数据库的侧重点
在大部分的数据仓库设计中，一般是不怎么考虑是否满足第几范式的，特别是互联网场景下的数据建设就更少考虑数据仓库和范式之间的关系，但是这并不妨碍我们去理解它们设计背后的出发点。至少我们可以搞明白为什么数据仓库设计不用过多关注范式。

我们这里聊到的数据库的设计，可以理解是联机事务处理OLTP（On-Line Transaction Processing），主要是基本的、日常的事务处理，例如银行交易。直白点讲，就是各种增删改查，需要对数据进行操作。而数据仓库，我们可以理解为是联机分析处理OLAP（On-Line Analytical Processing），主要是面向日常数据分析，它的数据主要是插入和查询，基本不涉及删除和修改操作。

本文的主人公-范式，主要优化的是增删改的问题，比如数据冗余、更新异常、删除异常等。这些也正是数据库设计比较关注的点。而数据仓库对这方面的关注度则比较少，数据仓库更关注的是使用是否方便，查询效率是否高，因此在设计数据仓库的时候不必太多关注范式的设计，一般第一或者第二范式就够用。

另外，数据仓库不同层级的设计也会用到不同的建模方式，比如说接近业务数据的层次，会更倾向使用范式建模，接近数据分析的层次则会更倾向于维度建模，这个话题会在数据分层的文章中有更详细的讲解。

0xFF 总结
本文主要是聊一聊数据仓库和范式之间的关系，算是对数据仓库相关理论的一种梳理。虽说对日常工作的影响不大，但是仍可以作为补充知识的学习。

===============

0x00 概述
数据分层是数据仓库设计中十分重要的一个环节，优秀的分层设计能够让整个数据体系更易理解和使用。而目前网络中大部分可以被检索到相关文章只是简单地提及数据分层的设计，或缺少明确而详细的说明，或缺少可落地实施的方案，或缺少具体的示例说明。

因此，本文将指出一种通用的数据仓库分层方法，具体包含如下内容：

介绍数据分层的作用
提出一种通用的数据分层设计，以及分层设计的原则
举出具体的例子说明
提出可落地的实践意见
0x01 数据分层？

这应该是数据仓库同学在设计数据分层时首先要被挑战的问题，类似的问题可能会有很多，比如说“为什么要做数据仓库？”、“为什么要做元数据管理？”、“为什么要做数据质量管理？”。当然，这里我们只聊一下为什么要做设计数据分层。

作为一名数据的规划者，我们肯定希望自己的数据能够有秩序地流转，数据的整个生命周期能够清晰明确被设计者和使用者感知到。直观来讲就是如下的左图这般层次清晰、依赖关系直观。

但是，大多数情况下，我们完成的数据体系却是依赖复杂、层级混乱的。如下的右图，在不知不觉的情况下，我们可能会做出一套表依赖结构混乱，甚至出现循环依赖的数据体系。

data-layer-intro

因此，我们需要一套行之有效的数据组织和管理方法来让我们的数据体系更有序，这就是谈到的数据分层。数据分层并不能解决所有的数据问题，但是，数据分层却可以给我们带来如下的好处：

清晰数据结构：每一个数据分层都有它的作用域和职责，在使用表的时候能更方便地定位和理解
减少重复开发：规范数据分层，开发一些通用的中间层数据，能够减少极大的重复计算
统一数据口径：通过数据分层，提供统一的数据出口，统一对外输出的数据口径
复杂问题简单化：将一个复杂的任务分解成多个步骤来完成，每一层解决特定的问题
0x02 一种通用的数据分层设计
为了满足前面提到数据分层带来的好处，我们将数据模型分为三层：数据运营层（ ODS ）、数据仓库层（DW）和数据应用层（APP）。如下图所示。简单来讲，我们可以理解为：**ODS层存放的是接入的原始数据，DW层是存放我们要重点设计的数据仓库中间层数据，APP是面向业务定制的应用数据。**下面详细介绍这三层的设计。

data-layer-intro

一、数据运营层：ODS（Operational Data Store）
“面向主题的”，数据运营层，也叫ODS层，是最接近数据源中数据的一层，数据源中的数据，经过抽取、洗净、传输，也就说传说中的 ETL 之后，装入本层。本层的数据，总体上大多是按照源头业务系统的分类方式而分类的。

一般来讲，为了考虑后续可能需要追溯数据问题，因此对于这一层就不建议做过多的数据清洗工作，原封不动地接入原始数据即可，至于数据的去噪、去重、异常值处理等过程可以放在后面的DWD层来做。

二、数据仓库层：DW（Data Warehouse）
数据仓库层是我们在做数据仓库时要核心设计的一层，在这里，从 ODS 层中获得的数据按照主题建立各种数据模型。DW层又细分为 DWD（Data Warehouse Detail）层、DWM（Data WareHouse Middle）层和DWS（Data WareHouse Servce）层。

1. 数据明细层：DWD（Data Warehouse Detail）

该层一般保持和ODS层一样的数据粒度，并且提供一定的数据质量保证。同时，为了提高数据明细层的易用性，该层会采用一些维度退化手法，将维度退化至事实表中，减少事实表和维表的关联。

另外，在该层也会做一部分的数据聚合，将相同主题的数据汇集到一张表中，提高数据的可用性，后文会举例说明。

2. 数据中间层：DWM（Data WareHouse Middle）

该层会在DWD层的数据基础上，对数据做轻度的聚合操作，生成一系列的中间表，提升公共指标的复用性，减少重复加工。

直观来讲，就是对通用的核心维度进行聚合操作，算出相应的统计指标。

3. 数据服务层：DWS（Data WareHouse Servce）

又称数据集市或宽表。按照业务划分，如流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP分析，数据分发等。

一般来讲，该层的数据表会相对比较少，一张表会涵盖比较多的业务内容，由于其字段较多，因此一般也会称该层的表为宽表。

在实际计算中，如果直接从DWD或者ODS计算出宽表的统计指标，会存在计算量太大并且维度太少的问题，因此一般的做法是，在DWM层先计算出多个小的中间表，然后再拼接成一张DWS的宽表。由于宽和窄的界限不易界定，也可以去掉DWM这一层，只留DWS层，将所有的数据在放在DWS亦可。

三、数据应用层：APP（Application）
在这里，主要是提供给数据产品和数据分析使用的数据，一般会存放在 ES、PostgreSql、Redis等系统中供线上系统使用，也可能会存在 Hive 或者 Druid 中供数据分析和数据挖掘使用。比如我们经常说的报表数据，一般就放在这里。

四、维表层（Dimension）
最后补充一个维表层，维表层主要包含两部分数据：

高基数维度数据：一般是用户资料表、商品资料表类似的资料表。数据量可能是千万级或者上亿级别。
低基数维度数据：一般是配置表，比如枚举值对应的中文含义，或者日期维表。数据量可能是个位数或者几千几万。
至此，我们讲完了数据分层设计中每一层的含义，这里做一个总结便于理解，如下图。

data-layer-intro

0x03 举个栗子
趁热打铁，举个栗子说明一下，如下图，可以认为是一个电商网站的数据体系设计。我们暂且只关注用户访问日志这一部分数据。

在ODS层中，由于各端的开发团队不同或者各种其它问题，用户的访问日志被分成了好几张表上报到了我们的ODS层。
为了方便大家的使用，我们在DWD层做了一张用户访问行为天表，在这里，我们将PC网页、H5、小程序和原生APP访问日志汇聚到一张表里面，统一字段名，提升数据质量，这样就有了一张可供大家方便使用的明细表了。
在DWM层，我们会从DWD层中选取业务关注的核心维度来做聚合操作，比如只保留人、商品、设备和页面区域维度。类似的，我们这样做了很多个DWM的中间表
然后在DWS层，我们将一个人在整个网站中的行为数据放到一张表中，这就是我们的宽表了，有了这张表，就可以快速满足大部分的通用型业务需求了。
最后，在APP应用层，根据需求从DWS层的一张或者多张表取出数据拼接成一张应用表即可。
备注：例子只是为了简单地说明每一层的作用，并不是最合理的解决方案，大家辩证地看待即可。


数据层的存储一般如下：

Data Source：数据源一般是业务库和埋点，当然也会有第三方购买数据等多种数据来源方式。业务库的存储一般是Mysql 和 PostgreSql。
ODS 层：ODS 的数据量一般非常大，所以大多数公司会选择存在HDFS上，即Hive或者Hbase，Hive居多。
DW 层：一般和 ODS 的存储一致，但是为了满足更多的需求，也会有存放在 PG 和 ES 中的情况。
APP 层：应用层的数据，一般都要求比较快的响应速度，因此一般是放在 Mysql、PG、Redis中。
计算引擎的话，可以简单参考图中所列就行。目前大数据相关的技术更新迭代比较快，本节所列仅为简单参考。

data-layer-intro

0x05 思考
如同《漫谈数据仓库和范式》一文在最后思考数据仓库和范式之间的关系一样，本文也将思考和总结一下数据分层的原则是什么？为什么要这样分层？每层之间的界限又是什么？

我个人从这几个角度来理解数据分层的划分：

从对应用的支持来讲，我们希望越靠上层次，越对应用友好。比如APP层，基本是完全为应用来设计的，很易懂，DWS层的话，相对来讲就会有一点点理解成本，然后DWM和DWD层就比较难理解了，因为它的维度可能会比较多，而且一个需求可能要多张表经过很复杂的计算才能完成。
从能力范围来讲，我们希望80%需求由20%的表来支持。直接点讲，就是大部分（80%以上）的需求，都用DWS的表来支持就行，DWS支持不了的，就用DWM和DWD的表来支持，这些都支持不了的极少一部分数据需要从原始日志中捞取。结合第一点来讲的话就是：80%的需求，我们都希望以对应用很友好的方式来支持，而不是直接暴露给应用方原始日志。
从数据聚合程度来讲，我们希望，越上层数据的聚合程度越高，看上面的例子即可，ODS和DWD的数据基本是原始日志的粒度，不做任何聚合操作，DWM做了轻度的聚合操作只保留了通用的维度，DWS做了更高的聚合操作，可能只保留一到两个能表征当前描述主体的维度。从这个角度来看，我们又可以理解为我们是按照数据的聚合程度来划分数据层次的。
0xFF 总结
数据分层的设计，在某种程度上也需要通过数据命名来体现，本文的核心在于讲解数据分层的思想和方法，后面会有单独的文章来分享该如何根据数据分层来设计数据表的命名规范。
=========










============
#########################################################3

《数据仓库工具箱  维度建模权威指南（第3版）》

##############################################

ETL

加载星型模型过程 会有明显差异

加载 维度表 缓慢变化维

区分新变化的数据 处理

构成变化情况在
源模式 星型模式 存在差异


加载事实表 外键  源系统提供事务伴随自然键  加载过程必须用代理键 相同自然键 可能存在于维度表多行

必须处理存在问题的源数据 进行清理
多数数据清理任务可以作为加载过程一部分自动处理 有些最好放在操作型源模式

数据清理工作
规则 映射表 操作型数据可以采用特殊技术合并到星型模型
即使这样做可能会丢失一些适当的细节

数据迁移 集成 展现
在规定处理时间窗口内完成 将对操作型系统影响降到最低
自动处理 错误自动恢复

查询时间开展分析工作 容易

-------------------------------------
工具
设计文档的需求 完成 星型模型


需要原子数据逻辑仓库 从操作性数据资源中获取并集 这些信息在结构上多维 可直接擦好像

数据集市 导出模式 聚集表 补充信息

ETL过程填充数据 数据展现

从操作性数据源中获取数据 填充数据集市

数据源 单一 被集成和标准化

必须满足同样的基本处理需求

加载星型模型
加载维度表 增量 处理缓慢变化过程 区分新的 和变化的数据 管理代理键

加载事务级事实表 至少在较高的级别上看简单  引用维度表的代理键替换描述商业事务的自然键




事实表 包含 引用维度表行的外键

维度处理
维度表不存在依赖关系 处理完

仓库表分为一个模块或程序 按照能反映表间依赖关系的方式组织

以实时方式加载模式的模块 可能会在单独处理相关事务

可以定义单独的SQL事务用于在事实表中插入行 同时处理维度表需要发生的改变


加载维度表

检查基础表中存在新变化的信息 插入或更新记录 增量过程

步骤
获取数据源->组合维度属性->识别新变化的维度记录 自然键->管理代理键->处理新纪录->处理类型1变化->处理类型2变化


变化数据识别系统可以识别在获取前产生的新记录
某个ETL工具包具有在单个步骤中处理不同类型缓慢变化的能力

每晚都批量加载

获取源数据
以行处理方式组织数据
组合维度属性
处理的值是新的自然键
存在类型1 变化 更新维度表
存在类型2 变化 更新先前版本 分配代理键 插入维度表





获取数据 按目标表设计的需要 汇集到多维格式中

1.将需要的源数据加载到维度表中
多数据源 单一记录池 每个数据源设计一个加载处理程序
通过多种方法获取源数据
通过文件 关系数据 sql 导出文件
实时数据 消息系统 web service 获取
外部数据 在线 批处理

非关系数据 大容量加载到关系过渡区 然后执行sql

源数据 旋转或者 置换 以便构成维度记录所有元素处于单一行
异构数据结构

每个源数据行汇集到维度属性 转换规则
描述性的值
多个属性的字段划分成多个属性

串联

NUll字段值 unavaliable unkonwn
属性大小写 格式
分解
包含清理任务 名称和地址标准化

简单的Sql语句


------------------------------------------------


新纪录 分配代理键 插入维度表

确定是否是新记录 搜索自然键 如果存在确定是否发生变化

对变化数据识别系统 可以直接监视数据源 识别新的或变化的数据
获取源数据并处理新纪录



新的需要增加到已存在的product维度表源记录例子

产品维度设计 prodcut_key 的单值属性代理键
用于唯一区分维度表中的行

自然键 SKU 库存单位 唯一区分源系统中的产品

其他熟悉 表示如何响应源中发生的变化
类型1变化导致重写
类型2变化触发插入新行

维度单一产品可能有多行
内部列current_version表面哪个行最新的

缓慢变化维 其中一个版本为current


处理类型1变化
重写 获取记录的自然键与数据仓库中当前记录的自然键值匹配
不匹配 发生变化
未匹配 经历了类型1变化
更新维度表

product

product_key
sku
product_name
brand_code
brand_manager

...

current_version


2变化可能源记录多个维度行发生改变 应用到存在的具有相同自然键的维度表记录上
必须对product_name 进行更新
所有版本

某个属性类型1变化如果不完全依赖于自然键 做的处理工作会更复杂


复杂类型1
选择放弃使用与维度粒度不对应的类型1熟悉 增加维护聚集或多维数据集的复杂性

详细依赖关系 雪花模式
ETL产生问题有所缓解  品牌熟悉被放在不同表中

-----------------------------------
处理类型2变化

使用自然键和所有类型2属性组合 发现匹配
没匹配
先前的记录不再是最新的记录
current_version 更新为not current
新版本被分配一个代理键 并被加载到数据仓库中

源记录可能同时包含类型1和类型2 变化
为这些考虑为要么 或者之类的陈述非常严重错误

===============================================================
加载事实表
计算事实  识别出正确外键 在星型模式中插入记录

识别出正确的外键
原系统仅提供自然键
事实表必须使用外键引维度

每个事实 必须由代理减替换 代理键区分唯度表中的行
可能在维度表中包含多行

模式设计技巧辅助

1.加载事实表必须完成
处理缓慢变化

步骤：
获取信息->以行处理方式组织数据->计算事实->聚集事实以匹配事实表粒度->为每个维度获取代理键->加载到仓库


准备要处理的记录


多行变大行

可加性事实 order_dollars 通过将源熟悉unit_price * quantity
计算复杂

源数据粒度更细 聚集

针对自然键集合汇总


最耗费时间和工作

外部约束

有创意

无结构

ETL
源系统

----------------------
需求综合

收集 理解所有已知将会影响ETL系统的需求 现实和约束
检查列表示例
商业用户用于指定明智的商业决策所需信息内容

KPI
下钻
跨钻

合规性
数字准确 完整 未被篡改

列出数据输入和数据转换步骤 维护 监管链

数据质量
集成

持续监控和标记的数据元素

数据集成

一致性维度：跨不同数据库建立公共维度属性 属性构建横向钻取报表
一致性事实 对公共业务度量达成一致 包括不同数据库的KPI，计算差异和比率开展数学比较工作

利用业务过程的总线矩阵建立一致性维度 总线矩阵的列 优先列表 标注


-------------
数据延迟
高效处理算法 并行化 强大的硬件系统
延迟紧迫

列举所以合法的日为单位 天为基础多次发生 秒为基础 即时提供的数据的业务需求

---------------
归档与世系
需要副本 变化记录

ETL每个活动暂存数据 清洗 一致化 发布
从持久性介质上读取数据 更容易
过后通过ETL系统重新处理

时间变化 原始获取不能被重建

归档数据描述 来源  步骤

世系跟踪


----------------

BI 发布接口


数据内容和结构

确定数据切换的具体需求

BI工具的敏感性

列出可以直接被BI工具利用的事实和维度表
列出OLAp多维数据库 特定的数据库结构

列出所有您已经打算建立并用于支持BI性能的已知的索引和聚集

----------------
可用的技能

清查所在部门操作系统 ETL工具 脚本语言 编程语言 SQL DBMS 以及OLAP技能


--------------------
传统的许可证书

清查所在部门操作系统 ETL工具 脚本语言 编程语言 SQL DBMS 以及OLAP许可证书
独家使用授权 还是仅仅被建议使用


--------------
ETL 34个关键子系统


获取
从源系统收集原始数据 写道ETL环境磁盘上 子系统1-子系统3用于支持获取过程

数据分析：




-----------------------
清洗 转换
将来自两个或多个数据源数据融合 建立和执行一致性维度和一致性度量 子系统4-子系统8



--------------------------
发布
物理构建并加载数据到目标维度模型 子系统9-21




--------------------------
管理

以一致方法管理与ETL环境相关系统和过程 子系统22-34 描述支持ETL系统持续管理所需各种部件

---------------------------------

获取 将数据插入到数据仓库




=============================================================
https://cloud.tencent.com/document/product/878/31441


云数据仓库套件 Sparkling 简介
云数据仓库套件 Sparkling（Tencent Sparkling Data Warehouse Suite）为您提供一套全托管、简单易用的、高性能的PB级云端数据仓库解决方案。Sparkling 基于业界领先的 Apache Spark 框架，您可以在数分钟内创建数千节点的企业级云端分布式数据仓库，并高效的按需快速弹性扩缩容。通过一站式大数据开发和科学平台 DataStudio 进行集群管控、数据集成、元数据管理、工作流开发、数据加工处理、结果可视化等操作，深度集成商业智能分析 BI，构建应用数据集市，提供海量数据的离线加工、数据建模、即席查询分析、数据挖掘和可视化探查能力。还可以借助 Sparkling 跨数据源联合分析特性，轻松分析位于 COS 和 CDB 等数据引擎上的数据，帮助企业专注于数据价值的挖掘和探索。


 腾讯云 Snova 数据仓库服务简介
Snova 数据仓库（下文简称 Snova）为您提供简单、快速、经济高效的 PB 级云端数据仓库解决方案。Snova 兼容 Greenplum 开源数据仓库，是一种基于 MPP（大规模并行处理）架构的数仓服务。借助于 Snova，您可以使用丰富的 PostgreSQL 开源生态工具，实现对 Snova 中海量数据的即席查询分析、ETL 处理及可视化探索；还可以借助 Snova 云端数据无缝集成特性，轻松分析位于 COS、TencentDB、ES 等数据引擎上的 PB 级数据。


产品简介
Snova 数据仓库产品文档
 文档
腾讯云 Snova 数据仓库产品特性

弹性伸缩
提供便利的弹性扩容能力，通过云控制台或云 API 简单操作便可以实现数百节点的伸缩或变配。 根据业务需求，可选择计算单元、CPU、内存、存储空间的等比扩展，提高性能以适配业务的发展。



简单易用
通过控制台操作，即可实现集群管理、监控维护等工作，无需关注底层基础设施的繁重运维工作。完全支持 ANSI SQL 2008 标准，使用标准 SQL 即可构建企业级数据仓库。支持直接查询 COS 数据，而无需提前数据预加载。



无缝集成
支持 COS 云存储扩展，实现存储空间的无限扩展。搭配多种工具及方案支持多源数据（如传统关系型数据库、Ckafka、流计算等）高速导入，实现对云端多源数据的汇聚分析。


性能卓越
基于分布式大规模并行处理 MPP 框架，可线性扩展存储及计算能力。支持行列混合存储，可按业务需求选择最佳存储方案。查询引擎深度优化，查询效率数倍于传统数据仓库。



安全可靠
双节点同步冗余，实现用户无感的故障转移和容灾备份。分布式部署，计算单元、服务器、机柜三重防护，提高重要数据基础设施保障。用户集群独立部署，支持 VPC 隔离，数据访问安全多重保障。

应用场景
经营分析决策

海量日志分析

用户行为实时洞察
在金融、零售等领域，需要对销售、资产、供应链等业务数据进行汇总分析，以便通过数据掌握公司经营情况，提高决策精准度及效率。
通过同步或 ETL 工具将分散在 CDB、Oracle、PostgreSQL 中的数据导入到 Snova 中，利用其对多源异构数据的分析能力，辅助业务决策。


客户案例
安心保险
安心保险
互联网保险
腾讯云 Snova 数据仓库为安心保险提供了海量数据存储，并提供高性能查询能力助力挖掘数据价值。


萌蛋互动
萌蛋互动
游戏研发与运营
腾讯云 Snova 数据仓库支持了萌蛋海外游戏运营数据分析需求，使用户国内外都可使用腾讯云，降低了运维及采购成本。


微众银行
微众银行


Snova 数据仓库（下文简称 Snova）为您提供简单、快速、经济高效的 PB 级云端数据仓库解决方案。Snova 兼容 Greenplum 开源数据仓库，是一种基于 MPP（大规模并行处理）架构的数仓服务。借助于 Snova，您可以使用丰富的 PostgreSQL 开源生态工具，实现对 Snova 中海量数据的即席查询分析、ETL 处理及可视化探索；还可以借助 Snova 云端数据无缝集成特性，轻松分析位于 COS、TencentDB、ES 等数据引擎上的 PB 级数据。

Snova 以集群为基本使用单位，一个用户可以拥有多个集群，一个集群通常由2个 master 节点和不少于2个的计算节点组成。单集群随着计算节点的增加，容量和性能将线性提升。
Snova 按提供计算和存储能力的节点规格和数量进行收费，包含按量计费和包月计费两种方式。
功能
Snova 为您提供简单、快速、经济高效的 PB 级云端数据仓库解决方案。

操作简单
使用 Snova 数据仓库服务，您能够快速在云端搭建 TB 级-PB 级数据仓库，无需关注集群的管理以及繁重的运维工作。通过在控制台的操作，即可实现集群管理、监控维护等工作。Snova 支持 ANSI SQL 2008 标准，使用标准 SQL 即可对数仓中的数据以及 COS 中的数据进行分析。

弹性扩容
使用 Snova 云控制台或通过调用云 API，可对 Snova 数据仓库的节点进行扩容，提升分析能力，以应对业务增长等场景。 Snova 对节点对扩容，会提升包括 CPU、内存、存储空间的能力，并实施数据倾斜等策略，以保证新扩节点的快速使用。

数据传输
Snova 支持 COS 云存储，可对 COS 中数据直接进行分析。对云上产品如 CDB、CKafka、流计算等产品中的数据支持直接高速导入。Snova 兼容业界 PostgreSQL 生态，可使用业界的工具或方案实现数据的传输。

高性能
Snova 基于分布式大规模并行处理 MPP 框架，可线性扩展存储及计算能力。支持行列混合存储，可按业务需求选择最佳存储方案。通过对硬件、软件、算法等多维度进行加速，优化查询效率。

安全性
Snova 中节点会自动配备一份备份，以此实现故障转移以及容灾备份。同时提供了机柜、服务器、计算单元的三重防护，提高基础设施的安全性。对每个用户的集群都支持 VPC 隔离，保障数据的访问安全。



文档中心  Snova 数据仓库  快速入门
快速入门
最近更新时间：2018-12-13 20:01:47

 编辑   查看pdf
在这篇文章中：
一. 创建集群
二. 连接数据库
三. 导入数据
四. 分析数据
使用 Snova 数据仓库，您需要完成以下操作：

一. 创建集群
登录 Snova 数据仓库 创建集群。
在创建集群之前，需要明确数据量，数据所在地域，以及访问集群的网络环境。
目前只支持 VPC 网络，因此在创建集群之前需要创建好访问集群的 VPC 网络及其子网。

二. 连接数据库
创建完集群之后，在之前配置好的子网下申请一台 CVM 用于访问集群。然后在 CVM 上通过 psql 连接数据库，如果没有安装客户端，可通过以下命令安装 PostgreSQL 的客户端程序。

 yum install -y postgresql.x86_64
Snova 完全兼容 PostgreSQL 8.3.23 协议。使用 psql 连接数据库的基本语法如下：

 psql  -h 10.0.0.3 -p 5436 -d postgres -U testuser
其中 postgres 是 Snova 默认的数据库，testuser 是创建数据库的时候需要用户输入的管理员帐号，5436是数据库默认的端口号，10.0.0.3 是创建完数据库后返回的 vip，该 vip 可以在控制台查询。

三. 导入数据
使用 INSERT 导入数据。
您可以通过 INSERT 语句直接向 Snova 写入数据，适用于数据量较小的场景。

使用客户端工具 psql 连接 Snova，并使用标准 INSERT 语法写入数据。
通过 PostgreSQL JDBC 驱动书写应用程序向 Snova 写入数据。
使用 \COPY 命令导入数据。
您可以使用 \COPY 命令将客户端所在主机上的文件导入到 Snova 中，语法可以参见 PostgreSQL 相关 \COPY 语法。

从 COS 外表中导入数据。
COS 外表语法详见 导入外部数据，在创建一个可读的 COS 外表后，可以使用如下语法将 COS 外表的数据导入到一张结构相同的内表中。

 INSERT INTO cos_local_tbl SELECT * FROM cos_tbl
从公有云其它环境导入数据详见 使用外表。

四. 分析数据
在 Snova 中，语法完全兼容 Greenplum Database 5.x 语法，您可以参考其语法进行数据分析。

前提条件
使用管理员用户或者由其创建的其他用户连接到数据库。
创建了相应的数据库以及数据库表，例如 testdb 与 testtable。
向数据库表中插入了数据，具体插入数据方法参见 插入数据。
简单的 SELECT 语句
 SELECT col1,col2,col3 FROM testtable WHERE col1 = val1 AND col2 = val2;
使用上述语句可以获取数据库表 testtable 中 col1 的值为 val1 并且 col2 的值为 val2 的记录。更多分析语句可参见 Greenplum Database 5.x 官方文档。

==================

离线计算中的幂等和DataWorks中的相关事项


本页目录
离线计算与幂等
计算
ETL
幂等这个词在软件研发中经常被提到。比如消息发送时不应该同时给同个用户推送多次相同的消息，针对同一笔交易的付款也不应该在重试过程中扣多次钱。曾见过一个案例，有个对于一个单据的确认模块没有考虑到幂等性，导致对应的单据有两条确认记录。其实幂等这个词是个数学的概念，表示这个操作执行多次的结果和执行一次是完全一样的。严格的定义这里不展开讨论，有兴趣的可以到网上搜一下，会有很多介绍。通俗一些说，幂等表示这个操作可以多次重跑，不用担心重跑后到结果会乱掉。就赋值而言，i=1就是个幂等到操作，无论做多少次赋值，只要有做成功一次，i的值就是1。而i++就不是一个幂等的操作。如果多次执行这个操作，i的值会不断增加1。

从前面的示例可以看出，幂等的优势是可以屏蔽重试带来的问题。在分布式的环境里，一般会通过消息中间件、异步调用等方式实现服务之间的解耦。在此过程中，如出现系统异常状况下的状态不明确的情况，一般会进行重试。如果应用不满足幂等的要求，则会出现错误的结果。

离线计算与幂等
离线计算中的作业量较大，跑一个作业需要较多时间。而且由于其特性，经常是凌晨开始计算，在OLTP业务调用量上来以前需要产出结果。如果发现问题，经常没有太多的时间留给技术人员去详细定位问题的原因，然后清理脏数据后重新进行计算。这时候您需要计算能够进行任意次的重跑，也就是说计算需要满足幂等性。对于一个满足幂等性要求的作业，出现问题的时候，您可以首先先重跑一下作业，以期能尽快恢复业务，后续再根据之前的日志慢慢定位问题。

下面以MaxCompute+DataWorks为例，从不同的角度里讨论离线计算的典型场景——离线数仓，看看都有哪些地方需要做到幂等以及如何做到。

计算
目前的离线计算，出于开发的效率考虑，一般都会考虑使用SQL进行代码开发。SQL中包含DDL和DML两种语句。除了SQL，计算引擎一般还支持MapReduce、Graph等计算模型。

DDL
DDL语法可以通过语句里的if exists/if not exists来确保幂等性。比如创建表可以用create table if not exists xxx，删除表可以通过drop table if exists xxx来保证不报错而且可以重复执行。当然创建表也可以先删除后再创建来实现幂等性。当然，如果是建表这种一次性的操作，可以在上线的时候手工做好，但是日常的分区创建/删除等操作就需要通过写进代码里，通过if exists/if not exists来保证可以重试。

DML
DML对数据有影响的是Insert操作。目前Insert有两种模式：Insert into和Insert overwrite。

其中Insert into是把数据追加到原来的数据里，而Insert overwrite是把以前的数据直接覆盖。所以可以清楚地看到，Insert into不满足幂等性要求，而Insert overwrite满足。如果使用Dataworks的SQL节点跑一个Insert into的作业，会有如下提示：

!!!警告!!!
在SQL中使用insert into语句有可能造成不可预料的数据重复，尽管对于insert into语句已经取消SQL级别的重试，但仍然存在进行任务级别重试的可能性，请尽量避免对insert into语句的使用！
一些使用Insert into的用户，要使用这种数据更新方式的原因，除去手工数据订正，发现一般都是针对一些不会变化的数据（比如网站的日志、每天的统计结果等）每天需要追加到表中。其实更好的方法是创建一个分区表，把每天需要Insert into的数据改成Insert overwrite到每天的一个不同分区里。

MapReduce
MapReduce默认使用覆盖写入的模式。如果确实有需要追加写入，可以使用com.aliyun.odps.mapred.conf.JobConf的setOutputOverwrite(boolean isOverwrite)来实现。如果需要改成幂等的，可以使用前面SQL里提到的，把数据写入特定的分区里来实现。

ETL
ETL暂时不考虑数据清洗（一般数据清洗是通过计算来实现的），只讨论数据的同步。在Dataworks中，数据的同步通过数据集成模块来实现。在数仓中，数据同步包括数据导入到数仓和数据从数仓中导出两种场景。

数据导入的场景要实现幂等性比较容易。首先我们对于导入数据，建议把每天新增的数据导入到新的一个分区里，然后只需要设置导入的MaxCompute表的清洗规则为写入前清理已有数据Insert Overwr即可。这样数据在导入的过程中会先清空数据后再导入，从而实现幂等。



数据导出的场景，如果数据是全量导出的，也可以用类似数据导入的方法，配置导入前准备语句，把原来的数据全部删除后重新导入。另外如果数据源支持主键冲突设置时，可以通过主键冲突设置成Replace Into来实现数据的替换。



由上图可见，目前Dataworks本身就支持设置出错重试，如果同步作业满足幂等性要求的，可以大胆开启这个设置，从而降低运维成本提高稳定性。




---------

解析运行时间和定时时间的理解
更新时间：2018-03-16 14:08:08


本页目录
业务日期和定时时间结合调度参数使用
测试调度参数
业务日期和定时时间结合调度参数使用
关于调度参数的使用，可以参考一下官网文档：参数配置。现在我来给大家解析一下这篇文档：

DataWorks调度系统参数：
调度系统参数：这两个调度系统参数无需赋值，可直接使用。

${bdp.system.cyctime}：定义为一个实例的定时运行时间，默认格式为：yyyymmddhh24miss。
${bdp.system.bizdate}：定义为一个实例计算时对应的业务日期，业务日期默认为运行日期的前一天，默认以 yyyymmdd 的格式显示（业务日期不精确到时分秒）。
DataWorks 自定义调度参数：有时候我们需要对时间参数进行加减，此时使用调度系统参数已经无法满足我们的需求了。面对这种情况，DataWorks 提供了自定义调度参数，用户可根据自己的业务需求，灵活的对时间参数进行加减，完美的解决各种复杂的场景。

自定义系统参数
自定义系统参数是以 bdp.system.cyctime 为基准的，任何的时间加减都是以定时时间为基线，向上或者向下移动。

举个例子：
代码为： select ${today} from dual ;

注 ：其中 ${today} 是声明变量

调度配置为：today = $[yyyymmdd]

注：其中 $[yyyymmdd] 是给声明的变量赋值

测试运行的时候，选择的业务日期是 20180305，测试运行时，日志中打印出来的实际运行sql为：select 20180306 from dual;

附上一张步骤图
image

敲黑板：请注意调度参数的配置时 ， 声明变量的符号和赋值的符号是不一样的，详情如下：

${} 这个符号是声明变量时使用的；

$[] 这个符号是给变量赋值的时候使用的；

以下提供一些调度参数的赋值方法：
后N年：$[add_months(yyyymmdd,12*N)]

前N年：$[add_months(yyyymmdd,-12*N)]

后N月：$[add_months(yyyymmdd,N)]

前N月：$[add_months(yyyymmdd,-N)]

后N周：$[yyyymmdd+7*N]

前N周：$[yyyymmdd-7*N]

后N天：$[yyyymmdd+N]

前N天：$[yyyymmdd-N]

后N小时：$[hh24miss+N/24]

前N小时：$[hh24miss-N/24]

后N分钟：$[hh24miss+N/24/60]

前N分钟：$[hh24miss-N/24/60]

小时级调度的例子
例一
业务场景1：查看业务日期为 20180305 的小时任务，上午 3 点的实例，运行时执行的代码。

代码：select ${min} from dual ;

注：其中 ${min} 是声明变量

调度配置：min = $[yyyymmddhh24miss]

注：其中 $[yyyymmddhh24miss] 是给声明的变量赋值

测试运行时，日志中的运行代码为：select 20180306030000 from dual ;

例二
业务场景2：如何获得业务日期为 20180305 的小时任务，上午 3 点的实例，前 15 分钟的时间。

代码 ： select ${min} from dual;

注：其中 ${min} 是声明变量

调度配置：min = $[yyyymmddhh24miss-15/24/60]

注：其中 $[yyyymmddhh24miss-15/24/60] 是给声明的变量赋值

测试运行时，日志中的运行代码为：select 20180306024500 from dual ;

测试调度参数
有不少同学可能没有接触过如何测试调度参数，这里放上我之前写的一篇文章《解析Dataworks中的运行和测试运行的区别》 ，调度参数和测试运行是需要结合使用的，没有经过调度系统，调度参数是无法生效的。


解析Dataworks中的运行和测试运行的区别
更新时间：2017-09-29 10:22:29


本页目录
页面上的运行
测试运行
有很多用户在使用Dataworks的数据开发中运行SQL和在数据集成中运行同步任务时，都会有一个疑惑。我在页面上运行和测试运行有什么区别呢？为什么我明明配置了系统参数，在代码中运行时，却没有自动解析，而提醒我去填写系统变量的临时值？

image

下面我就给大家讲讲这两者的主要区别。

页面上的运行
页面上的运行是不会经过调度系统的，直接将任务下发到底层去执行。所以在使用了调度参数后，运行时，是需要指定调度参数解析出来的值的。页面上触发的运行是不会生成实例的，所以也就没有办法去指定运行任务的机器，只能下发到Dataworks的默认资源组上去执行。

数据开发在页面上运行时如何给自定义参数赋值
在数据开发中，创建了SQL节点任务时，在SQL中使用了自定义参数。点击页面上的运行，会弹出一个提示框，在这个提示框里一定要填一个具体的值，而不要填$[yyyymmdd] 这种，不然在代码中$[yyyymmdd]是不会识别出来的。1imageimage

数据集成在页面上运行时如何给自定义参数赋值
在数据集成中，创建脚本模式的任务时。在脚本中使用了自定义参数，保存后，点击页面上的运行，提示我需要给自定义参数赋值。我填了一个值以后，却没有解析出来呢？

imageimage

原因是因为：系统参数和自定义系统参数，是调度系统的参数，只有通过调度系统后，才会解析出来。而我们点击的运行，是没有经过调度系统的，所以提示你输入的自定义变量参数 是需要填一个具体的值才行，这样在执行任务的时候，才会直接替换掉。

image

image

测试运行
测试运行会通过调度系统，去生成实例的，所以在使用了调度参数后，运行时，调度参数就会自动解析出来了，而且可以指定实例运行所在的资源组。

安全的数据开发模式
更新时间：2017-11-07 11:49:22


本页目录
实验背景
解决方案
操作步骤
实验背景
因为开发角色拥有删除表的权限，有用户质疑如果让其直接操作生产环境的表，会导致数据不安全。本文将为您介绍如何保证生产环境的数据安全。

解决方案
解决数据安全问题的解决方案的整体流程，如下图所示：



操作步骤
前期准备
创建两个项目，一个作为开发项目，一个作为生产项目，比如：Project_A 和 Project_B。

进入 Project_A 的 项目管理 页面，指定此项目发布到 Project_B 下。指定后，这两个项目便具有了关联关系，可以通过发布功能，将任务发布。



在项目管理中 Maxcompute 配置下，配置使用个人账号访问 Maxcompute 资源。如下图所示：



代码编辑
在 Project_A 中进行编辑代码，配置任务等操作。

将编辑好的代码和任务，通过 发布 功能，发布到 Project_B 中。

查询生产项目下的数据
如果需要操作生产项目下的表，可以进入 数据管理 页面，申请生产项目表的权限，这样开发角色便可在 Project_A 项目中通过 Project_B.table 的方式来查询生产项目中表的数据（申请的只有查询表权限，没有 drop 表权限）。

在 数据管理 页面，您不仅可以申请表的权限，还可以申请资源以及函数的权限。


注意：

从 Project_A 发布到 Project_B 后，有一些项目级别的配置是不会发布过去的，比如说数据源、表、资源、函数等，都需要在 Project_B中重新建立。

=================

配置不同周期任务依赖

本页目录
天任务依赖小时任务
小时任务依赖分钟任务
总结
大数据开发过程中常遇到不同运行周期的任务进行依赖，常见的有天任务依赖小时任务和小时任务依赖分钟任务。那么如何通过DataWorks开发这两种场景呢？

本文将从上述两种场景出发，结合调度依赖/参数/调度执行等，为您介绍不同周期调度依赖的最佳实践。

在开始操作前，为您介绍以下几个概念：

业务日期：业务数据产生的日期，这里指完整一天的业务数据。在DataWorks中，任务每天能处理的最近的完整一天的业务数据是昨天的数据，所以业务日期=日常调度日期-1天。

依赖关系：依赖关系是描述两个或多个节点/工作流之间的语义连接关系，其中上游节点/工作流的运行状态可以影响下游节点/工作流的运行状态，反之则不成立。

调度实例：DataWorks的调度系统对周期任务进行调度执行时，会先根据任务的配置进行实例化，每个实例带上具体的定时时间、状态、上下游依赖等属性。

注意：

目前数加DataWorks每天自动调度的实例都是在昨天晚上23:30生成。

调度规则：调度任务是否能运行起来需要满足以下条件。

确认上游任务实例是否都运行成功。若所有上游任务实例都运行成功则触发任务进入等待时间状态。

确认是否到任务实例的定时时间。任务实例进入等待时间状态后会check是否到达本身的定时时间，如果时间到了则进入等待资源状态。

确认当前调度资源是否充足。任务实例进入等待资源状态后，check当前本项目调度资源是否充足，若充足即可成功运行。

天任务依赖小时任务
业务场景
系统需求统计截止到每小时的业务数据增量，然后在最后一个小时的数据汇总完成后需要一个任务进行一整天的汇总 。

需求分析
每个小时的增量，即每整点起任务统计上个小时时间段的数据量。需要配置一个每天每整点调度一次的任务，每天最后一个小时的数据是在第二天的第一个实例进行统计。

最后的汇总任务为每天执行一次，且必须是在每天最后一个小时的数据统计完成之后才能执行，那么需要配置一个天任务，依赖小时任务的第一个实例 。

分析得出的调度形态如下图所示：

1

但是，真正如上图调度任务定义那样配置调度依赖后，调度任务实例并没有得到上图的效果，而是如下图所示：

1

上图中，天任务必须等小时任务当天的其它所有实例也执行完成才能执行，而需求是天任务只需依赖小时任务第一个实例，此效果明显不能满足需求。

要满足该场景的需求，需要结合任务的跨周期依赖进行配置，可以将小时任务的跨周期依赖属性配置为自依赖，然后天任务配置定时时间为零点整，且依赖属性配置为依赖小时任务。

分析得出的最终方案调度形态如下图所示：

1

此时，小时任务的实例为串行执行，第一个实例能执行成功，可保证它前面（昨天）的实例都已经执行成功，因此天任务可以只需要依赖第一个实例。

配置实践
小时任务的调度配置如下图所示：

1

1

参数配置：小时任务每整点实例处理前一小时的数据，如可以用$[yyyy-mm-dd-hh24-1/24]。天任务：若时间格式为yyyymmdd，用${bdp.system.bizdate}；若时间格式为yyyy-mm-dd，用自定义参数$[yyyy-mm-dd-1]，具体视详细设计而定。参数配置如下图所示：

1

测试/补数据/自动调度
天任务实例的定时时间为2017-01-11 00:00:00。

小时实例的定时时间为2017-01-11 00:00:00至2017-01-11 23:00:00。

${bdp.system.bizdate}赋值结果为20170110（实例定时间年月日减1天）。

$[yyyy-mm-dd-hh24-1/24]赋值结果为2017-01-10-23至2017-01-11-22（实例定时间年月日时减1小时）。

自动调度：调度系统自动生成的实例，每天的实例定时时间都是当天，如需求分析中的最终方案效果图。

小时任务依赖分钟任务
业务场景
已经有任务每30分钟进行一次同步，将前30分钟的系统数据增量导入到MaxCompute，任务定时为每天的每个整点和整点30分运行。现在需要配置一个小时任务，每6个小时进行一次统计，即每天分别统计0点到6点之间、6点到12点之间、12点到18点之间、18点到明天0点整之间的数据。

需求分析
分钟任务

00:00实例同步的是昨天最后30分钟的数据，产出的表分区如：昨天日期年-月-日-23:30。

00:30实例同步的是今天00:00-00:30之间的数据，产出的分区如：今天日期年-月-日-00:00。

01:00实例同步的是今天00:30-01:00之间的数据，产出的分区如：今天日期年-月-日-00:30。

以此类推，23:30实例同步的是今天23:00-23:30之间的数据，产出的分区如：今天日期年-月-日-23:00。

小时任务

每6个小时进行一次统计，则一天调度4次。

统计0点到6点之间的数据，则依赖分钟任务当天的00:30—6:00，共12个实例。

统计6点到12点之间的数据，则依赖分钟任务当天的6:30—12:00，共12个实例。

统计12点到18点之间的数据，则依赖分钟任务当天的12:30—18:00，共12个实例。

统计18点到第二天0点之间的数据，则依赖分钟任务当天的18:30—23:30以及第二天00:00，共12个实例。

分析得出的调度形态如下图所示：

1

但是，真正如上图调度任务定义那样配置调度依赖后，调度任务实例并没有得到上图的效果，而是如下图所示：

1

如上图所示，10日18点到11日0点之间的数据，11日小时任务0点，整点实例只依赖了分钟任务11日0点整实例，不能确保分钟任务10日18:30至23:30的实例可以执行成功。

要达到该场景需求，此时就需要结合任务的跨周期依赖进行配置，可以将分钟任务跨周期依赖属性配置成自依赖，然后小时任务依赖属性配置依赖小时任务。

分析得出的最终方案调度形态如下图所示：


配置实践
分钟任务的调度配置如下图所示：


小时任务调度配置如下图所示：


参数配置：分钟任务每个实例处理前面30分钟数据产出的分区可以用参数如$[yyyy-mm-dd-hh24:mi-30/24/60]，具体视详细设计而定。配置如下图所示：


测试/补数据/自动调度
测试和补数据：都是手动生成的调度实例，选择的是业务日期。如选择业务日期为2017-01-10。

分钟任务实例的定时时间是2017-01-11 00:00:00至2017-01-11 23:30:00，共48个实例。

小时实例的定时时间是2017-01-11 00:00:00、06:00:00、12:00:00、18:00:00，共4个实例。

$[yyyy-mm-dd-hh24:mi-30/24/60]赋值结果为2017-01-10-23:30至2017-01-11-23:00（实例定时间年月日时分减30分钟）。

自动调度：调度系统自动生成的实例，每天都实例定时时间都是当天，如需求分析中的最终方案效果图。

总结
长周期任务依赖短周期任务时，如果短周期有自依赖：当天的调度实例中，长周期任务的每个实例只依赖短周期实例中定时时间与它最近（且小于）的一个实例。

长周期任务（小时）依赖短周期任务（分钟）时，如果短周期无自依赖：当天的调度实例中，长周期任务的每个实例会依赖定时时间小于等于且没被本任务其他实例依赖的短周期实例。天/周/月依赖小时/分钟任务例外，因为天任务实例会依赖所有小时/分钟任务。

调度周期和调度时间参数配合使用，最终调度参数替换的值取决于每次调度的实例定时时间，而调度上看到的业务日期=实例定时时间年月日减1天。

==========
实验涉及大数据产品
大数据计算服务 MaxCompute
大数据开发套件 DataWorks
实验环境准备
必备条件：首先需要确保自己有阿里云云账号并已实名认证。详细请参见：

注册阿里云账号
企业实名认证
个人实名认证
开通大数据计算服务MaxCompute
若已经开通和购买了MaxCompute，请忽略次步骤直接进入创建DataWorks项目空间。

step1：进入阿里云官网并单击右上角登录阿里云账号。
step1_

step2：点击进入大数据计算服务产品详情页，单击立即开通。
step2_

step2_2_

step3：选择按量付费并单击立即购买。
step3_
创建DataWorks项目空间
确保阿里云账号处于登录状态。

step1：点击进入大数据（数加）管理控制台>大数据开发套件tab页面下。
step2：单击右上角创建项目或者直接在项目列表—>创建项目，跳出创建项目对话框。
1
选择相应的服务器时如果没有购买是选择不了会提示您去开通购买。数据开发、运维中心、数据管理默认是被选择中。

step3：勾选相应的服务单击 确认，跳转到下面的界面，填写相应的信息单击确认，创建项目完成。
2

项目名需要字母或下划线开头，只能包含字母下划线和数字。
【注意】项目名称全局唯一，建议大家采用自己容易区分的名称来作为本次workshop的项目空间名称。

step4：单击进入项目跳转到下面的界面：
step2_2_

新建数据源
根据workshop模拟的场景，需要分别创建FTP数据源和RDS数据源。

1.新建FTP数据源
step1：选择数据集成>数据源，单击新增数据源。
step1_

step2：选择数据源类型ftp，同时Protocol选择为sftp，其他配置项如下。
1

FTP数据源配置信息如下：

数据源类型：有公网ip
数据源名称：ftp_workshop_log
数据源描述：ftp日志文件同步
Protocol：sftp
Host：10.80.177.33（内网）/118.31.238.64（公网）
Port：22
用户名/密码：workshop/workshop

注：若项目创建在华东2，建议使用内网Host。由于跨region可能会出现网络不可达，所以项目创建在其他region的同学请使用公网Host。

step3：单击测试连通性，连通性测试通过后，单击确定保存配置。
step3_

2.新建RDS数据源
step1：选择数据集成>数据源，单击新增数据源。
step1_
step2：选择数据源类型为RDS>mysql并完成相关配置项。
step2_
RDS数据源配置信息如下：

数据源类型：阿里云数据库（RDS）
数据源名称：rds_workshop_log
数据源描述：rds日志数据同步
RDS实例名称：rm-bp1z69dodhh85z9qa
RDS实例购买者ID：1156529087455811
数据库名：workshop
用户名/密码：workshop/workshop#2017

step3：单击测试连通性，连通性测试通过后，单击确定保存配置。
step3_

创建目标表
step1：单击数据开发，进入数据开发首页中单击新建脚本。
step1_
step2：配置文件名称为create_table_ddl，类型选择为ODPS SQL，单击提交。
1
step3：编写DDL创建表语句，如下分别创建FTP日志对应目标表和RDS对应目标表。
step3_DDL_FTP_RDS_
DDL语句如下：

--创建ftp日志对应目标表
DROP TABLE IF EXISTS ods_raw_log_d;
CREATE TABLE ods_raw_log_d (
  col STRING
)
PARTITIONED BY (
  dt STRING
);
--创建RDS对应目标表
DROP TABLE IF EXISTS ods_user_info_d;
CREATE TABLE ods_user_info_d (
  uid STRING COMMENT '用户ID',
  gender STRING COMMENT '性别',
  age_range STRING COMMENT '年龄段',
  zodiac STRING COMMENT '星座'
)
PARTITIONED BY (
  dt STRING
);
step3：单击运行，直至日志信息返回成功表示两张目标表创建成功。

运行DDL

step4：可以使用desc语法来确认创建表是否成功。

DESC

step5：单击保存，保存编写的SQL建表语句。
保存DDL

新建工作流任务
step1：单击新建并选择新建任务。
新建任务

step2：选择工作流任务，调度类型选择为周期调度，其他配置项如下。

配置任务

step3：点击创建。

step4：进入工作流配置面板，并向面板中拖入一个虚节点（命名为workshopstart）和两个数据同步节点（分别命名为ftp数据同步和rds_数据同步）：
1
1
1

step5：拖拽连线将workshop_start虚节点设置为两个数据同步节点的上游节点，如下所示：
1

step6：点击保存（或直接快捷键ctrl+s）。

配置数据同步任务
1）配置ftp_数据同步节点
step1：双击ftp_数据同步节点，进入节点配置界面。选择来源：并选择数据来源事先配置好的ftp数据源，为ftp_workshop_log，文件路径为/home/workshop/user_log.txt。可以对非压缩文件进行数据预览。
配置同步

同步预览

数据来源配置项具体说明如下：

数据来源：ftp_workshop_ftp
文件路径：/home/workshop/user_log.txt*
列分隔符：|
step2：选择目标。点击下一步。

数据流向选择数据源为odps_first，表名为ods_raw_log_d。分区信息和清理规则都采取系统默认，即清理规则为写入前清理已有数据，分区按照${bdp.system.bizdate}。

step3：配置字段映射。连接要同步的字段。如下：
字段映射

step4：在下一步操作中配置通道控制，作业速率上限为10MB/s，进入下一步。
通道控制

可在预览保存页面中，预览上述的配置情况，也可以进行修改，确认无误后，点击保存。

step5：点击返回工作流面板。
返回工作流

2）配置rds_数据同步节点
step1：双击rds_数据同步节点进入配置界面。选择来源：选择数据来源为rds_workshop_log，表名为ods_user_info_d；切分键为使用默认生成列即可。点击数据预览，可以看到表中数据样例。
RDS选择来源

step2：进入下一步，选择目标数据源和表名。
RDS选择目标

step3：进入下一步，配置字段映射。默认会同名映射，字段映射关系采用默认即可，如下所示：
RDS字段映射

step4：进入下一步，配置作业速率上限。
RDS通道控制

step5：在预览保存页面中确认配置信息，无误后点击保存配置。
RDS预览保存

配置调度、提交工作流任务
step1：点击调度配置，配置调度参数
调度配置

step2：点击提交，提交已经配置的工作流任务。
提交工作流任务

step3：在变更节点列表弹出框中点击确定提交。
确定提交任务

提交成功后工作流任务处于只读状态，如下：
只读状态

测试运行工作流任务
step1：点击测试运行。
测试运行

step2：在周期任务运行提醒弹出框点击确定。
周期任务运行提醒

step3：在测试运行弹出框中，实例名称和业务日期都保持默认，点击运行。
测试运行按钮

step4：在工作流任务测试运行弹出框中，点击前往运维中心。

在运维中心可以查看任务视图，如下图表示该工作流任务（名称为workshop_start）正在运行。运维中心测试
直至所有节点都运行返回成功状态即可（需要点击运维视窗中的刷新按钮查看实时状态）。如下所示：
数据同步测试成功

step5：点击节点，查看运行日志。
日志界面

确认数据是否成功导入MaxCompute
step1：返回到create_table_ddl脚本文件中。

step2：编写并执行sql语句查看导入ods_raw_log_d记录数。
数据预览

step3：同样编写并执行sql语句查看导入ods_user_info_d记录数。

附录：SQL语句如下，其中分区键需要更新为业务日期，如测试运行任务的日期为20171011，那么业务日期为20171010。

--查看是否成功写入MaxCompute
select count(*) from ods_raw_log_d where dt=业务日期;
select count(*) from ods_user_info_d where dt=业务日期;

实验背景介绍
本手册为阿里云MVP Meetup Workshop《云计算·大数据：海量日志数据分析与应用》的《数据加工：用户画像》篇而准备。主要阐述在使用大数据开发套件过程中如何将已经采集至MaxCompute上的日志数据进行加工并进行用户画像，学员可以根据本实验手册，去学习如何创建SQL任务、如何处理原始日志数据。

实验涉及大数据产品
大数据计算服务 MaxCompute
大数据开发套件 DataWorks
实验环境准备
必备条件：

开通大数据计算服务MaxCompute
创建大数据开发套件项目空间
进入大数据开发套件，创建DataWorks项目空间
确保阿里云账号处于登录状态。

step1：点击进入大数据（数加）管理控制台>大数据开发套件tab页面下。
step2：点击右上角创建项目或者直接在项目列表—>创建项目，跳出创建项目对话框。
1
选择相应的服务器时如果没有购买是选择不了会提示您去开通购买。数据开发、运维中心、数据管理默认是被选择中。

step3：勾选相应的服务单击 确认，跳转到下面的界面，填写相应的信息单击确认，创建项目完成。
2
项目名需要字母或下划线开头，只能包含字母下划线和数字。【注意】项目名称全局唯一，建议大家采用自己容易区分的名称来作为本次workshop的项目空间名称。

step4：单击进入项目跳转到下面的界面：
进入大数据开发套件
新建数据表
若在实验《数据采集：日志数据上传》中已经新建脚本文件，可以直接切换至脚本开发tab下，双击打开create_table_ddl脚本文件。若无新建脚本文件可通过如下详细步骤进行创建脚本文件。

1.新建ods_log_info_d表
step1：点击数据开发，进入数据开发首页中点击新建脚本。
新建脚本

step2：配置文件名称为create_table_ddl，类型选择为ODPS SQL，点击提交。
配置脚本

step3：编写DDL创建表语句。
编写DDL

DDL建表语句如下：

CREATE TABLE ods_log_info_d (
  ip STRING COMMENT 'ip地址',
  uid STRING COMMENT '用户ID',
  time STRING COMMENT '时间yyyymmddhh:mi:ss',
  status STRING COMMENT '服务器返回状态码',
  bytes STRING COMMENT '返回给客户端的字节数',
  region STRING COMMENT '地域，根据ip得到',
  method STRING COMMENT 'http请求类型',
  url STRING COMMENT 'url',
  protocol STRING COMMENT 'http协议版本号',
  referer STRING COMMENT '来源url',
  device STRING COMMENT '终端类型 ',
  identity STRING COMMENT '访问类型 crawler feed user unknown'
)
PARTITIONED BY (
  dt STRING
);
step4：选择需要执行的SQL语句，点击运行，直至日志信息返回成功表示表创建成功。
运行DDL

step5：可以使用desc语法来确认创建表是否成功。
DESC

step6：点击保存，保存编写的SQL建表语句。
保存DDL

2.新建dw_user_info_all_d表
创建表方法同上，本小节附建表语句:

--创建dw_user_info_all_d表
drop table if exists dw_user_info_all_d;
CREATE TABLE dw_user_info_all_d (
  uid STRING COMMENT '用户ID',
  gender STRING COMMENT '性别',
  age_range STRING COMMENT '年龄段',
  zodiac STRING COMMENT '星座',
  region STRING COMMENT '地域，根据ip得到',
  device STRING COMMENT '终端类型 ',
  identity STRING COMMENT '访问类型 crawler feed user unknown',
  method STRING COMMENT 'http请求类型',
  url STRING COMMENT 'url',
  referer STRING COMMENT '来源url',
  time STRING COMMENT '时间yyyymmddhh:mi:ss'
)
PARTITIONED BY (
  dt STRING
);
3.新建rpt_user_info_d表
创建表方法同上，本小节附建表语句:

--创建rpt_user_info_d表
DROP TABLE IF EXISTS rpt_user_info_d;
CREATE TABLE rpt_user_info_d (
  uid STRING COMMENT '用户ID',
  region STRING COMMENT '地域，根据ip得到',
  device STRING COMMENT '终端类型 ',
  pv BIGINT COMMENT 'pv',
  gender STRING COMMENT '性别',
  age_range STRING COMMENT '年龄段',
  zodiac STRING COMMENT '星座'
)
PARTITIONED BY (
  dt STRING
);
上述三张表创建成功后，保存脚本文件。
保存脚本文件

工作流设计
若成功完成实验《数据采集：日志数据上传》，即可切换至任务开发tab中，双击打开workshop工作流任务。

打开工作流任务

向画布中拖入三个ODPS SQL节点，依次命名为ods_log_info_d、dw_user_info_all_d、rpt_user_info_d，并配置依赖关系如下：

SQL依赖关系

若未完成实验《数据采集：日志数据上传》篇，可通过进入查看如何创建工作流任务。

创建自定义函数
step1：点击下载
ip2region.jar

step2：切换至资源管理tab页，点击上传按钮。

进入资源管理

step3：点击选择文件，选择已经下载到本地的ip2region.jar。
资源上传

step4：点击提交。

step5：切换至函数管理tab，点击创建函数按钮。
进入函数管理

step6：资源选择ip2region.jar，其他配置项如下所示。
新建函数

配置项说明如下：

函数名：getregion
类名：org.alidata.odps.udf.Ip2Region
资源：ip2region.jar
step7：点击提交。
配置ODPS SQL节点
1）配置ods_log_info_d节点：
step1：双击ods_log_info_d节点，进入节点配置界面，编写处理逻辑。
ODS
附SQL逻辑如下：

INSERT OVERWRITE TABLE ods_log_info_d PARTITION (dt=${bdp.system.bizdate})
SELECT ip
  , uid
  , time
  , status
  , bytes --使用自定义UDF通过ip得到地域
  , getregion(ip) AS region --通过正则把request差分为三个字段
  , regexp_substr(request, '(^[^ ]+ )') AS method
  , regexp_extract(request, '^[^ ]+ (.*) [^ ]+$') AS url
  , regexp_substr(request, '([^ ]+$)') AS protocol --通过正则清晰refer，得到更精准的url
  , regexp_extract(referer, '^[^/]+://([^/]+){1}') AS referer --通过agent得到终端信息和访问形式
  , CASE
    WHEN TOLOWER(agent) RLIKE 'android' THEN 'android'
    WHEN TOLOWER(agent) RLIKE 'iphone' THEN 'iphone'
    WHEN TOLOWER(agent) RLIKE 'ipad' THEN 'ipad'
    WHEN TOLOWER(agent) RLIKE 'macintosh' THEN 'macintosh'
    WHEN TOLOWER(agent) RLIKE 'windows phone' THEN 'windows_phone'
    WHEN TOLOWER(agent) RLIKE 'windows' THEN 'windows_pc'
    ELSE 'unknown'
  END AS device
  , CASE
    WHEN TOLOWER(agent) RLIKE '(bot|spider|crawler|slurp)' THEN 'crawler'
    WHEN TOLOWER(agent) RLIKE 'feed'
    OR regexp_extract(request, '^[^ ]+ (.*) [^ ]+$') RLIKE 'feed' THEN 'feed'
    WHEN TOLOWER(agent) NOT RLIKE '(bot|spider|crawler|feed|slurp)'
    AND agent RLIKE '^[Mozilla|Opera]'
    AND regexp_extract(request, '^[^ ]+ (.*) [^ ]+$') NOT RLIKE 'feed' THEN 'user'
    ELSE 'unknown'
  END AS identity
  FROM (
    SELECT SPLIT(col, '##@@')[0] AS ip
    , SPLIT(col, '##@@')[1] AS uid
    , SPLIT(col, '##@@')[2] AS time
    , SPLIT(col, '##@@')[3] AS request
    , SPLIT(col, '##@@')[4] AS status
    , SPLIT(col, '##@@')[5] AS bytes
    , SPLIT(col, '##@@')[6] AS referer
    , SPLIT(col, '##@@')[7] AS agent
  FROM ods_raw_log_d
  WHERE dt = ${bdp.system.bizdate}
) a;
step2：点击保存。
保存ODS

step3：点击返回，返回至工作流开发面板。
返回工作流任务

2）配置dw_user_info_all_d节点：
step1：双击dw_user_info_all_d节点，进入节点配置界面，编写处理逻辑。
DW

附SQL语句如下：

INSERT OVERWRITE TABLE dw_user_info_all_d PARTITION (dt='${bdp.system.bizdate}')
SELECT COALESCE(a.uid, b.uid) AS uid
  , b.gender
  , b.age_range
  , b.zodiac
  , a.region
  , a.device
  , a.identity
  , a.method
  , a.url
  , a.referer
  , a.time
FROM (
  SELECT *
  FROM ods_log_info_d
  WHERE dt = ${bdp.system.bizdate}
) a
LEFT OUTER JOIN (
  SELECT *
  FROM ods_user_info_d
  WHERE dt = ${bdp.system.bizdate}
) b
ON a.uid = b.uid;
step2：点击保存。

step3：点击返回，返回至工作流开发面板。

配置rpt_user_info_d节点
step1：双击进入rpt_user_info_d节点进入配置界面。rpt
附SQL代码如下：

INSERT OVERWRITE TABLE rpt_user_info_d PARTITION (dt='${bdp.system.bizdate}')
SELECT uid
  , MAX(region)
  , MAX(device)
  , COUNT(0) AS pv
  , MAX(gender)
  , MAX(age_range)
  , MAX(zodiac)
FROM dw_user_info_all_d
WHERE dt = ${bdp.system.bizdate}
GROUP BY uid;
step2：点击保存。

step3：点击返回，返回至工作流开发面板。

提交工作流任务
step1：点击提交，提交已配置的工作流任务。
提交工作流

step2：在变更节点列表弹出框中点击确定提交。
变更节点列表

提交成功后工作流任务处于只读状态，如下：

只读状态

通过补数据功能测试新建的SQL任务
鉴于在数据采集阶段已经测试了数据同步任务，本节中直接测试下游SQL任务即可，也保证了时效性。

step1：进入运维中心>任务列表，找到workshop工作流任务。
工作流任务

step2：单击名称展开工作流。
![进入节点试图]image

step3：选中ods_log_info_d节点，单击补数据。
![选择补数据节点]image

step4：在补数据节点对话框中全选节点名称，选择业务日期，点击运行选中节点。
补数据节点列表

自动跳转到补数据任务实例页面。

step5：输入字母‘d’，通过过滤条件刷新，直至SQL任务都运行成功即可。
展开子节点
确认数据是否成功写入MaxCompute相关表
step1：返回到create_table_ddl脚本文件中。

step2：编写并执行sql语句查看rpt_user_info_d数据情况。
数据预览

附录：SQL语句如下。

---查看rpt_user_info_d数据情况
select * from rpt_user_info_d where dt=业务日期 limit 10;


实验环境准备
必备条件：

开通大数据计算服务MaxCompute
创建大数据开发套件项目空间
进入大数据开发套件，创建DataWorks项目空间
确保阿里云账号处于登录状态。

step1：点击进入大数据（数加）管理控制台>大数据开发套件tab页面下。
step2：点击右上角创建项目或者直接在项目列表—>创建项目，跳出创建项目对话框。1
选择相应的服务器时如果没有购买是选择不了会提示您去开通购买。数据开发、运维中心、数据管理默认是被选择中。

step3：勾选相应的服务单击 确认，跳转到下面的界面，填写相应的信息单击确认，创建项目完成。2
项目名需要字母或下划线开头，只能包含字母下划线和数字。【注意】项目名称全局唯一，建议大家采用自己容易区分的名称来作为本次workshop的项目空间名称。

step4：单击进入项目跳转到下面的界面：进入大数据开发套件
数据质量
数据质量（DQC），是支持多种异构数据源的质量校验、通知、管理服务的一站式平台。数据质量以数据集（DataSet）为监控对象，目前支持MaxCompute数据表和DataHub实时数据流的监控，当离线MaxCompute数据发生变化时，数据质量会对数据进行校验，并阻塞生产链路，以避免问题数据污染扩散。同时，数据质量提供了历史校验结果的管理，以便您对数据质量分析和定级。在流式数据场景下，数据质量能够基于Datahub数据通道进行断流监控，第一时间告警给订阅用户，并且支持橙色、红色告警等级，以及告警频次设置，以最大限度的减少冗余报警。

数据质量的使用流程是，针对已有的表进行监控规则配置，配置完规则后可以进行试跑，验证此规则是否试用。当试跑成功后，可将此规则和调度任务进行关联。关联成功后，每次调度任务代码运行完毕，都会触发数据质量的校验规则，以提升任务准确性。在关联调度后，可根据业务情况，对重要的表进行订阅。订阅成功后，此表的数据质量一旦出问题，都会有邮件或者报警进行通知。

注：数据质量会产生额外的计算费用，在使用时请注意。

新增表规则配置
若已完成《日志数据上传》、《用户画像》实验，我们会得到表：ods_raw_log_d、ods_user_info_d、ods_log_info_d、dw_user_info_all_d、rpt_user_info_d。

数据质量最重要的就是表规则的配置，那么如何配置表规则才是合理的呢？我们来看一下上面这几张表应该如何配置表规则。

ods_raw_log_d
在数据质量中可以看到该项目下的所有表信息，现在我们来给 ods_raw_log_d 表进行数据质量的监控规则配置。

image

选择ods_raw_log_d表，点击配置监控规则，将会进入如下页面。

image

我们可以回顾一下 ods_raw_log_d 这张表的数据来源，ods_raw_log_d 这张表的数据是从ftp中获取到的日志数据，其分区是以${bdp.system.bizdate}格式写入进表中（”dbp.system.bizdate” 是获取到前一天的日期）。

image

对于这种每日的日志数据，我们可以配置一下表的分区表达式，分区表达式有如下几种，我们选择 dt=$[yyyymmdd-1] 这种表达式，有关调度表达式的详细解读，请参考文档调度参数。

imageimage

注：若表中无分区列，可以配置无分区，请根据真实的分区值，来配置对应的分区表达式。

确认以后，可以见到如下界面，我们可以选择创建规则。

image

选择创建规则后，出现如下界面：

image

点击添加监控规则，会出现一个提示窗，来配置规则。

image

这张表里的数据来源于FTP上传的日志文件，作为源头表，我们需要尽早判断此表分区中是否有数据。如果这张表中没有数据，那么就需要阻止后面的任务运行，因为来源表没有数据，后面的任务运行是没有意义的。

注：只有强规则下红色报警会导致任务阻塞，阻塞会将任务的实例状态置为失败。

我们在配置规则的时候，选择模板类型为表行数，将规则的强度设置为强，比较方式设置为期望值不等于0，设置完毕后点击批量保存按钮即可。

image

此配置主要是为了避免分区中没有数据，导致下游任务的数据来源为空的问题。

规则试跑
右上角有一个节点试跑的按钮，可以在规则配置完毕后，进行规则校验，试跑按钮可立即触发数据质量的校验规则。

image

点击试跑按钮后，会提示一个弹窗，确认试跑日期。点击试跑后，下方会有一个提示信息，点击提示信息，可跳转至试跑结果中。

image

image

可根据试跑结果，来确认此次任务产出的数据是否符合预期。建议每个表规则配置完毕后，都进行一次试跑操作，以验证表规则的适用性。

在规则配置完毕，且试跑又都成功的情况下。我们需要将表和其产出任务进行关联，这样每次表的产出任务运行完毕后，都会触发数据质量规则的校验，以保证数据的准确性。

关联调度
数据质量支持任务关联调度，在表规则和调度任务绑定后，每次任务运行完毕，都会触发数据质量的检查。可以在表规则配置界面，点击关联调度，配置规则与任务的绑定关系。

image

点击关联调度，可以与已提交到调度的节点任务进行绑定，我们会根据血缘关系给出推荐绑定的任务，也支持自定义绑定。

image

选中搜索结果后，点击添加，添加完毕后即可完成与调度节点任务的绑定。

image

关联调度后，表名后面的小图标会变成蓝色。

image

配置任务订阅
关联调度后，每次调度任务运行完毕，都会触发数据质量的校验，但是我们如何去跟进校验结果呢？数据质量支持设置规则订阅，可以针对重要的表及其规则设置订阅，设置订阅后会根据数据质量的校验结果，进行告警。若数据质量校验结果异常，则会根据配置的告警策略进行通知。

点击订阅管理，设置接收人以及订阅方式，目前支持邮件通知及邮件和短信通知。

imageimageimage

订阅管理设置完毕后，可以在我的订阅中进行查看及修改。

image

建议将全部规则订阅，避免校验结果无法及时通知。

ods_user_info_d
ods_user_info_d 表的数据来至于rds的数据库，为用户信息表。我们在配置规则的时候，需要配置表的行数校验；还需要配置主键唯一的校验，避免数据重复。

同样，我们还是需要先配置一个分区字段的监控规则，监控的时间表达式为：dt=$[yyyymmdd-1]，配置成功后，在已添加的分区表达式中可以看到成功的分区配置记录。

image

分区表达式配置完毕后，点击右侧的创建规则，进行数据质量的校验规则配置。添加表行数的监控规则，规则强度设置为强，比较方式设置为期望值不等于0。

image

添加列级规则，设置主键列(uid)为监控列，模板类型为：字段重复值个数校验，规则设置为弱，比较方式设置为字段重复值个数小于1，设置完毕后，点击批量保存按钮即可。

image

此配置主要是为了避免数据重复，导致下游数据被污染的情况。

请不要忘记试跑->关联调度->规则订阅。

ods_log_info_d
ods_log_info_d 这张表的数据，主要是解析ods_raw_log_d 表里的数据，鉴于日志中的数据无法配置过多监控，只需配置表数据不为空的校验规则即可。先配置表的分区表达式为：dt=$[yyyymmdd-1]

image

配置表数据不为空的校验规则，规则强度设置为强，比较方式设置为期望值不等于0，设置完毕后，点击批量保存按钮即可。

image

请不要忘记试跑->关联调度->规则订阅。

dw_user_info_all_d
dw_user_info_all_d 这个表是针对ods_user_info_d 和 ods_log_info_d 表的数据汇总，由于此流程较为简单，ods层又都已配置了表行数不为空的规则，所以此表不进行数据质量监控规则的配置，以节省计算资源。

rpt_user_info_d
rpt_user_info_d 表是数据汇总后的结果表，根据此表的数据，我们可以进行表行数波动监测，针对主键进行唯一值校验等。先配置表的分区表达式：dt=$[yyyymmdd-1]

image

然后配置监控规则，单击右侧创建规则，点击添加监控规则。添加列级规则，设置主键列(uid)为监控列，模板类型为：字段重复值个数校验，规则设置为弱，比较方式设置为字段重复值个数小于1。

image

继续添加监控规则，添加表级规则，模板类型为：SQL任务表行数，7天波动检测；规则强度设置为弱，橙色阈值设置成0%，红色阈值设置成50%（此处阈值范围根据业务逻辑进行设置），配置完毕后，点击批量保存即可。

image

注：此处我们监控表行数主要是为了查看每日uv的波动，好及时了解应用动态。

请不要忘记试跑->关联调度->规则订阅。

大家可能注意到了，我们在设置表规则强度的时候，数据仓库中越底层的表，设置强规则的次数越多。那是因为ods层的数据作为数仓中的原始数据，一定要保证其数据的准确性，避免因ods层的数据质量太差而影响其他层的数据，及时止损。

数据质量还提供了一个任务查询的界面，在此界面上，我们可以查看已配置规则的校验结果。

维度的基本概念

在维度建模中，将度量称为“事实” ，将环境描述为“维度”，

维度是用于分析事实所需要的多样环境。例如，在分析交易过程时，可以通过买家、卖家、商品和时间等维度描述交易
发生的环境。


维度所包含的表示维度的列，称为维度属性。


维度属性是查询约束条件、分组和报表标签生成的基本来源，是数据易用性的关键。

例如，
在查询请求中，获取某类目的商品、正常状态的商品等，
是通过约束商品类目属性和商品状态属性来实现的；


统计淘宝不同商品类目的每日成交金额，是通过商品维度的类目属性进行分组的；

我们在报表中看到的类目、BC 类型（ B 指天猫， C 指集市）等，都是维度属性。

所以维度的作用一般是查询约束、分类汇总以及排序等。


如何获取维度或维度属性？
如上面所提到的，一方面，可以在报表中获取；
另一方面，可以在和业务人员的交谈中发现维度或维度属性。

因为它们经常出现在查询或报表请求中的“按照”（ by ）语句内。

例如，用户要“按照”月份和产品来查看销售情况，那么用来描述其业务的自然方法应该作为维度或维度属性包括在维度模型中。

维度使用主键标识其唯一性，

主键也是确保与之相连的任何事实表

之间存在引用完整性的基础。

主键有两种：代理键和自然键，

它们都是用于标识某维度的具体值。

但代理键是不具有业务含义的键， 一般用于处理缓慢变化维；

自然键是具有业务含义的键。比如商品，在ETL 过程中，对于商品维表的每一行，可以生成一个唯一的代理键与之对应；
商品本身的自然键可能是商品ID 等。


其实对于前台应用系统来说，商品ID 是代理键：


而对于数据仓库系统来说，商品ID 则属于自然键。

============

维度的基本设计方法

正如Kimball 所说的，数据仓库的能力直接与维度属性的质量和深度成正比。


淘宝的商品维度为例对维度设计方法
------------------
第一步：选择维度或新建维度。

作为维度建模的核心，在企业级数据仓库中必须保证维度的唯一性。
以淘宝商品维度为例，有且只允许有一个维度定义

------------------
第二步：确定主维表。此处的主维表一般是ODS 表，
直接与业务系统同步。

以淘宝商品维度为例， s_a uction_ auctions 是与前台商品中心系统同步的商品表，此表即是主维表。
------------------
第三步：确定相关维表。

根据对业务的梳理，确定哪些表和主维表存在关联关系，并选择其中的某些表用于生成维度属性。

商品与类目
SPU
卖家
店铺
------------------

第四步：确定维度属性。本步骤主要包括两个阶段，

其中第一个阶段是从主维表中选择维度属性或生成新的维度属性；

第二个阶段是从相关维表中选择维度属性或生成新的维度属性。

以淘宝商品维度为例，
从主维表（ s_auction_auctions ）

和类目、SPU 、卖家、店铺等相关维表中
选择维度属性或生成新的维度属性


( 1 ）尽可能生成丰富的维度属性

比如淘宝商品维度有近百个维度属性，

为下游的数据统计、分析、探查提供了良好的基础。


(2 ）尽可能多地给出包括一些富有意义的文字性描述

在间里巴巴维度建模中，一般是编码和文字同时存在，

商品维度中的商品ID 和商品标题、类目ID 和类目名称等。

ID 一般用于不同表之间的关联，
名称一般用于报表标签。


( 3 ）区分数值型属性和事实

数值型宇段是作为事实还是维度属性，可以参考字段的一般用途。

如果通常用于查询约束条件或分组统计，则是作为维度属性；

如果通常用于参与度量的计算， 则是作为事实。

商品价格，可以用于查询约束条件或统计价格区间的商品数量，
此时是作为维度属性使用的；

也可以用于统计某类目下商品的平均价格，此时是作为事实使用的。

如果数值型字段是离散值，则作为维度属性存在的可能性较大；

如果数值型宇段是连续值，则作为度量存在的可能性较大，


(4 ）尽量沉淀出通用的维度属性

有些维度属性获取需要进行比较复杂的逻辑处理，

有些需要通过多表关联得到，

通过单表的不同宇段混合处理得到，

或者通过对单表的某个字段进行解析得到。

此时，需要将尽可能多的通用的维度属性进行沉淀。

一方面，可以提高下游使用的方便性，减少复杂度；

另一方面，可以避免下游使用解析时由于各自逻辑不同而导致口径不一致。


商品是否在线，即在淘宝网站是否可以查看到此商品，是重要的查询约束的条件，

但是无法直接获取，需要进行加工，

加工逻辑是：
商品状态为0 和 l 且商品上架时间小于或等于当前时间，则是在线商品g
否则是非在线商品。

所以需要封装商品是否在线的逻辑作为一个单独的属性字段。

--------------------------

维度的层次结构

维度中的一些描述属性

以层次方式或一对多的方式相互关联，

可以被理解为包含连续主从关系的属性层次。

维度常常有多个这样的嵌入式层次结构。

比如淘宝商品维度，有卖家、类目、品牌等。

商品属于类目，

类目属于行业，

其中类目的最低级别是叶子类目，叶子

类目属于二级类目，二级类目属于一级类目。


在属性的层次结构中进行钻取是数据钻取的方法之一。

看看如何在层次结构中进行钻取。

假设己有一个淘宝交易订单，创建事实表。

现在统计2015 年“双
l 1 ”的下单GMV ， 得到一行记录；沿着层次向下钻取，
添加行业，得到行业实例个数的记录数；

继续沿着层次向下钻取，添加一级类目，得到一级类目实例个数的记录数。

可以看到，通过向报表中添加连续的维度细节级别，实现在层次结构中进行钻取。


==============================================================================


规范化和反规范化
当属性层次被实例化为一系列维度，
被称为雪花模式。大多数联机事务处理系统（ OLTP ）的底层数据结构在设计
时采用此种规范化技术，

通过规范化处理将重复属性移至其自身所属的表中，删除冗余数据。

这种方法用在OLTP 系统中可以有效避免数据冗余导致的不一致
性。

比如在OLTP 系统中，存在商品表和类目表，且商品表中有冗余的
类目表的属性字段，假设对某类目进行更新，则必须更新商品表和类目
表，且由于商品和类目是一对多的关系，商品表可能每次需要更新几十
万甚至上百万条记录，这是不合理的。


而对于联机分析处理系统（ OLAP)来说，数据是稳定的，不存在OLTP 系统中所存在的问题。

对于淘系商品维度，如果采用雪花模式进行规范化处理，将表现为

----------------------
将维度的属性层次合并到单个维度中的操作称为反规范化。分析系
统的主要目的是用于数据分析和统计，如何更方便用户进行统计分析决
定了分析系统的优劣。

采用雪花模式，用户在统计分析的过程中需要大量的关联操作，使用复杂度高，同时查询性能很差；

而采用反规范化处理，则方便、易用且性能好。

对于淘宝商品维度，如果采用反规范化处理，将表现为所示的形式。

如上所述，从用户角度来看简化了模型，
并且使数据库查询优化器的连接路径比完全规范化的模型简化许多。

反规范化的维度仍包含与规范化模型同样的信息和关系，

从分析角度来看，没有丢失任何信息，但复杂性降低了。、

商品
商品ID
商品标题
类目名称
类目特征
行业名称
行业特征
品牌名称
品牌特征
SPU名称
SPU特征


维表一般是很不规范化的。在实际应用中，几乎总是使用维表的空间来
换取简明性和查询性能。

==============

一致性维度和交叉探查


Kimball 的数据仓库总线架构提供了一种分解企业级数据仓库规划任
务的合理方法，通过构建企业范围内一致性维度和事实来构建总线架构。



数据仓库总线架构的重要基石之一就是一致性维度。

在针对不同数据域进行迭代构建或并行构建时，

存在很多需求是对于不同数据域的业务过程或者同一数据域的不同业务过程合并在一起观察。


比如

维度不一致性



	是商品维度1 ；对于交易数据域，统计使用的
是商品维度2 。商品维度l 包含维度属性B C 类型， 而商品维度2 无此
属性，则无法在BC 类型上进行交叉探查


	商品
		PV UV
		下单GMV
	计算转化率

	商品维度1 的商品上架时间
这一维度属性时间格式是yyyy-MM -dd HH:mm:ss

	商品维度2 的商品
上架时间这一维度属性时间格式是UNIX timestamp

	商品维度l 不包含
	阿里旅行的商品，商品维度2 包含全部的淘系商品

	维度格式和内容不一致

----------

一致性维度


共享维表

维度子集

交叉属性

在商品维度中具有类目属性，在卖家维度中具有主营类目属性，两个维度具
有相同的类目属性




======================================================================================

10.2.1 维度整合

数据仓库是一个面向主题的、集成的、非易失的且随时间变化的数据集合，用来支持管理人员的决策。

数据来源是大量的、分散的面向应用的操作型环境。

应用之间的差异具体表现在如下几个方面：
·应用在编码、命名习惯、度量单位等方面会存在很大的差异。

不同应用对于用户的性别编码不同，有0 和1 、F 和M 等；
不同应用的用户ID 含义相同，但字段名称不同，有user 、user_id等；
不同应用对于金额的度量单位不同，有元、分等。


·应用出于性能和扩展性的考虑，或者随技术架构的演变，以及业
务的发展，采用不同的物理实现。拆分至不同类型数据库中，部
分数据采用关系型数据库存储（如Oracle 、MySQL 等），部分数
据采用NoSQL 数据库存储（如HBase 、Tair 等）。拆分成同一类
型数据库中的多个物理表，比如对于淘宝商品，

有商品主表和商品扩展表，
商品主表存储商品基本信息，
商品扩展表存储商品特殊信息，如不同产品线的定制化信息等；

对于淘宝会员，有会员主表和会员扩展表，
会员主表存储用户基本信息，
会员扩展表存储用户扩展信息，如用户的各种标签信息等。

·命名规范的统一。表名、字段名等统一。

·字段类型的统一。相同和相似字段的字段类型统一。

·公共代码及代码值的统一。公共代码及标志性宇段的数据类型、
命名方式等统一。

· 业务含义相同的表的统一。

在物理实现中，将业务关系大、源系统影响差异小的表进行整合：
将业务关系小、游、系统影响差异大的表进行分而置之。

通常有如下几种集成方式：

〉采用主从表的设计方式，
将两个表或多个表都有的字段放在主表中（主要基本信息），从属信息分别放在各自的从表中。

对于主表中的主键，要么采用复合主键、源主键和系统或表区别标志：

要么采用唯一主键、“游、主键和系统或表区别标志”生成新的主键。

通常建议采用复合主键的方式。

》直接合并，共有信息和个性信息都放在同一个表中。如果表
字段的重合度较低，则会出现大量空值，对于存储和易用性
会有影响，需谨慎选择。


》不合并，因为源表的表结构及主键等差异很大，无法合并，
使用数据仓库里的多个表存放各自的数据。


表级别的整合，有两种表现形式。

第一种是垂直整合，即不同的来源表包含相同的数据集，只是存储
的信息不同。比如淘宝会员在源系统中有多个表，如会员基础信息表、
会员扩展信息表、淘宝会员等级信息表、天猫会员等级信息表，这些表
都属于会员相关信息表，依据维度设计方法，尽量整合至会员维度模型中，丰富其维度属性。


第二种是水平整合，
即不同的来源表包含不同的数据集，不同子集之间无交叉，也可以存在部分交叉。比如针对蚂蚁金服的数据仓库，其
采集的会员数据有淘宝会员、1688 会员、国际站会员、支付宝会员等，
是否需要将所有的会员整合到一个会员表中呢？

如果进行整合，首先需要考虑各个会员体系是否有交叉，如果存在交叉，则需要去重；如果不
存在交叉，则需要考虑不同子集的自然键是否存在冲突，如果不冲突，
则可以考虑将各子集的自然键作为整合后的表的自然键；另一种方式是
设置超自然键，将来源表各子集的自然键加工成一个字段作为超自然
键。在阿里巴巴，通常采用将来源表各子集的自然键作为联合主键的方
式，并且在物理实现时将来源字段作为分区字段。
有整合就有拆分，到底是整合还是拆分，由多种因素决定。下面两
节讨论维度的水平拆分和垂直拆分。

历史归档

历史归档
阿里巴巴历史截至当前的淘系（含淘宝、天猫和聚划算）商品有几
百亿条记录，在Max Compute 中，一天的全量数据占用约3 6TB 的存储。
面对如此庞大的数据量，如何设计模型、如何降低存储、如何让下游方
便获取数据，成为必须要解决的问题。对于历史数据，是否存在前台已
经不再使用的情况？答案是肯定的，对于如此庞大的数据量，现有的技
术架构也很难处理。前台有一套数据归档策略，比如将商品状态为下架
或删除的且最近31 天未更新的商品归档至历史库： 具体逻辑根据不同
BU 有不同的算法，且有特殊的规则。
在数据仓库中，可以借用前台数据库的归档策略， 定期将历史数据
归档至历史维表。在实践中，网里巴巴数据仓库设计了商品维表和历史
商品维表，每天将历史数据归档至历史商品维表。关于归档策略，有以
下几种方式。
归档策略l ：同前台归档策略，在数据仓库中实现前台归档算法，
定期对历史数据进行归档。但存在一些问题，一是前台归档策略复杂，
实现成本较高z 二是前台归档策略可能会经常变化， 导致数据仓库归档
算法也要随之变化，维护和沟通成本较高。此方式适用于前台归档策略
逻辑较为简单，且变更不频繁的情况。
归档策略2 ：同前台归档策略，但采用数据库变更日志的方式。对
于如此庞大的数据量，阿里巴巴采用的数据抽取策略一般是通过数据库
bin log 日志解析获取每日增量，通过增量m erge 全量的方式获取最新的
全量数据。可以使用增量日志的删除标志， 作为前台数据归档的标志。
通过此标志对数据仓库的数据进行归档。此方式不需要关注前台归档策
略，简单易行。但对前台应用的要求是数据库的物理删除只有在归档时
才执行，应用中的删除只是逻辑删除。
归档策略3 ：数据仓库自定义归档策略。可以将归档算法用简单、
171 .A
一寸大数据之路一一阿里巴巴大数据实践
直接的方式实现，但原则是尽量比前台应用晚归档、少归档。避免出现
数据仓库中已经归档的数据再次更新的情况。
如果技术条件允许，能够解析数据库bin log 日志，建议使用归档策
略2 ，规避前台归档算法。具体可以根据自身数据仓库的实际情况进行
选择。

--------
缓慢变化维

数据仓库的重要特点之一是反映历史变化，所以如何处理维度的变
化是维度设计的重要工作之一。缓慢变化维的提出是因为在现实世界
中，维度的属性并不是静态的，它会随着时间的流逝发生缓慢的变化。
与数据增长较为快速的事实表相比，维度变化相对缓慢。
在一些情况下，保留历史数据没有什么分析价值；而在另一些情况
下，保留历史数据将会起到至关重要的作用。在Kimball 的理论中， 有
三种处理缓慢变化维的方式，下面通过简单的实例进行说明，具体细节
请翻阅Kimball 的相关书籍。
第一种处理方式：重写维度值。采用此种方式，不保留历史数据，
始终取最新数据。比如，商品所属的类目于2015 年11 月16 日由类目
l 变成类目2 ，采用第一种处理方式，变化前后的数据记录分别如表I 0.4
和表l 0.5 所示。
商品Key
1000
订单Key
9000
.... 172
表10.4 变化前商品表和订单表
商品ID
item!
日期Key
2015-11-11
商品标题
titilel
商品Key
1000
所属类目
类自l
交易金额
103.00
其他维度属性
其他事实
第10 章维度设计丁一
表10.5 变化后商品表和订单表
商品Key 商品ID 商品标题所属类目其他维度属性
1000 item I titilel 类目2
订单Key 日期Key 商品Key 交易金额其他事实
9000 2015-11-11 1000 103.00
9001 2015- 11-16 1000 89 .00
第二种处理方式：插人新的维度行。采用此种方式，保留历史数据，
维度值变化前的事实和过去的维度值关联，维度值变化后的事实和当前
的维度值关联。同上面的例子，采用第二种处理方式，变化前的数据记
录同表10.4 ＇变化后的数据记录如表10.6 所示。
表10.6 变化后商品表和订单表
商品Key 商品ID 商品标题所属类目其他维度属性
1000 Item I titilel 类目l
1001 Item I titilel 类目2
订单Key 日期Key 商品Key 交易金额其他事实
9000 2015-11-11 1000 103.00
9001 2015-11-16 1001 89.00
第三种处理方式：添加维度列。采用第二种处理方式不能将变化前
后记录的事实归一为变化前的维度或者归一为变化后的维度。比如根据
业务需求，需要将l 1 月份的交易金额全部统计到类目2 上，采用第二
种处理方式无法实现。针对此问题，采用第三种处理方式，保留历史数
据，可以使用任何一个属性列。同上面的例子，采用第三种处理方式，
变化前后的数据记录分别如表10.7 和表10 .8 所示。通过变化后的商品
表和订单表关联，可以根据不同的业务需求，将l l 月份的交易金额全
部统计到类目2 或类目l 上。
商品Key
1000
商品ID
item I
表10 . 7 变化前商品表和订单表
商品标题｜所属新类目｜所属旧类目｜ 其他维度属性
titilel 类自1 类自1
173 ....
一寸大数据之路一一阿里巴巴大数据实践
订单Key 日期Key 商品Key 交易金额其他事实
9000 2015-11-1 I 1000 103.00
表10 . 8 变化后商品表和订单表
商品Key 商品ID 商品标题所属新类目所属旧类目｜ ；其他维度属性
1000 item I titilel 类目2 类目1
订单Key 日期Key 商品Key 交易金额其他事实
9000 2015- 11 - 1 I 1000 103 .00
9001 2015-11- 16 1000 89 .00
对于选择哪种方式处理缓慢变化维，并没有一个完全正确的答案，
可以根据业务需求来进行选择。比如根据商品所属的类目统计淘宝2015
年l 1 月的成交额，商品所属的类目于2015 年l l 月16 日由类目l 变成
类目2 ，假设业务需求方不关心历史数据，将所有的成交额都统计到最
新的类目2 上，则不需要保存历史数据：假设类目l 属于某个业务部门，
类目2 属于另一个业务部门，不同业务部门需要统计各自的业绩，则需
要保留历史数据。
-----------------------------


快照维表
在“维度的基本概念”中，介绍了自然键和代理键的定义，在Kimball
的维度建模中，必须使用代理键作为每个维表的主键，用于处理缓慢变
化维。
但在阿里巴巴数据仓库建设的实践过程中，虽然使用的是Kimba ll
的维度建模理论，但实际并未使用代理键。那么为什么不使用代理键？
如何处理缓慢变化维？
首先看“为什么不使用代理键”这个问题。第一个原因是，阿里巴
巴数据量庞大，使用的是阿里巴巴自助知识产权的分布式计算平台
Max Compute 。对于分布式计算系统，不存在事务的概念，对于每个表
的记录生成稳定的全局唯一的代理键难度很大，此处稳定指某条记录每
‘ 174
第10 章维度设计寸一
次生成的代理键都相同。第二个原因是，使用代理键会大大增加ETL
的复杂性，对E TL 任务的开发和维护成本很高。
接下来讨论不使用代理键如何处理缓慢变化维的问题。在阿里巴巴
数据仓库实践中，处理缓慢变化维的方法是采用快照方式。数据仓库的
计算周期一般是每天一次，基于此周期，处理维度变化的方式就是每天
保留一份全量快照数据。比如商品维度，每天保留一份全量商品快照数
据。任意一天的事实均可以获取到当天的商品信息，也可以获取到最新
的商品信息，通过限定日期，采用自然键进行关联即可。此方法既有优
点，也有弊端。
优点主要有以下两点：
· 简单而有效，开发和维护成本低。
· 使用方便，理解性好。数据使用方只需要限定日期，即可获取到
当天的快照数据。任意一天的事实快照和维度快照通过维度的自
然键进行关联即可。
弊端主要体现在存储的极大浪费上。比如某维度，每天的变化量占
总体数据量的比例很低，在极端情况下，每天无变化，使得存储浪费很
严重。此方法主要就是实现了牺牲存储获取E TL 效率的优化和逻辑上
的简化。但是一定要杜绝过度使用这种方法，而且必须要有对应的数据
生命周期制度，清除无用的历史数据。
综合来看，由于现在存储成本远低于CPU 、内存等的成本，此方
法弊大于利。那么是否有方法既可以实现上面的优点，同时又可以很好
地降低存储呢？答案是肯定的，那就是阿里巴巴的极限存储。




--------------
微型维度

    采用极限存储，需要避免维度的过度增长。比如对于商品维表，每天20 多亿条数据，
如果在设计商品维度时，将值变化频繁的属性加入到商品维度中，
极限情况是每天所有商品数据都发生变化，此时，极限存储没有意义；
反之，每天所有商品数据都不发生变化，此时，只需要存储一天的数据即可。
通过将一些属性从维表中移出，放置到全新的维表中，可以解决维
度的过度增长导致极限存储效果大打折扣的问题。其中一种解决方法就
是上一节提到的垂直拆分，保持主维度的稳定性；另一种解决方式是采
用微型维度。

    微型维度的创建是通过将一部分不稳定的属性从主维度中移出，并
将它们放置到拥有自己代理键的新表中来实现的。这些属性相互之间没
有直接关联，不存在自然键。通过为每个组合创建新行的一次性过程来
加载数据。比如淘宝用户维度，用户的注册日期、年龄、性别、身份信
息等基本不会发生变化，但用户VI P 等级、用户信用评价等级会随着用
户的行为不断发生变化。其中VIP 等级共有8 个值，即一l ～6 ；用户信
用评价等级共有18 个值。假设基于VIP 等级和用户信用评价等级构建
微型维度，则在此微型维度中共有8x18 个组合，即144 条记录，代理
键可能是l ～ 1440

    这里以淘宝交易事实表为例，其他维度忽略，星形模式可能表示如图10.3 所示。

但在阿里巴巴数据仓库实践中，并未使用此技术，主要有以下几点
原因：
· 微型维度的局限性。微型维度是事先用所有可能值的组合加载
的，需要考虑每个属性的基数，且必须是枚举值。很多属性可能
是非枚举型，比如数值类型，如VIP 分数、信用分数等；时间类
型，如上架时间、下架时间、变更时间等。
• ETL 逻辑复杂。对于分布式系统，生成代理键和使用代理键进行
ETL 加工都非常复杂， ETL 开发和维护成本过高。
· 破坏了维度的可浏览性。买家维度和微型维度通过事实表建立联
系，无法基于VIP 等级、信用等级进行浏览和统计。可以通过在
买家维度中添加引用微型维度的外键部分来解决此问题，但带来
的问题是微型维度未维护历史信息。




========

第十七条 按照大数据应用架构规范要求，大数据系统数据仓库分ODS层、DM层、OCP平台。

（一）ODS层（即BDP）作为公司内部唯一共享的基础数据平台，遵从“一份数据、多方使用”的原则，以项目或需求驱动，相应IT负责实施，如无法明确IT实施方，由源系统IT负责实施，最大程度确保数据正确性、完整性、一致性；


（二）DM层数据集市是面向各业务线、各部门、特定主题的数据仓库，由IT各团队自行建设，用于支撑用户数据分析、智能应用、经营决策等业务应用；


（三）OCP平台是公司对外数据输出的唯一通道，以项目或需求驱动，以项目或需求驱动，相应IT负责实施，如无法明确IT实施方，由源系统IT负责实施，它把公司对内、对外数据做有效隔离，确保其使用安全、可靠。


第十八条 由数据安全治理小组指定接口人，定期组织大数据治理例会，统筹跟踪IT各团队数据治理的进展，并负责BDP和OCP的版本管理和规范检查。
第十九条 由IT各团队指定接口人，统筹团队内数据集市的数据治理、及涉及BDP和OCP的相关整改等工作。

第二十条 ODS层治理规范
（一）用于存储操作型业务清单，数据来源于公司各业务系统、及外部系统；
（二）BDP建库规范
（1）Hive库命名须遵守“sx_bdp_源系统数据库id或源系统简称_safe”命名规范；
（2）对于每个内部源系统，只能创建一个ODS库，比如：对应金管家系统，创建ODS库“sx_bdp_rsapp_safe”；
（3）对于每个外部源系统，可以创建一个ODS库，如果外部源系统较分散、且表较少，可按主题分类创建ODS库，
比如：采购外部多家供应商100张征信数据表，可创建以征信为主题ODS库“sx_bdp_credit_safe”。
（三）BDP建表规范
（1）增量表设计遵守“idld(w/m)_源系统数据库id或源系统简称_源表名”命名规范，存储格式必须为TextFile，比如：“idld_lbs_pol_info”；
（2）全量表设计遵守“bas_源系统数据库id或源系统简称_源表名” 命名规范，存储格式必须为ORCFile，比如：“bas_lbs_pol_info”；
（3）基表设计遵守“dim_源系统数据库id或源系统简称_源表名_tbl” 命名规范，一般是全量同步，存储格式必须为TextFile，比如：“dim_lbs_case_state_tbl”；
（4）ODS层所有表、字段必须添加comment，用于标识表或字段业务含义；

第二十一条 DM层治理规范
（一）DM层用于存储各业务线、各部门的汇总数据及加工过程数据, 数据来源于ODS层。
（二）DM层建库规范
（1）Hive库命名须遵守“sx_项目简称或系统简称或部门简称_safe”命名规范；
（2）对于每个项目或系统或部门，建议创建一个Hive库，比如：对应管理会计项目，创建“sx_mas_safe”库；

（三）DM层建表规范
（1）主题明细表建议按模块划分，其设计遵守“sub_模块_主题[_day/mon/week/year]”命名规范，比如：再开发率模块的员工信息表sub_redev_emp_info；
（2）主题汇总表建议按模块划分，其设计遵守“agg_模块_主题[_day/mon/week/year]”命名规范，比如：
（3）公共明细表设计遵守“pub_业务含义[_day_mon/week/year]”命名规范，比如：客户信息表pub_client_info；
（4）基表设计遵守“dim_业务含义_tbl”命名规范；
（5）临时表建议按模块划分，其设计遵守“SEQ_目标表[_序号]”命名规范，比如：seq_app_app_smzq_day_01、seq_app_app_smzq_day_02；
（6）对于包含时间字段、且支持按时间批量处理的明细表或汇总表，建议按时间字段做分区处理；
（7）DM层所有表、字段必须添加comment，用于标识表或字段业务含义；


第二十二条 OCP平台治理规范

（一）OCP平台用于存储公司对外输出的数据，数据来源于ODS层或DM层。

（二）OCP平台仅创建一个Hive库sx_inout_safe，开放给各IT团队共同使用。

（三）OCP平台建表规范
（1）OCP平台建表遵守“out_源系统简称_to_目标系统简称_表名”命名规范；
（2）OCP平台表分区规则、表及字段comment必须与源表保持一致；

（四）公司数据对外输出流程
（1）步骤一：由项目或需求方明确输出数据范围（表、字段、数据量），征求属主部门同意；
（2）步骤二：由项目或需求方发起输出方案评审（邮件或会议），如经过数据安全治理小组评审无异议，再提交签报审批（须附上评审邮件或会议纪要）；
（3）步骤三：签报审批后，由项目或需求方安排实施；
（4）步骤四：由数据使用方提交签报，申请访问权限；
（5）步骤五：由数据安全治理小组完成输出数据登记；



第二十三条 敏感信息治理规范

（一）参考《数据脱敏和加密管理办法》，须对公司大数据平台涉及敏感信息的所有字段（包括姓名、身份证、银行卡、手机号、联系地址、Email等）进行脱敏，才可开放给开发、业务申请访问。

（二）敏感信息脱敏规范
（1）敏感信息、非敏感信息均存储在SAFE库，不分库，敏感信息通过白名单管理；
（2）Hadoop所有包含敏感信息的表，必须创建脱敏表，其设计遵守“表名_PV”命名规范；
（3）从生产库向开发或测试库导数，如涉及敏感信息，必须经过脱敏，才可导入；
（4）涉及脱敏的所有UDF，由业务安全团队负责开发、维护。
（三）公司大数据平台所有涉及敏感信息的表、字段等，将由数据安全治理小组登记、维护白名单；同时，业务安全团队会定期进行敏感信息审计，如发现有遗漏登记、遗漏脱敏的敏感信息，将通知数据安全治理小组、IT各团队进行确认、处理。
