分布式缓存

第　1章 基于HTTP的内存缓存服务　3
1．1　缓存服务的接口　3
1．1．1　REST接口　3
1．1．2　缓存Set流程　5
1．1．3　缓存Get流程　6
1．1．4　缓存Del流程　7
1．2　Go语言实现　8
1．2．1　main包的实现　8
1．2．2　cache包的实现　9
1．2．3　HTTP包的实现　14
1．3　功能演示　19
1．4　与Redis比较　21
1．4．1　Redis介绍　21
1．4．2　redis-benchmark介绍　23
1．4．3　cache-benchmark介绍　24
1．4．4　性能对比　26
1．5　小结　30
第　2章 基于TCP的内存缓存服务　32
2．1　基于TCP的缓存协议规范　33
2．1．1　协议范式　33
2．1．2　缓存Set流程　35
2．1．3　缓存Get流程　36
2．1．4　缓存Del流程　36
2．2　Go语言实现　37
2．2．1　main函数的变化　37
2．2．2　TCP包的实现　38
2．2．3　客户端的实现　44
2．3　功能演示　45
2．4　性能测试　47
2．5　小结　48
第3章　数据持久化　50
3．1　RocksDB简介　50
3．2　RocksDB性能测试　51
3．2．1　基本读写性能　52
3．2．2　大容量测试　52
3．3　用cgo调用C++库函数　55
3．4　Go语言实现　58
3．4．1　main函数的实现　58
3．4．2　cache包的实现　59
3．5　功能演示　65
3．6　性能测试　67
3．7　小结　69
第　2部分 性能相关
第4章　用pipelining加速性能　73
4．1　pipelining原理　73
4．2　redis pipelining性能对比　75
4．3　Go语言实现　77
4．3．1　main包的实现　77
4．3．2　cacheClient包的实现　86
4．4　性能测试　97
4．5　小结　99
第5章　批量写入　101
5．1　批量写入能够提升写入性能的原理　101
5．2　RocksDB批量写入性能测试　102
5．3　Go语言实现　103
5．4　性能测试　108
5．5　小结　112
第6章　异步操作　113
6．1　异步操作能够提升读取性能的原理　114
6．2　Go语言实现　117
6．3　性能测试　122
6．4　小结　127

第3部分　服务集群

第7章　分布式缓存　131

7．1　为什么我们需要集群服务　131

7．2　负载均衡和一致性散列　133

7．3　获取节点列表的接口　140

7．4　Go语言实现　140

7．4．1　main函数的实现　140

7．4．2　cluster包的实现　141

7．4．3　HTTP包的实现　145

7．4．4　TCP包的实现　147

7．5　功能演示　149

7．6　小结　152


第8章　节点再平衡　154

8．1　节点再平衡的技术细节　154

8．2　节点再平衡的接口　155

8．3　Go语言实现　155

8．3．1　HTTP包的实现　155

8．3．2　cache包的实现　157

第9章　缓存生存时间　166

9．1　缓存生存时间的作用　166
一般30秒OK，如果你网站浏览量比较大90秒也可以，根据你的网站需要即可，我一般都定位30，如果不设置缓存的话，服务器压力比较大！

9．2　Go语言实现　167

9．2．1　main函数的实现　167

9．2．2　cache包的实现　168

9．3　功能演示　172

-------------------------
第1章　缓存为王1

1.1　什么是缓存？1

1.2　为什么使用缓存？2

1.2.1　从用户体验说起3

1.2.2　关于系统的性能3

1.3　从网站的架构发展看缓存4

1.4　客户端缓存5

1.4.1　页面缓存6

1.4.2　浏览器缓存7

1.4.3　APP上的缓存8

1.5　网络中的缓存11

1.5.1　Web代理缓存11

1.5.2　边缘缓存12

1.6　服务端缓存14

1.6.1　数据库缓存14

1.6.2　平台级缓存16

1.6.3　应用级缓存18

第2章　分布式系统理论24

2.1　分布式系统概论24

2.2　分布式系统概念26

2.2.1　进程与线程26

2.2.2　并发26

2.2.3　锁26

2.2.4　并行27

2.2.5　集群27

2.2.6　状态特性28

2.2.7　系统重发与幂等性28

2.2.8　硬件异常30

2.3　分布式系统理论31

2.3.1　CAP理论32

2.3.2　CAP理论澄清34

2.3.3　Paxos35

2.3.4　2PC38

2.3.5　3PC39

2.3.6　Raft40

2.3.7　Lease机制41

2.3.8　解决“脑裂”问题43

2.3.9　Quorum NWR44

2.3.10　MVCC45

2.3.11　Gossip46

2.4　分布式系统设计策略49

2.4.1　心跳检测50

2.4.2　高可用设计50

2.4.3　容错性52

2.4.4　负载均衡53

2.5　分布式系统设计实践54

2.5.1　全局ID生成54

2.5.2　哈希取模56

2.5.3　一致性哈希57

2.5.4　路由表58

2.5.5　数据拆分58

第3章　动手写缓存60

3.1　缓存定义的规范60

3.1.1　新规范的主要内容及特性60

3.1.2　新规范的API介绍61

3.2　缓存框架的实现62

3.2.1　前期准备63

3.2.2　缓存的架构介绍63

3.2.3　设计思路以及知识点详解64

3.3　缓存框架的使用示例74

第4章 　Ehcache与Guava Cache76

4.1　Ehcache的主要特性76

4.2　Ehcache使用介绍77

4.2.1　Ehcache架构图77

4.2.2　缓存数据过期策略78

4.2.3　Ehcache缓存的基本用法81

4.2.4　在Spring中使用Ehcache83

4.3　Ehcache集群介绍85

4.3.1　集群的方式86

4.3.2　如何配置集群88

4.4　 Ehcache的适用场景89

4.5　Guava Cache的使用92

4.5.1　Guava Cache的适用场景92

4.5.2　Guava Cache的创建方式93

4.5.3　缓存数据删除95

4.5.4　并发场景下的使用95

4.6　本章小结96

第5章　从Memcached开始了解集中式缓存97

5.1　Memcached基本知识98

5.1.1　Memcached的操作命令98

5.1.2　Memcached使用场景100

5.1.3　Memcached特征100

5.1.4　Memcached的一些问题101

5.2　Memcached内存存储102

5.2.1　Slab Allocation机制102

5.2.2　使用 Growth Factor进行调优104

5.2.3　Item105

5.3　典型问题解析106

5.3.1　过期机制106

5.3.2　哈希算法107

5.3.3　热点问题108

5.3.4　缓存与数据库的更新问题108

5.3.5　别把缓存当存储109

5.3.6　命名空间110

5.3.7　CAS110

5.4　Memcached客户端分析110

5.4.1　Memcached的Client111

5.4.2　Spymemcached设计思想解析111

5.5　Memcached周边工具发展117

第6章　Memcached 周边技术119

6.1　Twemcache119

6.1.1　Twemcache 的设计原理120

6.1.2　Twemcache的安装及命令行详解122

6.1.3　基于Java的Twemcache用法125

6.2　Twemproxy126

6.2.1　Twemproxy的常用部署模式127

6.2.2　Twemproxy的可扩展性129

6.2.3　Twemproxy源代码简析131

6.3　Mcrouter137

6.3.1　Mcrouter路由算法138

6.3.2　典型的使用场景139

6.3.3　Mcrouter的可扩展性142

6.3.4　源码简要解析144

第7章　Redis探秘148

7.1　数据结构148

7.1.1　value对象的通用结构149

7.1.2　String149

7.1.3　List152

7.1.4　Map155

7.1.5　Set157

7.1.6　Sorted-Set159

7.2　客户端与服务器的交互160

7.2.1　客户端/服务器协议161

7.2.2　请求/响应模式163

7.2.3　事务模式164

7.2.4　脚本模式168

7.2.5　发布/订阅模式169

7.3　单机处理逻辑171

7.3.1　多路复用171

7.3.2　定时任务处理173

7.4　持久化174

7.4.1　基于全量模式的持久化174

7.4.2　基于增量模式的持久化176

7.4.3　基于增量模式持久化的优化178

第8章　分布式Redis180

8.1　水平拆分（sharding）181

8.1.1　数据分布181

8.1.2　请求路由182

8.2　主备复制（replication）182

8.2.1　主备复制流程183

8.2.2　断点续传183

8.3　故障转移（failover）184

8.3.1　sentinel间的相互感知185

8.3.2　master的故障发现186

8.3.3　failover决策186

8.4　Redis Cluster187

8.4.1　拓扑结构187

8.4.2　配置的一致性188

8.4.3　sharding190

8.4.4　failover193

8.4.5　可用性和性能196

第9章　Tair探秘198

9.1　Tair总体架构198

9.2　Config Server简介199

9.3　Data Server简介201

9.4　Tair高可用和负载均衡204

9.4.1　对照表204

9.4.2　数据迁移219

9.5　存储引擎220

9.6　Tair的API222

9.6.1　key/value相关API223

9.6.2　prefix相关的API226

第10章　EVCache探秘229

10.1　EVCache项目介绍230

10.1.1　EVCache的由来231

10.1.2　EVCache的发展232

10.1.3　EVCache的演进234

10.2　EVCache 的使用场景238

10.2.1　典型用例238

10.2.2　典型部署239

10.3　EVCache的性能240

10.3.1　EVCache集群的性能240

10.3.2　全局化复制时的性能问题242

10.3.3　Moneta项目中的组件性能243

10.4　EVCache 的高可用性244

10.4.1　AWS的多可用区244

10.4.2　EVCache对AWS高可用性的增强245

10.5　源码与示例245

10.5.1　源码浅析245

10.5.2　EVCache 示例253

第11章　Aerospike原理及广告业务应用259

11.1　Aerospike架构259

11.2　Aerospike具体实现261

11.2.1　Aerospike集群管理261

11.2.2　数据分布263

11.3　Aerospike集群配置和部署265

11.3.1　搭建集群的方式与配置266

11.3.2　部署集群267

11.4　Aerospike与Redis的对比271

11.5　Aeropsike在广告行业的具体应用272

11.5.1　Aerospike在个性化推荐广告中的应用273

11.5.2　Aerospike在实时竞价广告中的应用274

第12章　社交场景架构进化：从数据库到缓存283

12.1　社交业务示例283

12.1.1　业务模型283

12.1.2　业务场景284

12.1.3　业务特点285

12.2　关系（relation）的存储286

12.2.1　基于DB的最简方案286

12.2.2　DB的sharding方案288

12.2.3　引入缓存290

12.2.4　缓存的优化方案292

12.3　帖子（post）的存储293

12.3.1　基于DB的方案294

12.3.2　引入服务端缓存296

12.3.3　本地缓存297

12.4　时间线（timeline）的存储297

12.4.1　基于DB的方案—push模式298

12.4.2　基于DB的方案—pull模式300

12.4.3　增量查询引入服务端缓存302

第13章　缓存在社交网络Feed系统中的架构实践304

13.1　Feed系统架构304

13.2　Feed缓存模型307

13.3　Feed缓存架构的设计309

13.3.1　简单数据类型的缓存设计310

13.3.2　集合类数据的缓存设计312

13.3.3　其他类型数据的缓存设计314

13.4　Feed缓存的扩展 315

13.4.1　Redis的扩展315

13.4.2　计数器的扩展316

13.4.3　存在性判断的扩展318

13.5　Feed缓存的服务化319

第14章　典型电商应用与缓存324

14.1　电商类应用的挑战及特点324

14.2　应用数据静态化架构高性能单页Web应用325

14.2.1　整体架构326

14.2.2　CMS系统326

14.2.3　前端展示系统328

14.2.4　控制系统328

14.3　应用多级缓存模式支撑海量读服务329

14.3.1　多级缓存介绍329

14.3.2　如何缓存数据331

14.3.3　分布式缓存与应用负载均衡332

14.3.4　热点数据与更新缓存334

14.3.5　更新缓存与原子性336

14.3.6　缓存崩溃与快速修复336

14.4　构建需求响应式亿级商品详情页337

14.4.1　商品详情页前端结构338

14.4.2　单品页技术架构发展338

14.4.3　详情页架构设计原则343

14.4.4　遇到的一些问题349

第15章　同程凤凰缓存系统基于Redis的设计与实践357

15.1　同程凤凰缓存系统要解决什么问题357

15.1.1　Redis用法的凌乱358

15.1.2　从实际案例再看Redis的使用360

15.1.3　如何改变Redis用不好的误区362

15.1.4　凤凰缓存系统对Redis系统化改造364

15.2　用好Redis先运维好它366

15.2.1　传统的Redis运维方式366

15.2.2　Redis的Docker化部署368

15.2.3　凤凰缓存系统对Redis的监控369

15.2.4　凤凰缓存系统对Redis的集群分片优化370

15.2.5　客户端在运维中的作用371

15.2.6　凤凰缓存系统在Redis运维上的工具372

15.3　凤凰缓存系统的使用效果373

第16章　新的旅程374

16.1　更好的引入缓存技术374

16.1.1　缓存引入前的考量374

16.1.2　缓存组件的选择375

16.1.3　缓存架构的设计376

16.1.4　缓存系统的监控及演进377

16.2　缓存分类总结377

16.3　缓存知识结构更多Tips378

16.3.1　缓存使用模式379

16.3.2　缓存协议379

16.3.3　缓存连接池380

16.3.4　几个关注点383

16.3.5　管理缓存387

16.3.6　缓存可用性390

16.3.7　数据一致性392

16.3.8　热点数据处理393

16.3.9　注意事项Tips396


存储在计算机上的原始数据复制集

CUP缓存 临时存储器 容量比内存小很多 交换速度比内存快很多 等待数据 解决CPU运算速度与内存读写速度不匹配的矛盾

短时间内CPU即将访问 多级缓存

虚拟内存 页虚拟地址->page table、 MMU 内存管理单元 ->物理地址
    page table 记录哪些是物理页 哪些是虚拟页 页表条目 PTE

    MMU 内存管理单元 虚拟地址到物理地址的翻译 硬件
    获取页的ＰＴＥ　使用翻译后备缓存器　ＴＬＢ的缓存页号

用户体验
产品 系统 服务的认知印象和回应
情感 信仰 喜好  认知印象 生理反应 心理反应  行为和成就 等

可用性

使用者的状态 系统性能 环境

--------------------------

系统性能

响应时间
系统对用户请求做出响应的时间
与人对软件性能的主观感受是非常一致的
完整记录了整个系统处理请求的时间

平均
最大响应时间

系统响应时间
    网络传输时间 CS传输时间
    应用延迟时间 系统实际处理请求

吞吐量是系统在单位时间内处理请求的数量

无并发应用 与响应时间成反比

并发用户数 系统可以同时承载的正常使用系统功能的用户数量

资源利用率反映 在一段时间内资源平均被占用

缓存更快
重复使用 降低用户带宽

流量付费

低水平 更容易维护

降低系统响应时间 减少网络传输时间和应用延迟时间
提高吞吐量 增加系统的并发用户数

最小化系统的工作量
使用了缓存就可以不必反复从数据源中查找
缓存所创建或提供的同一条数据更好利用系统


延迟时间

吞吐量

并发用户数

资源利用率

-------------------

缓存机制 减少数据库连接资源的竞争和对数据库读的压力

静态页面缓存

动态缓存登场

页面片段缓存


系统中重复获取数据信息从数据库加载到本地

应用服务器 中数据缓存信息同步
缓存同步机制 共享文件系统 共享存储

数据库集群

分库分表  DataAcessLayer

分布式缓存

无极缩放的

添加服务器


----------------------
页面缓存
自身某些元素或全部元素缓存
服务端将静态页面或动态页面元素缓存

单页面应用 HTML5  离线缓存 本地存储

localStorage

开启离线缓存步骤：
1.描述页面需要缓存的资源列表清单按文件 mainfest text /cache-mainfest
2.在需要离线使用的页面中添加mainfest属性 指定缓存清单文件的路径



---------------------
浏览器缓存




=======================
缓存定义规范

对象的创建 访问 失效 一致性
缓存java对象

进程内 分布式的缓存实现
支持by-value by-reference 缓存对象
缓存注解
javax.cache CacheManager 接口负责保存和控制一系列的缓存

缓存中读取
数据写入缓存
缓存具有原子性
缓存事件监听器
具有缓存注解
保存缓存的Key value 类型应该为泛型

Cache API 定义了4个核心概念

CachingProvider
定义 配置 获取 管理和控制多个CacheManager
一个应用可以在运行期访问多个CachingProvider

CacheManager
定义创建 配置 获取 管理和控制多个唯一命名的Cache
存在于CacheManager上下文中
一个CacheManager仅被一个CacheProvider拥有

Cache:类似Map的数据结构并临时存储以key为索引的值
一个Cache仅被一个CacheManager拥有

Entry:一个存储在Cache中的key value对

每一个存储在Cache中的条目有一个定义的有效期
Expiry Duration

一旦超过这个时间  条目即为过期的状态
一旦过期 条目将不可访问、更新和删除
缓存有效期可以通过ExpiryPolicy设置

store-by-value和store-by-reference
两种不同的缓存实现
store-by-value:
指在key/value



####################

Store-By-Value

在kv 存入时，将值拷贝一份存入缓存 避免其他程序修改 污染缓存中的数据。如常见的堆外缓存和进程外缓存 一般使用引用技术复杂 使用这种

Store_By-Reference
在kv存入时 直接将引用存入缓存，如java常见的堆内缓存 提升缓存性能


缓存过期策略
过期 不能反悔
默认 永久 external
配置时 提供一个ExpiryPolicy

当数据创建后的到期持续时间
当数据访问后的到期持续时间
当数据修改后的到期持续时间

持续时间=缓存过期时间
Duration.ZERO 表面数据目前是过期的

特定缓存持续一段时间数据需要回收
Duration(TimeUnit,durationAmount)

--------------------------------------------
缓存框架实现

内存管理 使用LRU淘汰算法
支持Weak key

缓存标准 JCache JSR107


get 获取
put 放入
remove 根据key删除
clear 清空

------------------------------
客户端层client
数据交互


-----------------------------
缓存提供层
CacheProvider
缓存管理层的生命周期维护 负责缓存管理层的创建  保存 获取 销毁

---------------------------------------------------------------
缓存管理层 缓存客户端的生命周期进行维护 创建 保持 获取 销毁 管理多个Cache客户端实例
CacheManager


缓存实例创建和获取 基于一个缓存池实现
代码中使用的是ConcurrentHashMap 可以根据多个不同的缓存名称创建多个缓存实例  并发读取

-----------------------
数据客户端层
CsCache
CsCache107 适配JSR107标准
CsCache107Manager 实现JSR107标准中的 CacheManager 管理多个cache实例
CsCaching107Provider 实现JSR107标准中的CacheProvider 提供SPI服务

利用java spi 进行组件发现和加载

Service Provider Interface
jdk内置服务提供发现机制 Java.util.ServiceLoader文档有详细介绍
模块直接基于接口编程

设计具体的实现类 违反可拔插原则 替换 修改代码

模块装配时 不在程序里动态指明

为某个接口寻找服务实现的机制

将装配的控制权移动到程序之外

文件必须为UTF-8编码

spi
当服务提供者 提供服务接口实现 jar/META-INF/service/ 同时创建一个以服务接口命名的文件 内容就是具体实现类
当外部程序装配模块  通过配置文件找到实现类 装载实例化 完成模块注入

jdk提供服务查找工具类 java.uti.ServiceLoader

如何使用
ServiceLoad<HelloInterface> loads = ServiceLoad.load(HelloInterface.class)

-------------
调用

CachingProvider cachingProvider = Caching.getCachingProvider();
CacheManager manager = cachingProvider.getCacheManager();

Configuration<String,User>
MutableConfigration<String,User>()

Cache = manager.createCache

cache.put

cache.get(key).getName


-------------------------------------------------------

缓存存储层 数据什么形式存储 Cache(
基本存储 ConcurrentHashMap 数据不淘汰
LRU存储、最近最少
Weak存储）弱引用





DataStore 存储数据的规范定义

BasicDataStore
BasicValueHolder 简单强引用值存储

WeakValueDataStore
基于引用的淘汰算法 JVM GC
StrongRef GC不回收 空间不足 OOM
SoftRefence 内存空间不足 GC回收 实现内存敏感的告诉缓存 可以和ReferenceQueue 如果被GC 把软引用加入队列中
WeakReference 更短生命周期 GC线程扫描 发现 就回收 GC优先级低 不一定发现 可以和ReferenceQueue 如果被GC 把弱引用加入队列中
PhantomReference 没有引用一样 任何时候都可GC
WeakValueHolder 简单弱引用存储



LRUDataStore LRUEntry 简单LRU数据存储
根据历史访问记录进行淘汰 如果最近访问过 将来访问概率也高

维护List<Entry> 最少访问的键值维持在entry尾部
数据量超过Cache 容量做LRU 删除链表尾部的数据

put->加入链表头部 最新 超出链表设定大小 删除尾部最不活跃的节点
get 将节点移动到链表头部 表示数据被最新请求访问 再返回




ValueHolder 具体存储值 规范定义


###############################################

缓存引入
缓存场景 缓存层次 缓存（更新/同步）策略 缓存组件 数据结构 分布 部署 制定缓存系统的SLA 监控报警  优化演进


图片 分布式文件系统

数据规模 访问量达 持续快速增加 保证服务的稳定性 突发流量 快速响应

更新方式 一致性保障策略


----------
组件选择：
看缓存位置 待存数据类型 访问方式  内存效率 数据模型 缓存成本


业务系统 kv数据类型 不需要在缓存端计算 适合memcached

需要部分获取 事务型变更 缓存端计算集合类 redis 主从 持久化

冷热区分 数据访问量不大  数据量特别大 使用pika ssdb 等其他缓存组件  多线程 持久化 复制 单个缓存实例 缓存几百G 少部分热数据放内存 大部分温冷数据放磁盘 降低缓存成本




------------
架构设计
微博 最初json xml protocol buffer  保护数据平均size 缓存数据量 峰值读写Qps 命中率 过期时间 平均穿透加载时间

设计缓存读写策略 分布策略 国企策略
主从读写分离
hash算法 分布策略  方便数据分散 请求访问 均衡
主动删除冷数据 低峰scan清理过期数据 热数据常驻内存 确保高命中率

缓存一致性 高可用

---------------------

监控 演进

实时监控报警  故障无法满足需求 突发流量 进行修复及快速扩展
集中探测 分布式汇报
监控系统特点确定

微博 Main-HA LI-Main-HA 多层结构 高可用

---------------

缓存使用模式

封装 同步异步 操作顺序

Cache-Aside 业务代码管理维护
读 没命中 都原数据 更新缓存
写成功 同步 缓存过期 下次读取再加载
利用数据库高可用 写成功 缓存更新 失败 重试

Cache-As-SoR
缓存当作存储记录系统 业务代码只对Cache操作

包括

    Read-Through
            业务代码获取数据 有返回 先访问缓存 没有从数据库加载 然后放入缓存
            Guava Cache支持

    Refresh-Ahead
            业务代码仅调用cache get 操作
            设定数据过期时间 过期自动从数据库加载
            性能高 对数据精确度有一定容忍场景适合

    Write-Through 业务代码调用Cache写 实际Cache更新缓存

    Write-Behind 业务代码只更新缓存数据 什么时候到数据库由同步策略决定


----------

缓存协议
redis 为RESP
Memcached 分两种 文本  二进制


-----------------------------
几个关注点

集群组建方式
sharding key在客户端通过一致性hash进行sharding 运维简单 需要客户端实现动态扩缩容机制

proxy 后端缓存集群管理 proxy也是集群 通过LVS或客户端
    流量大 LVS 集群
    proxy 运维复杂 扩展性强 可在proxy实现限流等扩展

服务集群
    redis cluster 基于Gossip协议


统计
    进程外缓存 监控cpu 进程内存使用情况 连接数


Gc
二级缓存热key 大key 本地缓存
java 本地缓存 on-heap jvm 缓存的数据量一般较大 对GC影响大
             off-heap 直接在Page Cache中申请 生命周期不由Jvm管理


监控项
启动总时长、总分配内存量、已使用内存量、可用内存量、缓存对象总数、总执行命令数、每秒命中数
每秒未命中数 每秒失效数 慢查询

off-heap 优点
支持更大内存
减少GC开销
减轻FGC压力频率 FGC 在old区数据整理 对象标注 迁移 空间一般较大 处理时间长

序列话
    读取本地缓存 堆内 对象
                堆外 字节 序列号 反序列化

            序列化时间 对层次深的对象结构 字段多的对象 不同的序列化机制
            序列化之后包大小 开启压缩
           序列化消耗CPU 反序列化 解析对象结构 缓存结构 消耗CPU

           具体序列化性能 https://github.com/eishay/jvm-serializers/wiki

    缓存命中率

            命中率高 收益高 响应时间 吞吐量高 抗并发能力强

            监控
            Memcached state cmd_get 总get次数
                            get_hits get 总命中次数
                            命中率 = get_hits/cmd_get
                     第三方 zabbix MemAdmin

            redis info
             keysapce_hits 总命中次数
             keyspace_misses 总miss次数
                    命中率= khits/(khits+kmiss)

            redis-stat zabbix插件


    影响缓存命中率因素
        业务场景需求
            读多写少 时效性 过期 更新策略
            缓存时间

        缓存设计 缓存粒度要小 命中率高

        缓存容量 基础设施
             容量有限 容易引起缓存失效 被淘汰 LRU
             分布式缓存
             系统容量规划 考虑是否可扩展
             不同缓存框架或中间件 效率 稳定性存在差异

        其他因素
            缓存节点故障 避免缓存失效
            通过一致性Hash 或通过节点冗余 高可用

            在相同缓存时间和key情况下 并发越高 缓存收益越高

    提高缓存命中率方法
        尽可能通过缓存获取数据 避免失效 缓存粒度 缓存策略 技术选型
        聚集在高频访问 时效性要求不高 热点业务
        缓存预加载预热 增加存储容量 调整缓存粒度 更新缓存


缓存穿透
    选择不同缓存策略 淘汰算法

    先检查缓存中是否存在 如果不存在要回源
    查询的某一个数据在缓存中一直不存在 就会造成每一次请求都会回源
    缓存失去意义 流量大 压力大

    有人利用不存在的key频繁攻击
    将不存在的key预设一个值 比如 key &&返回&&时
    应用就认为不存在的key 决定是否回源

    网站并发高  一个缓存失效 出现多进程同时查询DB 造成回源系统压力大

    对缓存查询加锁
        如果key 不存在 就枷锁 然后回源 更新缓存 解锁

其他进程发现有锁就等待解锁 返回数据 回源查询  会造成部分请求等等

主key+附属key 标识数据修改到期时间 快到的时候重新加载数据
如果key多可以把结束时间放到主key中 附属key起到锁的作用

缺点：产生双份数据 需要同时控制附属key与key之间的关系 操作上有一定复杂度

mutex 解决方案：
热点key 过期 增加key_mutex
从数据库load key的数据放入缓存
添加成功 则删除key_mutex
返回key值给上层应用

key_mutx
放到client 跨集群枷锁
放到cache server 把代码plugin in 到cache server

增加key_mutex 是否要sleep retry sleep 多长时间好
-----------------------------------------------------

缓存失效
缓存过期时间 1min 5min
高并发 同一时刻生成很多缓存 过期时间都一样
引发过期时间后，缓存同时失效 全部转发到DB DB压力过重

失效时间分散开 增加随机值 如1-5分钟随机 每一个缓存过期时间重复率就会降低

分析用户行为 让失效时间点均匀分布
、----------------------------------------------------------
淘汰算法

淘汰策略

LRU
LRU 最近最少 最近被访问 将来被访问概率也高
链表保存缓存数据

新数据插入头部
缓存命中 移动到头部
链表满 尾部丢弃

热点数据时 效率很好

偶发性 周期性批量操作 导致命中率急剧下降




LRU-K 最近使用过k次

多维护一个队列 用于记录所有缓存数据被访问历史
只有当数据访问次数达到k次 才将数据放入缓存

淘汰第K次访问时间距离当前时间最大的数据

数据第一次被访问 加入到访问历史列表

没有达到k次访问 按照一定规则 FIFO LRU 淘汰

达到k次 将数据索引从历史队列删除 数据索引从历史队列删除
将数据移动到缓存队列 缓存队列重新按时间排序

缓存数据队列被再次访问后 重新排序

需要淘汰数据是 淘汰缓存队列中排在末尾的数据
即 淘汰第k次访问离现在最久的数据



实际应用中LRU-2综合各种因素最优
需要基于时间排序 淘汰时拍下 也可以即时排序 内存和CPU消耗高



Two queues 缓存队列 FIFO  LRU
Multi Queues 按访问频率将数据划分为多个队列 不同的队列具有不同的访问优先级

---------------

LFU 根据数据历史访问频率来淘汰
LFU* 淘汰访问过一次的数据
LFU-Aging 除了访问次数 还要考虑访问时间
LFU*-Aging LFU* 和LFU-Aging合成体
Window-LFU 记录过去一段时间内的访问历史


FIFO
FIFo
Second Chance 被淘汰的数据被访问过 给其第二次机会
Clock 通过一个环形队列 避免将数据在FIFO队列中移动


--------------------------------------

缓存可用性

主备方案 换成热备


Cluster-salve
Redis Cluster 多个Cluster节点构成
不同节点组服务 数据无交集 每一个节点组对应数据的一个分片

master-slave 准实时同步 异步化 主备复制机制

master 才提供写服务
master异常 从salve节点中选择一个晋级为master节点

kv全集被分成5分 即5个slot 实际总共有16384个slot
每个节点服务一部分slot
A B 两个master节点
对外提供数据的读写服务 分别负责 123 三个slot
4 5 两个slot



---------------------
数据一致性

缓存数据与DB一致性

1.最终一致性
写缓存失败 通过补偿动作 达到最终一致性
更新数据库 把需要删除的key给McSqueal 异步删除缓存数据

对于时间敏感数据 可以设置很短失效时间 从数据库重新加载

多级缓存之间一致性

京东采用canal更新缓存原子性
更新使用更新时间戳或者版本对比  利用redis 单线程机制原子化更新
canal订阅mysql binlog 增量订阅 消费组件
更新请求按照相应规则分散到多个队列 每个队列单线程更新 更新时来去最新数据保存
更新之前获取相关锁进行更新

2.强一致性
InnoDB memcached 结合mysql 解决缓存与DB一致性问题


cache_policies 缓存策略

innodb_only 只使用innoDb作为数据存储
cache-only 只使用传统Memcached引擎作为后端存储
caching memcache找不到 就innoDB

读性能比直接读数据库提升1倍 性能不如单纯的内存Mem存储模式

-----------------------------------------------------------
热点数据处理
sharding cluster 模式

将不同的key sharding到不同机器  避免访问同一台机器导致性能瓶颈
同一个key访问都是在同一个缓存服务 热key 很容易出现性能瓶颈
一般 主从 预热 本地缓存

1.数据预热

监控确保预热数据写成功

预热需要回滚 遇到紧急回滚便于操作

先从冷集群获取key 获取不到 从热集群获取 同时把获取到的key put 到冷集群

做好容量评估 容量允许范围预热全量 否则预热访问量最高的

预热过程中需要注意是否会因为批量数据库操作 或慢sql 引发数据库性能问题

2.非预期热点策略

实时热点发现系统 发现热点

Nginx+Lua 应用内缓存

分布式缓存tair 还是redis
发现策略
通过实时统计访问分布式缓存的热点key 把对应的key推送到本地缓存 满足用户最近原则

-------------

3.多级缓存模式

本地cache

Nginx+Lua 应用缓存 减少redis 访问冲击
应用本地缓存
命中直接缓存
没有命中 查询 然后将数据缓存到应用本地

nginx负载机制

一致性哈希 如果某个请求类型访问量突破阈值 自动降级为轮询机制

预先推送热点数据到nginx 并将负载均衡降级为轮询

-----------------
数据复制模式
多个key_index(key:xxx#N)解决数据热点读问题

所有key发布到所有web服务器

每个服务器key有对应别名 通过client端的算法路由到某台服务器

做删除动作时，删除所有的别名key

一个通用的group内一致模式

把缓存集群分为若干group 组内 所有的缓存服务器都发布热点key的数据

大量读操作
通过client端路由策略 随意返回一台机器即可
写操作 通过定时任务写入 facebook采取的是删除所有别名key的策略

如何保障一个批量操作都成功
1.容忍部分失败导致的数据版本问题
2.只要有写操作 通过定时任务刷新缓存
如果涉及 3台服务器 都操作成功代表该任务表的这条记录成功完成使命 否则会重试


--------------------
缓存就近原则

优先访问离自己最近的数据

CPU缓存

主存

QPI总线传输 between sockets not drawn

L3 cache
L2 cache
L1 cache
寄存器

离CPU越近 访问速度越快

客户端缓存
本地缓存 需要读写 数据同步给其他节点本地缓存


CDN缓存

静态资源 CDN 内容分发网络

实时根据网络流量和各节点连接  负载状况 以及用户距离和响应时间等综合信息
将用户请求重新导向离用户最近的服务节点上

距离用户越近 性能越高

---------

并发控制手段

乐观锁

Latch 处理数据库内部机制策略

mutex

CAS

多版本并发控制MVCC 保证一致性


























