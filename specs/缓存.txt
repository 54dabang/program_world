存储在计算机上的原始数据复制集

CUP缓存 临时存储器 容量比内存小很多 交换速度比内存快很多 等待数据 解决CPU运算速度与内存读写速度不匹配的矛盾

短时间内CPU即将访问 多级缓存

虚拟内存 页虚拟地址->page table、 MMU 内存管理单元 ->物理地址
    page table 记录哪些是物理页 哪些是虚拟页 页表条目 PTE

    MMU 内存管理单元 虚拟地址到物理地址的翻译 硬件
    获取页的ＰＴＥ　使用翻译后备缓存器　ＴＬＢ的缓存页号

用户体验
产品 系统 服务的认知印象和回应
情感 信仰 喜好  认知印象 生理反应 心理反应  行为和成就 等

可用性

使用者的状态 系统性能 环境

--------------------------

系统性能

响应时间
系统对用户请求做出响应的时间
与人对软件性能的主观感受是非常一致的
完整记录了整个系统处理请求的时间

平均
最大响应时间

系统响应时间
    网络传输时间 CS传输时间
    应用延迟时间 系统实际处理请求

吞吐量是系统在单位时间内处理请求的数量

无并发应用 与响应时间成反比

并发用户数 系统可以同时承载的正常使用系统功能的用户数量

资源利用率反映 在一段时间内资源平均被占用

缓存更快
重复使用 降低用户带宽

流量付费

低水平 更容易维护

降低系统响应时间 减少网络传输时间和应用延迟时间
提高吞吐量 增加系统的并发用户数

最小化系统的工作量
使用了缓存就可以不必反复从数据源中查找
缓存所创建或提供的同一条数据更好利用系统


延迟时间

吞吐量

并发用户数

资源利用率

-------------------

缓存机制 减少数据库连接资源的竞争和对数据库读的压力

静态页面缓存

动态缓存登场

页面片段缓存


系统中重复获取数据信息从数据库加载到本地

应用服务器 中数据缓存信息同步
缓存同步机制 共享文件系统 共享存储

数据库集群

分库分表  DataAcessLayer

分布式缓存

无极缩放的

添加服务器


----------------------
页面缓存
自身某些元素或全部元素缓存
服务端将静态页面或动态页面元素缓存

单页面应用 HTML5  离线缓存 本地存储

localStorage

开启离线缓存步骤：
1.描述页面需要缓存的资源列表清单按文件 mainfest text /cache-mainfest
2.在需要离线使用的页面中添加mainfest属性 指定缓存清单文件的路径



---------------------
浏览器缓存




=======================
缓存定义规范

对象的创建 访问 失效 一致性
缓存java对象

进程内 分布式的缓存实现
支持by-value by-reference 缓存对象
缓存注解
javax.cache CacheManager 接口负责保存和控制一系列的缓存

缓存中读取
数据写入缓存
缓存具有原子性
缓存事件监听器
具有缓存注解
保存缓存的Key value 类型应该为泛型

Cache API 定义了4个核心概念

CachingProvider
定义 配置 获取 管理和控制多个CacheManager
一个应用可以在运行期访问多个CachingProvider

CacheManager
定义创建 配置 获取 管理和控制多个唯一命名的Cache
存在于CacheManager上下文中
一个CacheManager仅被一个CacheProvider拥有

Cache:类似Map的数据结构并临时存储以key为索引的值
一个Cache仅被一个CacheManager拥有

Entry:一个存储在Cache中的key value对

每一个存储在Cache中的条目有一个定义的有效期
Expiry Duration

一旦超过这个时间  条目即为过期的状态
一旦过期 条目将不可访问、更新和删除
缓存有效期可以通过ExpiryPolicy设置

store-by-value和store-by-reference
两种不同的缓存实现
store-by-value:
指在key/value



####################

Store-By-Value

在kv 存入时，将值拷贝一份存入缓存 避免其他程序修改 污染缓存中的数据。如常见的堆外缓存和进程外缓存 一般使用引用技术复杂 使用这种

Store_By-Reference
在kv存入时 直接将引用存入缓存，如java常见的堆内缓存 提升缓存性能


缓存过期策略
过期 不能反悔
默认 永久 external
配置时 提供一个ExpiryPolicy

当数据创建后的到期持续时间
当数据访问后的到期持续时间
当数据修改后的到期持续时间

持续时间=缓存过期时间
Duration.ZERO 表面数据目前是过期的

特定缓存持续一段时间数据需要回收
Duration(TimeUnit,durationAmount)

--------------------------------------------
缓存框架实现

内存管理 使用LRU淘汰算法
支持Weak key

缓存标准 JCache JSR107


get 获取
put 放入
remove 根据key删除
clear 清空

------------------------------
客户端层client
数据交互


-----------------------------
缓存提供层
CacheProvider
缓存管理层的生命周期维护 负责缓存管理层的创建  保存 获取 销毁

---------------------------------------------------------------
缓存管理层 缓存客户端的生命周期进行维护 创建 保持 获取 销毁 管理多个Cache客户端实例
CacheManager


缓存实例创建和获取 基于一个缓存池实现
代码中使用的是ConcurrentHashMap 可以根据多个不同的缓存名称创建多个缓存实例  并发读取

-----------------------
数据客户端层
CsCache
CsCache107 适配JSR107标准
CsCache107Manager 实现JSR107标准中的 CacheManager 管理多个cache实例
CsCaching107Provider 实现JSR107标准中的CacheProvider 提供SPI服务

利用java spi 进行组件发现和加载

Service Provider Interface
jdk内置服务提供发现机制 Java.util.ServiceLoader文档有详细介绍
模块直接基于接口编程

设计具体的实现类 违反可拔插原则 替换 修改代码

模块装配时 不在程序里动态指明

为某个接口寻找服务实现的机制

将装配的控制权移动到程序之外

文件必须为UTF-8编码

spi
当服务提供者 提供服务接口实现 jar/META-INF/service/ 同时创建一个以服务接口命名的文件 内容就是具体实现类
当外部程序装配模块  通过配置文件找到实现类 装载实例化 完成模块注入

jdk提供服务查找工具类 java.uti.ServiceLoader

如何使用
ServiceLoad<HelloInterface> loads = ServiceLoad.load(HelloInterface.class)

-------------
调用

CachingProvider cachingProvider = Caching.getCachingProvider();
CacheManager manager = cachingProvider.getCacheManager();

Configuration<String,User>
MutableConfigration<String,User>()

Cache = manager.createCache

cache.put

cache.get(key).getName


-------------------------------------------------------

缓存存储层 数据什么形式存储 Cache(
基本存储 ConcurrentHashMap 数据不淘汰
LRU存储、最近最少
Weak存储）弱引用





DataStore 存储数据的规范定义

BasicDataStore
BasicValueHolder 简单强引用值存储

WeakValueDataStore
基于引用的淘汰算法 JVM GC
StrongRef GC不回收 空间不足 OOM
SoftRefence 内存空间不足 GC回收 实现内存敏感的告诉缓存 可以和ReferenceQueue 如果被GC 把软引用加入队列中
WeakReference 更短生命周期 GC线程扫描 发现 就回收 GC优先级低 不一定发现 可以和ReferenceQueue 如果被GC 把弱引用加入队列中
PhantomReference 没有引用一样 任何时候都可GC
WeakValueHolder 简单弱引用存储



LRUDataStore LRUEntry 简单LRU数据存储
根据历史访问记录进行淘汰 如果最近访问过 将来访问概率也高

维护List<Entry> 最少访问的键值维持在entry尾部
数据量超过Cache 容量做LRU 删除链表尾部的数据

put->加入链表头部 最新 超出链表设定大小 删除尾部最不活跃的节点
get 将节点移动到链表头部 表示数据被最新请求访问 再返回




ValueHolder 具体存储值 规范定义


###############################################

缓存引入
缓存场景 缓存层次 缓存（更新/同步）策略 缓存组件 数据结构 分布 部署 制定缓存系统的SLA 监控报警  优化演进


图片 分布式文件系统

数据规模 访问量达 持续快速增加 保证服务的稳定性 突发流量 快速响应

更新方式 一致性保障策略


----------
组件选择：
看缓存位置 待存数据类型 访问方式  内存效率 数据模型 缓存成本


业务系统 kv数据类型 不需要在缓存端计算 适合memcached

需要部分获取 事务型变更 缓存端计算集合类 redis 主从 持久化

冷热区分 数据访问量不大  数据量特别大 使用pika ssdb 等其他缓存组件  多线程 持久化 复制 单个缓存实例 缓存几百G 少部分热数据放内存 大部分温冷数据放磁盘 降低缓存成本




------------
架构设计
微博 最初json xml protocol buffer  保护数据平均size 缓存数据量 峰值读写Qps 命中率 过期时间 平均穿透加载时间

设计缓存读写策略 分布策略 国企策略
主从读写分离
hash算法 分布策略  方便数据分散 请求访问 均衡
主动删除冷数据 低峰scan清理过期数据 热数据常驻内存 确保高命中率

缓存一致性 高可用

---------------------

监控 演进

实时监控报警  故障无法满足需求 突发流量 进行修复及快速扩展
集中探测 分布式汇报
监控系统特点确定

微博 Main-HA LI-Main-HA 多层结构 高可用

---------------

缓存使用模式

封装 同步异步 操作顺序

Cache-Aside 业务代码管理维护
读 没命中 都原数据 更新缓存
写成功 同步 缓存过期 下次读取再加载
利用数据库高可用 写成功 缓存更新 失败 重试

Cache-As-SoR
缓存当作存储记录系统 业务代码只对Cache操作

包括

    Read-Through
            业务代码获取数据 有返回 先访问缓存 没有从数据库加载 然后放入缓存
            Guava Cache支持

    Refresh-Ahead
            业务代码仅调用cache get 操作
            设定数据过期时间 过期自动从数据库加载
            性能高 对数据精确度有一定容忍场景适合

    Write-Through 业务代码调用Cache写 实际Cache更新缓存

    Write-Behind 业务代码只更新缓存数据 什么时候到数据库由同步策略决定


----------

缓存协议
redis 为RESP
Memcached 分两种 文本  二进制


-----------------------------
几个关注点

集群组建方式
sharding key在客户端通过一致性hash进行sharding 运维简单 需要客户端实现动态扩缩容机制

proxy 后端缓存集群管理 proxy也是集群 通过LVS或客户端
    流量大 LVS 集群
    proxy 运维复杂 扩展性强 可在proxy实现限流等扩展

服务集群
    redis cluster 基于Gossip协议


统计
    进程外缓存 监控cpu 进程内存使用情况 连接数


Gc
二级缓存热key 大key 本地缓存
java 本地缓存 on-heap jvm 缓存的数据量一般较大 对GC影响大
             off-heap 直接在Page Cache中申请 生命周期不由Jvm管理


监控项
启动总时长、总分配内存量、已使用内存量、可用内存量、缓存对象总数、总执行命令数、每秒命中数
每秒未命中数 每秒失效数 慢查询

off-heap 优点
支持更大内存
减少GC开销
减轻FGC压力频率 FGC 在old区数据整理 对象标注 迁移 空间一般较大 处理时间长

序列话
    读取本地缓存 堆内 对象
                堆外 字节 序列号 反序列化

            序列化时间 对层次深的对象结构 字段多的对象 不同的序列化机制
            序列化之后包大小 开启压缩
           序列化消耗CPU 反序列化 解析对象结构 缓存结构 消耗CPU

           具体序列化性能 https://github.com/eishay/jvm-serializers/wiki

    缓存命中率

            命中率高 收益高 响应时间 吞吐量高 抗并发能力强

            监控
            Memcached state cmd_get 总get次数
                            get_hits get 总命中次数
                            命中率 = get_hits/cmd_get
                     第三方 zabbix MemAdmin

            redis info
             keysapce_hits 总命中次数
             keyspace_misses 总miss次数
                    命中率= khits/(khits+kmiss)

            redis-stat zabbix插件


    影响缓存命中率因素
        业务场景需求
            读多写少 时效性 过期 更新策略
            缓存时间

        缓存设计 缓存粒度要小 命中率高

        缓存容量 基础设施
             容量有限 容易引起缓存失效 被淘汰 LRU
             分布式缓存
             系统容量规划 考虑是否可扩展
             不同缓存框架或中间件 效率 稳定性存在差异

        其他因素
            缓存节点故障 避免缓存失效
            通过一致性Hash 或通过节点冗余 高可用

            在相同缓存时间和key情况下 并发越高 缓存收益越高

    提高缓存命中率方法
        尽可能通过缓存获取数据 避免失效 缓存粒度 缓存策略 技术选型
        聚集在高频访问 时效性要求不高 热点业务
        缓存预加载预热 增加存储容量 调整缓存粒度 更新缓存


缓存穿透
    选择不同缓存策略 淘汰算法

    先检查缓存中是否存在 如果不存在要回源
    查询的某一个数据在缓存中一直不存在 就会造成每一次请求都会回源
    缓存失去意义 流量大 压力大

    有人利用不存在的key频繁攻击
    将不存在的key预设一个值 比如 key &&返回&&时
    应用就认为不存在的key 决定是否回源

    网站并发高  一个缓存失效 出现多进程同时查询DB 造成回源系统压力大

    对缓存查询加锁
        如果key 不存在 就枷锁 然后回源 更新缓存 解锁

其他进程发现有锁就等待解锁 返回数据 回源查询  会造成部分请求等等

主key+附属key 标识数据修改到期时间 快到的时候重新加载数据
如果key多可以把结束时间放到主key中 附属key起到锁的作用

缺点：产生双份数据 需要同时控制附属key与key之间的关系 操作上有一定复杂度

mutex 解决方案：
热点key 过期 增加key_mutex
从数据库load key的数据放入缓存
添加成功 则删除key_mutex
返回key值给上层应用

key_mutx
放到client 跨集群枷锁
放到cache server 把代码plugin in 到cache server

增加key_mutex 是否要sleep retry sleep 多长时间好
-----------------------------------------------------

缓存失效
缓存过期时间 1min 5min
高并发 同一时刻生成很多缓存 过期时间都一样
引发过期时间后，缓存同时失效 全部转发到DB DB压力过重

失效时间分散开 增加随机值 如1-5分钟随机 每一个缓存过期时间重复率就会降低

分析用户行为 让失效时间点均匀分布
、----------------------------------------------------------
淘汰算法

淘汰策略

LRU
LRU 最近最少 最近被访问 将来被访问概率也高
链表保存缓存数据

新数据插入头部
缓存命中 移动到头部
链表满 尾部丢弃

热点数据时 效率很好

偶发性 周期性批量操作 导致命中率急剧下降




LRU-K 最近使用过k次

多维护一个队列 用于记录所有缓存数据被访问历史
只有当数据访问次数达到k次 才将数据放入缓存

淘汰第K次访问时间距离当前时间最大的数据

数据第一次被访问 加入到访问历史列表

没有达到k次访问 按照一定规则 FIFO LRU 淘汰

达到k次 将数据索引从历史队列删除 数据索引从历史队列删除
将数据移动到缓存队列 缓存队列重新按时间排序

缓存数据队列被再次访问后 重新排序

需要淘汰数据是 淘汰缓存队列中排在末尾的数据
即 淘汰第k次访问离现在最久的数据



实际应用中LRU-2综合各种因素最优
需要基于时间排序 淘汰时拍下 也可以即时排序 内存和CPU消耗高



Two queues 缓存队列 FIFO  LRU
Multi Queues 按访问频率将数据划分为多个队列 不同的队列具有不同的访问优先级

---------------

LFU 根据数据历史访问频率来淘汰
LFU* 淘汰访问过一次的数据
LFU-Aging 除了访问次数 还要考虑访问时间
LFU*-Aging LFU* 和LFU-Aging合成体
Window-LFU 记录过去一段时间内的访问历史


FIFO
FIFo
Second Chance 被淘汰的数据被访问过 给其第二次机会
Clock 通过一个环形队列 避免将数据在FIFO队列中移动


--------------------------------------

缓存可用性

主备方案 换成热备


Cluster-salve
Redis Cluster 多个Cluster节点构成
不同节点组服务 数据无交集 每一个节点组对应数据的一个分片

master-slave 准实时同步 异步化 主备复制机制

master 才提供写服务
master异常 从salve节点中选择一个晋级为master节点

kv全集被分成5分 即5个slot 实际总共有16384个slot
每个节点服务一部分slot
A B 两个master节点
对外提供数据的读写服务 分别负责 123 三个slot
4 5 两个slot



---------------------
数据一致性

缓存数据与DB一致性

1.最终一致性
写缓存失败 通过补偿动作 达到最终一致性
更新数据库 把需要删除的key给McSqueal 异步删除缓存数据

对于时间敏感数据 可以设置很短失效时间 从数据库重新加载

多级缓存之间一致性

京东采用canal更新缓存原子性
更新使用更新时间戳或者版本对比  利用redis 单线程机制原子化更新
canal订阅mysql binlog 增量订阅 消费组件
更新请求按照相应规则分散到多个队列 每个队列单线程更新 更新时来去最新数据保存
更新之前获取相关锁进行更新

2.强一致性
InnoDB memcached 结合mysql 解决缓存与DB一致性问题


cache_policies 缓存策略

innodb_only 只使用innoDb作为数据存储
cache-only 只使用传统Memcached引擎作为后端存储
caching memcache找不到 就innoDB

读性能比直接读数据库提升1倍 性能不如单纯的内存Mem存储模式

-----------------------------------------------------------
热点数据处理
sharding cluster 模式

将不同的key sharding到不同机器  避免访问同一台机器导致性能瓶颈
同一个key访问都是在同一个缓存服务 热key 很容易出现性能瓶颈
一般 主从 预热 本地缓存

1.数据预热

监控确保预热数据写成功

预热需要回滚 遇到紧急回滚便于操作

先从冷集群获取key 获取不到 从热集群获取 同时把获取到的key put 到冷集群

做好容量评估 容量允许范围预热全量 否则预热访问量最高的

预热过程中需要注意是否会因为批量数据库操作 或慢sql 引发数据库性能问题

2.非预期热点策略

实时热点发现系统 发现热点

Nginx+Lua 应用内缓存

分布式缓存tair 还是redis
发现策略
通过实时统计访问分布式缓存的热点key 把对应的key推送到本地缓存 满足用户最近原则

-------------

3.多级缓存模式

本地cache

Nginx+Lua 应用缓存 减少redis 访问冲击
应用本地缓存
命中直接缓存
没有命中 查询 然后将数据缓存到应用本地

nginx负载机制

一致性哈希 如果某个请求类型访问量突破阈值 自动降级为轮询机制

预先推送热点数据到nginx 并将负载均衡降级为轮询

-----------------
数据复制模式
多个key_index(key:xxx#N)解决数据热点读问题

所有key发布到所有web服务器

每个服务器key有对应别名 通过client端的算法路由到某台服务器

做删除动作时，删除所有的别名key

一个通用的group内一致模式

把缓存集群分为若干group 组内 所有的缓存服务器都发布热点key的数据

大量读操作
通过client端路由策略 随意返回一台机器即可
写操作 通过定时任务写入 facebook采取的是删除所有别名key的策略

如何保障一个批量操作都成功
1.容忍部分失败导致的数据版本问题
2.只要有写操作 通过定时任务刷新缓存
如果涉及 3台服务器 都操作成功代表该任务表的这条记录成功完成使命 否则会重试


--------------------
缓存就近原则

优先访问离自己最近的数据

CPU缓存

主存

QPI总线传输 between sockets not drawn

L3 cache
L2 cache
L1 cache
寄存器

离CPU越近 访问速度越快

客户端缓存
本地缓存 需要读写 数据同步给其他节点本地缓存


CDN缓存

静态资源 CDN 内容分发网络

实时根据网络流量和各节点连接  负载状况 以及用户距离和响应时间等综合信息
将用户请求重新导向离用户最近的服务节点上

距离用户越近 性能越高

---------

并发控制手段

乐观锁

Latch 处理数据库内部机制策略

mutex

CAS

多版本并发控制MVCC 保证一致性


























