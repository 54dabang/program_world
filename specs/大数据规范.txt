第四章 资源管理规范
第十二条 大数据资源分为存储、计算两大类，按应用场景可分数据存储、后台计算、交互式查询、数据挖掘四类。
（一） 数据存储主要是指HDFS，存储介质为磁盘
（二） 后台计算是指系统后台进行数据加工处理的计算
资源，包括MapReduce、Spark、Kafka等。
（三） 交互式查询是指用户与大数据系统直接交互、访
问数据涉及的计算资源，包括HBase、Druid、Impala、Presto、ES等。
（四） 数据挖掘主要是指机器学习、深度学习涉及的计
算资源，包括Spark、TensorFlow等。
第十三条 所有大数据资源由系统运营团队统一管理，涉及预算由各开发部门提供、智能平台团队统筹编制，资源报价详见《平安科技服务及产品目录》。
第十四条 IT各团队申请大数据资源，须经过平台方、系统运营团队、系统规划部共同评审，并提交签报审批。
第十五条 系统运营团队对大数据资源实施定期监控，建立资源优化、数据清理机制，动态管控平台资源，定期发送大数据平台运营月报，并跟踪IT各团队大数据资源优化进展。
第十六条 为实现对大数据计算资源的有效管控，采用父子队列管理机制，按部门进行队列划分，子队列可共享父队列空闲资源。
（一）父队列与BU挂钩，命名如“root.queue_sx**”，各部门父队列命名示例如下
部门 父队列
数据分析团队&智能应用团队 root.queue_sx01
…
root.queue_sx19
智能研发团队 root.queue_sx20
…
root.queue_sx29
系统运营与安全部安全团队 root.queue_sx30
…
root.queue_sx39
销售平台开发部 root.queue_sx40
…
root.queue_sx49
销售平台开发部网销开发团队 root.queue_sx50
…
root.queue_sx59
金管家管理部 root.queue_sx70
…
root.queue_sx79
核心系统开发部 root.queue_sx80
…
root.queue_sx89


（二）子队列类型划分
队列类型编码 计算资源 队列类型说明
01 MapReduce 离线计算
02 Spark 离线计算
03 Spark 实时计算
04 Druid Druid数据导入
05 ElasticSearch ElasticSearch数据导入
06 Impala Impala查询


（三）子队列与Hduser用户挂钩，命名遵从“父队列名.xxxx_yy”，其中，“xxxx”为Hduser用户的后四位数字，“yy”为子队列类型编码，如：root.queue_sx30.1506_01。


（四）子队列大小设置原则
（1）所有子队列最小CPU数总和 <= 父队列最小CPU；
（2）子队列最大CPU数 <= 父队列最大CPU数-父队列最小CPU数；
（3）父队列最大并发Application数 >= 所有子队列最大并发Application数总和；
（4）子队列最大并发Application数 <= 子队列最大CPU数 / 3；
（5）某子队列最大CPU数 <= 某子队列最小CPU数 * 4；


（五）大数据计算资源收费规则如下：
父队列收费=[父队列CPU配额-∑（Spark队列CPU最大值）]*MR单价+∑（Spark队列CPU最大值）*Spark单价。


==============

第六章 权限管理规范
第二十四条 Hadoop用户分实名用户、非实名用户两类。
（一）实名用户是指通过登陆IDE访问Hadoop数据的用户，一般只有生产库查询权限，用户命名同UM；
（二）非实名用户是指Hive库属主用户，拥有属主库的所有操作权限，用户命名格式如：hduserxxxx，由平安科技GBD分配；
第二十五条 涉及访问大数据的人员分六类，即：采集、运营、安全、开发、挖掘、业务。
（一）采集人员指智能平台团队数据采集组内勤人员；
（二）运营人员指系统运营团队内勤人员；
（三）安全人员指业务安全团队合规检查相关内勤人员；
（四）开发人员指IT各团队大数据开发内勤人员；
（五）挖掘人员指智能平台团队及IT各团队数据挖掘相关内勤人员；
（六）业务人员指业务部门涉及数据分析、产品运营、稽核检查等相关的内勤人员；
第二十六条 IDE角色分敏感信息角色、非敏感信息角色两类。
（一）敏感信息角色指包含敏感信息访问权限的角色。
（1）命名遵守“hive库名_qry” 规范，比如：“sx_adm_safe_qry”；
（2）每个Hive库必须创建敏感信息角色；
（二）非敏感信息角色指不包含敏感信息访问权限的角色。
（1）命名遵守“hive库名_sec_qry” 规范，比如：“sx_adm_safe_sec_qry”；
（2）每个Hive库必须创建非敏感信息角色；
第二十七条 IDE实名用户权限管理规范
（一）IDE实名用户授权仅限“查询”权限，且权限管理须遵守“最小化”原则，各类人员权限要求如下表；
人员
分类 属主库 关联库（公司内） 关联库（公司外）
 库级 表级 敏感信息 导出 库级 表级 敏感信息 导出 库级 表级 敏感信息 导出
采集 √ √ √ √ √ √ √ √ × √ × ×
运营 √ √ √ × √ √ √ × × √ × ×
安全 √ √ √ √ √ √ √ √ × √ × ×
开发 √ √ × × × √ × × × × × ×
挖掘 √ √ × × × √ × × × × × ×
业务 × √ × √ × √ × √ × √ × ×
（二）运营类用户包括运营、采集、安全人员，可按“库”、“表”、“敏感信息角色”、“非敏感信息角色”粒度申请权限，允许访问敏感信息；
（三）开发类用户包括开发、挖掘人员，只能按“表”、“非敏感信息角色”粒度申请权限，不允许访问敏感信息；
（四）业务类用户只能按“表”粒度申请权限，不允许访问敏感信息；
（五）所有人员申请IDE权限必须遵守“不超过90天”的期限要求，过期后需重新申请；
第二十八条 非实名用户权限管理规范
（一）非实名用户拥有属主库的所有操作权限，申请关联库权限必须遵守“最小化”原则，且仅限“查询”权限，其涉及的管理人员、及权限分布如下表；
管理
人员 属主库 关联库（公司内） 关联库（公司外）
 库级 表级 敏感信息 SUDO 库级 表级 敏感信息 SUDO 库级 表级 敏感信息 SUDO
采集 √ √ √ √ √ √ √ × × √ √ ×
运营 √ √ √ √ √ √ √ √ × √ √ ×
安全 √ √ √ √ √ √ √ × × √ √ ×
开发 × × × × × × × × × × × ×
挖掘 √ √ × √ × √ × × × √ × ×
业务 × × × × × × × × × × × ×
（二）运营负责管理Hadoop所有非实名用户，并拥有SUDO权限；
（三）采集、安全人员可拥有自己的非实名用户及SUDO权限，用于数据采集、安全合规检查；
（四）开发、业务人员禁止拥有生产非实名用户及SUDO权限；
（五）挖掘人员可拥有自己的非实名用户及SUDO权限，用于模型训练，但不涉及敏感信息；
（六）跨库授权规范
（1）企业级DM库非实名用户访问公司内DM库或ODS库，无需提交签报审批；访问公司外DM库或ODS库，需征求公司外关联方同意，并提交签报审批；
（2）部门级DM库非实名用户访问关联方（包括公司内、公司外Hive库）DM库或ODS库，需征求关联方同意，并提交签报审批；


=========
通过分析业务手工执行的频次，任务执行的前置条件，相互依赖关系，并结合系统硬件性能，为每一个任务设置执行的时间、频次、功能开关、执行时间范围、所属任务分组、执行优先级、关键字等规则，并配置到智能调度规则配置表中，由规则引擎解析规则，并由定时任务调用规则引擎，从而完成整个模型点任务的智能调度。

通过分析业务场景，识别出不同的任务具体依赖的KETTLE，并通过优化自动调度配置规则表，包括依赖的前置KETTLE、前置任务、优先级、所在任务分组等，实现调度差异化配置，并通过优化前置校验处理逻辑，达到不同的任务差异化自动调度，以避免相互影响，提升AIO月结时效。

开发人员只需在excel模板中按照常规使用excel的方式，将格式定义好（如标题、列字段名称、数据绑定变量定义），工具引擎通过读取excel模板文件，并进行SAX解析，通过分析xml模板结构，如版本定义、头部公共参数、样式定义、内容部分格式、行列结构、特殊函数等，生成对应的st格式模板文件。

通过分析每月准备金的变化类型，抽象出新增单、脱退单、状态变化单、信息变化单、其他单，并以险种、机构、渠道、保单为不同纬度，查看各纬度下，上月与本月准备金的变化情况，本月与上月准备金的变化情况，并生成柱状图、饼状图等可视化图形，实时查看准备金的变化原因，各原因占比等。

采用新的大数据架构Spark+Hadoop+Hive，并重新优化了业务逻辑，以便更好的支持数据量的快速增长。

可以考虑开发一个公共的生产问题案例化平台，提供各系统的生产问题收集整理，支持rar、zip等压缩包，也支持excel、txt、excel等文件，形成案例化，并通关键字管理这些案列，通过智能关键字算法快速定位到案例，开发通过查看案例的处理过程，可以快速了解此类问题的处理机制，从而为解决问题提供思路。

为了解决这个情况，我们的思路就是需要统一数据源头，让财务结算和精算计量采用同一套数据源。因此我们引出了保单数据集市的概念。我们设计一个宽表，定时抽取各个分离模块的数据，因此该表即包含精算计量字段又包含财务结算字段。有了该数据集市，精算计量和财务结算都可以在这个统一的数据集市中进行取数。进而保证了数据的一致性。同时该数据集市还可以规划用于保险的经验分析。

由于计算赔付率需要使用大量的历史保单数据，我们将计算赔付率的基础数据同步到分布式存储HDFS上，由于赔付率计算，需要计算有效保额、释放准备金、理赔小项等分支步骤，我们将这些分支步骤拆分成单独的区块节点进行计算，区块平台可以监控各个节点的运行状态，待依赖节点运行完毕，最后赔付率计算模块通过区块链网关与各个节点通信，组装计算出最后的赔付率。由于采用去中心化，节点自治独立运行的分布式方式运行，效率将得到大大提升。各个区块节点可以单独对外提供接口供其他服务使用。

改进目前风险保费的计算方式，从险种层面细化到保单责任层面，将风险保费分摊到责任进行计算，再利用大数据的手段，根据现有数据进行挖掘分析，形成风险保费未来走势，进而得到未来时点的风险保费。
针对这种情况，我们使用spring的AOP编程和java的annotion功能，自动获取设置缓存的信息，然后集成一个设置工具类。在工具类中进行redis的统一设置和获取。同时工具类中还利用fastjson来实现数据类型的自动转换，让其适应不同数据类型的的缓存实现。最后我们只需要在使用缓存的地方加上annotion注解即可，以此达到“一词”即可实现缓存功能。

针对这种情况，我们可以开发一个app，该app通过抓取手机的短信、app消息、保险公司合作渠道等方式自动抓取客户的投保单信息，同事也支持客户自动录入和管理投保单信息。获取了所有的投保单信息后，通过保单信息按照险种分类、责任划分等进行后台大数据演算，得到个人投保情况分析指南，该指南中体现了客户分责任的投保情况、投保得分、推荐投保以及未来保障预测。

基于分摊载体经常变更，而分摊逻辑趋于不变的前提下，我们将分摊算法抽离出来，形成泛型数据类型接口，并重载成二级机构、三级机构等不同的的接口。我们在需要分摊的地方调用相应的分摊接口，传入分摊因子即可得到不同要求的的分摊结果。同时也方便后续算法的统一调整。

我们应该建立完善的客户健康评审跟踪机制，记录保险客户每年的身体个性明细指标，评估出客户的生活行为习惯，对于身体健康状态一直保持良好，生活习惯健康的客户，我们给与保费和保额上一定的优惠政策，人都是喜欢对自己的行为能有所收获的，这种鼓励机制将会大大提高社会的健康程度和续保产品的续保率，和新产品投保率。

我们可以建设一个智能的基础系统代码生成工厂，虽说是工厂，其他它本身也是一个系统，一个专门生成OA等一些基础系统，社会在大量使用的系统的代码。我们在基础系统代码生成工厂里面，只要简单得选择我们要定制是的什么系统，系统的页面样式，需要系统里面有什么功能，每个功能需要哪些基础控件等。定制好了，我们只要点击生成，就可以把这个系统的代码给生成了，我们只要再做一点点的简单个性化修改就可以使用了。

我们可以针对每一个分单，不管分单成功不成功，都记录下每个保单的分单轨迹，提供一个轨迹查询的页面功能，给机构同事核实有疑问的保单，同时我们可以增加预分单的功能，在执行真正分单之前，先进行预分单，机构人员可以根据分单结果是否满意确定什么时候执行真正的分单，减少分单后的人工调整。预分单和分单轨迹追踪，都是我们行业领先的功能，将会大大减少业务员咨询的情况。
我们可以做一个准备金月结任务执行情况可视化展示系统，实时展示各任务情况，用拓扑图展示各任务之间的依赖关系，根据任务执行情况，任务正常执行表绿色，任务没有启动标灰色，任务执行异常标红色等，我们就可以实时跟踪月结情况，同时我们增加任务失败自动补执行机制，系统可以展示任务的执行次数，执行时间等详细执行情况。让准备金月结情况一目了然。

我们在邀请客户来购买续期宝产品的时候，会先用大数据进行分析，根据往常客户缴费情况和一些基本信息，计算出客户缴费的难易程度，根据客户缴费的难易程度，我们会给客户不同的续期宝产品收益率，对于缴费困难的客户会给予稍微高一点的收益，以达到吸引客户来购买续期宝产品，最终用续期宝抵交续期保费目的。这是我们对于推广续期宝产品和提高续收率的有效手段。

"1、2号以保全系统的卖出价（1号便可获取）计算投连的单位准备金，用于模型投连价格计算，并制作上传文件；（原流程下在3号下午才能进行模型投连价格计算）
2、2号在现有投连流程中增加一步骤，使用保全万能系统的卖出价来计算单位准备金，存储在一张新表中，从而计算未决长险调整（原流程下在4号才能得到投连未决长险调整比例）
3、3号中午在获取投连资产净值后，按照原有流程计算投资单位价格、单位准备金，并上传财务系统，使得最终财务系统中投连报表的投连单位准备金和投连资产净值数据一致。
"
"准备金系统在保单信息表中通过保单号字段查询到对应保单的渠道码，
获得渠道码后查询《渠道码和业务段对应表》提取业务段信息,该表在财务系统中记录，由财务部开放财务接口给精算准备金系统。LARS准备金系统通过上述财务接口获取业务段信息，接口按渠道码入参，出参为业务段。目的是：如果后续财务部再新增07、08等业务段，或者新增其他关联表格，精算不用修改准备金系统，准备金系统仍然通过财务接口取数即可，必要的话，修改入参参数即可。"

"1.利用准备金分摊原币提存数、调整后未到期准备金表中的险种代码、业务段进行匹配，计算出上月每个险种、业务段的分摊比例;

2.利用准备金分摊原币提存数上月数据按每个险种、业务段进行分组求和准备金;

3.最后用1步骤中的分摊比例乘以2步骤中准备金便可得到正确的分摊金额。"
理赔小项需要从配置表取算法、责任计算理赔金额，由逐单接口调整为批量执行接口，充分考虑逻辑性，把类似的逻辑通过union all的方式生成子查询，让多次表查询 变为一次，提高了执行效率.

"1.利用准备金分摊原币提存数、已报案未决赔款准备金汇总表中的险种代码、业务段进行匹配，计算出上月每个险种、业务段的分摊比例;

2.利用准备金分摊原币提存数上月数据按每个险种、业务段进行分组求和准备金;

3.最后用1步骤中的分摊比例乘以2步骤中准备金便可得到正确的分摊金额。"

新增算法参数配置表，建好相应的触发器trigger，记录所有的操作，把相同算法的参数都配置在表里，新增取算法参数的函数，做到可配置化

充分利用大数据的分布式架构，把业务逻辑迁移到大数据平台，新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产.

月结的问题大体类似，可以写一个过程把每次月结的问题一次反映出来（跑批时间，和上月对比增加还是减少，数据修改是否发生了和上次同样的问题），月结完定时的把结果打印出来

走流程也太慢了，新产品组的数据给的太慢，影响了下游系统的开发，我们可以把问题给抛出，让业务方和新产品部门提供早点把因子给出来。

支持流式计算、离线计算、内存计算,结合实际业务场景和痛点，帮助业务快速发现问题，定位问题，解决问题,帮助业务进行预测性分析，实现对未来的掌控，图形化，可视化

为了节省月结的操作时间，我们把月结步骤回退做成系统自动化实现。业务发现步骤有问题或者数据有问题时，只需要在对应的模块中找到相关步骤，自己选择步骤进行回退。系统会自动处理回退的步骤，不再需要准备金脚本，预执行等一系列的操作，只需要几秒钟就可以，每回退一个步骤节省1个小时左右的时间。使当前的月结更加流畅，更加符合业务的要求，在实际操作中更流畅没有其他外在阻力。
把这一系列的操作用系统自动化来实现。首先TJS同步已经存在的OF数据，然后再调用相关程序进行逻辑处理，再保存数据到相关表中进行下一步的操作。业务只需要执行对应的步骤不需要等待OF数据结果，处理数据上传及数据核对，节省大量的时间并且减少操作的失误，让业务流程化不会被动进行操作。

建一个系统的规范配置表，涵盖基本的配置情况。一些固定的东西和硬编码的东西通过查询配置表来实现，之后需要相关的需求就只要改动配置表，不需要修改代码，这样既简便又不影响其他的功能模块，这样
更高的保障系统的稳定性和代码的安全性，也减少开发出现问题的风险。
结合相关业务引入大数据，把业务逻辑中数据量大的表放到大数据平台上进行处理。不仅解决了性能问题，还能兼容以后不停数据增加的问题，这样对月结提速时一个很好的推动。把大数据的处理的事情交给专业的软件来处理，实现准备金系统的真正的高效性，符合现代系统的规范和专业性。

结合现有情况和系统分析，对系统的分红、万能模块进行改造，新增新口径的功能进行逻辑处理。通过系统自动化来实现IFRS9的功能:计算应投资收益，计算利差盈余,计算公允价值变动，调整投资收益和损益，获取不分明细(死差和利差)，计算投资价值等计算，分析处理然后生成财务需要的新接口数据。保证数据的准确性，业务流程化，系统完善化。

整理所有的业务知识和逻辑，记录下来，一是有一个规范的文档遇到问题可以有参考，方便理解需求和开发任务,能够快速准确的评估需求的影响，也能高校的制定最合适的解决方案，二是能帮助新人或者其他对准备金系统感兴趣的人更快熟悉系统，三是对之后的系统业务模块改动提供有效的参考和依据，使我们的系统更加完善，为我们的业务提供更完美的服务。

根据前面的痛点，结合业务场景，对每个险种的条件判断机制创建两张配置表，主表存放险种的相关信息，副表存放具体的判断条件，主副表一对多的关系。这样在判断时，只需要对副表进行循环遍历，满足条件即能往下走，不满足往下一个循环。这样在代码中就能动态地使用一套逻辑代码进行条件判断，减少硬编码，使用代码更简洁。

建立赔付率全流程过程的执行配置表，对每个过程的开始，执行，结束时间（包括依赖关系，开关等）进行记录监控。通过配置表启动后续的依赖任务，使得过程之间不需要再等待，形成一个完成的闭环。

由于业务是通过外部软件算出需要使用的数据，直接开发小工具与准备金月结系统对接，自动上传月结结果，减少了中间的环境，也保证了数据的准备性。

开发有效保额处理接口，提供运算有效保额的统一逻辑及数据，接口使用统一的参数输入，对于不同的险种，提供一个险种参数对应对作为校验输入参数的必要性及有效性。有效保额统一输出为数组形式，为同一保单输出多个有效保额

开发批量处理接口，每5万单批量处理并提交，采用对发生率的主副两个配置表进行转列的形式，并用With关键字生成临时表减少重复调用的资源消耗。由原来单列处理，调整为直接表之间的关联，再用case when进行逻辑判断，最终计算出发生率，利用oracle的关系数据优势，使得数据能在2小时内完成。

对宽表逻辑进行优化，使用1个临时表，可以对10多个外部数据进行存放。临时表A保存保单、险种、各种数据类型各一个，外部字段名。每个外部数据保存时按照数据类型存放到指定数据类型中，并且在外部字段名填上相应类型名称。这样在组合成宽表字段时就能使用With的方式把各个数据转换成需要的形式进行关联。

寿险系统可以做一个月结准备金作业完成后自动发送邮件给相关的月结人员。如机构准备金作业（JOB45）是否已完成？当系统检验到job45的任务已经完成后，就自动发送一条邮件通知该任务已经完成的邮件，设定任务没有按规定时间完成，或任务执行失败，都发送邮件通知。类似监控平台

寿险准备金新产品的在计算有效保额和重大风险测试算法，用配置表方式将计算需要的参数和结果，放在一个算法结果表，对新的产品增加不同算法时，只需要在配置表里配置一些参数，再计算出来，保存结果在配置表。计算出有效保额和重大风险测试时直接从表里取，减少在代码里计算。
将用户源主机上的操作系统（如Windows Server、CentOS、Ubuntu等）和运行的应用程序及数据整体迁移至另一账号的云主机上，可以实现跨地域和经典网络到VPC的迁移。

用eBackup第三方软件通过REST接口（即备份、恢复API）对云主机发送控制命令给VM打快照，远程对CNA上的快照文件进行读写操作以实现备份恢复功能。
提供保险传送门，只要用户输入保险的相关关键词汇，系统就根据这些词汇并根据用户的信息查询到用户购买保险的账务状况，搜索出用户需要所有保险公司里面相类似的保险以及保险类型，以微信，短信，邮件推送该用户。

为了增加kettle同步效率，在kettle同步页面增加循环机制，以15分钟左右为循环一次，一旦判断同步出现失败则进入循环重新运行，如当日一直未解决失败原因则当日23点后退出。
数据库内在分摊程序结束后添加一个新的包体程序，将模型分摊结果表以及PROPHET压缩回传结果数据表进行对比算出结果差异，以类别以及险种为维度进行区分查看。页面上增加一个下载按钮，点击可下载结果对比excel文档

以年缴保费等字段为备用字段进行模型分摊，在运算SQL脚本中进行判断当份数及保额字段为0时使用备用字段进行分摊。
将相关类别的险种配置入表，在kettle中新加一个trans程序将配置表内的险种按类别封装成参数再传入抽取过程内，一旦需要增加险种则直接更改配置表即可不再需要进行版本下发。
将两表数据根据分类进行多表拆分，拆分后的表名封装成参数传入运算程序中，页面上根据类别分运行按钮。

建一个新表专门储存发生率险种责任关系配置主表、发生率险种责任关系配置分段表、发生率系数表三表相关联后的数据。在与宽表关联时，先判断上述三表的数据是否改动，如果有改动就将改动后三表的数据关联，存放到新表中，如果没有更改，就用原来的数据，不需要将三个表关联。

对传统险结果表采用分区的方式，对于每次月结会自动建立分区，在分区上又会建立自己的子分区，创建索引，大表关联相互匹配数据的时候,能将搜索范围的数据量降至最低。提升运行效率。
在月结期间执行传统险移动分析时，

建立断点机制，若处理数据失败，已完成处理的数据将不需要再次处理，只需要处理失败或未执行的数据。保证了数据处理失败不会整个流程重新再次执行，节省了大量时间。

在执行移动轨迹分析时，根据保单信息尾号，将数据分块处理，在程序中，通过创建定时任务，并行处理移动分析，既保证了数据完整性及准确性，同时也能达到并行处理节省时间的目的。
"将传统分红，保证续保等分批执行，减少每次判断保单从期初到期末数据的

保单属性变化的数据量，期间判断保单属性是新增、脱退等在同一逻辑中实现，精确定位不同月份保单的移动轨迹，不再多步骤执行，减少手工操作，实现自动执行，计算时效大大提升。可缩小在几小时完成。"

实现大数据分析处理模型，将需要大数据处理的逻辑在大数据平台上进行处理。直接生产结果表数据，推送到数据库对应表。可以满足数据量增加带来的性能瓶颈，大大提升月结的实效性，保证提供给业务的数据及时性。提升业务核对数据的效率。