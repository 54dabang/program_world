

ACTOR SUPERVISION

失败更像是分布式系统的一个特性。因此Akka用一个容忍失败的模型，

在你的业务逻辑与失败处理逻辑(supervision逻辑)中间你能有一个清晰的边界

ACTOR SUPERVISION
想象一个方法调用了你栈顶的方法但却出了一个异常。那么在栈下的方法能做什么呢？

抓住异常并按顺序处理恢复
抓住异常，也许记个日志并保持安静。
下层的方法也可以选择无视这个异常（或者抓住并重扔出来）
想象下一直扔到main方法仍然没有处理这个异常。这种情况下，程序肯定会输出一个异常给console后退出。


你可以把同样的情况套用在线程上。如果一个子线程抛了异常而再假设run或**call*方法没有处理它，那么这个异常就会期望放在父线程或主线程中解决，无论哪种情况，如果主线程没有处理他，系统就会退出。

让我们再看看 - 如果被context.actorof创建出来的子Actor因为一个异常失败了。父actor（指supervisor）可以处理子actor的任何失败。如果父actor做了，他可以处理并恢复（Restart/Resume）。另外，把异常传递（Escalate）给父actor。 还有一种做法，可以直接stop掉子actor - 这就是那个子actor结局了。 为什么我说父actor（那个supervisor）？这是因为akka的监护方式为家长监护 - 这意味着只有创建了actor的人才能监护他们。

就这么多了！我们已经覆盖到所有监护指令（Directoives）了。

策略
我忘了说一点： 你已经知道一个Akka Actor可以创建子actor并且子actor也可以随意创建他们自己的子actor。

现在，想下以下两个场景：

1.OneForOneStrategy

你的actor创建了很多子actor并且每一个子actor都连接了不同的数据源。假设你运行的是一个将英语翻译成多种语言的应用。



假设，一个子actor失败了然而你可以接受在最终结果里跳过这个结果，你想怎么做？关掉这个服务？当然不，你可能想要重启/关闭这个有问题的子actor。是吧？现在这个策略在Akka的监护策略中叫OneForOneStrategy策略 - 如果一个actor挂了，只单独处理这个actor。

基于你的业务异常，你可能需要对不同的异常有不同的反应（停止，重启，升级，恢复）。要配置你自己的策略，你只需要override你Actor类中的supervisorStrategy方法。

声明OneForOneStrategy的例子

import akka.actor.Actor
import akka.actor.ActorLogging
import akka.actor.OneForOneStrategy
import akka.actor.SupervisorStrategy.Stop


class TeacherActorOneForOne extends Actor with ActorLogging {

    ...
    ...
  override val supervisorStrategy=OneForOneStrategy() {

    case _: MinorRecoverableException     => Restart
    case _: Exception                   => Stop

  }
  ...
  ...
2.AllForOneStrategy策略

假设你在做一个外部排序 (这是个又证明了我没啥创造力的例子！），你的每个块都被一个不同的actor处理。突然，一个Actor失败了并抛了一个异常。这样再往下处理就没什么意思了因为最终结果肯定是错的。所以，逻辑就是停止stop所有的actor。


我为什么说stop而不是重启？因为在这个例子里重启也没用，每个actor的mailbox在重启时并不会被清理。所以，如果我们重启了，另外的chunk仍然会被处理。这不是我们想要的。重建actor并用新的mailbox在这里是个更合适的策略。

与OneForOneStrategy一样，只需要用AllForOneStrategy的实现覆写supervisorStrategy

下面是例子

import akka.actor.{Actor, ActorLogging}
import akka.actor.AllForOneStrategy
import akka.actor.SupervisorStrategy.Escalate
import akka.actor.SupervisorStrategy.Stop


class TeacherActorAllForOne extends Actor with ActorLogging {

  ...

  override val supervisorStrategy = AllForOneStrategy() {

    case _: MajorUnRecoverableException => Stop
    case _: Exception => Escalate

  }
  ...
  ...
指令 DIRECTIVES
AllForOneStrategy和OneForOneStrategy的构造方法都接受一个叫Decider的PartialFunction[Throwable,Directive]方法，他把Throwable与Directive指令做了一个映射：

case _: MajorUnRecoverableException => Stop
这就简单的四个指令 - Stop，Resume，Escalate和Restart

Stop

在异常发生时子actor会停止，任何发给停止的actor的消息都会被转到deadLetter队列。

Resume

子actor会忽略抛出异常的消息并且继续处理队列中的其他消息。

Restart

子actor会停止并且一个新的actor会初始化。继续处理mailbox中其他的消息。世界对这个是无感知的因为同样的ActorRef指向了新的Actor。

Escalate

supervisor复制了失败并让他的supervisor处理这个异常。

缺省策略
如果我们的actor没指定任何策略但是创建了子actor。他们会怎样处理？Actor会有一个缺省的策略：

override val supervisorStrategy=OneForOneStrategy() {

    case _: ActorInitializationException=> Stop
    case _: ActorKilledException        => Stop
    case _: DeathPactException             => Stop
    case _: Exception                   => Restart

}
所以，缺省策略处理了四个case：

1. ACTORINITIALIZATIONEXCEPTION => STOP

当actor不能初始化，他会抛出一个ActorInitializationException。actor会被停止。让我们在preStart调用中模拟下这个：

package me.rerun.akkanotes.supervision

import akka.actor.{ActorSystem, Props}
import me.rerun.akkanotes.protocols.TeacherProtocol.QuoteRequest
import akka.actor.Actor
import akka.actor.ActorLogging

object ActorInitializationExceptionApp extends App{

  val actorSystem=ActorSystem("ActorInitializationException")
  val actor=actorSystem.actorOf(Props[ActorInitializationExceptionActor], "initializationExceptionActor")
  actor!"someMessageThatWillGoToDeadLetter"
}

class ActorInitializationExceptionActor extends Actor with ActorLogging{
  override def preStart={
    throw new Exception("Some random exception")
  }
  def receive={
    case _=>
  }
}
Ru
运行ActorInitializationExceptionApp会产生一个ActorInitializationException 异常然后所有的消息都会进deadLetterActor的消息队列：

Log

[ERROR] [11/10/2014 16:08:46.569] [ActorInitializationException-akka.actor.default-dispatcher-2] [akka://ActorInitializationException/user/initializationExceptionActor] Some random exception
akka.actor.ActorInitializationException: exception during creation
    at akka.actor.ActorInitializationException$.apply(Actor.scala:164)
...
...
Caused by: java.lang.Exception: Some random exception
    at me.rerun.akkanotes.supervision.ActorInitializationExceptionActor.preStart(ActorInitializationExceptionApp.scala:17)
...
...

[INFO] [11/10/2014 16:08:46.581] [ActorInitializationException-akka.actor.default-dispatcher-4] [akka://ActorInitializationException/user/initializationExceptionActor] Message [java.lang.String] from Actor[akka://ActorInitializationException/deadLetters] to Actor[akka://ActorInitializationException/user/initializationExceptionActor#-1290470495] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2. ACTORKILLEDEXCEPTION => STOP

当Actor被kill消息关闭后，他会抛出一个ActorKilledException。如果抛这个异常，缺省策略会让子actor停止。看起来停止一个被kill掉的actor没什么意义。但想想这个：

ActorKilledException 会被传递给supervisor。 那么之前我们在DeathWatch里面提到的Actor里的生命周期watch或deathwatchers。 直到Actor被停掉前watcher不会知道任何事情。

给Actor发送kill只会让那个特定的监管actor知道。用stop处理会暂停那个actor的mailbox，暂停了子actor的mailbox，停止了子actor，发送了Terminated给所有子actor的watcher，发送给所有类一个Terminated，然后actor的watcher都会迅速失败最终让Actor自己停止、

package me.rerun.akkanotes.supervision

import akka.actor.{ActorSystem, Props}
import me.rerun.akkanotes.protocols.TeacherProtocol.QuoteRequest
import akka.actor.Actor
import akka.actor.ActorLogging
import akka.actor.Kill

object ActorKilledExceptionApp extends App{

  val actorSystem=ActorSystem("ActorKilledExceptionSystem")
  val actor=actorSystem.actorOf(Props[ActorKilledExceptionActor])
  actor!"something"
  actor!Kill
  actor!"something else that falls into dead letter queue"
}

class ActorKilledExceptionActor extends Actor with ActorLogging{
  def receive={
    case message:String=> log.info (message)
  }
}
Log

日志说只要ActorKilledException 进来，supervisor就会停掉actor并且消息会进入deadLetter队列

INFO  m.r.a.s.ActorKilledExceptionActor - something

ERROR akka.actor.OneForOneStrategy - Kill
akka.actor.ActorKilledException: Kill

INFO  akka.actor.RepointableActorRef - Message [java.lang.String] from Actor[akka://ActorKilledExceptionSystem/deadLetters] to Actor[akka://ActorKilledExceptionSystem/user/$a#-1569063462] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
3. DEATHPACTEXCEPTION => STOP

在DeathWatch文中，你可以看到当一个Actor观察一个子Actor时，他期望在他的receive中处理Terminated消息。如果没有呢？你会得到一个DeathPactException



代码演示了supervisorwatch子actor但没有从子actor处理Terminated消息。

package me.rerun.akkanotes.supervision

import akka.actor.{ActorSystem, Props}
import me.rerun.akkanotes.protocols.TeacherProtocol.QuoteRequest
import akka.actor.Actor
import akka.actor.ActorLogging
import akka.actor.Kill
import akka.actor.PoisonPill
import akka.actor.Terminated

object DeathPactExceptionApp extends App{

  val actorSystem=ActorSystem("DeathPactExceptionSystem")
  val actor=actorSystem.actorOf(Props[DeathPactExceptionParentActor])
  actor!"create_child" //Throws DeathPactException
  Thread.sleep(2000) //Wait until Stopped
  actor!"someMessage" //Message goes to DeadLetters

}

class DeathPactExceptionParentActor extends Actor with ActorLogging{

  def receive={
    case "create_child"=> {
      log.info ("creating child")
      val child=context.actorOf(Props[DeathPactExceptionChildActor])
      context.watch(child) //Watches but doesnt handle terminated message. Throwing DeathPactException here.
      child!"stop"
    }
    case "someMessage" => log.info ("some message")
    //Doesnt handle terminated message
    //case Terminated(_) =>
  }
}

class DeathPactExceptionChildActor extends Actor with ActorLogging{
  def receive={
    case "stop"=> {
      log.info ("Actor going to stop and announce that it's terminated")
      self!PoisonPill
    }
  }
}
Log

日志告诉我们DeathPactException 进来了，supervisor停止了actor然后消息都进入了deadLetter的队列

INFO  m.r.a.s.DeathPactExceptionParentActor - creating child

INFO  m.r.a.s.DeathPactExceptionChildActor - Actor going to stop and announce that it's terminated

ERROR akka.actor.OneForOneStrategy - Monitored actor [Actor[akka://DeathPactExceptionSystem/user/$a/$a#-695506341]] terminated
akka.actor.DeathPactException: Monitored actor [Actor[akka://DeathPactExceptionSystem/user/$a/$a#-695506341]] terminated

INFO  akka.actor.RepointableActorRef - Message [java.lang.String] from Actor[akka://DeathPactExceptionSystem/deadLetters] to Actor[akka://DeathPactExceptionSystem/user/$a#-1452955980] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
4. EXCEPTION => RESTART

对于其他的异常，缺省的指令是重启Actor。看下这个应用。只是要证明下Actor重启了，OtherExceptionParentActor让child抛出一个异常并立刻发送一条消息。消息在子actor重启的时候到达了mailbox，并被处理了。真不错！
[图片描述][5]

package me.rerun.akkanotes.supervision

import akka.actor.Actor
import akka.actor.ActorLogging
import akka.actor.ActorSystem
import akka.actor.OneForOneStrategy
import akka.actor.Props
import akka.actor.SupervisorStrategy.Stop

object OtherExceptionApp extends App{

  val actorSystem=ActorSystem("OtherExceptionSystem")
  val actor=actorSystem.actorOf(Props[OtherExceptionParentActor])
  actor!"create_child"

}

class OtherExceptionParentActor extends Actor with ActorLogging{

  def receive={
    case "create_child"=> {
      log.info ("creating child")
      val child=context.actorOf(Props[OtherExceptionChildActor])

      child!"throwSomeException"
      child!"someMessage"
    }
  }
}

class OtherExceptionChildActor extends akka.actor.Actor with ActorLogging{

  override def preStart={
    log.info ("Starting Child Actor")
  }

  def receive={
    case "throwSomeException"=> {
      throw new Exception ("I'm getting thrown for no reason")
    }
    case "someMessage" => log.info ("Restarted and printing some Message")
  }

  override def postStop={
    log.info ("Stopping Child Actor")
  }

}
Log

1.异常抛出了，我们能在trace中看到

子类重启了 - stop和start被调用了（我们稍后能看到preRestart和postRestart）
消息在重启开始前被发送给子actor。
INFO  m.r.a.s.OtherExceptionParentActor - creating child

INFO  m.r.a.s.OtherExceptionChildActor - Starting Child Actor

ERROR akka.actor.OneForOneStrategy - I'm getting thrown for no reason

java.lang.Exception: I'm getting thrown for no reason
    at me.rerun.akkanotes.supervision.OtherExceptionChildActor$$anonfun$receive$2.applyOrElse(OtherExceptionApp.scala:39) ~[classes/:na]
    at akka.actor.Actor$class.aroundReceive(Actor.scala:465) ~[akka-actor_2.11-2.3.4.jar:na]
...
...

INFO  m.r.a.s.OtherExceptionChildActor - Stopping Child Actor

INFO  m.r.a.s.OtherExceptionChildActor - Starting Child Actor

INFO  m.r.a.s.OtherExceptionChildActor - Restarted and printing some Message
ESCALATE AND RESUME

我们在defaultStrategy中看到stop和restart的例子。现在让我们快速看下Escalate。

Resume忽略了异常并处理mailbox中的下条消息。这就像是抓住了异常但什么事也没做。

Escalating更像是异常是致命的而supervisor不能处理它。所以，他要向他的supervisor求救。让我们看个例子。

假设有三个Actor - EscalateExceptionTopLevelActor, EscalateExceptionParentActor 和 EscalateExceptionChildActor。 如果一个子actor抛出一个日常并且父级别actor不能处理它，他可以Escalate这个异常到顶级actor。顶级actor也可以选择对哪些指令做出响应。在我们的例子里，我们只是做了stop。stop会立即停掉child（这里是EscalateExceptionParentActor）。我们知道，当一个actor执行stop时，他的所有子类都会在actor自己停掉前先停止。


package me.rerun.akkanotes.supervision

import akka.actor.Actor
import akka.actor.ActorLogging
import akka.actor.ActorSystem
import akka.actor.OneForOneStrategy
import akka.actor.Props
import akka.actor.SupervisorStrategy.Escalate
import akka.actor.SupervisorStrategy.Stop
import akka.actor.actorRef2Scala

object EscalateExceptionApp extends App {

  val actorSystem = ActorSystem("EscalateExceptionSystem")
  val actor = actorSystem.actorOf(Props[EscalateExceptionTopLevelActor], "topLevelActor")
  actor ! "create_parent"
}

class EscalateExceptionTopLevelActor extends Actor with ActorLogging {

  override val supervisorStrategy = OneForOneStrategy() {
    case _: Exception => {
      log.info("The exception from the Child is now handled by the Top level Actor. Stopping Parent Actor and its children.")
      Stop //Stop will stop the Actor that threw this Exception and all its children
    }
  }

  def receive = {
    case "create_parent" => {
      log.info("creating parent")
      val parent = context.actorOf(Props[EscalateExceptionParentActor], "parentActor")
      parent ! "create_child" //Sending message to next level
    }
  }
}

class EscalateExceptionParentActor extends Actor with ActorLogging {

  override def preStart={
    log.info ("Parent Actor started")
  }

  override val supervisorStrategy = OneForOneStrategy() {
    case _: Exception => {
      log.info("The exception is ducked by the Parent Actor. Escalating to TopLevel Actor")
      Escalate
    }
  }

  def receive = {
    case "create_child" => {
      log.info("creating child")
      val child = context.actorOf(Props[EscalateExceptionChildActor], "childActor")
      child ! "throwSomeException"
    }
  }

  override def postStop = {
    log.info("Stopping parent Actor")
  }
}

class EscalateExceptionChildActor extends akka.actor.Actor with ActorLogging {

  override def preStart={
    log.info ("Child Actor started")
  }

  def receive = {
    case "throwSomeException" => {
      throw new Exception("I'm getting thrown for no reason.")
    }
  }
  override def postStop = {
    log.info("Stopping child Actor")
  }
}
Log

可以在log中看到,

子actor抛了异常。
supervisor（EscalateExceptionParentActor）升级了（escalate）异常抛给了他的supervisor（EscalateExceptionTopLevelActor）
EscalateExceptionTopLevelActor 的指令是关闭actor。在顺序上，子actor先停止。
父actor之后再停止（在watcher被通知后）
INFO  m.r.a.s.EscalateExceptionTopLevelActor - creating parent

INFO  m.r.a.s.EscalateExceptionParentActor - Parent Actor started

INFO  m.r.a.s.EscalateExceptionParentActor - creating child

INFO  m.r.a.s.EscalateExceptionChildActor - Child Actor started

INFO  m.r.a.s.EscalateExceptionParentActor - The exception is ducked by the Parent Actor. Escalating to TopLevel Actor

INFO  m.r.a.s.EscalateExceptionTopLevelActor - The exception from the Child is now handled by the Top level Actor. Stopping Parent Actor and its children.

ERROR akka.actor.OneForOneStrategy - I'm getting thrown for no reason.
java.lang.Exception: I'm getting thrown for no reason.
    at me.rerun.akkanotes.supervision.EscalateExceptionChildActor$$anonfun$receive$3.applyOrElse(EscalateExceptionApp.scala:71) ~[classes/:na]
    ...
    ...

INFO  m.r.a.s.EscalateExceptionChildActor - Stopping child Actor

INFO  m.r.a.s.EscalateExceptionParentActor - Stopping parent Actor
请记住无论哪个指令发出只会使用在被escalated的子类上。 例如，一个restart指令从顶层发出，只有父类会被重启并且在构造函数中/preStart中的都会被执行。如果一个父actor的子类在构造函数中呗创建，他们就会被创建。然而，在消息中创建的child的父actor仍然会在Terminated状态。

TRIVIA

实际上，你可以控制是否preStart被调用。我们可以在下节看到。如果你好奇，可以看下Actor中的**postRestart*方法

def postRestart(reason: Throwable): Unit = {
  preStart()
}
代码
跟往常一样，代码在github

===============================

Actor中的Future-询问模式


和java线程中的future挺像的

可以将一个actor的返回结果重定向到另一个actor中进行处理，主actor或者进程无需等待actor的返回结果。

package akka.future;

import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.PoisonPill;
import akka.actor.Props;
import akka.pattern.Patterns;
import com.typesafe.config.ConfigFactory;
import scala.concurrent.Await;
import scala.concurrent.Future;
import scala.concurrent.duration.Duration;

import java.util.concurrent.TimeUnit;

/**
 * Created by liubenlong on 2017/1/16.
 */
public class AskMain {

    public static void main(String[] args) throws Exception {
        ActorSystem system = ActorSystem.create("strategy", ConfigFactory.load("akka.config"));
        ActorRef printActor = system.actorOf(Props.create(PrintActor.class), "PrintActor");
        ActorRef workerActor = system.actorOf(Props.create(WorkerActor.class), "WorkerActor");

        //等等future返回
        Future<Object> future = Patterns.ask(workerActor, 5, 1000);
        int result = (int) Await.result(future, Duration.create(3, TimeUnit.SECONDS));
        System.out.println("result:" + result);

        //不等待返回值，直接重定向到其他actor，有返回值来的时候将会重定向到printActor
        Future<Object> future1 = Patterns.ask(workerActor, 8, 1000);
        Patterns.pipe(future1, system.dispatcher()).to(printActor);


        workerActor.tell(PoisonPill.getInstance(), ActorRef.noSender());
    }
}
package akka.future;

import akka.actor.UntypedActor;
import akka.event.Logging;
import akka.event.LoggingAdapter;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class PrintActor extends UntypedActor {

    private final LoggingAdapter log = Logging.getLogger(getContext().system(), this);

    @Override
    public void onReceive(Object o) throws Throwable {
        log.info("akka.future.PrintActor.onReceive:" + o);
        if (o instanceof Integer) {
            log.info("print:" + o);
        } else {
            unhandled(o);
        }
    }

}

package akka.future;

import akka.actor.*;
import akka.event.Logging;
import akka.event.LoggingAdapter;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class WorkerActor extends UntypedActor {

    private final LoggingAdapter log = Logging.getLogger(getContext().system(), this);

    @Override
    public void onReceive(Object o) throws Throwable {
        log.info("akka.future.WorkerActor.onReceive:" + o);

        if (o instanceof Integer) {
            Thread.sleep(1000);
            int i = Integer.parseInt(o.toString());
            getSender().tell(i*i, getSelf());
        } else {
            unhandled(o);
        }
    }

}



输出结果：

[INFO] [01/16/2017 16:22:32.983] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/WorkerActor] akka.future.WorkerActor.onReceive:5
result:25
[INFO] [01/16/2017 16:22:33.984] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/WorkerActor] akka.future.WorkerActor.onReceive:8
[INFO] [01/16/2017 16:22:34.997] [strategy-akka.actor.default-dispatcher-6] [akka://strategy/user/PrintActor] akka.future.PrintActor.onReceive:64
[INFO] [01/16/2017 16:22:34.997] [strategy-akka.actor.default-dispatcher-6] [akka://strategy/user/PrintActor] print:64
其实这里和之前的文章中那样，在workerActor执行完毕以后，向printActor发消息不也行吗？
参考资料

书籍《java高并发程序设计》
==========
actor生命周期

import akka.actor.UntypedActor;
import akka.event.Logging;
import akka.event.LoggingAdapter;

public class MyWork extends UntypedActor {

    LoggingAdapter logger = Logging.getLogger(getContext().system(), this);

    public static enum Msg{
        WORKING, DONE, CLOSE;
    }

    /**
    *
    * /
    @Override
    public void preStart() {
        logger.info("myWork starting.");
    }

    @Override
    public void postStop() throws Exception {
        logger.info("myWork stoping..");
    }

    @Override
    public void onReceive(Object msg) {
        try {
            if(msg == Msg.WORKING){
                logger.info("i am  working");
            }else if(msg == Msg.DONE){
                logger.info("stop  working");
            }else if(msg == Msg.CLOSE){
                logger.info("stop  close");
                getSender().tell(Msg.CLOSE, getSelf());
                getContext().stop(getSelf());
            }else {
                unhandled(msg);
            }
        }catch (Exception e){
            e.printStackTrace();
        }
    }
}
import akka.actor.ActorRef;
import akka.actor.Terminated;
import akka.actor.UntypedActor;
import akka.event.Logging;
import akka.event.LoggingAdapter;

public class WatchActor extends UntypedActor {

  LoggingAdapter logger = Logging.getLogger(getContext().system(), this);

  /**
   * 监听一个actor
   * @param actorRef
   */
  public WatchActor(ActorRef actorRef){
    getContext().watch(actorRef);
  }

  @Override
  public void onReceive(Object msg) throws InterruptedException {
    if(msg instanceof Terminated){
      //这里简单打印一下，然后停止system
      logger.error(((Terminated)msg).getActor().path() + " has Terminated. now shutdown the system");
      getContext().system().shutdown();
    }else{
      unhandled(msg);
    }

  }

}


import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.PoisonPill;
import akka.actor.Props;
import com.typesafe.config.ConfigFactory;

public class Main {

  public static void main(String[] args) {
    //创建ActorSystem。一般来说，一个系统只需要一个ActorSystem。
    //参数1：系统名称。参数2：配置文件
    ActorSystem system = ActorSystem.create("Hello", ConfigFactory.load("akka.config"));
    ActorRef myWork = system.actorOf(Props.create(MyWork.class), "MyWork");
    ActorRef watchActor = system.actorOf(Props.create(WatchActor.class, myWork), "WatchActor");

    myWork.tell(MyWork.Msg.WORKING, ActorRef.noSender());
    myWork.tell(MyWork.Msg.DONE, ActorRef.noSender());

    //中断myWork
    myWork.tell(PoisonPill.getInstance(), ActorRef.noSender());
  }
}



输出结果：

[INFO] [01/05/2017 15:26:15.705] [Hello-akka.actor.default-dispatcher-4] [akka://Hello/user/MyWork] myWork starting.
[INFO] [01/05/2017 15:26:15.730] [Hello-akka.actor.default-dispatcher-4] [akka://Hello/user/MyWork] i am  working
[INFO] [01/05/2017 15:26:15.730] [Hello-akka.actor.default-dispatcher-4] [akka://Hello/user/MyWork] stop  working
[INFO] [01/05/2017 15:26:15.736] [Hello-akka.actor.default-dispatcher-4] [akka://Hello/user/MyWork] myWork stoping..
[ERROR] [01/05/2017 15:26:15.749] [Hello-akka.actor.default-dispatcher-10] [akka://Hello/user/WatchActor] akka://Hello/user/MyWork has Terminated. now shutdown the system
1
2
3
4
5
监督

这里可以对actor进行监督，在actor报出异常的时候进行处理。由于这个和生命周期也有关，所以放到这里一起说了。

akka监督策略有两种：

OneForOneStrategy
只对出问题的子actor进行处理. 这是默认策略
AllForOneStrategy
对子actor以及他的所有兄弟actor进行处理
定义监督者的行为：


package akka.strategy;

import akka.actor.OneForOneStrategy;
import akka.actor.Props;
import akka.actor.SupervisorStrategy;
import akka.actor.UntypedActor;
import akka.japi.Function;
import scala.concurrent.duration.Duration;

import java.util.concurrent.TimeUnit;

/**
 * Created by liubenlong on 2017/1/9.
 * 监督者，监督策略
 */
public class SuperVisor extends UntypedActor{

    /**
     * 配置自己的strategy
     * @return
     */
    @Override
    public SupervisorStrategy supervisorStrategy(){
        return new OneForOneStrategy(3, Duration.create(1, TimeUnit.MINUTES),//一分钟内重试3次，超过则kill掉actor
                new Function<Throwable, SupervisorStrategy.Directive>() {
                    @Override
                    public SupervisorStrategy.Directive apply(Throwable throwable) throws Exception {
                        if(throwable instanceof ArithmeticException){//ArithmeticException是出现异常的运算条件时，抛出此异常。例如，一个整数“除以零”时，抛出此类的一个实例。
                            System.out.println("meet ArithmeticException ,just resume.");
                            return  SupervisorStrategy.resume();//继续; 重新开始; 恢复职位;
                        }else if(throwable instanceof NullPointerException){
                            System.out.println("meet NullPointerException , restart.");
                            return SupervisorStrategy.restart();
                        }else if(throwable instanceof IllegalArgumentException){
                            System.out.println("meet IllegalArgumentException ,stop.");
                            return SupervisorStrategy.stop();
                        }else{
                            System.out.println("escalate.");
                            return SupervisorStrategy.escalate();//使逐步升级; 使逐步上升; 乘自动梯上升;也就是交给更上层的actor处理。抛出异常
                        }
                    }
                });
    }

    @Override
    public void onReceive(Object o) throws Throwable {
        if(o instanceof Props){
            getContext().actorOf((Props)o , "restartActor");
        }else{
            unhandled(o);
        }
    }
}



定义restartActor的实现：

package akka.strategy;

import akka.actor.UntypedActor;
import scala.Option;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class RestartActor extends UntypedActor {

    public  enum  Msg{
        DONE, RESTART;
    }


    @Override
    public void preStart() throws Exception {
        System.out.println("preStart    hashCode=" + this.hashCode());
    }
    @Override
    public void postStop() throws Exception {
        System.out.println("postStop    hashCode=" + this.hashCode());
    }



    @Override
    public void preRestart(Throwable reason, Option<Object> message) throws Exception {
        System.out.println("preRestart    hashCode=" + this.hashCode());
    }
    @Override
    public void postRestart(Throwable reason) throws Exception {
        super.postRestart(reason);
        System.out.println("postRestart    hashCode=" + this.hashCode());
    }



    @Override
    public void onReceive(Object o) throws Throwable {
        if(o == Msg.DONE){
            getContext().stop(getSelf());
        }else if(o == Msg.RESTART){
            System.out.println(((Object) null).toString());
            //抛出异常，默认会被restart，但这里会resume
            //double a = 1/0;
        }else{
            unhandled(o);
        }

    }
}



定义main方法：

package akka.strategy;

import akka.actor.*;
import com.typesafe.config.ConfigFactory;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class Main {

    public static void main(String[] args) {
        ActorSystem system = ActorSystem.create("strategy", ConfigFactory.load("akka.config"));
        ActorRef superVisor = system.actorOf(Props.create(SuperVisor.class), "SuperVisor");
        superVisor.tell(Props.create(RestartActor.class), ActorRef.noSender());

        ActorSelection actorSelection = system.actorSelection("akka://strategy/user/SuperVisor/restartActor");//这是akka的路径。restartActor是在SuperVisor中创建的。

        for(int i = 0 ; i < 100 ; i ++){
            actorSelection.tell(RestartActor.Msg.RESTART, ActorRef.noSender());
        }
    }

}



输出结果（省略部分异常）：

com.intellij.rt.execution.application.AppMain akka.strategy.Main
preStart    hashCode=463293128
meet NullPointerException , restart.
preRestart    hashCode=463293128
preStart    hashCode=1195770342
postRestart    hashCode=1195770342
meet NullPointerException , restart.
preRestart    hashCode=1195770342
preStart    hashCode=1139511720
postRestart    hashCode=1139511720
meet NullPointerException , restart.
preRestart    hashCode=1139511720
preStart    hashCode=1906622979
postRestart    hashCode=1906622979
meet NullPointerException , restart.
postStop    hashCode=1906622979
[ERROR] [01/12/2017 10:52:05.563] [strategy-akka.actor.default-dispatcher-2] [akka://strategy/user/SuperVisor/restartActor] null
java.lang.NullPointerException
    at akka.strategy.RestartActor.onReceive(RestartActor.java:44)
    at akka.actor.UntypedActor$$anonfun$receive$1.applyOrElse(UntypedActor.scala:165)



结果分析：
preStart是restartActor初始化时调用的，他的hashcode是463293128，接着遇到空指针异常，根据自定义策略，会重启改actor。此时会调用preRestart，注意他的hashcode依然是463293128，因为preRestart是在正式启动前在老的actor上调用的。
随后打印出preStart,说明新的actor开始创建了，他的hashcode是1195770342,新的actor实例将替代旧的实例工作，这说明同一个restartActor工作的过程中，未必真的是同一个actor。重启完成之后调用postRestart.

再经历3次（自定义策略配置的）重启以后，达到重启上限，系统将直接关闭该actor。

选择actor

上面程序中使用到了ActorSelection actorSelection = system.actorSelection("akka://strategy/user/SuperVisor/restartActor");进行actor的选择。
工作过程中可能会存在成千上万的actor，可以通过actorSelection方便的选择actor进行消息投递，其支持通配符匹配getContext().actorSelection("/user/worker_*").


=======
agent

我们知道在JDK中，编写多线程代码时要谨慎处理临界区的数据，可以加锁或者使用JDK自带的CAS库：atomic相关包。

那么在akka中怎么处理呢？akka给我们提供了一个agent。可以使用agent来实现共享变量的安全处理。

下面示例为10个actor并发累加countAgent变量。每个累加10000次。如果正确的话，最终结果应该是10W。

package akka;

import akka.actor.*;
import akka.agent.Agent;
import akka.dispatch.ExecutionContexts;
import akka.dispatch.Futures;
import akka.dispatch.Mapper;
import akka.dispatch.OnComplete;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import com.typesafe.config.ConfigFactory;
import scala.concurrent.Future;
import scala.concurrent.duration.Duration;

import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class AgentTest extends UntypedActor {

    private final LoggingAdapter log = Logging.getLogger(getContext().system(), this);

    @Override
    public void onReceive(Object o) throws Throwable {
        if(o instanceof Integer){
            for(int i = 0 ; i < 10000 ; i ++){
                Future<Integer> future = countAgent.alter(new Mapper<Integer, Integer>() {
                    @Override
                    public Integer apply(Integer parameter) {
                        return parameter + 1;
                    }
                });
                queue.add(future);
            }

            getContext().stop(getSelf());//完成任务，关闭自己
        }else{
            unhandled(o);
        }
    }


    public static CountDownLatch latch = new CountDownLatch(10);
    public static Agent<Integer> countAgent = Agent.create(0, ExecutionContexts.global());
    public static ConcurrentLinkedQueue<Future<Integer>> queue = new ConcurrentLinkedQueue<>();

    public static void main(String [] args) throws InterruptedException, TimeoutException {
        ActorSystem system = ActorSystem.create("inbox", ConfigFactory.load("akka.conf"));

        ActorRef[] actorRefs = new ActorRef[10];
        for(int i = 0 ; i < 10 ; i ++){
            actorRefs[i] = system.actorOf(Props.create(AgentTest.class), "AgentTest" + i);
        }

        Inbox inbox = Inbox.create(system);
        for (ActorRef ref : actorRefs) {
            inbox.send(ref, 1);
            inbox.watch(ref);
        }

        System.out.println("countAgent 1:" + countAgent.get());


        /*
         * 这里本来想用JDK里的AtomicInteger, 但是不行，不适用于这里的actor
         */


        //等待所有actor执行完毕
        int closeCount = 0;
        while(true){
            Object o = inbox.receive(Duration.create(1, TimeUnit.SECONDS));
            if(o instanceof Terminated){
                closeCount ++;
                if(closeCount == actorRefs.length){
                    break;
                }
            }else{
                System.out.println("o:" + o);
            }
        }

        System.out.println("countAgent 2:" + countAgent.get());

        //等待所有累加线程完成
        Futures.sequence(queue, system.dispatcher()).onComplete(new OnComplete<Iterable<Integer>>() {
            @Override
            public void onComplete(Throwable throwable, Iterable<Integer> integers) throws Throwable {
                System.out.println("countAgent 3:" + countAgent.get());
                system.shutdown();
            }
        }, system.dispatcher());

    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
运行结果：

countAgent 1:0
countAgent 2:10
countAgent 3:100000
1
2
3
参考资料

书籍《java高并发程序设计》
AKKA官方文档
=================
Akka群集提供容错分散的对等群集成员服务，没有单点故障或单点瓶颈。 它使用gossip协议和自动故障检测器。

术语

节点
群集的逻辑成员。 一台物理机上可能有多个节点。 定义格式是【主机名：port：uid】
集群
通过成员服务连接在一起的一组节点。
leader
集群中充当领导者的单个节点。 管理集群和成员状态转换。
节点状态

akka.cluster.allow-weakly-up-members=off 时：


akka.cluster.allow-weakly-up-members=off 时：


状态（Member States）
joining： 假如集群的临时状态
weakly up： 出现网络分区时的临时状态（仅当akka.cluster.allow-weakly-up-members = on时）
up： 正常工作状态
leaving / exiting： 正常删除
down： marked as down (no longer part of cluster decisions)
removed： tombstone state (no longer a member)
动作（User Actions）
join： 一个节点加入到集群（can be explicit or automatic on startup if a node to join have been specified in the configuration）
leave： 优雅移除节点
down： 将一个节点标记为关闭
leader动作（Leader Actions）
领导人有以下职责：将成员移入和移出群集
加入 -> 正常运行
退出 -> 删除
故障检测和不可达性
fd *
the failure detector of one of the monitoring nodes has triggered causing the monitored node to be marked as unreachable
unreachable*
unreachable is not a real member states but more of a flag in addition to the state signaling that the cluster is unable to talk to this node, after being unreachable the failure detector may detect it as reachable again and thereby remove the flag
初始配置

引入akka-cluster的maven依赖

<dependency>
  <groupId>com.typesafe.akka</groupId>
  <artifactId>akka-cluster_2.11</artifactId>
  <version>2.4.16</version>
</dependency>
1
2
3
4
5
修改配置文件reference.conf

akka {
  loglevel = "INFO"

  actor {
      provider = "akka.cluster.ClusterActorRefProvider"
    }
    remote {
      log-remote-lifecycle-events = off
      netty.tcp {
        hostname = "127.0.0.1"
        port = 2551
      }
    }

    cluster {
      seed-nodes = [
        "akka.tcp://akkaClusterTest@127.0.0.1:2551",
        "akka.tcp://akkaClusterTest@127.0.0.1:2552"]

      #//#snippet
      # excluded from snippet
      auto-down-unreachable-after = 10s
      #//#snippet
      # auto downing is NOT safe for production deployments.
      # you may want to use it during development, read more about it in the docs.
      #
      auto-down-unreachable-after = 10s

      # Disable legacy metrics in akka-cluster.
      metrics.enabled=off
    }
}

# 持久化相关
akka.persistence.journal.plugin = "akka.persistence.journal.inmem"
# Absolute path to the default snapshot store plugin configuration entry.
akka.persistence.snapshot-store.plugin = "akka.persistence.snapshot-store.local"
37
编写测试代码（来自于自官网示例）

package akka.myCluster;

import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.Props;
import akka.actor.UntypedActor;
import akka.cluster.Cluster;
import akka.cluster.ClusterEvent;
import akka.cluster.ClusterEvent.MemberEvent;
import akka.cluster.ClusterEvent.MemberUp;
import akka.cluster.ClusterEvent.MemberRemoved;
import akka.cluster.ClusterEvent.UnreachableMember;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import com.typesafe.config.ConfigFactory;

public class SimpleClusterListener extends UntypedActor {

  LoggingAdapter log = Logging.getLogger(getContext().system(), this);
  Cluster cluster = Cluster.get(getContext().system());

  //subscribe to cluster changes
  @Override
  public void preStart() {
    //#subscribe
    cluster.subscribe(getSelf(), ClusterEvent.initialStateAsEvents(),
        MemberEvent.class, UnreachableMember.class);
    //#subscribe
  }

  //re-subscribe when restart
  @Override
  public void postStop() {
    cluster.unsubscribe(getSelf());
  }

  @Override
  public void onReceive(Object message) {
    if (message instanceof MemberUp) {
      MemberUp mUp = (MemberUp) message;
      log.info("Member is Up: {}", mUp.member());

    } else if (message instanceof UnreachableMember) {
      UnreachableMember mUnreachable = (UnreachableMember) message;
      log.info("Member detected as unreachable: {}", mUnreachable.member());

    } else if (message instanceof MemberRemoved) {
      MemberRemoved mRemoved = (MemberRemoved) message;
      log.info("Member is Removed: {}", mRemoved.member());

    } else if (message instanceof MemberEvent) {
      // ignore

    } else {
      unhandled(message);
    }

  }

  public static void main(String [] args){
    System.out.println("Start simpleClusterListener");
    ActorSystem system = ActorSystem.create("akkaClusterTest", ConfigFactory.load("reference.conf"));
    system.actorOf(Props.create(SimpleClusterListener.class), "simpleClusterListener");
    System.out.println("Started simpleClusterListener");
  }
}
将以上项目复制一份，并修改其端口为2552
运行结果

先启动2551服务：

Start simpleClusterListener
[INFO] [01/18/2017 15:39:14.886] [main] [akka.remote.Remoting] Starting remoting
[INFO] [01/18/2017 15:39:15.728] [main] [akka.remote.Remoting] Remoting started; listening on addresses :[akka.tcp://akkaClusterTest@127.0.0.1:2551]
[INFO] [01/18/2017 15:39:15.744] [main] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Starting up...
[INFO] [01/18/2017 15:39:15.853] [main] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Registered cluster JMX MBean [akka:type=Cluster]
[INFO] [01/18/2017 15:39:15.853] [main] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Started up successfully
Started simpleClusterListener
[WARN] [01/18/2017 15:39:15.900] [akkaClusterTest-akka.actor.default-dispatcher-18] [akka.tcp://akkaClusterTest@127.0.0.1:2551/system/cluster/core/daemon/downingProvider] Don't use auto-down feature of Akka Cluster in production. See 'Auto-downing (DO NOT USE)' section of Akka Cluster documentation.
[WARN] [01/18/2017 15:39:17.057] [akkaClusterTest-akka.remote.default-remote-dispatcher-8] [akka.tcp://akkaClusterTest@127.0.0.1:2551/system/endpointManager/reliableEndpointWriter-akka.tcp%3A%2F%2FakkaClusterTest%40127.0.0.1%3A2552-0] Association with remote system [akka.tcp://akkaClusterTest@127.0.0.1:2552] has failed, address is now gated for [5000] ms. Reason: [Association failed with [akka.tcp://akkaClusterTest@127.0.0.1:2552]] Caused by: [Connection refused: no further information: /127.0.0.1:2552]
[INFO] [01/18/2017 15:39:17.073] [akkaClusterTest-akka.actor.default-dispatcher-2] [akka://akkaClusterTest/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin$] from Actor[akka://akkaClusterTest/system/cluster/core/daemon/firstSeedNodeProcess-1#1750766313] to Actor[akka://akkaClusterTest/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [01/18/2017 15:39:17.073] [akkaClusterTest-akka.actor.default-dispatcher-2] [akka://akkaClusterTest/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin$] from Actor[akka://akkaClusterTest/system/cluster/core/daemon/firstSeedNodeProcess-1#1750766313] to Actor[akka://akkaClusterTest/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [01/18/2017 15:39:17.915] [akkaClusterTest-akka.actor.default-dispatcher-21] [akka://akkaClusterTest/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin$] from Actor[akka://akkaClusterTest/system/cluster/core/daemon/firstSeedNodeProcess-1#1750766313] to Actor[akka://akkaClusterTest/deadLetters] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [01/18/2017 15:39:18.914] [akkaClusterTest-akka.actor.default-dispatcher-17] [akka://akkaClusterTest/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin$] from Actor[akka://akkaClusterTest/system/cluster/core/daemon/firstSeedNodeProcess-1#1750766313] to Actor[akka://akkaClusterTest/deadLetters] was not delivered. [4] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [01/18/2017 15:39:19.914] [akkaClusterTest-akka.actor.default-dispatcher-2] [akka://akkaClusterTest/deadLetters] Message [akka.cluster.InternalClusterAction$InitJoin$] from Actor[akka://akkaClusterTest/system/cluster/core/daemon/firstSeedNodeProcess-1#1750766313] to Actor[akka://akkaClusterTest/deadLetters] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [01/18/2017 15:39:21.008] [akkaClusterTest-akka.actor.default-dispatcher-19] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] is JOINING, roles []
[INFO] [01/18/2017 15:39:21.024] [akkaClusterTest-akka.actor.default-dispatcher-19] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Leader is moving node [akka.tcp://akkaClusterTest@127.0.0.1:2551] to [Up]
[INFO] [01/18/2017 15:39:21.024] [akkaClusterTest-akka.actor.default-dispatcher-2] [akka://akkaClusterTest/user/simpleClusterListener] Member is Up: Member(address = akka.tcp://akkaClusterTest@127.0.0.1:2551, status = Up)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
此时再启动2552端口,2552的输出日志为：

Start simpleClusterListener
[INFO] [01/18/2017 15:40:35.671] [main] [akka.remote.Remoting] Starting remoting
[INFO] [01/18/2017 15:40:36.458] [main] [akka.remote.Remoting] Remoting started; listening on addresses :[akka.tcp://akkaClusterTest@127.0.0.1:2552]
[INFO] [01/18/2017 15:40:36.474] [main] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2552] - Starting up...
[INFO] [01/18/2017 15:40:36.552] [main] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2552] - Registered cluster JMX MBean [akka:type=Cluster]
[INFO] [01/18/2017 15:40:36.552] [main] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2552] - Started up successfully
Started simpleClusterListener
[WARN] [01/18/2017 15:40:36.567] [akkaClusterTest-akka.actor.default-dispatcher-15] [akka.tcp://akkaClusterTest@127.0.0.1:2552/system/cluster/core/daemon/downingProvider] Don't use auto-down feature of Akka Cluster in production. See 'Auto-downing (DO NOT USE)' section of Akka Cluster documentation.
[INFO] [01/18/2017 15:40:37.067] [akkaClusterTest-akka.actor.default-dispatcher-2] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2552] - Welcome from [akka.tcp://akkaClusterTest@127.0.0.1:2551]
[INFO] [01/18/2017 15:40:37.082] [akkaClusterTest-akka.actor.default-dispatcher-4] [akka://akkaClusterTest/user/simpleClusterListener] Member is Up: Member(address = akka.tcp://akkaClusterTest@127.0.0.1:2551, status = Up)
[INFO] [01/18/2017 15:40:37.925] [akkaClusterTest-akka.actor.default-dispatcher-15] [akka://akkaClusterTest/user/simpleClusterListener] Member is Up: Member(address = akka.tcp://akkaClusterTest@127.0.0.1:2552, status = Up)
1
2
3
4
5
6
7
8
9
10
11
12
同时2551会增加几行日志：

[INFO] [01/18/2017 15:40:36.942] [akkaClusterTest-akka.actor.default-dispatcher-2] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Node [akka.tcp://akkaClusterTest@127.0.0.1:2552] is JOINING, roles []
[INFO] [01/18/2017 15:40:37.893] [akkaClusterTest-akka.actor.default-dispatcher-3] [akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Leader is moving node [akka.tcp://akkaClusterTest@127.0.0.1:2552] to [Up]
[INFO] [01/18/2017 15:40:37.893] [akkaClusterTest-akka.actor.default-dispatcher-4] [akka://akkaClusterTest/user/simpleClusterListener] Member is Up: Member(address = akka.tcp://akkaClusterTest@127.0.0.1:2552, status = Up)
1
2
3
上面日志中可以看到Akka集群中各个节点的状态迁移信息，第一个种子节点正在加入自身创建的集群时的状态时JOINING，由于第一个种子节点将自己率先选举为Leader，因此它还将自己的状态改变为Up。后面它还将第二个种子节点和第三个节点从JOINING转换到Up状态。
同样再添加一个2553端口的服务，与上面一样，就不多说了。
我们现在吧2553服务停止，看看日志输出：

[akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Leader is auto-downing unreachable node [akka.tcp://akkaClusterTest@127.0.0.1:2553]. Don't use auto-down feature of Akka Cluster in production. See 'Auto-downing (DO NOT USE)' section of Akka Cluster documentation.
[akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Marking unreachable node [akka.tcp://akkaClusterTest@127.0.0.1:2553] as [Down]
[akka.cluster.Cluster(akka://akkaClusterTest)] Cluster Node [akka.tcp://akkaClusterTest@127.0.0.1:2551] - Leader is removing unreachable node [akka.tcp://akkaClusterTest@127.0.0.1:2553]
[akka://akkaClusterTest/user/simpleClusterListener] Member is Removed: Member(address = akka.tcp://akkaClusterTest@127.0.0.1:2553, status = Removed)
1
2
3
4
2553被标记为Removed

注意： 我们在配置文件中配置了auto-down-unreachable-after=10s。所以在2553关闭10s后才会真正将其移除。
参考资料


=======

package com.aiso.thread.akka;

public class Message {
    String url;

    Message(String url) {
        this.url = url;
    }
}

package com.aiso.thread.akka;

import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.Props;
import akka.actor.UntypedActorFactory;

import java.util.List;
import java.util.concurrent.atomic.AtomicReference;

import static akka.actor.TypedActor.self;


public class Querier {
    private String question;
    private List<String> engines;
    private AtomicReference<String> result;

    public Querier(String question, List<String> engines, AtomicReference<String> result) {
        this.question = question;
        this.engines = engines;
        this.result = result;
    }

    @Override
    public void onReceive(Object message) throws Exception {
        if (message instanceof Result) {
            result.compareAndSet(null, ((Result) message).html);
            getContext().stop(self());
        } else {
            for (String base : engines) {
                String url = base + question;
                ActorRef fetcher = this.getContext().actorOf(Props.create(UrlFetcher.class), "fetcher-" + base.hashCode());
                Message m = new Message(url);
                fetcher.tell(m, self());
            }
        }
    }

    private static String getFirstResultActors(String question, List<String> engines) {
        ActorSystem system = ActorSystem.create("Search");
        AtomicReference<String> result = new AtomicReference<>();
        final ActorRef q = system.actorOf(
                Props.create((UntypedActorFactory) () -> new Querier(question, engines, result)), "master");
        q.tell(new Object(), ActorRef.noSender());
        while (result.get() == null) ;
        return result.get();
    }
}

package com.aiso.thread.akka;

public class Result {
    String html;

    Result(String html) {
        this.html = html;
    }
}


package com.aiso.thread.akka;

import akka.actor.ActorRef;

import static akka.actor.Actor$class.unhandled;

public class UrlFetcher extends {

    private ActorRef self;

    @Override
    public void onReceive(Object message) throws Exception {
        if (message instanceof Message) {
            Message work = (Message) message;
            String result = WS.url(work.url).get();
            getSender().tell(new Result(result), getSelf());
        } else {
            unhandled(message);
        }
    }

    private ActorRef getSender() {
        return null;
    }

    public ActorRef getSelf() {
        return self;
    }
}
====================

上一篇文章介绍了akka集群的搭建，现在假如服务的生产者与消费者两个角色，模拟真实的服务调用。
本篇文章主要参考 使用Akka构建集群（二）
整体架构

服务端三个服务，端口为2552,2553,2551；客户端有两个：2554,2555
服务端角色为[server]；客户端角色为[client]

服务端

集群角色

首先配置服务端集群角色为[server]:

akka {
  loglevel = "INFO"

  actor {
      provider = "akka.cluster.ClusterActorRefProvider"
    }
    remote {
      log-remote-lifecycle-events = off
      netty.tcp {
        hostname = "127.0.0.1"
        port = 2551
      }
    }

    cluster {
      seed-nodes = [
        "akka.tcp://akkaClusterTest@127.0.0.1:2551",
        "akka.tcp://akkaClusterTest@127.0.0.1:2552"]

      #//#snippet
      # excluded from snippet
      auto-down-unreachable-after = 10s
      #//#snippet
      # auto downing is NOT safe for production deployments.
      # you may want to use it during development, read more about it in the docs.
      #
      auto-down-unreachable-after = 10s

      roles = [server]
      # Disable legacy metrics in akka-cluster.
      metrics.enabled=off
    }
}

# 持久化相关
akka.persistence.journal.plugin = "akka.persistence.journal.inmem"
# Absolute path to the default snapshot store plugin configuration entry.
akka.persistence.snapshot-store.plugin = "akka.persistence.snapshot-store.local"
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
定义通讯的数据结构

实际开发过程中，可以将该数据结构作为单独的接口供服务端和客户端引用。
package akka.myCluster;

import java.io.Serializable;

public class TransformationMessages {

    /**
     * 传递的数据（参数）
     */
    public static class TransformationJob implements Serializable {
        private final String text;

        public TransformationJob(String text) {
            this.text = text;
        }

        public String getText() {
            return text;
        }
    }

    /**
     * 返回结果
     */
    public static class TransformationResult implements Serializable {
        private final String text;

        public TransformationResult(String text) {
            this.text = text;
        }

        public String getText() {
            return text;
        }

        @Override
        public String toString() {
            return "TransformationResult(" + text + ")";
        }
    }

    /**
     * 异常处理
     */
    public static class JobFailed implements Serializable {
        private final String reason;
        private final TransformationJob job;

        public JobFailed(String reason, TransformationJob job) {
            this.reason = reason;
            this.job = job;
        }

        public String getReason() {
            return reason;
        }

        public TransformationJob getJob() {
            return job;
        }

        @Override
        public String toString() {
            return "JobFailed(" + reason + ")";
        }
    }

    /**
     * 用于服务端向客户端注册
     */
    public static final int BACKEND_REGISTRATION = 1;

}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
真正服务端业务逻辑处理代码：简单讲收到的字符串转为大写返回

package akka.myCluster;

import akka.actor.ActorSystem;
import akka.actor.Props;
import akka.actor.UntypedActor;
import akka.cluster.Cluster;
import akka.cluster.ClusterEvent;
import akka.cluster.Member;
import akka.cluster.MemberStatus;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import com.typesafe.config.ConfigFactory;

import static akka.myCluster.TransformationMessages.BACKEND_REGISTRATION;

public class MyAkkaClusterServer extends UntypedActor {

    LoggingAdapter logger = Logging.getLogger(getContext().system(), this);

    Cluster cluster = Cluster.get(getContext().system());

    // subscribe to cluster changes
    @Override
    public void preStart() {
        // #subscribe
        cluster.subscribe(getSelf(), ClusterEvent.MemberUp.class);
        // #subscribe
    }

    // re-subscribe when restart
    @Override
    public void postStop() {
        cluster.unsubscribe(getSelf());
    }

    @Override
    public void onReceive(Object message) {
        if (message instanceof TransformationMessages.TransformationJob) {
            TransformationMessages.TransformationJob job = (TransformationMessages.TransformationJob) message;
            logger.info(job.getText());
            getSender().tell(new TransformationMessages.TransformationResult(job.getText().toUpperCase()), getSelf());

        } else if (message instanceof ClusterEvent.CurrentClusterState) {
            /**
             * 当前节点在刚刚加入集群时，会收到CurrentClusterState消息，从中可以解析出集群中的所有前端节点（即roles为frontend的），并向其发送BACKEND_REGISTRATION消息，用于注册自己
             */
            ClusterEvent.CurrentClusterState state = (ClusterEvent.CurrentClusterState) message;
            for (Member member : state.getMembers()) {
                if (member.status().equals(MemberStatus.up())) {
                    register(member);
                }
            }

        } else if (message instanceof ClusterEvent.MemberUp) {
            /**
             * 有新的节点加入
             */
            ClusterEvent.MemberUp mUp = (ClusterEvent.MemberUp) message;
            register(mUp.member());

        } else {
            unhandled(message);
        }

    }

    /**
     * 如果是客户端角色，则像客户端注册自己的信息。客户端收到消息以后会讲这个服务端存到本机服务列表中
     * @param member
     */
    void register(Member member) {
        if (member.hasRole("client"))
            getContext().actorSelection(member.address() + "/user/myAkkaClusterClient").tell(BACKEND_REGISTRATION, getSelf());
    }

    public static void main(String [] args){
        System.out.println("Start MyAkkaClusterServer");
        ActorSystem system = ActorSystem.create("akkaClusterTest", ConfigFactory.load("reference.conf"));
        system.actorOf(Props.create(MyAkkaClusterServer.class), "myAkkaClusterServer");
        System.out.println("Started MyAkkaClusterServer");

    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
如何保证服务发现与维护

上面代码已经有注释了，有2点：
- 有新节点加入时，如果是客户端角色，则像客户端注册自己的信息。客户端收到消息以后会讲这个服务端存到本机服务列表中
- 服务端当前节点在刚刚加入集群时，会收到CurrentClusterState消息，从中可以解析出集群中的所有前端节点（即roles为frontend的），并向其发送BACKEND_REGISTRATION消息，用于注册自己

客户端

修改客户端roles为client

akka {
  loglevel = "INFO"

  actor {
      provider = "akka.cluster.ClusterActorRefProvider"
    }
    remote {
      log-remote-lifecycle-events = off
      netty.tcp {
        hostname = "127.0.0.1"
        port = 2554
      }
    }

    cluster {
      seed-nodes = [
        "akka.tcp://akkaClusterTest@127.0.0.1:2551",
        "akka.tcp://akkaClusterTest@127.0.0.1:2552"]

      #//#snippet
      # excluded from snippet
      auto-down-unreachable-after = 10s
      #//#snippet
      # auto downing is NOT safe for production deployments.
      # you may want to use it during development, read more about it in the docs.
      #
      auto-down-unreachable-after = 10s

    roles = [client]
      # Disable legacy metrics in akka-cluster.
      metrics.enabled=off
    }
}

# 持久化相关
akka.persistence.journal.plugin = "akka.persistence.journal.inmem"
# Absolute path to the default snapshot store plugin configuration entry.
akka.persistence.snapshot-store.plugin = "akka.persistence.snapshot-store.local"
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
客户端代码

package akka.myCluster;

import akka.actor.*;
import akka.dispatch.OnSuccess;
import akka.util.Timeout;
import com.typesafe.config.ConfigFactory;
import scala.concurrent.ExecutionContext;
import scala.concurrent.duration.Duration;
import scala.concurrent.duration.FiniteDuration;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

import static akka.myCluster.TransformationMessages.BACKEND_REGISTRATION;
import static akka.pattern.Patterns.ask;

public class MyAkkaClusterClient extends UntypedActor {

    List<ActorRef> backends = new ArrayList<ActorRef>();
    int jobCounter = 0;

    @Override
    public void onReceive(Object message) {
        if ((message instanceof TransformationMessages.TransformationJob) && backends.isEmpty()) {//无服务提供者
            TransformationMessages.TransformationJob job = (TransformationMessages.TransformationJob) message;
            getSender().tell(
                    new TransformationMessages.JobFailed("Service unavailable, try again later", job),
                    getSender());

        } else if (message instanceof TransformationMessages.TransformationJob) {
            TransformationMessages.TransformationJob job = (TransformationMessages.TransformationJob) message;
            /**
             * 这里在客户端业务代码里进行负载均衡操作。实际业务中可以提供多种负载均衡策略，并且也可以做分流限流等各种控制。
             */
            jobCounter++;
            backends.get(jobCounter % backends.size())
                    .forward(job, getContext());

        } else if (message == BACKEND_REGISTRATION) {
            /**
             * 注册服务提供者
             */
            getContext().watch(getSender());//这里对服务提供者进行watch
            backends.add(getSender());

        } else if (message instanceof Terminated) {
            /**
             * 移除服务提供者
             */
            Terminated terminated = (Terminated) message;
            backends.remove(terminated.getActor());

        } else {
            unhandled(message);
        }
    }

    public static void main(String [] args){
        System.out.println("Start myAkkaClusterClient");
        ActorSystem actorSystem = ActorSystem.create("akkaClusterTest", ConfigFactory.load("reference.conf"));
        final ActorRef myAkkaClusterClient = actorSystem.actorOf(Props.create(MyAkkaClusterClient.class), "myAkkaClusterClient");
        System.out.println("Started myAkkaClusterClient");

        final FiniteDuration interval = Duration.create(2, TimeUnit.SECONDS);
        final Timeout timeout = new Timeout(Duration.create(5, TimeUnit.SECONDS));
        final ExecutionContext ec = actorSystem.dispatcher();
        final AtomicInteger counter = new AtomicInteger();

        actorSystem.scheduler().schedule(interval, interval, new Runnable() {
            public void run() {
                ask(myAkkaClusterClient, new TransformationMessages.TransformationJob("hello-" + counter.incrementAndGet()), timeout)
                        .onSuccess(new OnSuccess<Object>() {
                            public void onSuccess(Object result) {
                                System.out.println(result.toString());
                            }
                        }, ec);
            }
        }, ec);

    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
可以看到TransformationFrontend处理的消息分为以下三种：

BACKEND_REGISTRATION：收到此消息说明有服务端通知客户端，TransformationFrontend首先将服务端的ActorRef加入backends列表，然后对服务端的ActorRef添加监管；
Terminated：由于TransformationFrontend对服务端的ActorRef添加了监管，所以当服务端进程奔溃或者重启时，将收到Terminated消息，此时TransformationFrontend将此服务端的ActorRef从backends列表中移除；
TransformationJob：此消息说明有新的转换任务需要TransformationFrontend处理，处理分两种情况：
backends列表为空，则向发送此任务的发送者返回JobFailed消息，并告知“目前没有服务端可用，请稍后再试”；
backends列表不为空，则通过取模运算选出一个服务端，将TransformationJob转发给服务端进一步处理；
运行结果

启动3个服务端，2个客户端
服务端2551输出：

[INFO] [01/18/2017 17:01:57.167] [akkaClusterTest-akka.actor.default-dispatcher-20] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-4
[INFO] [01/18/2017 17:02:02.438] [akkaClusterTest-akka.actor.default-dispatcher-20] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-4
[INFO] [01/18/2017 17:02:03.124] [akkaClusterTest-akka.actor.default-dispatcher-3] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-7
[INFO] [01/18/2017 17:02:08.416] [akkaClusterTest-akka.actor.default-dispatcher-20] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-7
[INFO] [01/18/2017 17:02:09.137] [akkaClusterTest-akka.actor.default-dispatcher-18] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-10
[INFO] [01/18/2017 17:02:14.414] [akkaClusterTest-akka.actor.default-dispatcher-17] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-10
[WARN] [01/18/2017 17:02:15.104] [akkaClusterTest-akka.remote.default-remote-dispatcher-6]
[INFO] [01/18/2017 17:02:15.204] [akkaClusterTest-akka.actor.default-dispatcher-17] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-13
1
2
3
4
5
6
7
8
服务端2552输出：

[INFO] [01/18/2017 17:01:53.178] [akkaClusterTest-akka.actor.default-dispatcher-5] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-2
[INFO] [01/18/2017 17:01:59.125] [akkaClusterTest-akka.actor.default-dispatcher-22] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-5
[INFO] [01/18/2017 17:02:00.433] [akkaClusterTest-akka.actor.default-dispatcher-17] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-3
[INFO] [01/18/2017 17:02:05.126] [akkaClusterTest-akka.actor.default-dispatcher-6] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-8
[INFO] [01/18/2017 17:02:06.427] [akkaClusterTest-akka.actor.default-dispatcher-17] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-6
[INFO] [01/18/2017 17:02:11.130] [akkaClusterTest-akka.actor.default-dispatcher-5] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-11
[INFO] [01/18/2017 17:02:12.420] [akkaClusterTest-akka.actor.default-dispatcher-17] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-9
[WARN] [01/18/2017 17:02:15.053] [akkaClusterTest-akka.remote.default-remote-dispatcher-7]
[INFO] [01/18/2017 17:02:17.123] [akkaClusterTest-akka.actor.default-dispatcher-16] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-14
1
2
3
4
5
6
7
8
9
10
服务端2553输出：

[INFO] [01/18/2017 17:01:55.144] [akkaClusterTest-akka.actor.default-dispatcher-20] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-3
[INFO] [01/18/2017 17:01:58.428] [akkaClusterTest-akka.actor.default-dispatcher-4] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-2
[INFO] [01/18/2017 17:02:01.130] [akkaClusterTest-akka.actor.default-dispatcher-16] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-6
[INFO] [01/18/2017 17:02:04.413] [akkaClusterTest-akka.actor.default-dispatcher-16] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-5
[INFO] [01/18/2017 17:02:07.141] [akkaClusterTest-akka.actor.default-dispatcher-5] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-9
[INFO] [01/18/2017 17:02:10.413] [akkaClusterTest-akka.actor.default-dispatcher-18] [akka://akkaClusterTest/user/myAkkaClusterServer] hello.2555-8
[INFO] [01/18/2017 17:02:13.128] [akkaClusterTest-akka.actor.default-dispatcher-18] [akka://akkaClusterTest/user/myAkkaClusterServer] hello-12
1
2
3
4
5
6
7
客户端2554输出

JobFailed(Service unavailable, try again later)
TransformationResult(HELLO-2)
TransformationResult(HELLO-3)
TransformationResult(HELLO-4)
TransformationResult(HELLO-5)
TransformationResult(HELLO-6)
TransformationResult(HELLO-7)
TransformationResult(HELLO-8)
TransformationResult(HELLO-9)
TransformationResult(HELLO-10)
TransformationResult(HELLO-11)
TransformationResult(HELLO-12)

客户端2555输出

JobFailed(Service unavailable, try again later)
TransformationResult(HELLO.2555-2)
TransformationResult(HELLO.2555-3)
TransformationResult(HELLO.2555-4)
TransformationResult(HELLO.2555-5)
TransformationResult(HELLO.2555-6)
TransformationResult(HELLO.2555-7)
TransformationResult(HELLO.2555-8)
TransformationResult(HELLO.2555-9)
TransformationResult(HELLO.2555-10)

可以发现，客户端发送的消息被服务端正确消费，并且进行了负载均衡。不过上面第一条消息由于客户端节点刚开始处理消息时，backends列表里还没有缓存好任何backend的ActorRef，所以报错JobFailed(Service unavailable, try again later)

总结

与thrift一样，使用akka需要自己进行服务的发现治理工作。但是著名的spark都完全依赖akka，所以我们在工作中是可以使用akka的。当然akka的一些概念比较困难，学习路线比较长，所以想要学会也需要一些时日，必须经过深入学习实战才可。

参考资料

==============

Akka持久化简介

Akka持久化可以使有状态的actor能够保持其内部状态，以便在启动、JVM崩溃后重新启动、或在集群中迁移时，恢复它们的内部状态。 Akka持久性关键点在于，只有对actor内部状态的更改才会被持久化，而不会直接保持其当前状态（可选快照除外）。 这些更改只会追加到存储，没有任何修改，这允许非常高的事务速率和高效的复制。 通过加载持久化的数据Stateful actors可以重建内部状态。 这可以是所有修改的完整历史记录，也可以从一个快照开始，这可以显着减少恢复时间。 Akka持久性还提供至少一次消息传递语义的点对点通信。【翻译与官方文档】

接下来将官方文档的示例运行一遍

依赖与配置

引入persistence依赖

<dependency>
    <groupId>com.typesafe.akka</groupId>
    <artifactId>akka-persistence_2.11</artifactId>
    <version>2.4.16</version>
</dependency>
1
2
3
4
5
Akka持久性扩展依赖一些内置持久性插件，包括基于内存堆的日志，基于本地文件系统的快照存储和基于LevelDB的日志。

基于LevelDB的插件将需要以下附加的依赖声明：

<dependency>
  <groupId>org.iq80.leveldb</groupId>
  <artifactId>leveldb</artifactId>
  <version>0.7</version>
</dependency>
<dependency>
  <groupId>org.fusesource.leveldbjni</groupId>
  <artifactId>leveldbjni-all</artifactId>
  <version>1.8</version>
</dependency>
1
2
3
4
5
6
7
8
9
10
不过本文没有使用leveldb。

添加配置文件

这里需要配置持久化使用到的配置信息journal

默认情况下，持久化actor或视图将使用在reference.conf配置资源的以下部分中配置的“default”日志和快照存储插件。
注意，在这种情况下，actor或视图只覆盖persistenceId方法。
当持久化actor或视图覆盖journalPluginId和snapshotPluginId方法时，actor或视图将由这些特定的持久性插件提供服务，而不是默认值。
reference.conf：

akka {
  loglevel = "INFO"
}

akka.persistence.journal.plugin = "akka.persistence.journal.inmem"
# Absolute path to the default snapshot store plugin configuration entry.
akka.persistence.snapshot-store.plugin = "akka.persistence.snapshot-store.local"
1
2
3
4
5
6
7
上代码

package akka.serializable;

import akka.actor.UntypedActor;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import akka.persistence.SnapshotOffer;
import akka.persistence.UntypedPersistentActor;
import com.alibaba.fastjson.JSON;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.UUID;

import static java.util.Arrays.asList;

class Cmd implements Serializable {
    private static final long serialVersionUID = 1L;
    private final String data;

    public Cmd(String data) {
        this.data = data;
    }

    public String getData() {
        return data;
    }
}

class Evt implements Serializable {
    private static final long serialVersionUID = 1L;
    private final String data;
    private final String uuid;

    public Evt(String data, String uuid) {
        this.data = data;
        this.uuid = uuid;
    }

    public String getUuid() {
        return uuid;
    }

    public String getData() {
        return data;
    }
}

class ExampleState implements Serializable {
    private static final long serialVersionUID = 1L;
    private final ArrayList<String> events;

    public ExampleState() {
        this(new ArrayList<String>());
    }

    public ExampleState(ArrayList<String> events) {
        this.events = events;
    }

    public ExampleState copy() {
        return new ExampleState(new ArrayList<String>(events));
    }

    public void update(Evt evt) {
        events.add(evt.getData());
    }

    public int size() {
        return events.size();
    }

    @Override
    public String toString() {
        return events.toString();
    }
}

class ExamplePersistentActor extends UntypedPersistentActor {

    LoggingAdapter log = Logging.getLogger(getContext().system (), this );

    @Override
    public String persistenceId() { return "sample-id-1"; }

    private ExampleState state = new ExampleState();

    public int getNumEvents() {
        return state.size();
    }

    /**
     * Called on restart. Loads from Snapshot first, and then replays Journal Events to update state.
     * @param msg
     */
    @Override
    public void onReceiveRecover(Object msg) {
        log.info("onReceiveRecover: " + JSON.toJSONString(msg));
        if (msg instanceof Evt) {
            log.info("onReceiveRecover -- msg instanceof Event");
            log.info("event --- " + ((Evt) msg).getData());
            state.update((Evt) msg);
        } else if (msg instanceof SnapshotOffer) {
            log.info("onReceiveRecover -- msg instanceof SnapshotOffer");
            state = (ExampleState)((SnapshotOffer)msg).snapshot();
        } else {
          unhandled(msg);
        }
    }

    /**
     * Called on Command dispatch
     * @param msg
     */
    @Override
    public void onReceiveCommand(Object msg) {
        log.info("onReceiveCommand: " + JSON.toJSONString(msg));
        if (msg instanceof Cmd) {
            final String data = ((Cmd)msg).getData();

            // generate an event we will persist after being enriched with a uuid
            final Evt evt1 = new Evt(data + "-" + getNumEvents(), UUID.randomUUID().toString());
            final Evt evt2 = new Evt(data + "-" + (getNumEvents() + 1), UUID.randomUUID().toString());

            // persist event and THEN update the state of the processor
            persistAll(asList(evt1, evt2), evt -> {
                state.update(evt);
                if (evt.equals(evt2)) {
                    // broadcast event on eventstream 发布该事件
                    getContext().system().eventStream().publish(evt);
                }
            });
        } else if (msg.equals("snap")) {
            // IMPORTANT: create a copy of snapshot
            // because ExampleState is mutable !!!
            saveSnapshot(state.copy());
        } else if (msg.equals("print")) {
            System.out.println("state:  " + state);
        } else {
          unhandled(msg);
        }
    }
}

class EventHandler extends UntypedActor {


    LoggingAdapter log = Logging.getLogger(getContext().system(), this);

    @Override
    public void onReceive(Object msg ) throws Exception {
        log.info( "Handled Event: " + JSON.toJSONString(msg));
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
main方法

package akka.serializable;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.Props;


public class MainTest {

  public static final Logger log = LoggerFactory.getLogger(System.class);

  public static void main(String... args) throws Exception {

    final ActorSystem actorSystem = ActorSystem.create("actor-server");

    final ActorRef handler = actorSystem.actorOf(Props.create(EventHandler. class));
    // 订阅
    actorSystem.eventStream().subscribe(handler , Evt.class);

    Thread.sleep(5000);

    final ActorRef actorRef = actorSystem.actorOf(Props.create(ExamplePersistentActor. class), "eventsourcing-processor" );

    actorRef.tell( new Cmd("CMD 1" ), null);
    actorRef.tell( new Cmd("CMD 2" ), null);
    actorRef.tell( new Cmd("CMD 3" ), null);
    actorRef.tell( "snap", null );//发送保存快照命令
    actorRef.tell( new Cmd("CMD 4" ), null);
    actorRef.tell( new Cmd("CMD 5" ), null);
    actorRef.tell( "print", null );

    Thread.sleep(5000);

    log.info( "Actor System Shutdown Starting..." );

    actorSystem.shutdown();
  }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
运行结果：

[INFO] [01/17/2017 16:16:02.526] [actor-server-akka.actor.default-dispatcher-5] [akka://actor-server/user/eventsourcing-processor] onReceiveRecover: {}
[INFO] [01/17/2017 16:16:02.526] [actor-server-akka.actor.default-dispatcher-5] [akka://actor-server/user/eventsourcing-processor] onReceiveRecover -- msg instanceof SnapshotOffer
[INFO] [01/17/2017 16:16:02.560] [actor-server-akka.actor.default-dispatcher-5] [akka://actor-server/user/eventsourcing-processor] onReceiveRecover: {"instance":{"$ref":"@"}}
[INFO] [01/17/2017 16:16:02.565] [actor-server-akka.actor.default-dispatcher-5] [akka://actor-server/user/eventsourcing-processor] onReceiveCommand: {"data":"CMD 1"}
[INFO] [01/17/2017 16:16:02.591] [actor-server-akka.actor.default-dispatcher-5] [akka://actor-server/user/eventsourcing-processor] onReceiveCommand: {"data":"CMD 2"}
[INFO] [01/17/2017 16:16:02.592] [actor-server-akka.actor.default-dispatcher-6] [akka://actor-server/user/eventsourcing-processor] onReceiveCommand: {"data":"CMD 3"}
[INFO] [01/17/2017 16:16:02.593] [actor-server-akka.actor.default-dispatcher-8] [akka://actor-server/user/$a] Handled Event: {"data":"CMD 1-37","uuid":"fe0fca08-a415-425d-b618-c730b117ca7d"}
[INFO] [01/17/2017 16:16:02.594] [actor-server-akka.actor.default-dispatcher-6] [akka://actor-server/user/eventsourcing-processor] onReceiveCommand: "snap"
[INFO] [01/17/2017 16:16:02.595] [actor-server-akka.actor.default-dispatcher-8] [akka://actor-server/user/$a] Handled Event: {"data":"CMD 2-39","uuid":"76fbf9e8-befd-40f4-a4fe-49b5698c7c7d"}
[INFO] [01/17/2017 16:16:02.595] [actor-server-akka.actor.default-dispatcher-8] [akka://actor-server/user/$a] Handled Event: {"data":"CMD 3-41","uuid":"3b9f70c2-83c5-47d3-9f0a-4710905c3cfe"}
[INFO] [01/17/2017 16:16:02.595] [actor-server-akka.actor.default-dispatcher-6] [akka://actor-server/user/eventsourcing-processor] onReceiveCommand: {"data":"CMD 4"}
[INFO] [01/17/2017 16:16:02.596] [actor-server-akka.actor.default-dispatcher-5] [akka://actor-server/user/$a] Handled Event: {"data":"CMD 4-43","uuid":"f8bb1e7e-716e-4f3c-9d81-e4570e0501c0"}
[INFO] [01/17/2017 16:16:02.596] [actor-server-akka.actor.default-dispatcher-8] [akka://actor-server/user/eventsourcing-processor] onReceiveCommand: {"data":"CMD 5"}
[INFO] [01/17/2017 16:16:02.597] [actor-server-akka.actor.default-dispatcher-5] [akka://actor-server/user/$a] Handled Event: {"data":"CMD 5-45","uuid":"574f9cdf-59f3-421c-8337-df8a50c95ee6"}
state:  [CMD 1-0, CMD 1-1, CMD 2-2, CMD 2-3, CMD 3-4, CMD 3-5, CMD 1-6, CMD 1-7, CMD 2-8, CMD 2-9, CMD 3-10, CMD 3-11, CMD 1-12, CMD 1-13, CMD 2-14, CMD 2-15, CMD 3-16, CMD 3-17, CMD 1-18, CMD 1-19, CMD 2-20, CMD 2-21, CMD 3-22, CMD 3-23, CMD 1-24, CMD 1-25, CMD 2-26, CMD 2-27, CMD 3-28, CMD 3-29, CMD 1-30, CMD 1-31, CMD 2-32, CMD 2-33, CMD 3-34, CMD 3-35, CMD 1-36, CMD 1-37, CMD 2-38, CMD 2-39, CMD 3-40, CMD 3-41, CMD 4-42, CMD 4-43, CMD 5-44, CMD 5-45]
[INFO] [01/17/2017 16:16:02.598] [actor-server-akka.actor.default-dispatcher-8] [akka://actor-server/user/eventsourcing-processor] onReceiveCommand: "print"
[INFO] [01/17/2017 16:16:02.613] [actor-server-akka.actor.default-dispatcher-15] [akka://actor-server/user/eventsourcing-processor] onReceiveCommand: {}
2017-01-17 16:16:06.835 [main            ] INFO  System                  - Actor System Shutdown Starting...

Process finished with exit code 0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
这里注意：如果再次执行该程序，系统会首先恢复上次处理器的状态。本程序中会首先恢复快照中的状态然后是其他的状态。
快照使得处理器的状态持久化更加高效。
假如现在运行结果是酱紫的：
state:  [
CMD 1-0, CMD 1-1,
CMD 2-2, CMD 2-3,
CMD 3-4, CMD 3-5,

CMD 1-6, CMD 1-7,
CMD 2-8, CMD 2-9,
CMD 3-10, CMD 3-11,
CMD 4-12, CMD 4-13,
CMD 5-14, CMD 5-15]

在运行一次，结果就是酱紫的：

state:  [
CMD 1-0, CMD 1-1,
CMD 2-2, CMD 2-3,
CMD 3-4, CMD 3-5,

CMD 1-6, CMD 1-7,
CMD 2-8, CMD 2-9,
CMD 3-10, CMD 3-11,

CMD 1-12, CMD 1-13,
CMD 2-14, CMD 2-15,
CMD 3-16, CMD 3-17,
CMD 4-18, CMD 4-19,
CMD 5-20, CMD 5-21]
由于我们采用的是默认的持久化策略，会持久化到本地磁盘，进入项目统计目录下，会看到文件夹snapshots:
这里写图片描述

参考资料

书籍《java高并发程序设计》
AKKA官方文档


==========
CHILD ACTORS与ACTORPATH -6


Actor是完全的继承结构。你创建的任何Actor肯定都是一个其他Actor的child。
让我们分析下：

PATH
我们用ActorSystem.actorof创建一个ActorRef并打印出他的path

val actorSystem=ActorSystem("SupervisionActorSystem")
val actorRef=actorSystem.actorOf(Props[BasicLifecycleLoggingTeacherActor])
println (actorRef.path) // (prints) akka://SupervisionActorSystem/user/$a
可以看到，一个path看起来很像是文件系统中的一个文件路径。

这里的akka是固定的，因为这些都是Akka Actor的地址 - 与**file://**和**http://**前缀差不多（跟协议没啥关系）

SupervisionActorSystem就是你创建的ActorSystem的名字。

user我们下节再说。

$a是系统为你生成出来的Actor的名字。你对操作系统给你随机生成的文件名怎么看？很明显是人都不喜欢，因为你之后还要用这个名字。所以，让我们给他一个有意义的名字：

val actorRef=actorSystem.actorOf(Props[BasicLifecycleLoggingTeacherActor], "teacherActor")
println (actorRef.path)     // (prints) akka://SupervisionActorSystem/user/teacherActor
现在这个路径（path）看起来差不多了。


CHILD ACTORS
跟从ActorSystem里面创建的顶级actor类似，我们也可以给ActorContext创建child actor。事实上， Actor的容错能力很大程度上就是靠使用Actor的继承层次和一个parent管理child actor的生命周期的方式。

现在假设你又一个TeacherSupervisor并且你打算创建一个TeacherActor来作为Supervisor的child，可以用ActorContext.actorof来代替使用ActorSystem.actorof:

class TeacherSupervisor extends Actor with ActorLogging {
  val teacherActor=context.actorOf(Props[TeacherActor], "teacherActor")
...
...
基本上，在任何应用里，不像顶层actor，你会创建一堆的child actor - 这意思就是与调用actorSystem.actorof不同，你会调用一堆actorContext.actor


你会注意到child actor的path是akka://SupervisionActorSystem/user/teacherSupervisor/teacherActor，看起来跟给父目录创建一个子目录是一样的。

你什么时候开始创建子Actor？

在你的任务是由子任务或多个子任务组成的时候你就应该创建一个子actor了。在你执行的子任务是一个易错的时候，你想要隔离他（这样如果错了，你能恢复他）的时候你也需要创建一个子actor。当task之间没有父子关系时，你千万别创建子actor。

并且，还可以让子actor创建自己的子actor来代理他们自己的子任务。Actor的创建成本很低但产出却很高（我们在谈supervision的时候可以看到这个）

现在那个PATH中的USER是什么？
作为一个对比，我把ActorSystem比拟成一个Unix文件系统 - 有一个/root目录，还有其他的/etc,/usr,/bin和其他目录。

ActorSystem跟那个差不多。他创建一些顶层Actor - 最重要根Actor就是根目录/， user Actor就是/usrr目录，一个system Actor就是一个/system目录。（还有一个/deadLetters来代表DeadLetterActorRef。我们在上一篇里面看到过）

ActorSystem内组合了三个Actor（从ActorRefProvider）。他们是ActorSystem创建的所有actor的根actor。

systemGuardian actor - 所有在/system下的actor的根
guardian actor - 所有/user下actor的根
rootGuardian Actor - systemGuardian和userGuardianactor
的根
  /**
   * Reference to the supervisor of guardian and systemGuardian; ....
   */
  def rootGuardian: InternalActorRef

  /**
   * Reference to the supervisor used for all top-level user actors.
   */
  def guardian: LocalActorRef

  /**
   * Reference to the supervisor used for all top-level system actors.
   */
  def systemGuardian: LocalActorRef


/user(aka) user guardian

任何你在自己程序中像StudentActor或TeacherActor用ActorSystem的actof方法来创建的Actor都直接在/user。这就是之前teacherActor的路径是/user/teacherActor的原因。

/system(aka) system guardian

当userGuardian死的时候system guardian会将自己关闭。当userGuardian关闭时这是合乎常理的， 他下面所有的业务actor都停掉了所以所有的管理员actor都需要一样停掉。

我们能看到System Actor被创建在两个地方 - 意思是在**/system*继承关系下的actor。

像我们之前看到的，所有发给一个已经终结掉的Actor的消息都会被转发给一个内部Actor（DeadLetterActor）的邮箱。DeadLetter Actor把每个消息包装成**DeadLetter*然后发送给EventStream。另一个叫DeadLetterListener的Actor消费所有的DeadLetter并且将其作为一个日志消息发送出去。现在，DeadLetterListener是一个在/system/deadLetterListener下的system Actor。

想想我们之前写的订阅了EventStream的日志消息的TestEventListener?他们也是System actor。事实上，所有的akka.logger都是作为System actor来创建的。

class TeacherTest extends TestKit(ActorSystem("UniversityMessageSystem", ConfigFactory.parseString("""akka.loggers = ["akka.testkit.TestEventListener"]""")))
...
...
这个文档提到所有用配置文件配置的Actor都会在启动的时候被创建并部署到ActorSystem，躲在/system的保护伞下。当我找到有趣的地方再更新下这个。

/(aka)root guardian
像我们之前看到的，/下的Actor是user和system guardian的父 actor。

杂七杂八
技术上来讲，root actor也有个父actor。这个actor的唯一任务就是当root actor失败是关闭整个ActorSystem。因此他没有被算在Actor的继承结构里， Akka项目组叫他：

  private[akka] val theOneWhoWalksTheBubblesOfSpaceTime: InternalActorRef = new MinimalActorRef {

==========
hello-world

本示例来自于官方示例（http://doc.akka.io/docs/akka/2.4.4/intro/getting-started.html）：
文中找到 Using Akka with Maven 。点击“Akka Main in Java”下载示例。

http://www.lightbend.com/activator/template/akka-sample-main-java

注意：新版本的akka需要使用jdk8
里面有两个Actor：

package sample.hello;

import akka.actor.Props;
import akka.actor.UntypedActor;
import akka.actor.ActorRef;

public class HelloWorld extends UntypedActor {

  @Override
  public void preStart() {
    // create the greeter actor
    final ActorRef greeter = getContext().actorOf(Props.create(Greeter.class), "greeter");
    // tell it to perform the greeting
    greeter.tell(Greeter.Msg.GREET, getSelf());
  }

  @Override
  public void onReceive(Object msg) {
    if (msg == Greeter.Msg.DONE) {
      // when the greeter is done, stop this actor and with it the application
      getContext().stop(getSelf());
    } else
      unhandled(msg);
  }
}
package sample.hello;

import akka.actor.UntypedActor;

public class Greeter extends UntypedActor {

  public static enum Msg {
    GREET, DONE;
  }

  @Override
  public void onReceive(Object msg) throws InterruptedException {
    if (msg == Msg.GREET) {
      System.out.println("Hello World!");
      Thread.sleep(1000);
      getSender().tell(Msg.DONE, getSelf());
    } else
      unhandled(msg);
  }

}
main方法

package sample.hello;

public class Main {

  public static void main(String[] args) {
    akka.Main.main(new String[] { HelloWorld.class.getName() });
  }
}
另一种main写法，通过创建actor的方式

 public static void main(String[] args) {
    ActorSystem system = ActorSystem.create("Hello");
    ActorRef a = system.actorOf(Props.create(HelloWorld.class), "helloWorld");
    System.out.println(a.path());
  }

--------------------

inbox消息收件箱



LOGGING与测试ACTORS -2
3.THROW IN A LOGBACK.XML
现在我们把SLF4J日志配置在logback。

<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <appender name="FILE"
        class="ch.qos.logback.core.rolling.RollingFileAppender">
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>

        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs\akka.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>50MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
    </appender>

    <root level="DEBUG">
        <appender-ref ref="FILE" />
    </root>
</configuration>
我们把这个放在跟application.conf一样的位置， main/resources。 请保证main/resources在你的eclipse或其他IDE的classpath中。并且把logback和slf4j-api放到你的build.sbt文件里。

当我们启动StudentSimulatorApp并发了一条消息给我们的新TeacherLogActor,我们配置的输出日志文件akkaxxxxx.log文件是这样的。



测试AKKA
我们这里并无意进行一个详尽的Akka覆盖测试。我们会在下面增加新特性的时候进行测试。这些测试用例主要是用来覆盖我们之前写的Actors代码。

当StudentSimulatorApp做了我们想要的，

想摆脱测试之痛， Akka带了一套很牛的测试工具能让我们做一些很神奇的事情，例如让你的测试代码直接进入到Actor的内部实现里。

说的差不多了，让我们看下测试用例。

让我们先将StudentSimulatorApp映射到一个测试用例（Testcase）上。



让我们看一下代码的声明：

class TeacherPreTest extends TestKit(ActorSystem("UniversityMessageSystem"))
  with WordSpecLike
  with MustMatchers
  with BeforeAndAfterAll {
所以，从TestCase的用例定义我们可以看到：

1.TestKit从ActorSystem接受一个我们要创建的Actors.在内部，TestKit装饰了ActorSystem并且替换了缺省的分发者（dispatcher）。
2.我们在写ScalaTest的测试用例时会使用WordSpec,它可以用许多有趣的方式驱邪。
3.MustMatchers提供便利的方法让测试写起来像自然语言。
4.我们把BeforeAndAfterAll加进来是因为它可以在测试用例结束后关掉ActorSystem。afterAll方法提供的特性很像JUnit中的tearDown方法。

1，2 - 发送消息给ACTORS
1)在第一个测试用例时我们发送了一个消息给PrintActor。但并没有断言什么东西 :-(

2)在第二个例子中我们发了一个消息给日志actor，它用一个ActorLogging发送消息给EventStream。这块也没做任何断言 :-(

  //1. Sends message to the Print Actor. Not even a testcase actually
  "A teacher" must {

    "print a quote when a QuoteRequest message is sent" in {

      val teacherRef = TestActorRef[TeacherActor]
      teacherRef ! QuoteRequest
    }
  }

  //2. Sends message to the Log Actor. Again, not a testcase per se
  "A teacher with ActorLogging" must {

    "log a quote when a QuoteRequest message is sent" in {

      val teacherRef = TestActorRef[TeacherLogActor]
      teacherRef ! QuoteRequest
    }
3-断言（ASSERTING）ACTORS的内部状态
第三个例子用TestActorRef的underlyingActor方法去调用TeacherActor的quoteList。quoteList方法返回格言（quoteList）的列表。我们用这个列表来断言它的size。

如果说到quoteList会比较晕，可以看下TeacherLogActor的代码

//From TeacherLogActor
//We'll cover the purpose of this method in the Testing section
  def quoteList=quotes
    //3. Asserts the internal State of the Log Actor.
    "have a quote list of size 4" in {

      val teacherRef = TestActorRef[TeacherLogActor]
      teacherRef.underlyingActor.quoteList must have size (4)
      teacherRef.underlyingActor.quoteList must have size (4)
    }
4 - 断言日志消息
我们之前讨论过EventStream和Logging,所有的log消息都会发送到EventStream然后SLF4JLogger订阅了这些消息并将其写到日志文件或控制台等。如果让我们的测试用例订阅EventStream并直接断言log消息不是更妙？看起来值得一试。

这需要两步：

1）你需要给TestKit增加一个额外的配置：

class TeacherTest extends TestKit(ActorSystem("UniversityMessageSystem", ConfigFactory.parseString("""akka.loggers = ["akka.testkit.TestEventListener"]""")))
  with WordSpecLike
  with MustMatchers
  with BeforeAndAfterAll {
2)现在我们订阅了EventStream，我们可以在我们的用例中断言：

 //4. Verifying log messages from eventStream
    "be verifiable via EventFilter in response to a QuoteRequest that is sent" in {

      val teacherRef = TestActorRef[TeacherLogActor]
      EventFilter.info(pattern = "QuoteResponse*", occurrences = 1) intercept {
        teacherRef ! QuoteRequest
      }
    }
EventFilter.info这块代码拦截了一条以QuoteResponse(pattern='QuoteResponse* )开头的消息。（如果用start=‘QuoteResponse'也一样能拦截到）。日过没有一条日志消息发送给TeacherLogActor，这个测试用例就会失败。

5 - 用构造函数参数测试ACTORS
请注意我们在用例中创建Actors时是用TestActorRef[TeacherLogActor]而不是用system.actorOf。这是因为我们可以通过TeacherActorRef的underlyingActor方法来进入Actor的内部。我们用ActorRef是不可能在常规运行时环境达到这个效果。（这不是我们在生产环境使用TestActorRef的理由，千万别）。

如果Actor能接受参数，那么我们创建TestActorRef时就会是这样：

val teacherRef = TestActorRef(new TeacherLogParameterActor(quotes))
整个的测试用例就会像这样：

//5. have a quote list of the same size as the input parameter
    " have a quote list of the same size as the input parameter" in {

      val quotes = List(
        "Moderation is for cowards",
        "Anything worth doing is worth overdoing",
        "The trouble is you think you have time",
        "You never gonna know if you never even try")

      val teacherRef = TestActorRef(new TeacherLogParameterActor(quotes))
      //val teacherRef = TestActorRef(Props(new TeacherLogParameterActor(quotes)))

      teacherRef.underlyingActor.quoteList must have size (4)
      EventFilter.info(pattern = "QuoteResponse*", occurrences = 1) intercept {
        teacherRef ! QuoteRequest
      }
    }
关闭ACTORSYSTEM
最后，afterAll生命周期方法

override def afterAll() {
    super.afterAll()
    system.shutdown()
  }
CODE 代码
跟往常一样，整个项目可以在github这里下载。

==============
Router

  简单来说Akka是一个用于构建服务端分布式应用的框架，其具有高并发、可扩展、容错性等特点。Akka中的基本单位是Actor，Actor可以与线程来作为类比，有自己的标识符、存储空间、调度策略、生命周期等。每个Actor相互之间的交互都是通过消息(可以是字符串、二进制数据、自定义对象等)来实现的，这样就避免了每个Actor的耦合。更重要的是生成一个Actor只占用40多个字节的存储空间(我自己测试的是50字节左右)，1G内存的情况下，可以生成250w个Actor！其并发性能超强悍~~~
     Akka官方文档:http://akka.io/docs/
      背景知识简要介绍完了，本篇的主题是怎样实现Akka文档中介绍的router
      router即路由，消息传递到router后，router根据响应的策略将消息下发到其所管理的routees, routees可以看做是一系列Actor的集合，每个Actor当然既可以是本地的Actor也    可以是远程的Actor。本文将给出本地和远程的两种测试实例。
准备工作:
   开发环境:ItelliJ IDEA
   工程类型:Maven
1.工程目录结构



2.Maven 配置文件
[plain] view plain copy
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.akka.route</groupId>
    <artifactId>akka</artifactId>
    <version>1.0-SNAPSHOT</version>
    <name>${project.artifactId}-${project.version}</name>

    <repositories>
        <repository>
            <id>akka-snapshots</id>
            <name>Akka Snapshots</name>
            <url>http://repo.akka.io/snapshots/</url>
            <layout>default</layout>
        </repository>
    </repositories>

    <dependencies>
        <dependency>
            <groupId>com.typesafe.akka</groupId>
            <artifactId>akka-actor_2.11</artifactId>
            <!--Must be 2.2-SNAPSHOT-->
            <version>2.3.12</version>
        </dependency>
        <dependency>
            <groupId>com.typesafe.akka</groupId>
            <artifactId>akka-remote_2.11</artifactId>
            <version>2.3.12</version>
        </dependency>
        <dependency>
            <groupId>org.apache.maven.archetypes</groupId>
            <artifactId>maven-archetype-quickstart</artifactId>
            <version>1.1</version>
        </dependency>

    </dependencies>

</project>


此项目中用到的akka版本是2.3.12，对应的远程模块remote版本也是2.3.12

3.akka配置文件 application.conf
[plain] view plain copy
# akka 2.3
LocalSys{
  akka {
    actor {
      provider = "akka.remote.RemoteActorRefProvider"

      deployment {
        /router1{
          router = round-robin-pool
          nr-of-instances = 5

        }

        /router3{
          router = random-group
          routees.paths = [
            #set the remote actor path
            "akka.tcp://RemoteNodeApp@192.168.86.129:2552/user/remoteActor",
            #set the localhost actor path
            "akka.tcp://RemoteNodeApp@127.0.0.1:2552/user/remoteActor"
          ]
        }

      }
    }
  }
}

Akka的配置文件很复杂，此处只给出了需要的配置。

3.Main 程序
[plain] view plain copy
import akka.actor.*;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import com.typesafe.config.ConfigFactory;

/**
 * Created by rootigo on 2016/7/28.
 */
public class Main {
   /**For a remote akka project ,the top system must be set once,otherwise it will cause "Address already in use" exception,
   *The akka use default port 2552
   */
    public static ActorSystem _system = ActorSystem.create("parent", ConfigFactory
            .load().getConfig("LocalSys"));
    public static void main(String[] args) throws InterruptedException {
       ActorRef masterRef =
               _system.actorOf(Props.create(Master.class),"Master");
       for(int i = 0 ;i < 10;i ++) {
           int payload = i * 10;
           masterRef.tell(new Work(""+payload+""), null);
           Thread.sleep(1000 * 2);
       }


   }

}


Main是此项目的启动程序，先根据配置文件application.conf创建ActorSystem,后面由此system创建的Actor都在此system根路径之下，即/parent/user/some_actor

4.Work文件
[java] view plain copy
import java.io.Serializable;
import java.util.Arrays;
import java.util.List;

import akka.actor.*;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import akka.routing.*;
import com.typesafe.config.ConfigFactory;


public final class Work implements Serializable{
    private static final long serialVersionUID = 1L;
    public String payload;
    public Work(String payload){
        this.payload = payload;
    }
}
     /** Route Logic
       * RoundRobinRoutingLogic
       * RandomRoutingLogic
       * SmallestMailboxRoutingLogic
       * BroadcastRoutingLogic
       * ScatterGatherFirstCompletedRoutingLogic
       * TailChoppingRoutingLogic
       * ConsistentHashRoutingLogic
       * */
class Master extends UntypedActor {
    LoggingAdapter log = Logging.getLogger(getContext().system(), this);
    ActorRef getRouteeRef(){

        ActorRef workerpool = Main._system.actorOf(Props.create(Worker.class)
        );
        return workerpool;
    }
    ActorRef getRemoteRouter(String remoteAddr){

        String remoteActorAddr = String.format("akka.tcp://RemoteNodeApp@%s/user/remoteActor",remoteAddr);
        ActorRef routerRemote = getContext().actorFor(remoteActorAddr);
        return routerRemote;

    }
    ActorRef getRoundRobinPoolRef(){
        //Props.create(Worker.class) means create a Worker actor
        ActorRef routerRef = Main._system.actorOf(FromConfig.getInstance().props(Props.create(Worker.class)),"router1");
        System.out.printf("RoundRobinGroup actor path is:{%s}\n",routerRef.path());
        return routerRef;
    }
    ActorRef getRoundRobinGroupRefByCoding(){
        //Before using RoundRobinGroup(paths) to router w1,w2,w3,this three actors must be created
        Main._system.actorOf(Props.create(Worker.class),"w1");
        Main._system.actorOf(Props.create(Worker.class),"w2");
        Main._system.actorOf(Props.create(Worker.class),"w3");

        ///Round-robin-Group by program code
        List<String> paths = Arrays.asList("/user/w1", "/user/w2",
                "/user/w3");
        ActorRef routerRef = Main._system.actorOf(new RoundRobinGroup(paths).props(), "router2");
        ActorRef w1 = Main._system.actorFor("/user/w1");
        ActorRef w2 = Main._system.actorFor("/user/w2");
        ActorRef w3 = Main._system.actorFor("/user/w3");
        System.out.printf("W1 path:{%s,%s},W2 path:{%s,%s},W3 path:{%s,%s}\n",
                w1.path(),w1.isTerminated(),w2.path(),w2.isTerminated(),w3.path(),w3.isTerminated());
         /// Round-robin-group
         System.out.printf("RoundRobinGroup actor path is:{%s}\n",routerRef.path());
         return routerRef;

    }
    ActorRef getRoundRobinGroupRefByConfigureFile(){
        //router the remote actor as routees,make sure that the remote actors must be running
        ActorRef routerRef = Main._system.actorOf(FromConfig.getInstance().props(),"router3");
        System.out.printf("RoundRobinGroup actor path is:{%s}\n",routerRef.path());
        return routerRef;
    }
    void addRouteeProgramtically(List<Routee> routees){
        for(int i = 0 ;i < 5;i++){
            // ActorRef r = getContext().actorOf(Props.create(Worker.class),"Worker" + i);
            String remoteAddr = "192.168.86.129:2552";
            if(i % 2 ==0){
                remoteAddr = "127.0.0.1:2552";
            }
            ActorRef r = getRemoteRouter(remoteAddr);
            System.out.printf("{%s} path is {%s}\n",i,r.path());
            getContext().watch(r);
            routees.add(new ActorRefRoutee(r));
        }

    }
    //1.Use router and routees to router the message
    Router router ;
    /*
    {
        List<Routee> routees = new ArrayList<Routee>();
        ActorRef r = getRoundRobinGroupRefByConfigureFile();
        getContext().watch(r);
        routees.add(new ActorRefRoutee(r));
        router = new Router(new RoundRobinRoutingLogic(),routees);
    }
    */
    //2.Use the RoundRobinGroup or RoundRobinPool to get the router
    ActorPath routerPath =  getRoundRobinGroupRefByConfigureFile().path();
    public void onReceive(Object msg){
        ActorRef sender = getSender();
        if(msg instanceof String){
            log.info("Msg From Sender[{}]:{}\n",sender.path(),msg);
        }
        else if(msg instanceof Work){
            log.info("[{}]Send Forward Message:'{}' to router \n" ,getSelf().path(), ((Work) msg).payload,routerPath);
            /*
            //Sending messages via the router,the sender is the router iteself
            router.route(((Work) msg).payload,getSelf());
            */
            ActorSelection selection = getContext().actorSelection(routerPath);
            selection.tell(((Work) msg).payload,getSelf());

        } else if(msg instanceof Terminated){
            router = router.removeRoutee(((Terminated)msg).actor());
            ActorRef r = getContext().actorOf(Props.create(Worker.class));
            getContext().watch(r);
            router = router.addRoutee(new ActorRefRoutee(r));
        }
    }


}

需要强调的是，在用RoundRobinGroup(和其他Group)获取作为router的Actor时，一定要保证routees.path中涉及的远程Actor已经存在，否则消息无法正确传递。
方法getRoundRobinGroupByCoding()中的/user/w1,/user/w2,/user/w3三个Actor要提前创建。
从代码中可以看出，创建Router有两种方法，一种是通过向Router中逐个添加routee，另外一种就是用RoundRobinGroup或者RoudRobinPool来创建Router的ActorRef。

5.Worker文件
[java] view plain copy
import akka.actor.ActorPath;
import akka.actor.UntypedActor;
import akka.event.Logging;
import akka.event.LoggingAdapter;

public class Worker extends UntypedActor {
    LoggingAdapter log = Logging.getLogger(getContext().system(), this);
    @Override
    public void onReceive(Object msg){
        ActorPath path = getSender().path();
        ActorPath myself = getSelf().path();
        if(msg instanceof  Work){
            String payload = ((Work)msg).payload;
            log.info("Receive Work({}) From :{}",payload,path);
        } else if(msg instanceof  String){
            log.info("Receive message:{} From :{}",msg,path);
        }

    }
}



最后，还需要一个远程的服务端RemoteNodeApp，不再列出，下面给出附件，自行下载。
http://download.csdn.net/detail/igoqhb/9590561


===========
Spring与Akka的集成

   近年来随着Spark的火热，Spark本身使用的开发语言Scala、用到的分布式内存文件系统Tachyon（现已更名为Alluxio）以及基于

   由于历史原因，

   很多Web系统在开发分布式服务时

   首先会选择RMI(Remote Method Invoke ,远程方法调用)、RPC(Remote Procedure Call Protocol,远程过程调用)或者使用JMS（Java Messaging Service,Java消息服务）。

   但是使用RMI只能使用java语言，而且开发、执行效率都不高；

   RPC框架虽然可以通过匹配方法签名的方式比RMI更灵活，但是其存在调用超时、调用丢失等缺点；

   JMS方式虽然可以通过At Least Delivery Once、消息持久化等机制保证消息不会丢失，但是只能作为一种跨服务的生产者、消费者编程模型使用

   Akka不但处理了以上问题，而且还可以使用Actor作为并发编程模型，减少java多线程编程的阻塞、调度、上下文开销甚至死锁等问题

   Akka还提供了集群Sharding、流处理等功能的支持，更易于实现有限状态自动机等功能


   本文参考Akka官方使用文档，根据自身的经验和理解，提供Akka与Spring集成的方案。本文不说明Spring框架的具体使用，并从Spring已经配置完备的情况开始叙述。


Actor系统——ActorSystem

   ActorSystem是一个重量级的结构体，可以用于分配1到N个线程，所以每个应用都需要创建一个ActorSystem。通常而言，使用以


ActorSystem system = ActorSystem.create("Hello");



不过对于接入Spring而言，由IOC（Inversion of Control，控制反转）方式会更接地气，你可以这样：
   <!-- AKKA System Setup -->
<bean id="actorSystem" class="akka.actor.ActorSystem" factory-method="create" destroy-method="shutdown" scope="singleton">
<constructor-arg value="helloAkkaSystem"/>
</bean>


然后在你需要的地方依赖注入即可。

Actor编程模型

   有关Actor编程模型的具体介绍可以看我的另一篇博文——《Spark如何使用Akka实现进程、节点通信的简明介绍》，里面有更多的介绍。需要补充的是，在最新的Scala官方网站上已经决定废弃Scala自身的Actor编程模型，转而全面拥抱Akka提供的Actor编程模型。

   我们可以通过以下代码（代码片段借用了Akka官网的例子）创建一个简单的Actor例子。

   Greeter是代表问候者的Actor：
1
2
3
4
5
6
public class Greeter extends UntypedActor

 {

  public static enum Msg {
    GREET, DONE;
  }

  @Override
  public void onReceive(Object msg) {
    if (msg == Msg.GREET) {
      System.out.println("Hello World!");
      getSender().tell(Msg.DONE, getSelf());
    } else
      unhandled(msg);
  }

}
一般情况下我们的Actor都需要继承自UntypedActor，并实现其onReceive方法。onReceive用于接收消息，你可以在其中实现对消息的匹配并做不同的处理。

HelloWorld是用于向Greeter发送问候消息的访客：

public class HelloWorld extends UntypedActor {

  @Override
  public void preStart() {
    // create the greeter actor
    final ActorRef greeter = getContext().actorOf(Props.create(Greeter.class), "greeter");
    // tell it to perform the greeting
    greeter.tell(Greeter.Msg.GREET, getSelf());
  }

  @Override
  public void onReceive(Object msg) {
    if (msg == Greeter.Msg.DONE) {
      // when the greeter is done, stop this actor and with it the application
      getContext().stop(getSelf());
    } else
      unhandled(msg);
  }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
有了Actor之后，我们可以这样使用它：
ActorRef a = system.actorOf(Props.create(HelloWorld.class), "helloWorld");
在HelloWorld的preStart实现中，获取了Greeter的ActorRef（Actor的引用）并向Greeter发送了问候的消息，Greeter收到问候消息后，会先打印Hello World！，然后向HelloWorld回复完成的消息，HelloWorld得知Greeter完成了向世界问好这个伟大的任务后，就结束了自己的生命。HelloWorld的例子用编程API的方式告诉了我们如何使用Actor及发送、接收消息。为了便于描述与Spring的集成，下面再介绍一个例子。

   CountingActor（代码主体借用自Akka官网）是用于计数的Actor，见代码清单1所示。
1
2
代码清单1

@Named("CountingActor")
@Scope("prototype")
public class CountingActor extends UntypedActor {

    public static class Count {
    }

    public static class Get {
    }

    // the service that will be automatically injected
    @Resource
    private CountingService countingService;

    private int count = 0;

    @Override
    public void onReceive(Object message) throws Exception {
        if (message instanceof Count) {
            count = countingService.increment(count);
        } else if (message instanceof Get) {
            getSender().tell(count, getSelf());
        } else {
            unhandled(message);
        }
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
CountingActor用于接收Count消息进行计数，接收Get消息回复给发送者当前的计数值。CountingService是用于计数的接口，其定义如下：

public interface CountingService {

    /**
     * 计数
     * @param count
     * @return
     */
    int increment(int count);

}
1
2
3
4
5
6
7
8
9
10
CountingService的具体实现是CountingServiceImpl，其实现如下：

@Service("countingService")
public class CountingServiceImpl implements CountingService {

    private static Logger logger = LoggerFactory.getLogger(CountingServiceImpl.class);

    /*
     * (non-Javadoc)
     *
     * @see com.elong.sentosa.metadata.service.CountingService#increment(int)
     */
    @Override
    public int increment(int count) {
        logger.info("increase " + count + "by 1.");
        return count + 1;
    }

}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
CountingActor通过注解方式注入了CountingService，CountingActor的计数实际是由CountingService完成。
细心的同学可能发现了CountingActor使用了注解Named，这里为什么没有使用@Service或者@Component等注解呢？由于Akka的Actor在初始化的时候必须使用System或者Context的工厂方法actorOf创建新的Actor实例，不能使用构造器来初始化，而使用Spring的Service或者Component注解，会导致使用构造器初始化Actor，所以会抛出以下异常：
[html] view plain copy 在CODE上查看代码片派生到我的代码片
akka.actor.ActorInitializationException: You cannot create an instance of [com.elong.metadata.akka.actor.CountingActor] explicitly using the constructor (new). You have to use one of the ‘actorOf’ factory methods to create a new actor. See the documentation.
如果我们不能使用@Service或者@Component，也不能使用XML配置的方式使用（与注解一个道理），那么我们如何使用CountingActor提供的服务呢？

IndirectActorProducer接口

    IndirectActorProducer是Akka提供的Actor生成接口，从其名字我们知道Akka给我们指出了另一条道路——石头大了绕着走！通过实现IndirectActorProducer接口我们可以定制一些Actor的生成方式，与Spring集成可以这样实现它，见代码清单2所示。
1
2
代码清单2

public class SpringActorProducer implements IndirectActorProducer {
    private final ApplicationContext applicationContext;
    private final String actorBeanName;
    private final Object[] args;

    public SpringActorProducer(ApplicationContext applicationContext, String actorBeanName, Object ... args) {
        this.applicationContext = applicationContext;
        this.actorBeanName = actorBeanName;
        this.args = args;
    }

    public Actor produce() {
        return (Actor) applicationContext.getBean(actorBeanName, args);
    }

    public Class<? extends Actor> actorClass() {
        return (Class<? extends Actor>) applicationContext.getType(actorBeanName);
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
SpringActorProducer的实现主要借鉴了Akka官方文档，我这里对其作了一些扩展以便于支持构造器带有多个参数的情况。从其实现看到实际是利用了ApplicationContext提供的getBean方式实例化Actor。
这里还有两个问题：一、ApplicationContext如何获取和设置？二、如何使用SpringActorProducer生成Spring需要的Actor实例？
对于第一个问题，我们可以通过封装SpringActorProducer并实现ApplicationContextAware接口的方式获取ApplicationContext；对于第二个问题，我们知道Akka中的所有Actor实例都是以Props作为配置参数开始的，这里以SpringActorProducer为代理生成我们需要的Actor的Props。

   SpringExt实现了以上思路，见代码清单3所示。
1
2
代码清单3

@Component("springExt")
public class SpringExt implements Extension, ApplicationContextAware {

    private ApplicationContext applicationContext;

    /**
     * Create a Props for the specified actorBeanName using the
     * SpringActorProducer class.
     *
     * @param actorBeanName
     *            The name of the actor bean to create Props for
     * @return a Props that will create the named actor bean using Spring
     */
    public Props props(String actorBeanName, Object ... args) {
        return Props.create(SpringActorProducer.class, applicationContext, actorBeanName, args);
    }

    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
        this.applicationContext = applicationContext;
    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
应用例子
经过了以上的铺垫，现在你可以使用创建好的CountingActor了，首先你需要在你的业务类中注入ActorSystem和SpringExt。

       @Autowired
private ActorSystem actorSystem;

@Autowired
private SpringExt springExt;
1
2
3
4
5
然后我们使用CountingActor进行计数，代码如下：

ActorRef counter = actorSystem.actorOf(springExt.props("CountingActor"), "counter");

// Create the "actor-in-a-box"
       final Inbox inbox = Inbox.create(system);

// tell it to count three times
       inbox.send(counter, new Count());
       inbox.send(counter, new Count());
       inbox.send(counter, new Count());

// print the result
FiniteDuration duration = FiniteDuration.create(3, TimeUnit.SECONDS);
Future<Object> result = ask(counter, new Get(), Timeout.durationToTimeout(duration));
try {
    System.out.println("Got back " + Await.result(result, duration));
} catch (Exception e) {
    System.err.println("Failed getting result: " + e.getMessage());
    throw e;
}
输出结果为：

Got back 3
1
总结
本文只是最简单的Akka集成Spring的例子，Akka的remote、cluster、persistence、router等机制都可以应用。

参考资料

书籍《java高并发程序设计》
AKKA官方文档



====================



STM软件事务内存
软件事务内存（STM）：顾名思义，这是事务。与关系型数据库中的事务类似，具有ACID属性。
在分布式任务中，有可能会有和事务相关的处理，这里将举例说明AKKA中STM的用法。

假设公司给员工发工资业务，CompanyActor是公司actor， EmployeeActor是员工actor，公司账户减钱，员工账户加钱，这就要求事务。代码中有重要注释。

package akka.stm;

import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.Props;
import akka.pattern.Patterns;
import akka.transactor.Coordinated;
import akka.util.Timeout;
import com.typesafe.config.ConfigFactory;
import scala.concurrent.Await;

import java.util.concurrent.TimeUnit;

/**
 * Created by liubenlong on 2017/1/16.
 */
public class STMMain {
    public static ActorRef companyActor = null;
    public static ActorRef employeeActor = null;


    public static void main(String [] args) throws Exception {
        ActorSystem system = ActorSystem.create("stm", ConfigFactory.load("akka.conf"));
        companyActor = system.actorOf(Props.create(CompanyActor.class), "CompanyActor");
        employeeActor = system.actorOf(Props.create(EmployeeActor.class), "EmployeeActor");

        Timeout timeout = new Timeout(1, TimeUnit.SECONDS);

        for(int i = 0 ; i < 23; i ++){
            companyActor.tell(new Coordinated(i, timeout), ActorRef.noSender());

            Thread.sleep(200);

            int companyCount = (int) Await.result(Patterns.ask(companyActor, "getCount", timeout), timeout.duration());
            int employeeCount = (int) Await.result(Patterns.ask(employeeActor, "getCount", timeout), timeout.duration());

            System.out.println("companyCount = " + companyCount + ";employeeCount = " + employeeCount);
            System.out.println("-----------------------");
        }

    }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
package akka.stm;

import akka.actor.*;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import akka.transactor.Coordinated;
import scala.concurrent.stm.Ref;
import scala.concurrent.stm.japi.STM;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class CompanyActor extends UntypedActor {

    private final LoggingAdapter log = Logging.getLogger(getContext().system(), this);

    private Ref.View<Integer> count = STM.newRef(100);//定义账户余额

    @Override
    public void onReceive(Object o) throws Throwable {
        if(o instanceof Coordinated){
            Coordinated coordinated = (Coordinated) o;
            int downCount = (int) coordinated.getMessage();//传递过来的参数，减多少。
            STMMain.employeeActor.tell(coordinated.coordinate(downCount), getSelf());//通知employeeActor增加费用

            try {//注意这里异常要及时处理，否则异常会一直扩散，导致回退到系统刚启动时的初始状态！
                coordinated.atomic(() -> {
                    if(count.get() < downCount) throw new RuntimeException("余额不足！");
                    STM.increment(count, -downCount);//减余额
                });
            }catch (Exception e){
                e.printStackTrace();
            }
        }else if("getCount".equals(o)){
            getSender().tell(count.get(), getSelf());
        }else{
            unhandled(o);
        }
    }

}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
package akka.stm;

import akka.actor.UntypedActor;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import akka.transactor.Coordinated;
import scala.concurrent.stm.Ref;
import scala.concurrent.stm.japi.STM;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class EmployeeActor extends UntypedActor {

    private final LoggingAdapter log = Logging.getLogger(getContext().system(), this);

    private Ref.View<Integer> count = STM.newRef(20);//员工账户

    @Override
    public void onReceive(Object o) throws Throwable {
        if(o instanceof Coordinated){
            Coordinated coordinated = (Coordinated) o;
            int downCount = (int) coordinated.getMessage();//员工增加的工资

            try {//注意这里异常要及时处理，否则异常会一直扩散，导致回退到系统刚启动时的初始状态！
                coordinated.atomic(() -> STM.increment(count, downCount));//Employee增加工资
            }catch (Exception e){
                e.printStackTrace();
            }

        }else if("getCount".equals(o)){
            getSender().tell(count.get(), getSelf());
        }else{
            unhandled(o);
        }
    }

}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
运行结果：

"D:\Program Files\Java\jdk1.8.0_111\bin\java" -Didea.launcher.port=7533 "-Didea.launcher.bin.path=D:\Program Files (x86)\ideaIU-2016.2.5\bin" -Dfile.encoding=UTF-8 -classpath "D:\Program Files\Java\jdk1.8.0_111\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\rt.jar;D:\workspace_git_idea\luffi-master\luffi\target\test-classes;D:\workspace_git_idea\luffi-master\luffi\target\classes;D:\LocalRepository\commons-fileupload\commons-fileupload\1.3.2\commons-fileupload-1.3.2.jar;D:\LocalRepository\commons-io\commons-io\2.2\commons-io-2.2.jar;D:\LocalRepository\org\apache\httpcomponents\httpmime\4.3.1\httpmime-4.3.1.jar;D:\LocalRepository\org\apache\httpcomponents\httpclient\4.3.1\httpclient-4.3.1.jar;D:\LocalRepository\org\apache\httpcomponents\httpcore\4.3\httpcore-4.3.jar;D:\LocalRepository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\LocalRepository\commons-codec\commons-codec\1.6\commons-codec-1.6.jar;D:\LocalRepository\com\alibaba\fastjson\1.2.17\fastjson-1.2.17.jar;D:\LocalRepository\com\letv\openapi\openapi-sdk-java\1.0.0-SNAPSHOT\openapi-sdk-java-1.0.0-20160721.094717-1.jar;D:\LocalRepository\org\slf4j\slf4j-api\1.7.5\slf4j-api-1.7.5.jar;D:\workspace_git_idea\luffi-master\luffi-api\target\classes;D:\workspace_git_idea\luffi-master\luffi-model\target\classes;D:\LocalRepository\com\github\pagehelper\pagehelper\4.1.1\pagehelper-4.1.1.jar;D:\LocalRepository\com\github\jsqlparser\jsqlparser\0.9.4\jsqlparser-0.9.4.jar;D:\LocalRepository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\LocalRepository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\LocalRepository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\workspace_git_idea\luffi-master\luffi-repository\target\classes;D:\LocalRepository\tk\mybatis\mapper\3.3.8\mapper-3.3.8.jar;D:\LocalRepository\javax\persistence\persistence-api\1.0\persistence-api-1.0.jar;D:\LocalRepository\org\mybatis\spring\boot\mybatis-spring-boot-starter\1.1.1\mybatis-spring-boot-starter-1.1.1.jar;D:\LocalRepository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\1.1.1\mybatis-spring-boot-autoconfigure-1.1.1.jar;D:\LocalRepository\org\mybatis\mybatis\3.4.0\mybatis-3.4.0.jar;D:\LocalRepository\org\mybatis\mybatis-spring\1.3.0\mybatis-spring-1.3.0.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter-jdbc\1.3.3.RELEASE\spring-boot-starter-jdbc-1.3.3.RELEASE.jar;D:\LocalRepository\org\apache\tomcat\tomcat-jdbc\8.0.32\tomcat-jdbc-8.0.32.jar;D:\LocalRepository\org\apache\tomcat\tomcat-juli\8.0.32\tomcat-juli-8.0.32.jar;D:\LocalRepository\org\springframework\spring-jdbc\4.2.5.RELEASE\spring-jdbc-4.2.5.RELEASE.jar;D:\LocalRepository\org\springframework\spring-tx\4.2.5.RELEASE\spring-tx-4.2.5.RELEASE.jar;D:\workspace_git_idea\luffi-master\luffi-common\target\classes;D:\LocalRepository\org\apache\commons\commons-lang3\3.1\commons-lang3-3.1.jar;D:\LocalRepository\org\apache\zookeeper\zookeeper\3.4.8\zookeeper-3.4.8.jar;D:\LocalRepository\jline\jline\0.9.94\jline-0.9.94.jar;D:\LocalRepository\io\netty\netty\3.7.0.Final\netty-3.7.0.Final.jar;D:\LocalRepository\com\101tec\zkclient\0.9\zkclient-0.9.jar;D:\LocalRepository\log4j\log4j\1.2.15\log4j-1.2.15.jar;D:\LocalRepository\javax\mail\mail\1.4\mail-1.4.jar;D:\LocalRepository\com\alibaba\dubbo\2.8.4.lehi\dubbo-2.8.4.lehi.jar;D:\LocalRepository\org\springframework\spring-beans\4.2.4.RELEASE\spring-beans-4.2.4.RELEASE.jar;D:\LocalRepository\org\springframework\spring-core\4.2.4.RELEASE\spring-core-4.2.4.RELEASE.jar;D:\LocalRepository\org\springframework\spring-context\4.2.4.RELEASE\spring-context-4.2.4.RELEASE.jar;D:\LocalRepository\org\springframework\spring-aop\4.2.4.RELEASE\spring-aop-4.2.4.RELEASE.jar;D:\LocalRepository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\LocalRepository\org\springframework\spring-expression\4.2.4.RELEASE\spring-expression-4.2.4.RELEASE.jar;D:\LocalRepository\org\apache\logging\log4j\log4j-core\2.5\log4j-core-2.5.jar;D:\LocalRepository\org\apache\logging\log4j\log4j-api\2.5\log4j-api-2.5.jar;D:\LocalRepository\org\javassist\javassist\3.15.0-GA\javassist-3.15.0-GA.jar;D:\LocalRepository\org\springframework\spring-web\4.2.4.RELEASE\spring-web-4.2.4.RELEASE.jar;D:\LocalRepository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\LocalRepository\commons-pool\commons-pool\1.6\commons-pool-1.6.jar;D:\LocalRepository\org\apache\curator\curator-framework\2.5.0\curator-framework-2.5.0.jar;D:\LocalRepository\org\apache\curator\curator-client\2.5.0\curator-client-2.5.0.jar;D:\LocalRepository\com\google\guava\guava\16.0.1\guava-16.0.1.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter\1.3.6.RELEASE\spring-boot-starter-1.3.6.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot\1.3.6.RELEASE\spring-boot-1.3.6.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot-autoconfigure\1.3.6.RELEASE\spring-boot-autoconfigure-1.3.6.RELEASE.jar;D:\LocalRepository\org\yaml\snakeyaml\1.16\snakeyaml-1.16.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter-web\1.3.6.RELEASE\spring-boot-starter-web-1.3.6.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter-validation\1.3.6.RELEASE\spring-boot-starter-validation-1.3.6.RELEASE.jar;D:\LocalRepository\org\apache\tomcat\embed\tomcat-embed-el\8.0.36\tomcat-embed-el-8.0.36.jar;D:\LocalRepository\com\fasterxml\jackson\core\jackson-databind\2.6.7\jackson-databind-2.6.7.jar;D:\LocalRepository\com\fasterxml\jackson\core\jackson-annotations\2.6.0\jackson-annotations-2.6.0.jar;D:\LocalRepository\com\fasterxml\jackson\core\jackson-core\2.6.7\jackson-core-2.6.7.jar;D:\LocalRepository\org\springframework\spring-webmvc\4.2.7.RELEASE\spring-webmvc-4.2.7.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter-log4j2\1.3.6.RELEASE\spring-boot-starter-log4j2-1.3.6.RELEASE.jar;D:\LocalRepository\org\apache\logging\log4j\log4j-slf4j-impl\2.4.1\log4j-slf4j-impl-2.4.1.jar;D:\LocalRepository\org\slf4j\jcl-over-slf4j\1.7.21\jcl-over-slf4j-1.7.21.jar;D:\LocalRepository\org\slf4j\jul-to-slf4j\1.7.21\jul-to-slf4j-1.7.21.jar;D:\LocalRepository\mysql\mysql-connector-java\5.1.39\mysql-connector-java-5.1.39.jar;D:\LocalRepository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\LocalRepository\javax\el\javax.el-api\2.2.4\javax.el-api-2.2.4.jar;D:\LocalRepository\org\glassfish\web\javax.el\2.2.4\javax.el-2.2.4.jar;D:\LocalRepository\org\hibernate\hibernate-validator\5.2.4.Final\hibernate-validator-5.2.4.Final.jar;D:\LocalRepository\org\jboss\logging\jboss-logging\3.2.1.Final\jboss-logging-3.2.1.Final.jar;D:\LocalRepository\com\fasterxml\classmate\1.1.0\classmate-1.1.0.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-jaxrs\3.0.9.Final\resteasy-jaxrs-3.0.9.Final.jar;D:\LocalRepository\org\jboss\resteasy\jaxrs-api\3.0.9.Final\jaxrs-api-3.0.9.Final.jar;D:\LocalRepository\org\jboss\spec\javax\annotation\jboss-annotations-api_1.1_spec\1.0.1.Final\jboss-annotations-api_1.1_spec-1.0.1.Final.jar;D:\LocalRepository\javax\activation\activation\1.1\activation-1.1.jar;D:\LocalRepository\net\jcip\jcip-annotations\1.0\jcip-annotations-1.0.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-client\3.0.9.Final\resteasy-client-3.0.9.Final.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-netty\3.0.14.Final\resteasy-netty-3.0.14.Final.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-jdk-http\3.0.14.Final\resteasy-jdk-http-3.0.14.Final.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-jackson-provider\3.0.14.Final\resteasy-jackson-provider-3.0.14.Final.jar;D:\LocalRepository\org\codehaus\jackson\jackson-core-asl\1.9.12\jackson-core-asl-1.9.12.jar;D:\LocalRepository\org\codehaus\jackson\jackson-mapper-asl\1.9.12\jackson-mapper-asl-1.9.12.jar;D:\LocalRepository\org\codehaus\jackson\jackson-jaxrs\1.9.12\jackson-jaxrs-1.9.12.jar;D:\LocalRepository\org\codehaus\jackson\jackson-xc\1.9.12\jackson-xc-1.9.12.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-jaxb-provider\3.0.16.Final\resteasy-jaxb-provider-3.0.16.Final.jar;D:\LocalRepository\com\sun\xml\bind\jaxb-impl\2.2.7\jaxb-impl-2.2.7.jar;D:\LocalRepository\com\sun\xml\bind\jaxb-core\2.2.7\jaxb-core-2.2.7.jar;D:\LocalRepository\javax\xml\bind\jaxb-api\2.2.7\jaxb-api-2.2.7.jar;D:\LocalRepository\com\sun\istack\istack-commons-runtime\2.16\istack-commons-runtime-2.16.jar;D:\LocalRepository\com\sun\xml\fastinfoset\FastInfoset\1.2.12\FastInfoset-1.2.12.jar;D:\LocalRepository\javax\xml\bind\jsr173_api\1.0\jsr173_api-1.0.jar;D:\LocalRepository\org\apache\tomcat\embed\tomcat-embed-core\8.0.11\tomcat-embed-core-8.0.11.jar;D:\LocalRepository\org\apache\tomcat\embed\tomcat-embed-logging-juli\8.0.11\tomcat-embed-logging-juli-8.0.11.jar;D:\LocalRepository\junit\junit\4.12\junit-4.12.jar;D:\LocalRepository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;D:\LocalRepository\org\springframework\spring-test\4.2.4.RELEASE\spring-test-4.2.4.RELEASE.jar;D:\LocalRepository\org\apache\thrift\libthrift\0.9.3\libthrift-0.9.3.jar;D:\LocalRepository\redis\clients\jedis\2.9.0\jedis-2.9.0.jar;D:\LocalRepository\org\apache\commons\commons-pool2\2.4.2\commons-pool2-2.4.2.jar;D:\LocalRepository\org\springframework\spring-context-support\4.2.4.RELEASE\spring-context-support-4.2.4.RELEASE.jar;D:\LocalRepository\org\quartz-scheduler\quartz\2.2.3\quartz-2.2.3.jar;D:\LocalRepository\c3p0\c3p0\0.9.1.1\c3p0-0.9.1.1.jar;D:\LocalRepository\com\typesafe\akka\akka-actor_2.11\2.4.16\akka-actor_2.11-2.4.16.jar;D:\LocalRepository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\LocalRepository\com\typesafe\config\1.3.0\config-1.3.0.jar;D:\LocalRepository\org\scala-lang\modules\scala-java8-compat_2.11\0.7.0\scala-java8-compat_2.11-0.7.0.jar;D:\LocalRepository\com\typesafe\akka\akka-transactor_2.10\2.3.16\akka-transactor_2.10-2.3.16.jar;D:\LocalRepository\com\typesafe\akka\akka-actor_2.10\2.3.16\akka-actor_2.10-2.3.16.jar;D:\LocalRepository\org\scala-stm\scala-stm_2.10\0.7\scala-stm_2.10-0.7.jar;D:\LocalRepository\com\typesafe\akka\akka-testkit_2.11\2.4.16\akka-testkit_2.11-2.4.16.jar;D:\LocalRepository\com\typesafe\akka\akka-cluster_2.11\2.4.16\akka-cluster_2.11-2.4.16.jar;D:\LocalRepository\com\typesafe\akka\akka-remote_2.11\2.4.16\akka-remote_2.11-2.4.16.jar;D:\LocalRepository\com\typesafe\akka\akka-stream_2.11\2.4.16\akka-stream_2.11-2.4.16.jar;D:\LocalRepository\org\reactivestreams\reactive-streams\1.0.0\reactive-streams-1.0.0.jar;D:\LocalRepository\com\typesafe\ssl-config-core_2.11\0.2.1\ssl-config-core_2.11-0.2.1.jar;D:\LocalRepository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.4\scala-parser-combinators_2.11-1.0.4.jar;D:\LocalRepository\com\typesafe\akka\akka-protobuf_2.11\2.4.16\akka-protobuf_2.11-2.4.16.jar;D:\LocalRepository\org\uncommons\maths\uncommons-maths\1.2.2a\uncommons-maths-1.2.2a.jar;D:\LocalRepository\io\aeron\aeron-driver\1.0.4\aeron-driver-1.0.4.jar;D:\LocalRepository\io\aeron\aeron-client\1.0.4\aeron-client-1.0.4.jar;D:\LocalRepository\org\agrona\Agrona\0.9.0\Agrona-0.9.0.jar;D:\LocalRepository\org\projectlombok\lombok-maven-plugin\1.12.2.0\lombok-maven-plugin-1.12.2.0.jar;D:\LocalRepository\org\apache\maven\maven-plugin-api\3.0.4\maven-plugin-api-3.0.4.jar;D:\LocalRepository\org\apache\maven\maven-model\3.0.4\maven-model-3.0.4.jar;D:\LocalRepository\org\codehaus\plexus\plexus-utils\2.0.6\plexus-utils-2.0.6.jar;D:\LocalRepository\org\apache\maven\maven-artifact\3.0.4\maven-artifact-3.0.4.jar;D:\LocalRepository\org\sonatype\sisu\sisu-inject-plexus\2.3.0\sisu-inject-plexus-2.3.0.jar;D:\LocalRepository\org\codehaus\plexus\plexus-component-annotations\1.5.5\plexus-component-annotations-1.5.5.jar;D:\LocalRepository\org\codehaus\plexus\plexus-classworlds\2.4\plexus-classworlds-2.4.jar;D:\LocalRepository\org\sonatype\sisu\sisu-inject-bean\2.3.0\sisu-inject-bean-2.3.0.jar;D:\LocalRepository\org\sonatype\sisu\sisu-guice\3.1.0\sisu-guice-3.1.0-no_aop.jar;D:\LocalRepository\org\sonatype\sisu\sisu-guava\0.9.9\sisu-guava-0.9.9.jar;D:\LocalRepository\org\projectlombok\lombok\1.12.2\lombok-1.12.2.jar;D:\Program Files (x86)\ideaIU-2016.2.5\lib\idea_rt.jar" com.intellij.rt.execution.application.AppMain akka.stm.STMMain
companyCount = 100;employeeCount = 20
-----------------------
companyCount = 99;employeeCount = 21
-----------------------
companyCount = 97;employeeCount = 23
-----------------------
companyCount = 94;employeeCount = 26
-----------------------
companyCount = 90;employeeCount = 30
-----------------------
companyCount = 85;employeeCount = 35
-----------------------
companyCount = 79;employeeCount = 41
-----------------------
companyCount = 72;employeeCount = 48
-----------------------
companyCount = 64;employeeCount = 56
-----------------------
companyCount = 55;employeeCount = 65
-----------------------
companyCount = 45;employeeCount = 75
-----------------------
companyCount = 34;employeeCount = 86
-----------------------
companyCount = 22;employeeCount = 98
-----------------------
java.lang.RuntimeException: 余额不足！
    at akka.stm.CompanyActor.lambda$onReceive$0(CompanyActor.java:34)
    at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
	at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:50)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:43)
    at scala.concurrent.stm.ccstm.InTxnImpl.runBlock(InTxnImpl.scala:560)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAttempt(InTxnImpl.scala:516)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAtomicImpl(InTxnImpl.scala:387)
    at scala.concurrent.stm.ccstm.InTxnImpl.atomic(InTxnImpl.scala:248)
    at scala.concurrent.stm.ccstm.CCSTMExecutor.apply(CCSTMExecutor.scala:24)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl.atomic(CommitBarrierImpl.scala:43)
    at akka.transactor.Coordinated.atomic(Coordinated.scala:141)
    at akka.transactor.Coordinated.atomic(Coordinated.scala:157)
    at akka.stm.CompanyActor.onReceive(CompanyActor.java:33)
    at akka.actor.UntypedActor$$anonfun$receive$1.applyOrElse(UntypedActor.scala:165)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:496)
	at akka.actor.UntypedActor.aroundReceive(UntypedActor.scala:95)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526)
	at akka.actor.ActorCell.invoke(ActorCell.scala:495)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257)
	at akka.dispatch.Mailbox.run(Mailbox.scala:224)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:234)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
akka.transactor.CoordinatedTransactionException: Exception in coordinated atomic
	at akka.transactor.Coordinated.atomic(Coordinated.scala:144)
	at akka.transactor.Coordinated.atomic(Coordinated.scala:157)
	at akka.stm.EmployeeActor.onReceive(EmployeeActor.java:25)
	at akka.actor.UntypedActor$$anonfun$receive$1.applyOrElse(UntypedActor.scala:165)
    at akka.actor.Actor$class.aroundReceive(Actor.scala:496)
    at akka.actor.UntypedActor.aroundReceive(UntypedActor.scala:95)
    at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526)
    at akka.actor.ActorCell.invoke(ActorCell.scala:495)
    at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257)
    at akka.dispatch.Mailbox.run(Mailbox.scala:224)
    at akka.dispatch.Mailbox.exec(Mailbox.scala:234)
    at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: 余额不足！
    at akka.stm.CompanyActor.lambda$onReceive$0(CompanyActor.java:34)
    at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
	at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:50)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:43)
    at scala.concurrent.stm.ccstm.InTxnImpl.runBlock(InTxnImpl.scala:560)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAttempt(InTxnImpl.scala:516)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAtomicImpl(InTxnImpl.scala:387)
    at scala.concurrent.stm.ccstm.InTxnImpl.atomic(InTxnImpl.scala:248)
    at scala.concurrent.stm.ccstm.CCSTMExecutor.apply(CCSTMExecutor.scala:24)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl.atomic(CommitBarrierImpl.scala:43)
    at akka.transactor.Coordinated.atomic(Coordinated.scala:141)
    at akka.transactor.Coordinated.atomic(Coordinated.scala:157)
    at akka.stm.CompanyActor.onReceive(CompanyActor.java:33)
    ... 12 more
companyCount = 9;employeeCount = 111
-----------------------
java.lang.RuntimeException: 余额不足！
companyCount = 9;employeeCount = 111
    at akka.stm.CompanyActor.lambda$onReceive$0(CompanyActor.java:34)
-----------------------
    at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
	at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:50)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:43)
    at scala.concurrent.stm.ccstm.InTxnImpl.runBlock(InTxnImpl.scala:560)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAttempt(InTxnImpl.scala:516)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAtomicImpl(InTxnImpl.scala:387)
    at scala.concurrent.stm.ccstm.InTxnImpl.atomic(InTxnImpl.scala:248)
    at scala.concurrent.stm.ccstm.CCSTMExecutor.apply(CCSTMExecutor.scala:24)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl.atomic(CommitBarrierImpl.scala:43)
    at akka.transactor.Coordinated.atomic(Coordinated.scala:141)
    at akka.transactor.Coordinated.atomic(Coordinated.scala:157)
    at akka.stm.CompanyActor.onReceive(CompanyActor.java:33)
    at akka.actor.UntypedActor$$anonfun$receive$1.applyOrElse(UntypedActor.scala:165)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:496)
	at akka.actor.UntypedActor.aroundReceive(UntypedActor.scala:95)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526)
	at akka.actor.ActorCell.invoke(ActorCell.scala:495)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257)
	at akka.dispatch.Mailbox.run(Mailbox.scala:224)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:234)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
akka.transactor.CoordinatedTransactionException: Exception in coordinated atomic
	at akka.transactor.Coordinated.atomic(Coordinated.scala:144)
	at akka.transactor.Coordinated.atomic(Coordinated.scala:157)
	at akka.stm.EmployeeActor.onReceive(EmployeeActor.java:25)
	at akka.actor.UntypedActor$$anonfun$receive$1.applyOrElse(UntypedActor.scala:165)
    at akka.actor.Actor$class.aroundReceive(Actor.scala:496)
    at akka.actor.UntypedActor.aroundReceive(UntypedActor.scala:95)
    at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526)
    at akka.actor.ActorCell.invoke(ActorCell.scala:495)
    at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257)
    at akka.dispatch.Mailbox.run(Mailbox.scala:224)
    at akka.dispatch.Mailbox.exec(Mailbox.scala:234)
    at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: 余额不足！
    at akka.stm.CompanyActor.lambda$onReceive$0(CompanyActor.java:34)
    at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
	at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:50)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:43)
    at scala.concurrent.stm.ccstm.InTxnImpl.runBlock(InTxnImpl.scala:560)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAttempt(InTxnImpl.scala:516)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAtomicImpl(InTxnImpl.scala:387)
    at scala.concurrent.stm.ccstm.InTxnImpl.atomic(InTxnImpl.scala:248)
    at scala.concurrent.stm.ccstm.CCSTMExecutor.apply(CCSTMExecutor.scala:24)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl.atomic(CommitBarrierImpl.scala:43)
    at akka.transactor.Coordinated.atomic(Coordinated.scala:141)
    at akka.transactor.Coordinated.atomic(Coordinated.scala:157)
    at akka.stm.CompanyActor.onReceive(CompanyActor.java:33)
    ... 12 more
companyCount = 9;employeeCount = 111
-----------------------
java.lang.RuntimeException: 余额不足！
    at akka.stm.CompanyActor.lambda$onReceive$0(CompanyActor.java:34)
    at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
	at akka.transactor.Coordinated$$anonfun$atomic$1.apply(Coordinated.scala:157)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:50)
    at scala.concurrent.stm.ccstm.CommitBarrierImpl$MemberImpl$$anonfun$atomic$1.apply(CommitBarrierImpl.scala:43)
    at scala.concurrent.stm.ccstm.InTxnImpl.runBlock(InTxnImpl.scala:560)
    at scala.concurrent.stm.ccstm.InTxnImpl.topLevelAttempt(InTxnImpl.scala:516)

注意：需要引入transactor的maven配置：

<dependency>
    <groupId>com.typesafe.akka</groupId>
    <artifactId>akka-actor_2.11</artifactId>
    <version>2.4.16</version>
</dependency>
<dependency>
    <groupId>com.typesafe.akka</groupId>
    <artifactId>akka-agent_2.11</artifactId>
    <version>2.4.16</version>
</dependency>
<!-- https://mvnrepository.com/artifact/com.typesafe.akka/akka-transactor_2.10 -->
<dependency>
    <groupId>com.typesafe.akka</groupId>
    <artifactId>akka-transactor_2.10</artifactId>
    <version>2.3.16</version>
</dependency>
参考资料

书籍《java高并发程序设计》
AKKA官方文档


https://doc.akka.io/docs/akka/current/guide/tutorial_1.html

=========
不可变对象
我们都知道在编写java线程的时候，要传递不可变对象，这里akka也是如此

下面这个例子就是传递不可变对象：

package akka.unmodifiable;

import java.util.Collections;
import java.util.List;

public final class Message {

    private final int age;
    private final List<String> list;

    public Message(int age, List<String> list){
        this.age = age;
        /**
         * 把普通list包装为不可变对象
         */
        this.list = Collections.unmodifiableList(list);
    }

    public int getAge() {
        return age;
    }

    public List<String> getList() {
        return list;
    }
}


package akka.unmodifiable;

import akka.actor.UntypedActor;
import com.alibaba.fastjson.JSONObject;

public class Greeter extends UntypedActor {

  @Override
  public void onReceive(Object msg) throws InterruptedException {

    try {
      System.out.println("Greeter收到的数据为：" + JSONObject.toJSONString(msg));
      getSender().tell("Greeter工作完成。", getSelf());//给发送至发送信息.
    }catch (Exception e){
      e.printStackTrace();
    }

  }

}
package akka.unmodifiable;

import akka.actor.ActorRef;
import akka.actor.Props;
import akka.actor.UntypedActor;
import com.alibaba.fastjson.JSONObject;

import java.util.Arrays;

public class HelloWorld extends UntypedActor {

  ActorRef greeter;

  @Override
  public void preStart() {
    // create the greeter actor
    greeter = getContext().actorOf(Props.create(Greeter.class), "greeter");
    System.out.println("Greeter actor path：" + greeter.path());
    // tell it to perform the greeting
    greeter.tell(new Message(2, Arrays.asList("2", "dsf")), getSelf());
  }

  @Override
  public void onReceive(Object msg) {
    try {
      System.out.println("HelloWorld收到的数据为：" + JSONObject.toJSONString(msg));
    }catch (Exception e){
      e.printStackTrace();
    }
  }
}
package akka.unmodifiable;

import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.Props;
import com.typesafe.config.ConfigFactory;

public class Main {
//  public static void main(String[] args) {
//    akka.Main.main(new String[] { HelloWorld.class.getName() });
//  }

  public static void main(String[] args) {
    //创建ActorSystem。一般来说，一个系统只需要一个ActorSystem。
    //参数1：系统名称。参数2：配置文件
    ActorSystem system = ActorSystem.create("Hello", ConfigFactory.load("akka.config"));
    ActorRef a = system.actorOf(Props.create(HelloWorld.class), "helloWorld");
    System.out.println(a.path());
  }
}
参考资料

书籍《java高并发程序设计》
AKKA官方文档

===========
入门编程实例

【Akka】Akka入门编程实例
原创 2016年01月17日 19:26:16 标签：akka /scala 3498
引言

这篇文章主要是第一次学习Akka编程，先试试水，探探坑，对Akka和SBT的使用有一个直观的了解，以几个简单的akka编程实例来说明akka的使用。希望在日后的学习和编程中，能有更多自己的体会和经验总结来分享。

Actor模型

Actor实例可以想象成是服务器上的Web服务，你无法控制，只能通过发送消息去请求执行任务或查询信息，而不能直接在Web服务中修改状态或者处理资源。通过发送不可改变的消息，虽然看上去有些限制，但是可以很简单安全的编写并发程序。

Actor系统的形象理解

一个actor是基于Actor系统的最小单元，就像面向对象系统中的对象实例一样，它也封装了状态和行为。我们无法窥探actor内部的信息，只能通过发送消息来请求状态信息（就像是问一个人，他感觉如何）。actor中有一个存放不可变状态信息的信箱。我们通过发送信息和actor进行通信，当actor收到信息之后，它会运用相关算法来处理具体的信息。
在一个应用程序中，多个actor构成了一套层级系统，像是一个家族或者一个商业组织。一个actor可以认为是一个商业组织的个人。一个actor有一个父亲，称为监督者（supervisor），还有好多孩子，可以认为，在一个商业组织中，主席（actor）下面有多个副主席，副主席也有很多下属随从。
Actor系统的最佳实践是“委派任务”，尤其是当actor的行为被阻塞的时候。可以想象，在实际商业活动中，主席将要做的工作分配给下面的几个副主席去分别执行，而副主席也会将子任务分配给自己的随从，直到该任务被下属们执行完毕。

处理故障

Actor模型的一个重要内容是处理故障。在工作工程中，如果出现错误或者抛出异常，actor和其子actor都将暂停，然后发送一条信息给监督者（supervisor）actor，报告出现故障的信号。
根据工作任务和故障的性质，监督者actor将会作出几种选择：

恢复下属actor，保留内部状态
重启下属actor，清空状态
终止下属actor
上报故障
Hello,Actor实例

现在我用一个最简单的actor编程实例来介绍akka编程，先给出代码：

import akka.actor.Actor
import akka.actor.ActorSystem
import akka.actor.Props

class HelloActor extends Actor{
  def receive = {
    case "hello"  => println("hello back to you.")
    case _        => println("huh?")
  }
}

object Test1_HelloActor extends App {
  // actor need an ActorSystem
  val system = ActorSystem("HelloSystem")
  // create and start the actor
  val helloActor = system.actorOf(Props[HelloActor], name="helloActor")
  // send two messages
  helloActor ! "hello"
  helloActor ! "what"
  // shutdown the actor system
  system.shutdown
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
代码注解：

Actor由HelloActor定义
HelloActor的行为有receive方法定义实现，其中使用了模式匹配表达式
HelloActor接收字符串hello作为消息，做出相应打印动作
Test1_HelloActor的object用来测试actor
ActorSystem接收一个name参数，并且通过system.actorOf创建actor实例
创建Actor实例名为helloActor，其构造函数没有参数
Actor创建后自动运行，不需调用start或者run方法
通过!方法来发送消息
ActorSystem

一个actor system是actors的层级集团，分享公共配置信息（比如分发器dispatchers，部署deployments，远程功能remote capabilities，地址addresses）。它同时也是创建和查询actors的入口。ActorSystem是为你的应用程序分配线程资源的结构。

ActorRef

当你调用ActorSystem的actorOf方法时，将创建并返回一个ActorRef的实例：
def actorOf(props: Props, name: String): ActorRef。

这个引用用来处理actor，你可以将其看做是处理实际actor的代理人（broker）或包装外观（facade）。ActorRef防止你破坏Actor模型，比如直接处理Actor实例，或直接修改Actor实例中的变量。所以只能通过给actor发送消息方式来执行任务，这种“袖手旁观（不干涉，hands-off）”的方法帮助巩固适宜的编程实践。

ActorRef有以下特点：

它是不可变的
它与actor实体是一对一的关系
它是可序列化的，网络可感知的。这使得你可以在网络环境中传送一个ActorRef
Actor之间的通信实例

下面给出的是两个actor实例相互发送消息进行通信的PingPong示例：

import akka.actor._

case object PingMessage
case object PongMessage
case object StartMessage
case object StopMessage

class Ping(pong: ActorRef) extends Actor{
  var count = 0
  def incrementAndPrint {count += 1; println(s"$count:ping")}
  def receive = {
    case StartMessage =>
      incrementAndPrint
      pong ! PongMessage
    case PingMessage =>
      incrementAndPrint
      if(count > 99) {
        sender ! StopMessage
        println("ping stopped")
        context.stop(self)
      }
      else
        sender ! PongMessage
    case _ => println("Ping got unexpected information")
  }
}

class Pong extends Actor {
  var count = 0
  def receive = {
    case StopMessage =>
      println("pong stopped")
      context.stop(self)
    case PongMessage =>
      count += 1
      println(s"$count:pong")
      sender ! PingMessage
    case _ => println("Pong got unexpected information")
  }
}

object PingPangTest extends App{
  val system = ActorSystem("PingPongTest")
  val pongActor = system.actorOf(Props[Pong], name="pong")
  val pingActor = system.actorOf(Props(new Ping(pongActor)),
                                  name = "ping")
  pingActor ! StartMessage
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
代码注释：

创建ActorSystem之后；
创建Pong的actor实例（pongActor对象其实是ActorRef的实例）；
之后创建Ping的actor实例，其构造函数接受ActorRef参数；
通过给pingActor发送一个StartMessage消息来启动pingActor和pongActor的具体动作；
Ping Actor和Pong Actor通过PingMessage和PongMessage相互发送消息，sender用来引用消息发送源Actor；
Ping通过计数，知道进行了100次消息的发送之后，发送StopMessage来终止actor。分别调用自己的context.stop方法来结束
启动Actor

在ActorSystem层面，通过调用system.actorOf方法来创建actors；在actor内部，通过调用context.actorOf方法来创建子actor。
下面给出一个ParentChild示例：

import akka.actor._

case class CreateChild (name: String)
case class Name (name: String)

class Child extends Actor {
  var name = "No name"
  override def postStop: Unit = {
    println(s"D'oh! They killed me ($name): ${self.path}")
  }
  def receive = {
    case Name(name) => this.name = name
    case _ => println(s"Child $name got message.")
  }
}

class Parent extends Actor {
  def receive = {
    case CreateChild(name) =>
      // Parent creates a new Child here
      println(s"Parent about to create Child ($name) ...")
      val child = context.actorOf(Props[Child], name=s"$name")
      child ! Name(name)
    case _ => println(s"Parent got some other message.")
  }
}

object ParentChildDemo extends App{
  val actorSystem = ActorSystem("ParentChildTest")
  val parent = actorSystem.actorOf(Props[Parent], name="Parent")

  // send messages to Parent to create to child actors
  parent ! CreateChild("XiaoMing")
  parent ! CreateChild("XiaoLiang")
  Thread.sleep(500)

  // lookup XiaoMing, the kill it
  println("Sending XiaoMing a PoisonPill ... ")
  val xiaoming = actorSystem.actorSelection("/user/Parent/XiaoMing")
  xiaoming ! PoisonPill
  println("XiaoMing was killed")

  Thread.sleep(5000)
  actorSystem.shutdown
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
打印结果：

Parent about to create Child (XiaoMing) ...
Parent about to create Child (XiaoLiang) ...
Sending XiaoMing a PoisonPill ...
XiaoMing was killed
D'oh! They killed me (XiaoMing): akka://ParentChildTest/user/Parent/XiaoMing
D'oh! They killed me (XiaoLiang): akka://ParentChildTest/user/Parent/XiaoLiang
1
2
3
4
5
6
终止Actor

在ActorSystem层面，通过system.stop(actorRef)来终止一个actor；在actor内部，使用context.stop(actorRef)来结束一个actor。
如果当前有正在处理的消息，对该消息的处理将在actor被终止之前完成，但是邮箱中的后续消息将不会被处理。缺省情况下这些消息会被送到 ActorSystem的dead letter mailbox, 但是这取决于邮箱的实现。

actor终止的相关处理

actor的终止分两步： 第一步actor将停止对邮箱的处理，向所有子actor发送终止命令，然后处理来自子actor的终止消息直到所有的子actor都完成终止， 最后终止自己(调用postStop,销毁邮箱,向DeathWatch发布Terminated,通知其监管者)。这个过程保证actor系统中的子树以一种有序的方式终止,将终止命令传播到叶子结点并收集它们回送的确认消息给被终止的监管者。如果其中某个actor没有响应(i.e.由于处理消息用了太长时间以至于没有收到终止命令), 整个过程将会被阻塞。

在 ActorSystem.shutdown被调用时, 系统根监管actor会被终止，以上的过程将保证整个系统的正确终止。

postStop() hook是在actor被完全终止以后调用的。这是为了清理资源:

override def postStop() = {
  // 关闭文件或数据库连接
}
1
2
3
PoisonPill和gracefulStop

还有其他两种方式，发送PoisonPill消息或者使用gracefulStop终止。
你也可以向actor发送akka.actor.PoisonPill消息,这个消息处理完成后actor会被终止。PoisonPill与普通消息一样被放进队列，因此会在已经入队列的其它消息之后被执行。

如果你想等待终止过程的结束，或者组合若干actor的终止次序，可以使用gracefulStop。
下面给出gracefulStop的代码示例：

import akka.actor._
import akka.pattern.gracefulStop
import scala.concurrent.{Await, ExecutionContext, Future}
import scala.concurrent.duration._
import scala.language.postfixOps

case object TestActorStop

class TestActor extends Actor {
  def receive = {
    case TestActorStop =>
      context.stop(self)
    case _ => println("TestActor got message")
  }
  override def postStop {println("TestActor: postStop")}
}

object GracefulStopTest extends App{
  val system = ActorSystem("GracefulStopTest")
  val testActor = system.actorOf(Props[TestActor], name="TestActor")
   // try to stop the actor graceful
  try {
    val stopped: Future[Boolean] = gracefulStop(testActor, 2 seconds, TestActorStop)
    Await.result(stopped, 3 seconds)
    println("testActor was stopped")
  } catch {
    case e: akka.pattern.AskTimeoutException => e.printStackTrace
  } finally {
    system.shutdown
  }
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
gracefulStop(actorRef, timeout)将返回一个Future实例，当目标actor有处理相关终止动作的消息时，会执行成功。
上面示例中，通过发送TestActorStop消息来终止actor；如果没有处理终止的工作，当超过2s后，Future抛出akka.pattern.AskTimeoutException异常。默认情况下，gracefulStop将发送PoisonPill消息。

Kill消息

当深入Akka actors，我们将认识监督者策略（supervisor strategies）概念。当实现了监督者策略，向actor发送一个Kill消息，这可以用来重新启动actor。如果使用默认的监督者策略，Kill消息将终止目标actor。
下面是示例代码：

import akka.actor._

class Number5 extends Actor {
  def receive = {
    case _ => println("Number 5 got a message")
  }
  override def preStart { println("Number 5 is alive")}
  override def postStop { println("Number 5::postStop called")}
  override def preRestart(reason: Throwable, message: Option[Any]): Unit = {
    println("Number 5::preRestart called")
  }
  override def postRestart(reason: Throwable): Unit = {
    println("Number 5::postRestart called")
  }
}

object KillTest extends App{
  val system = ActorSystem("KillTestSystem")
  val number5 = system.actorOf(Props[Number5], name="Number5")
  number5 ! "hello"
  number5 ! Kill
  system.shutdown
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
打印的信息：

Number 5 is alive
Number 5 got a message
[ERROR] [01/17/2016 19:20:09.342] [KillTestSystem-akka.actor.default-dispatcher-3] [akka://KillTestSystem/user/Number5] Kill (akka.actor.ActorKilledException)
Number 5::postStop called
1
2
3
4
转载请注明作者Jason Ding及其出处
Github博客主页(http://jasonding1354.github.io/)
GitCafe博客主页(http://jasonding1354.gitcafe.io/)
CSDN博客(http://blog.csdn.net/jasonding1354)
简书主页(http://www.jianshu.com/users/2bd9b48f6ea8/latest_articles)
Google搜索jasonding1354进入我的博客主页

=====================================

Akka基础

Akka笔记之Actor简介
　　  Akka中的Actor遵循Actor模型。你可以把Actor当作是人。这些人不会亲自去和别人交谈。他们只通过邮件来交流。

　　  1. 消息传递 2. 并发 3. 异常处理 4. 多任务 5. 消息链

Akka笔记之消息传递
        消息发送给actor代理；

        消息是不可变对象（可带有属性的case class）；

        分发器dispatcher和邮箱: dispatcher从actorRef取出一条消息放在目标actor邮箱中，然后放mailbox放在一个Thread上；当MailBox的run方法运行的时候，它会从队列中取出一条消息， 然后将它传给Actor去处理。在Actor的世界中，邮箱一有机会就会要求Actor去完成自己的任务。

Akka笔记之日志及测试
        使用slf4j打印日志：Akka通过一个叫做ActorLogging的特质(trait)来实现的这一功能。可以这个trait混入（mixin）到类中。当我们要打印一条消息的时候，ActorLogging中的日志方法会将日志信息发布到一个EventStream流中。没错，我的确说的是发布。

        EventStream：EventStream就像是一个我们用来发布及接收消息的消息代理。它与常见的消息中间件的根本区别在于EventStream的订阅者只能是一个Actor。DefaultLogger默认订阅这些消息并打印到标准输出。

akka{
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    loglevel = "DEBUG"
    logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}
Akka笔记之请求与响应
        技术上来讲，消息发送给Actor就是希望能有副作用的。设计上便是如此。目标Actor可以不做响应，也可以做如下两件事情——

        1. 给发送方回复一条响应（在本例中，TeacherActor会将一句名言回复给StudentActor）

        2. 将响应转发给其它的目标受众Actor，后者也可以进行响应/转发/产生副作用。Router和Supervisor就是这种情况。

Akka笔记之配置及调度
　　　配置管理：applicaiton.conf

        调度器: 一次调度和循环调度。import context.dispatcher这条语句非常重要。schedule方法需要一个非常重要的隐式参数——ExecutionContext。schedule方法只是把消息发送封装到了一个Runnable中，而它最终是由传进来的ExecutionContext来执行的。

Akka笔记之生命周期
        preStart: Actor重启的时候（比如说崩溃了之后重启）通过调用preStart方法还能重新初始化。而构造方法则实现不了这点（只会初始化一次）。

        postStop: ActorSystem.stop(), ActorContext.stop(), PoisonPill 都可以终止一个actor，关闭时回调用postStop()

Akka笔记之子Actor及路径
        Actor是纯粹的分层结构。你所创建出来的Actor必定是某个Actor的子Actor。actorRef.path可以获取到actor路径。

        子Actor：当某个任务由一个或多个子任务所组成的时候通常就会创建子Actor。或者当某个任务由父Actor执行比较容易出错，而你希望将它进行隔离的时候，也可以使用子Actor（这样当子Actor崩溃的时候，你还能够恢复它）。如果不存在父子Actor关系，就不要创建子Actor。

Akka笔记之Actor监控
        监控(Watch)：不管Actor是怎么挂掉的，系统里面会有些Actor希望能够知晓这一情况。ActorContext.watch和ActorContext.unwatch就是监控与取消监控的方法了。进行了监控之后，监控者会收到已停止的Actor发来的一条Terminated消息，它们只需要把这个消息放到receive函数的处理逻辑里就好了。

        监督（Supervision）：只存在于父子关系的actor之间。

 ===================================================================================
 1. 本地hello world

  1 [torstan@sparkb5-i ~/akka_example/hello_world]$ cat src/helloWorld.scala
  2 package our.examples
  3 import akka.actor.Actor
  4 import akka.actor.ActorSystem
  5 import akka.actor.Props
  6
  7 class HelloActor extends Actor {
  8   def receive = {
  9     case "hello" => println("hello back at you")
 10     case _       => println("huh?")
 11   }
 12 }
 13
 14 object HelloApp extends App {
 15         override def main(args: Array[String]){
 16                 val system = ActorSystem("HelloSystem")
 17                         // default Actor constructor
 18                         val helloActor = system.actorOf(Props[HelloActor], name = "helloactor")
 19                         helloActor ! "hello"
 20                         helloActor ! "buenos dias"
 21         }
 22 }
  1 [torstan@sparkb5-i ~/akka_example/hello_world]$ cat Makefile
  2 SRC_DIR := src
  3 SRC := $(shell find ${SRC_DIR} -name "*.scala")
  4 DIR=our
  5
  6 TARGET := HelloApp.jar
  7
  8 SCALAC := scalac
  9 SCFLAGS := /usr/local/scala-2.10.4/lib/akka-actors.jar
 10
 11 .PHONY: all clean
 12
 13 all: ${TARGET}
 14
 15 ${TARGET}: ${SRC}
 16         ${SCALAC} -cp ${SCFLAGS} $^
 17
 18 clean:
 19         ${RM} -r ${TARGET} ${DIR}
 1 [torstan@sparkb5-i ~/akka_example/hello_world]$ cat run.sh
 2 #!/bin/bash
 3
 4
 5 java -cp 6  .:/usr/local/scala-2.10.4/lib/scala-library.jar:/usr/local/scala-2.10.4/lib/akka-actors.jar:/usr/local/scala-2.10.4/lib/typesafe-config.jar7   our.examples.HelloApp
 执行结果：

 [torstan@sparkb5-i ~/akka_example/hello_world]$ ./run.sh
 hello back at you
 huh?



 2. 简单CS示例

 server端：

  1 [torstan@sparkb5-i ~/akka_example/remote_service/server]$ cat src/HelloRemote.scala
  2 package remote
  3 import akka.actor.Actor
  4 import akka.actor.ActorSystem
  5 import akka.actor.Props
  6
  7 class RemoteActor extends Actor{
  8         def receive = {
  9                 case msg:String =>
 10                         println(s"RemoteActor received message ‘$msg‘")
 11                         sender ! "hello from RemoteActor"
 12         }
 13 }
 14
 15 object HelloRemote extends App{
 16         val system = ActorSystem("HelloRemoteSystem")
 17         val remoteActor = system.actorOf(Props[RemoteActor], name="RemoteActor")
 18         remoteActor ! "The remote actor is alive"
 19 }
  1 [torstan@sparkb5-i ~/akka_example/remote_service/server]$ cat application.conf
  2 akka {
  3   loglevel = "DEBUG"
  4   actor {
  5     provider = "akka.remote.RemoteActorRefProvider"
  6    }
  7    remote {
  8      transport = "akka.remote.netty.NettyRemoteTransport"
  9      //log-sent-messages = on
 10      //log-received-messages = on
 11      netty {
 12        hostname = "127.0.0.1"
 13        port = 5150
 14      }
 15    }
 16 }
  1 [torstan@sparkb5-i ~/akka_example/remote_service/server]$ cat Makefile
  2 SRC_DIR := src
  3 SRC := $(shell find ${SRC_DIR} -name "*.scala")
  4 DIR=remote
  5
  6 TARGET := HelloRemote.jar
  7
  8 SCALAC := scalac
  9 SCFLAGS := /usr/local/scala-2.10.4/lib/akka-actors.jar
 10
 11 .PHONY: all clean
 12
 13 all: ${TARGET}
 14
 15 ${TARGET}: ${SRC}
 16         ${SCALAC} -cp ${SCFLAGS} $^
 17
 18 clean:
 19         ${RM} -r ${TARGET} ${DIR}
 1 [torstan@sparkb5-i ~/akka_example/remote_service/server]$ cat run.sh
 2 #!/bin/bash
 3
 4 AKKA_LIB_PATH="/usr/local/akka-2.1.4/lib/akka/"
 5
 6 java -cp 7  .:/usr/local/scala-2.10.4/lib/scala-library.jar:/usr/local/scala-2.10.4/lib/akka-actors.jar:/usr/local/scala-2.10.4/lib/typesafe-config.jar:${AKKA_LIB_PATH}/akka-remote_2.10-2.1.4.jar:${AKKA_LIB_PATH}/protobuf-java-2.4.1.jar:${AKKA_LIB_PATH}/netty-3.5.8.Final.jar 8  remote.HelloRemote
 client端：

  1 [torstan@sparkb5-i ~/akka_example/remote_service/client]$ cat src/HelloLocal.scala
  2 package client
  3 import akka.actor._
  4
  5 object HelloLocal extends App{
  6         implicit val system = ActorSystem("LocalSystem")
  7         val localActor = system.actorOf(Props[LocalActor], name="LocalActor")
  8         localActor ! "START"
  9 }
 10
 11 class LocalActor extends Actor{
 12         val remote = context.actorFor("akka://HelloRemoteSystem@172.27.6.240:5150/user/RemoteActor")
 13         var counter = 0
 14         def receive = {
 15                 case "START" =>
 16                         remote ! "HELLO from the LocalActor"
 17                 case msg:String =>
 18                         println(s"LocalActor received message: ‘$msg‘")
 19                         if(counter < 5){
 20                                 sender ! "hello back to you"
 21                                 counter += 1
 22                         }
 23         }
 24 }
  1 [torstan@sparkb5-i ~/akka_example/remote_service/client]$ cat application.conf
  2 akka {
  3   //loglevel = "DEBUG"
  4   actor {
  5     provider = "akka.remote.RemoteActorRefProvider"
  6   }
  7   remote {
  8     transport = "akka.remote.netty.NettyRemoteTransport"
  9     //log-sent-messages = on
 10     //log-received-messages = on
 11     netty {
 12       hostname = "127.0.0.1"
 13       port = 0
 14     }
 15   }
 16 }
  1 [torstan@sparkb5-i ~/akka_example/remote_service/client]$ cat Makefile
  2 SRC_DIR := src
  3 SRC := $(shell find ${SRC_DIR} -name "*.scala")
  4 DIR=client
  5
  6 TARGET := HelloLocal.jar
  7
  8 SCALAC := scalac
  9 SCFLAGS := /usr/local/scala-2.10.4/lib/akka-actors.jar
 10
 11 .PHONY: all clean
 12
 13 all: ${TARGET}
 14
 15 ${TARGET}: ${SRC}
 16         ${SCALAC} -cp ${SCFLAGS} $^
 17
 18 clean:
 19         ${RM} -r ${TARGET} ${DIR}
 1 [torstan@sparkb5-i ~/akka_example/remote_service/client]$ cat run.sh
 2 #!/bin/bash
 3
 4 AKKA_LIB_PATH="/usr/local/akka-2.1.4/lib/akka/"
 5
 6 java -cp 7  .:/usr/local/scala-2.10.4/lib/scala-library.jar:/usr/local/scala-2.10.4/lib/akka-actors.jar:/usr/local/scala-2.10.4/lib/typesafe-config.jar:${AKKA_LIB_PATH}/akka-remote_2.10-2.1.4.jar:${AKKA_LIB_PATH}/protobuf-java-2.4.1.jar:${AKKA_LIB_PATH}/netty-3.5.8.Final.jar 8  client.HelloLocal
 执行结果：

 [root@sparkb5-0 /data/torstan/akka_example/remote_service/server]# ./run.sh
 [DEBUG] [12/10/2014 17:31:57.074] [main] [EventStream(akka://HelloRemoteSystem)] logger log1-Logging$DefaultLogger started
 [DEBUG] [12/10/2014 17:31:57.080] [main] [EventStream(akka://HelloRemoteSystem)] Default Loggers started
 [INFO] [12/10/2014 17:31:57.269] [main] [NettyRemoteTransport(akka://HelloRemoteSystem@172.27.6.240:5150)] RemoteServerStarted@akka://HelloRemoteSystem@172.27.6.240:5150
 RemoteActor received message ‘The remote actor is alive‘
 [INFO] [12/10/2014 17:32:01.768] [HelloRemoteSystem-10] [NettyRemoteTransport(akka://HelloRemoteSystem@172.27.6.240:5150)] RemoteClientStarted@akka://LocalSystem@127.0.0.1:48437
 [DEBUG] [12/10/2014 17:32:01.769] [HelloRemoteSystem-10] [RemoteClient(akka://HelloRemoteSystem)] Starting remote client connection to [akka://LocalSystem@127.0.0.1:48437]
 [DEBUG] [12/10/2014 17:32:01.771] [HelloRemoteSystem-10] [NettyRemoteTransport(akka://HelloRemoteSystem@172.27.6.240:5150)] RemoteServerClientConnected@akka://HelloRemoteSystem@172.27.6.240:5150: Client[akka://LocalSystem@127.0.0.1:48437]
 RemoteActor received message ‘HELLO from the LocalActor‘
 [DEBUG] [12/10/2014 17:32:01.782] [HelloRemoteSystem-akka.actor.default-dispatcher-2] [akka.serialization.Serialization(akka://HelloRemoteSystem)] Using serializer[akka.serialization.JavaSerializer] for message [java.lang.String]
 RemoteActor received message ‘hello back to you‘
 RemoteActor received message ‘hello back to you‘
 RemoteActor received message ‘hello back to you‘
 RemoteActor received message ‘hello back to you‘
 RemoteActor received message ‘hello back to you‘



 [torstan@sparkb5-i ~/akka_example/remote_service/client]$ ./run.sh
 [INFO] [12/10/2014 17:32:01.668] [main] [NettyRemoteTransport(akka://LocalSystem@127.0.0.1:48437)] RemoteServerStarted@akka://LocalSystem@127.0.0.1:48437
 [INFO] [12/10/2014 17:32:01.755] [LocalSystem-akka.actor.default-dispatcher-3] [NettyRemoteTransport(akka://LocalSystem@127.0.0.1:48437)] RemoteClientStarted@akka://HelloRemoteSystem@172.27.6.240:5150
 LocalActor received message: ‘hello from RemoteActor‘
 LocalActor received message: ‘hello from RemoteActor‘
 LocalActor received message: ‘hello from RemoteActor‘
 LocalActor received message: ‘hello from RemoteActor‘
 LocalActor received message: ‘hello from RemoteActor‘
 LocalActor received message: ‘hello from RemoteActor‘



 遇到的坑：

 1. 运行时各种各样的依赖缺失
 比如：
 [torstan@sparkb5-i ~/akka_example/remote_service/client]$ ./run.sh
 Exception in thread "main" java.lang.ClassNotFoundException: akka.remote.RemoteActorRefProvider
 at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
 at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
 at java.security.AccessController.doPrivileged(Native Method)
 at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
 at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
 at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
 at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
 at java.lang.Class.forName0(Native Method)
 at java.lang.Class.forName(Class.java:270)
 at akka.actor.ReflectiveDynamicAccess$$anonfun$getClassFor$1.apply(DynamicAccess.scala:68)
 at akka.actor.ReflectiveDynamicAccess$$anonfun$getClassFor$1.apply(DynamicAccess.scala:67)
 at scala.util.Try$.apply(Try.scala:161)

 google到答案是没有加载依赖文件akka-remote.jar，后来发现是没有安装akka。



 2. Exception in thread "main" java.lang.NoSuchMethodException: akka.remote.RemoteActorRefProvider.<init>(java.lang.String, akka.actor.ActorSystem$Settings, akka.event.EventStream, akka.actor.Scheduler, akka.actor.DynamicAccess

 google到答案：


 12 maj 2014 kl. 22:55 skrev Liang Tang <liang...@gmail.com>:
 - show quoted text -
 Yes, Scala 2.10 comes with Akka 2.1.0, which is not binary compatible with Akka 2.3.2. I recommend using sbt to resolve the dependencies instead of manually constructing a command line, i.e. using the runMain task.

 Regards,

 Roland
 https://groups.google.com/forum/#!topic/akka-user/zibfABh4cs8

 因为安装的scala版本scala-2.10.4与akka的版本akka-2.2.4不兼容，scala-2.10.4应该与akka-2.1.4配套使用。


==============

内置状态转换Procedure


在actor运行过程中，可能会有多种状态，各个状态间可能会存在切换的情况，

akka已经帮我们考虑到这种情况情况的处理:Procedure.


下面模拟一个婴儿。

婴儿有两种不同的状态，

开心和生气，

婴儿有个特点就是好玩，永远不会累，

所以让其睡觉婴儿就会生气，

让他继续玩就会很高兴。

package akka;

import akka.actor.*;
import akka.event.Logging;
import akka.event.LoggingAdapter;
import akka.japi.Procedure;
import com.typesafe.config.ConfigFactory;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class ProcedureTest extends UntypedActor {

    private final LoggingAdapter log = Logging.getLogger(getContext().system(), this);

    Procedure<Object> happy = new Procedure<Object>() {
        @Override
        public void apply(Object o) throws Exception {
            log.info("i am happy! " + o);
            if (o == Msg.PLAY) {
                getSender().tell("i am alrady happy!!", getSelf());
                log.info("i am alrady happy!!");
            } else if (o == Msg.SLEEP) {
                log.info("i do not like sleep!");
                getContext().become(angray);
            } else {
                unhandled(o);
            }
        }
    };

    Procedure<Object> angray = new Procedure<Object>() {
        @Override
        public void apply(Object o) throws Exception {
            log.info("i am angray! "+o);
            if(o ==Msg.SLEEP){
                getSender().tell("i am alrady angray!!", getSelf());
                log.info("i am alrady angray!!");
            } else if(o ==Msg.PLAY) {
                log.info("i like play.");
                getContext().become(happy);
            } else {
                unhandled(o);
            }
        }
    };


    @Override
    public void onReceive(Object o) throws Throwable {
        log.info("onReceive msg: " + o);
        if(o == Msg.SLEEP){
            getContext().become(angray);
        }else if(o == Msg.PLAY){
            getContext().become(happy);
        }else {
            unhandled(o);
        }

    }



    public static void main(String[] args) throws InterruptedException {
        ActorSystem system = ActorSystem.create("strategy", ConfigFactory.load("akka.config"));
        ActorRef procedureTest = system.actorOf(Props.create(ProcedureTest.class), "ProcedureTest");

        procedureTest.tell(Msg.PLAY, ActorRef.noSender());
        procedureTest.tell(Msg.SLEEP, ActorRef.noSender());
        procedureTest.tell(Msg.PLAY, ActorRef.noSender());
        procedureTest.tell(Msg.PLAY, ActorRef.noSender());

        procedureTest.tell(PoisonPill.getInstance(), ActorRef.noSender());
    }
}
输出结果：

[INFO] [01/16/2017 15:50:53.967] [strategy-akka.actor.default-dispatcher-2] [akka://strategy/user/ProcedureTest] onReceive msg: PLAY
[INFO] [01/16/2017 15:50:54.000] [strategy-akka.actor.default-dispatcher-2] [akka://strategy/user/ProcedureTest] i am happy! SLEEP
[INFO] [01/16/2017 15:50:54.000] [strategy-akka.actor.default-dispatcher-2] [akka://strategy/user/ProcedureTest] i do not like sleep!
[INFO] [01/16/2017 15:50:54.000] [strategy-akka.actor.default-dispatcher-2] [akka://strategy/user/ProcedureTest] i am angray! PLAY
[INFO] [01/16/2017 15:50:54.000] [strategy-akka.actor.default-dispatcher-2] [akka://strategy/user/ProcedureTest] i like play.
[INFO] [01/16/2017 15:50:54.000] [strategy-akka.actor.default-dispatcher-2] [akka://strategy/user/ProcedureTest] i am happy! PLAY
[INFO] [01/16/2017 15:50:54.004] [strategy-akka.actor.default-dispatcher-2] [akka://strategy/user/ProcedureTest] i am alrady happy!!

akka.ProcedureTest#onReceive这个方法只被调用一次，只有的切换均在procedure中处理，所以在实际开发过程中要注意状态切换的准确性。
参考资料

书籍《java高并发程序设计》
AKKA官方文档


============
有限状态机


AKKA 笔记 - 有限状态机 -2
原文地址： http://rerun.me/2016/05/22/akka-notes-finite-state-machines-2/

在上一节的Akka FSM笔记中，我们看了一些基本的使用Akka FSM和咖啡机的使用方式 - Actor的数据结构和一队我们要发给Actor的消息。这次的第二部分也是最终部分，我们会过一遍这些状态的实现细节。

总结
作为一个快速的总结，让我们先看一下FMS的结构和我们要发过去的消息。

状态和数据
FSM的三个状态和要在各个状态发送的数据是：

object CoffeeMachine {

  sealed trait MachineState
  case object Open extends MachineState
  case object ReadyToBuy extends MachineState
  case object PoweredOff extends MachineState

  case class MachineData(currentTxTotal: Int, costOfCoffee: Int, coffeesLeft: Int)

}
消息
我们发给FSM的咖啡机和用户交互的消息是：

object CoffeeProtocol {

  trait UserInteraction
  trait VendorInteraction

  case class   Deposit(value: Int) extends UserInteraction
  case class   Balance(value: Int) extends UserInteraction
  case object  Cancel extends UserInteraction
  case object  BrewCoffee extends UserInteraction
  case object  GetCostOfCoffee extends UserInteraction

  case object  ShutDownMachine extends VendorInteraction
  case object  StartUpMachine extends VendorInteraction
  case class   SetNumberOfCoffee(quantity: Int) extends VendorInteraction
  case class   SetCostOfCoffee(price: Int) extends VendorInteraction
  case object  GetNumberOfCoffee extends VendorInteraction

  case class   MachineError(errorMsg:String)

}
FSM ACTOR的结构
这是我们在第一节看到的大致结构：

class CoffeeMachine extends FSM[MachineState, MachineData] {

  //What State and Data must this FSM start with (duh!)
  startWith(Open, MachineData(..))

  //Handlers of State
  when(Open) {
  ...
  ...

  when(ReadyToBuy) {
  ...
  ...

  when(PoweredOff) {
  ...
  ...

  //fallback handler when an Event is unhandled by none of the States.
  whenUnhandled {
  ...
  ...

  //Do we need to do something when there is a State change?
  onTransition {
    case Open -> ReadyToBuy => ...
  ...
  ...
}
状态初始化
跟其他状态机一样， FSM在启动时需要一个初始化状态。这个可以在Akka FSM内声明一个叫startWith的方法来实现。startWith接受两个参数 - 初始化状态和初始化数据。

class CoffeeMachine extends FSM[MachineState, MachineData] {

  startWith(Open, MachineData(currentTxTotal = 0, costOfCoffee =  5, coffeesLeft = 10))

...
...
以上代码说明了FSM的初始化状态是Open并且当咖啡机Open时的初始化数据是

MachineData(currentTxTotal = 0, costOfCoffee = 5, coffeesLeft = 10).
当机器启动时，咖啡机是一个干净的状态。它跟用户还没有任何交互，当前的余额是0。咖啡的价格呗设置成5元，总共能提供的咖啡设置为10杯。当咖啡机冲了10杯咖啡后数量为0时，咖啡机会shut down。

状态的实现
终于到最后了！！

我觉得最简单的方式来看咖啡机状态的交互就是给交互做个分组，为FSM的实现写测试用例。

如果你看下github的代码，所有的测试用例都在CoffeeSpec并且FSM在CoffeeMachine

以下所有的测试都被CoffeeSpec测试类包装了，声明就像这样：

class CoffeeSpec extends TestKit(ActorSystem("coffee-system")) with MustMatchers with FunSpecLike with ImplicitSender
设置并得到咖啡的价格

像我们之前看到的，MachineData初始化时设置为每杯咖啡5元并总数为10杯。这只是一个初始状态，咖啡机必须能在任何时候设置咖啡的价格和能提供的数量。

通过发送SetCostOfCoffee消息给Actor可以设置价格。我们也应该能拿到咖啡的价格。这个可以通过发送GetCostOfCoffee消息给机器来获得。

测试用例

describe("The Coffee Machine") {

   it("should allow setting and getting of price of coffee") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(7)
      coffeeMachine ! GetCostOfCoffee
      expectMsg(7)
    }
...
...
...
实现

像我们在第一节讨论的，所有发给FSM的消息都被包装成Event类，并且也被MachineData包装：

 when(Open) {
     case Event(SetCostOfCoffee(price), _) => stay using stateData.copy(costOfCoffee = price)
    case Event(GetCostOfCoffee, _) => sender ! (stateData.costOfCoffee); stay()
   ...
   ...
  }
}
以上代码有几个新词 - stay,using和stateData,让我们下面看下。

STAY和GOTO

想法是每一个被阻塞的case都必须返回一个State。这个可以用stay来完成，含义是已经在处理这条消息的最后了（SetCostOfCoffee或GetCostOfCoffee),咖啡机还在用一个状态，在这里是Open状态。

goto， 将状态变为另一个。我们在讨论Deposit时能看到它是怎么做的。

没啥奇怪的，看下stay方法的实现：

  final def stay(): State = goto(currentState.stateName)
USING

你可能已经猜到了，using方法可以让我们把改过的数据传给下个状态。在SetCostOfCoffee消息的例子里，我们设置了MachineData的costOfCoffee域。由于状态是个用例的例子（强烈建议使用不可变除非你喜欢debug），我们做了个copy。

状态数据STATEDATA

stateData是一个我们用来操作FSM数据的方法，就是MachineData。 所以，以下代码块是等价的

case Event(GetCostOfCoffee, _) => sender ! (stateData.costOfCoffee); stay()
case Event(GetCostOfCoffee, machineData) => sender ! (machineData.costOfCoffee); stay()
用GetNumberOfCoffee和SetNumberOfCoffee设置最大咖啡数的实现几乎与设置价格的方法差不多。我们先跳过这个来到更有趣的部分 - 买咖啡。

买咖啡

当咖啡爱好者为咖啡交了钱，我们还不能让咖啡机做咖啡，要等到得到了一杯咖啡的钱才行。而且如果多给了现金，我们还要找零钱，所以，例子会变成这样：

直到用户开始存钱了，我们开始追踪他的存款并stay在Open状态。
2.当现金数达到一杯咖啡的钱了，我们会转移成ReadyToBuy状态并允许他买咖啡。
在ReadyToBuy状态，他可以改变主意Cancel取消这次交易并拿到所有的退款Balance。
如果他想要喝咖啡，它发给咖啡机BrewCoffee煮咖啡的消息。（事实上，我们的代码里并不会分发咖啡。我们只是从用户的存款里减掉了咖啡的价格并找零。）
让我们看下以下的用例

用例1 用户存钱单但存的钱低于咖啡的价格

用例开始设置咖啡的价格为5元并且咖啡总数为10。 我们存2元并检查机器是不是在Open状态并且咖啡总数仍然是10.

 it("should stay at Transacting when the Deposit is less then the price of the coffee") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(5)
      coffeeMachine ! SetNumberOfCoffee(10)
      coffeeMachine ! SubscribeTransitionCallBack(testActor)

      expectMsg(CurrentState(coffeeMachine, Open))

      coffeeMachine ! Deposit(2)

      coffeeMachine ! GetNumberOfCoffee

      expectMsg(10)
    }
我们怎样确保机器在Open状态？

每个FSM都能处理一条叫FSM.SubscribeTransitionCallBack(callerActorRef)的特殊消息，能让调用者在任何状态变动时被通知。第一条发给订阅者的通知消息是CurrentState， 告诉我们FSM在哪个状态。 这之后会有若干条Transition消息。

实现

我们继续存钱并维持在Open状态并等待存更多的钱

when(Open) {
...
...
  case Event(Deposit(value), MachineData(currentTxTotal, costOfCoffee, coffeesLeft)) if (value + currentTxTotal) < stateData.costOfCoffee => {
        val cumulativeValue = currentTxTotal + value
        stay using stateData.copy(currentTxTotal = cumulativeValue)
  }
用例2和4 - 用户存钱并达到咖啡的价钱

测试用例1 - 存与咖啡价格等值的钱

我们的用例启动机器，确认是否当前状态是Open并存5元钱。 我们之后假定机器状态从Open到ReadyToBuy，这可以通过接受一条Transition消息来证明咖啡机状态的变更。在第一个例子，转换是从Open到ReadyToBuy。

下一步我们让凯飞机BrewCoffee煮咖啡，这时应该会有一条转换，ReadToBuy到Open。 最终我们断言咖啡机中的数量（就是9）。

it("should transition to ReadyToBuy and then Open when the Deposit is equal to the price of the coffee") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(5)
      coffeeMachine ! SetNumberOfCoffee(10)
      coffeeMachine ! SubscribeTransitionCallBack(testActor)

      expectMsg(CurrentState(coffeeMachine, Open))

      coffeeMachine ! Deposit(5)

      expectMsg(Transition(coffeeMachine, Open, ReadyToBuy))

      coffeeMachine ! BrewCoffee
      expectMsg(Transition(coffeeMachine, ReadyToBuy, Open))

      coffeeMachine ! GetNumberOfCoffee

      expectMsg(9)
    }
测试用例2 - 存大于咖啡价格的钱

第二个例子跟第一个比有90%一样，除了我们存在钱更多了（是6元）。 因为我们把咖啡价格设为5元， 现在我们期望应该有一块钱的Balance找零消息

it("should transition to ReadyToBuy and then Open when the Deposit is greater than the price of the coffee") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(5)
      coffeeMachine ! SetNumberOfCoffee(10)
      coffeeMachine ! SubscribeTransitionCallBack(testActor)

      expectMsg(CurrentState(coffeeMachine, Open))

      coffeeMachine ! Deposit(2)
      coffeeMachine ! Deposit(2)
      coffeeMachine ! Deposit(2)

      expectMsg(Transition(coffeeMachine, Open, ReadyToBuy))

      coffeeMachine ! BrewCoffee

      expectMsgPF(){
        case Balance(value)=>value==1
      }

      expectMsg(Transition(coffeeMachine, ReadyToBuy, Open))

      coffeeMachine ! GetNumberOfCoffee

      expectMsg(9)
    }
实现

这个实现比之前的测试用例简单。如果存款大于咖啡价格，那么我们转到goto ReadyToBuy状态。

when(Open){
...
...
 case Event(Deposit(value), MachineData(currentTxTotal, costOfCoffee, coffeesLeft)) if (value + currentTxTotal) >= stateData.costOfCoffee => {
      goto(ReadyToBuy) using stateData.copy(currentTxTotal = currentTxTotal + value)
    }
一旦转到ReadyToBuy状态， 当用户发送BrewCoffee，我们检查是否有零钱找零。

  when(ReadyToBuy) {
    case Event(BrewCoffee, MachineData(currentTxTotal, costOfCoffee, coffeesLeft)) => {
      val balanceToBeDispensed = currentTxTotal - costOfCoffee
      logger.debug(s"Balance is $balanceToBeDispensed")
      if (balanceToBeDispensed > 0) {
        sender ! Balance(value = balanceToBeDispensed)
        goto(Open) using stateData.copy(currentTxTotal = 0, coffeesLeft = coffeesLeft - 1)
      }
      else goto(Open) using stateData.copy(currentTxTotal = 0, coffeesLeft = coffeesLeft - 1)
    }
  }
用例3 用户要取消交易

实际上， 用户应该可以在交易的任何时间点Cancel取消，无论他在什么状态。我们之前在第一部分讨论过，最好的保存这里通用消息的地方在whenUnhandled代码块。我们要确定用户在取消前是否存了一些钱，我们要还给他们。

实现

  whenUnhandled {
  ...
  ...
    case Event(Cancel, MachineData(currentTxTotal, _, _)) => {
      sender ! Balance(value = currentTxTotal)
      goto(Open) using stateData.copy(currentTxTotal = 0)
    }
  }
测试用例

这个例子跟我们以上看到的差不多，除了找零。

 it("should transition to Open after flushing out all the deposit when the coffee is canceled") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(5)
      coffeeMachine ! SetNumberOfCoffee(10)
      coffeeMachine ! SubscribeTransitionCallBack(testActor)

      expectMsg(CurrentState(coffeeMachine, Open))

      coffeeMachine ! Deposit(2)
      coffeeMachine ! Deposit(2)
      coffeeMachine ! Deposit(2)

      expectMsg(Transition(coffeeMachine, Open, ReadyToBuy))

      coffeeMachine ! Cancel

      expectMsgPF(){
        case Balance(value)=>value==6
      }

      expectMsg(Transition(coffeeMachine, ReadyToBuy, Open))

      coffeeMachine ! GetNumberOfCoffee

      expectMsg(10)
    }
代码

我不想烦死你所以跳过了解释ShutDownMachine消息和PowerOff状态，如果你想要解释，可以留言。

像之前一样，代码在github

====================================================

在上一节的Akka FSM笔记中，我们看了一些基本的使用Akka FSM和咖啡机的使用方式 - Actor的数据结构和一队我们要发给Actor的消息。这次的第二部分也是最终部分，我们会过一遍这些状态的实现细节。

总结
作为一个快速的总结，让我们先看一下FMS的结构和我们要发过去的消息。

状态和数据
FSM的三个状态和要在各个状态发送的数据是：

object CoffeeMachine {

  sealed trait MachineState
  case object Open extends MachineState
  case object ReadyToBuy extends MachineState
  case object PoweredOff extends MachineState

  case class MachineData(currentTxTotal: Int, costOfCoffee: Int, coffeesLeft: Int)

}
消息
我们发给FSM的咖啡机和用户交互的消息是：

object CoffeeProtocol {

  trait UserInteraction
  trait VendorInteraction

  case class   Deposit(value: Int) extends UserInteraction
  case class   Balance(value: Int) extends UserInteraction
  case object  Cancel extends UserInteraction
  case object  BrewCoffee extends UserInteraction
  case object  GetCostOfCoffee extends UserInteraction

  case object  ShutDownMachine extends VendorInteraction
  case object  StartUpMachine extends VendorInteraction
  case class   SetNumberOfCoffee(quantity: Int) extends VendorInteraction
  case class   SetCostOfCoffee(price: Int) extends VendorInteraction
  case object  GetNumberOfCoffee extends VendorInteraction

  case class   MachineError(errorMsg:String)

}
FSM ACTOR的结构
这是我们在第一节看到的大致结构：

class CoffeeMachine extends FSM[MachineState, MachineData] {

  //What State and Data must this FSM start with (duh!)
  startWith(Open, MachineData(..))

  //Handlers of State
  when(Open) {
  ...
  ...

  when(ReadyToBuy) {
  ...
  ...

  when(PoweredOff) {
  ...
  ...

  //fallback handler when an Event is unhandled by none of the States.
  whenUnhandled {
  ...
  ...

  //Do we need to do something when there is a State change?
  onTransition {
    case Open -> ReadyToBuy => ...
  ...
  ...
}
状态初始化
跟其他状态机一样， FSM在启动时需要一个初始化状态。这个可以在Akka FSM内声明一个叫startWith的方法来实现。startWith接受两个参数 - 初始化状态和初始化数据。

class CoffeeMachine extends FSM[MachineState, MachineData] {

  startWith(Open, MachineData(currentTxTotal = 0, costOfCoffee =  5, coffeesLeft = 10))

...
...
以上代码说明了FSM的初始化状态是Open并且当咖啡机Open时的初始化数据是

MachineData(currentTxTotal = 0, costOfCoffee = 5, coffeesLeft = 10).
当机器启动时，咖啡机是一个干净的状态。它跟用户还没有任何交互，当前的余额是0。咖啡的价格呗设置成5元，总共能提供的咖啡设置为10杯。当咖啡机冲了10杯咖啡后数量为0时，咖啡机会shut down。

状态的实现
终于到最后了！！

我觉得最简单的方式来看咖啡机状态的交互就是给交互做个分组，为FSM的实现写测试用例。

如果你看下github的代码，所有的测试用例都在CoffeeSpec并且FSM在CoffeeMachine

以下所有的测试都被CoffeeSpec测试类包装了，声明就像这样：

class CoffeeSpec extends TestKit(ActorSystem("coffee-system")) with MustMatchers with FunSpecLike with ImplicitSender
设置并得到咖啡的价格

像我们之前看到的，MachineData初始化时设置为每杯咖啡5元并总数为10杯。这只是一个初始状态，咖啡机必须能在任何时候设置咖啡的价格和能提供的数量。

通过发送SetCostOfCoffee消息给Actor可以设置价格。我们也应该能拿到咖啡的价格。这个可以通过发送GetCostOfCoffee消息给机器来获得。

测试用例

describe("The Coffee Machine") {

   it("should allow setting and getting of price of coffee") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(7)
      coffeeMachine ! GetCostOfCoffee
      expectMsg(7)
    }
...
...
...
实现

像我们在第一节讨论的，所有发给FSM的消息都被包装成Event类，并且也被MachineData包装：

 when(Open) {
     case Event(SetCostOfCoffee(price), _) => stay using stateData.copy(costOfCoffee = price)
    case Event(GetCostOfCoffee, _) => sender ! (stateData.costOfCoffee); stay()
   ...
   ...
  }
}
以上代码有几个新词 - stay,using和stateData,让我们下面看下。

STAY和GOTO

想法是每一个被阻塞的case都必须返回一个State。这个可以用stay来完成，含义是已经在处理这条消息的最后了（SetCostOfCoffee或GetCostOfCoffee),咖啡机还在用一个状态，在这里是Open状态。

goto， 将状态变为另一个。我们在讨论Deposit时能看到它是怎么做的。

没啥奇怪的，看下stay方法的实现：

  final def stay(): State = goto(currentState.stateName)
USING

你可能已经猜到了，using方法可以让我们把改过的数据传给下个状态。在SetCostOfCoffee消息的例子里，我们设置了MachineData的costOfCoffee域。由于状态是个用例的例子（强烈建议使用不可变除非你喜欢debug），我们做了个copy。

状态数据STATEDATA

stateData是一个我们用来操作FSM数据的方法，就是MachineData。 所以，以下代码块是等价的

case Event(GetCostOfCoffee, _) => sender ! (stateData.costOfCoffee); stay()
case Event(GetCostOfCoffee, machineData) => sender ! (machineData.costOfCoffee); stay()
用GetNumberOfCoffee和SetNumberOfCoffee设置最大咖啡数的实现几乎与设置价格的方法差不多。我们先跳过这个来到更有趣的部分 - 买咖啡。

买咖啡

当咖啡爱好者为咖啡交了钱，我们还不能让咖啡机做咖啡，要等到得到了一杯咖啡的钱才行。而且如果多给了现金，我们还要找零钱，所以，例子会变成这样：

直到用户开始存钱了，我们开始追踪他的存款并stay在Open状态。
2.当现金数达到一杯咖啡的钱了，我们会转移成ReadyToBuy状态并允许他买咖啡。
在ReadyToBuy状态，他可以改变主意Cancel取消这次交易并拿到所有的退款Balance。
如果他想要喝咖啡，它发给咖啡机BrewCoffee煮咖啡的消息。（事实上，我们的代码里并不会分发咖啡。我们只是从用户的存款里减掉了咖啡的价格并找零。）
让我们看下以下的用例

用例1 用户存钱单但存的钱低于咖啡的价格

用例开始设置咖啡的价格为5元并且咖啡总数为10。 我们存2元并检查机器是不是在Open状态并且咖啡总数仍然是10.

 it("should stay at Transacting when the Deposit is less then the price of the coffee") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(5)
      coffeeMachine ! SetNumberOfCoffee(10)
      coffeeMachine ! SubscribeTransitionCallBack(testActor)

      expectMsg(CurrentState(coffeeMachine, Open))

      coffeeMachine ! Deposit(2)

      coffeeMachine ! GetNumberOfCoffee

      expectMsg(10)
    }
我们怎样确保机器在Open状态？

每个FSM都能处理一条叫FSM.SubscribeTransitionCallBack(callerActorRef)的特殊消息，能让调用者在任何状态变动时被通知。第一条发给订阅者的通知消息是CurrentState， 告诉我们FSM在哪个状态。 这之后会有若干条Transition消息。

实现

我们继续存钱并维持在Open状态并等待存更多的钱

when(Open) {
...
...
  case Event(Deposit(value), MachineData(currentTxTotal, costOfCoffee, coffeesLeft)) if (value + currentTxTotal) < stateData.costOfCoffee => {
        val cumulativeValue = currentTxTotal + value
        stay using stateData.copy(currentTxTotal = cumulativeValue)
  }
用例2和4 - 用户存钱并达到咖啡的价钱

测试用例1 - 存与咖啡价格等值的钱

我们的用例启动机器，确认是否当前状态是Open并存5元钱。 我们之后假定机器状态从Open到ReadyToBuy，这可以通过接受一条Transition消息来证明咖啡机状态的变更。在第一个例子，转换是从Open到ReadyToBuy。

下一步我们让凯飞机BrewCoffee煮咖啡，这时应该会有一条转换，ReadToBuy到Open。 最终我们断言咖啡机中的数量（就是9）。

it("should transition to ReadyToBuy and then Open when the Deposit is equal to the price of the coffee") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(5)
      coffeeMachine ! SetNumberOfCoffee(10)
      coffeeMachine ! SubscribeTransitionCallBack(testActor)

      expectMsg(CurrentState(coffeeMachine, Open))

      coffeeMachine ! Deposit(5)

      expectMsg(Transition(coffeeMachine, Open, ReadyToBuy))

      coffeeMachine ! BrewCoffee
      expectMsg(Transition(coffeeMachine, ReadyToBuy, Open))

      coffeeMachine ! GetNumberOfCoffee

      expectMsg(9)
    }
测试用例2 - 存大于咖啡价格的钱

第二个例子跟第一个比有90%一样，除了我们存在钱更多了（是6元）。 因为我们把咖啡价格设为5元， 现在我们期望应该有一块钱的Balance找零消息

it("should transition to ReadyToBuy and then Open when the Deposit is greater than the price of the coffee") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(5)
      coffeeMachine ! SetNumberOfCoffee(10)
      coffeeMachine ! SubscribeTransitionCallBack(testActor)

      expectMsg(CurrentState(coffeeMachine, Open))

      coffeeMachine ! Deposit(2)
      coffeeMachine ! Deposit(2)
      coffeeMachine ! Deposit(2)

      expectMsg(Transition(coffeeMachine, Open, ReadyToBuy))

      coffeeMachine ! BrewCoffee

      expectMsgPF(){
        case Balance(value)=>value==1
      }

      expectMsg(Transition(coffeeMachine, ReadyToBuy, Open))

      coffeeMachine ! GetNumberOfCoffee

      expectMsg(9)
    }
实现

这个实现比之前的测试用例简单。如果存款大于咖啡价格，那么我们转到goto ReadyToBuy状态。

when(Open){
...
...
 case Event(Deposit(value), MachineData(currentTxTotal, costOfCoffee, coffeesLeft)) if (value + currentTxTotal) >= stateData.costOfCoffee => {
      goto(ReadyToBuy) using stateData.copy(currentTxTotal = currentTxTotal + value)
    }
一旦转到ReadyToBuy状态， 当用户发送BrewCoffee，我们检查是否有零钱找零。

  when(ReadyToBuy) {
    case Event(BrewCoffee, MachineData(currentTxTotal, costOfCoffee, coffeesLeft)) => {
      val balanceToBeDispensed = currentTxTotal - costOfCoffee
      logger.debug(s"Balance is $balanceToBeDispensed")
      if (balanceToBeDispensed > 0) {
        sender ! Balance(value = balanceToBeDispensed)
        goto(Open) using stateData.copy(currentTxTotal = 0, coffeesLeft = coffeesLeft - 1)
      }
      else goto(Open) using stateData.copy(currentTxTotal = 0, coffeesLeft = coffeesLeft - 1)
    }
  }
用例3 用户要取消交易

实际上， 用户应该可以在交易的任何时间点Cancel取消，无论他在什么状态。我们之前在第一部分讨论过，最好的保存这里通用消息的地方在whenUnhandled代码块。我们要确定用户在取消前是否存了一些钱，我们要还给他们。

实现

  whenUnhandled {
  ...
  ...
    case Event(Cancel, MachineData(currentTxTotal, _, _)) => {
      sender ! Balance(value = currentTxTotal)
      goto(Open) using stateData.copy(currentTxTotal = 0)
    }
  }
测试用例

这个例子跟我们以上看到的差不多，除了找零。

 it("should transition to Open after flushing out all the deposit when the coffee is canceled") {
      val coffeeMachine = TestActorRef(Props(new CoffeeMachine()))
      coffeeMachine ! SetCostOfCoffee(5)
      coffeeMachine ! SetNumberOfCoffee(10)
      coffeeMachine ! SubscribeTransitionCallBack(testActor)

      expectMsg(CurrentState(coffeeMachine, Open))

      coffeeMachine ! Deposit(2)
      coffeeMachine ! Deposit(2)
      coffeeMachine ! Deposit(2)

      expectMsg(Transition(coffeeMachine, Open, ReadyToBuy))

      coffeeMachine ! Cancel

      expectMsgPF(){
        case Balance(value)=>value==6
      }

      expectMsg(Transition(coffeeMachine, ReadyToBuy, Open))

      coffeeMachine ! GetNumberOfCoffee

      expectMsg(10)
    }
代码

我不想烦死你所以跳过了解释ShutDownMachine消息和PowerOff状态，如果你想要解释，可以留言。

像之前一样，代码在github

===========
概述

Akka框架基本要点介绍
 2015-08-12 23:43:38    Yanjun
Akka基于Actor模型，提供了一个用于构建可扩展的（Scalable）、弹性的（Resilient）、快速响应的（Responsive）应用程序的平台。本文基本上是基于Akka的官方文档（版本是2.3.12），通过自己的理解，来阐述Akka提供的一些组件或概念，另外总结了Akka的一些使用场景。

Actor

维基百科这样定义Actor模型：

在计算科学领域，Actor模型是一个并行计算（Concurrent Computation）模型，它把actor作为并行计算的基本元素来对待：为响应一个接收到的消息，一个actor能够自己做出一些决策，如创建更多的actor，或发送更多的消息，或者确定如何去响应接收到的下一个消息。
Actor是Akka中最核心的概念，它是一个封装了状态和行为的对象，Actor之间可以通过交换消息的方式进行通信，每个Actor都有自己的收件箱（Mailbox）。
通过Actor能够简化锁及线程管理，可以非常容易地开发出正确地并发程序和并行系统，Actor具有如下特性：

提供了一种高级抽象，能够简化在并发（Concurrency）/并行（Parallelism）应用场景下的编程开发
提供了异步非阻塞的、高性能的事件驱动编程模型
超级轻量级事件处理（每GB堆内存几百万Actor）
实现一个Actor，可以继承特质akka.actor.Actor，实现一个receive方法，应该在receive方法中定义一系列的case语句，基于标准Scala的模式匹配方法，来实现每一种消息的处理逻辑。
我们先看一下Akka中特质Actor的定义：

01
trait Actor {
02

03
  import Actor._
04

05
  type Receive = Actor.Receive
06

07
  implicit val context: ActorContext = {
08
    val contextStack = ActorCell.contextStack.get
09
    if ((contextStack.isEmpty) || (contextStack.head eq null))
10
      throw ActorInitializationException(
11
        s"You cannot create an instance of [${getClass.getName}] explicitly using the constructor (new). " +
12
          "You have to use one of the 'actorOf' factory methods to create a new actor. See the documentation.")
13
    val c = contextStack.head
14
    ActorCell.contextStack.set(null :: contextStack)
15
    c
16
  }
17

18
  implicit final val self = context.self //MUST BE A VAL, TRUST ME
19

20
  final def sender(): ActorRef = context.sender()
21

22
  def receive: Actor.Receive // 这个是在子类中一定要实现的抽象方法
23

24
  protected[akka] def aroundReceive(receive: Actor.Receive, msg: Any): Unit = receive.applyOrElse(msg, unhandled)
25

26
  protected[akka] def aroundPreStart(): Unit = preStart()
27

28
  protected[akka] def aroundPostStop(): Unit = postStop()
29

30
  protected[akka] def aroundPreRestart(reason: Throwable, message: Option[Any]): Unit = preRestart(reason, message)
31

32
  protected[akka] def aroundPostRestart(reason: Throwable): Unit = postRestart(reason)
33

34
  def supervisorStrategy: SupervisorStrategy = SupervisorStrategy.defaultStrategy
35

36
  @throws(classOf[Exception]) // when changing this you MUST also change UntypedActorDocTest
37
  def preStart(): Unit = () // 启动Actor之前需要执行的操作，默认为空实现，可以重写该方法
38

39
  @throws(classOf[Exception]) // when changing this you MUST also change UntypedActorDocTest
40
  def postStop(): Unit = () // 终止Actor之前需要执行的操作，默认为空实现，可以重写该方法
41

42
  @throws(classOf[Exception]) // when changing this you MUST also change UntypedActorDocTest
43
  def preRestart(reason: Throwable, message: Option[Any]): Unit = { // 重启Actor之前需要执行的操作，默认终止该Actor所监督的所有子Actor，然后调用postStop()方法，可以重写该方法
44
    context.children foreach { child ⇒
45
      context.unwatch(child)
46
      context.stop(child)
47
    }
48
    postStop()
49
  }
50

51
  @throws(classOf[Exception]) // when changing this you MUST also change UntypedActorDocTest
52
  def postRestart(reason: Throwable): Unit = {  // 重启Actor之前需要执行的操作，默认执行preStart()的实现逻辑，可以重写该方法
53
    preStart()
54
  }
55

56
  def unhandled(message: Any): Unit = {
57
    message match {
58
      case Terminated(dead) ⇒ throw new DeathPactException(dead)
59
      case _                ⇒ context.system.eventStream.publish(UnhandledMessage(message, sender(), self))
60
    }
61
  }
62
}
上面特质中提供了几个Hook，具体说明可以看代码中注释，我们可以在继承该特质时重写Hook方法，实现自己的处理逻辑。
一个Actor是有生命周期（Lifecycle）的，如下图所示：
akka-actor-lifecycle
通过上图我们可以看到，一除了/system路径下面的Actor外，一个Actor初始时路径为空，调用ActorSystem的actorOf方法创建一个Actor实例，返回一个引用ActorRef，它包括一个UID和一个Path，标识了一个Actor，可以通过该引用向该Actor实例发送消息。

ActorSystem

在Akka中，一个ActorSystem是一个重量级的结构，他需要分配多个线程，所以在实际应用中，按照逻辑划分的每个应用对应一个ActorSystem实例。
一个ActorSystem是具有分层结构（Hierarchical Structure）的：一个Actor能够管理（Oversee）某个特定的函数，他可能希望将一个task分解为更小的多个子task，这样它就需要创建多个子Actor（Child Actors），并监督这些子Actor处理任务的进度等详细情况，实际上这个Actor创建了一个Supervisor来监督管理子Actor执行拆分后的多个子task，如果一个子Actor执行子task失败，那么就要向Supervisor发送一个消息说明处理子task失败。需要知道的是，一个Actor能且仅能有一个Supervisor，就是创建它的那个Actor。基于被监控任务的性质和失败的性质，一个Supervisor可以选择执行如下操作选择：

重新开始（Resume）一个子Actor，保持它内部的状态
重启一个子Actor，清除它内部的状态
终止一个子Actor
扩大失败的影响，从而使这个子Actor失败
将一个Actor以一个监督层次结构视图来看是非常重要的，因为它诠释了上面第4种操作选择的存在性，而且对前3种操作选择也有影响：重新开始（Resume）一个Actor，则该Actor的所有子Actor都继续工作；重启一个Actor，则该Actor的所有子Actor都被重新启动；终止一个Actor，则该Actor的所有子Actor都被终止。另外，一个Actor的preRestart方法的默认行为是终止所有子Actor，如果我们不想这样，可以在继承Actor的实现中重写preRestart方法的逻辑。
一个ActorSystem在创建过程中，至少启动3个Actor，如下图所示：
akka-actor-system
上图是一个类似树状层次结构，ActorSystem的Top-Level层次结构，与Actor关联起来，称为Actor路径（Actor Path），不同的路径代表了不同的监督范围（Supervision Scope）。下面说明ActorSystem的监督范围：

“/”路径：通过根路径可以搜索到所有的Actor
“/user”路径：用户创建的Top-Level Actor在该路径下面，通过调用ActorSystem.actorOf来实现Actor的创建
“/system”路径：系统创建的Top-Level Actor在该路径下面
“/deadLetters”路径：消息被发送到已经终止，或者不存在的Actor，这些Actor都在该路径下面
“/temp”路径：被系统临时创建的Actor在该路径下面
“/remote”路径：改路径下存在的Actor，它们的Supervisor都是远程Actor的引用
TypedActor

TypedActor是Akka基于Active对象（Active Object）设计模式的一个实现，关于Active对象模式，可以看维基百科的定义：
Active对象模式解耦了在一个对象上执行方法和调用方法的逻辑，执行方法和调用方法分别在各自的线程执行上下文中。该模式的目标是通过使用异步方法调用和一个调度器来处理请求，从而实现并行计算处理，该模式由6个元素组成：

一个Proxy对象，提供一个面向客户端的接口和一组公共的方法
一个接口，定义了请求一个Active对象上的方法的集合
一个来自客户端请求的列表
一个调度器，确定下一次处理哪一个请求
Active对象上方法的实现
一个回掉或者变量，供客户端接收请求被处理后的结果
通过前面对Actor的了解，我们知道Actor更适用于在Akka的Actor系统之间来实现并行计算处理，而TypedActor适用于桥接Actor系统和非Actor系统。TypedActor是基于JDK的Proxy来实现的，与Actor不同的是，Actor一次处理一个消息，而TypedActor一次处理一个调用（Call）。关于更多关于TypedActor，可以查看Akka文档。

Cluster

Akka Cluster提供了一个容错（Fault-Tolerant）、去中心化（Decentralized）、基于P2P的集群服务，而且不会出现单点故障（SPOF， Single Point Of Failure）。Akka基于Gossip实现集群服务，而且支持服务自动失败检测。
关于Gossip协议的说明，维基百科说明如下所示：

Gossip协议是点对点（Computer-to-Computer）通信协议的一种，它受社交网络中的流言传播的特点所启发。现在分布式系统常常使用Gossip协议来解决其他方式所无法解决的问题，或者是由于底层网络的超大特殊结构，或者是因为Gossip方案是解决这类问题最有效的一种方式。
一个Akka集群由一组成员节点组成，每个成员节点通过hostname:port:uid来唯一标识，并且每个成员节点之间是解耦合的（Decoupled）。一个Akka应用程序是一个分布式应用程序，它具有一个Actor的集合S，而每个节点上可以启动这个Akka应用S的集合的的一部分Actor，而不必是全集S。如果一个新的成员节点需要加入到Akka集群，只需要在集群中任意一个成员节点上执行Join命令即可。
Akka集群中各个成员节点之间的状态关系，如下图所示：
akka-cluster
Akka集群中任何一个成员节点都有可能成为集群的Leader，这是基于Gossip收敛（Convergence）过程得到的确定性结果，没有经过选举的过程。Leader只是一种角色，在各轮Gossip收敛过程中Leader是不断变化的。Leader的职责是使成员节点进入/离开集群。
一个成员节点开始于joining状态，一旦所有其节点都看到了该新加入Akka集群的节点，则Leader会设置这个节点的状态为up。
如果一个节点安全离开Akka集群，可预期地它的状态会变为leaving状态，当Leader看到该节点为leaving状态，会将其状态修改为exiting，然后当所有节点看到该节点状态为exiting，则Leader将该节点移除，状态修改为removed状态。
如果一个节点处于unreachable状态，基于Gossip协议Leader是无法执行任何操作收敛（Convergence）到该节点的，所以unreachable状态的节点的状态是必须被改变的，它必须变成reachable状态或者down状态。如果该节点想再次加入到Akka集群，它必须需要重新启动，并且重新加入集群（经由joining状态）。

Remoting

Akka Remoting的设计目标是基于P2P风格的网络通信，所以它存在如下限制：

不支持NAT（Network Address Translation）
不支持负载均衡器（Load Balancers）
Akka提供了种方式来使用Remoting功能：

通过调用actorSelection方法搜索一个actor，该方法输入的参数的模式为：akka.<protocol>://<actor system>@<hostname>:<port>/<actor path>
通过actorOf方法创建一个actor
下面看一下Remoting系统中故障恢复模型（Failure Recovery Model），如下图所示：
akka-remoting
上图中，连接到一个远程系统的过程中，包括上面4种状态：在进行任何通信之前，系统处于Idle状态；当第一次一个消息尝试向远程系统发送，或者当远程系统连接过来，这时系统状态变为Active；当两个系统通信失败，连接丢失，这时系统变为Gated状态；当系统通信过程中，由于参与通信的系统的状态不一致导致系统无法恢复，这时远程系统变为Quarantined状态，只有重新启动系统才能恢复，重启后系统变为Active状态。

Persistence

Akka的持久性能够使得有状态的Actor实例保存它的内部状态，在Actor重启后能够更快的进行恢复。需要强调的是，持久化的仅仅是Actor的内部状态，而不是Actor当前的状态，Actor内部状态的变化会被一追加的方式存到到指定的存储中，一旦追加完成存储状态，这些数据就不会被更新。有状态的Actor通过重放（Replay）持久化的状态来快速恢复，重建内部状态。
Akka Persistence的架构有如下几个要点：

PersistentActor
它是一个持久的、有状态的Actor，能够将持久化消息到一个日志系统中。当一个PersistentActor重启的时候，它能够重放记录到日志系统中的消息，从而基于这些消息来恢复一个Actor的内部状态。

PersistentView
持久化视图是一个持久的有状态的Actor，它接收被记录到一个PersistentActor中的消息，但是它本身并不记录消息到日志系统，而是通过复制一个PersistentActor的消息流，来更新自己内部状态。

AtLeastOnceDelivery
提供了一个消息至少传递一次（At-Lease-Once）的语义，在发送者和接收者所在的JVM崩溃的时候，将消息传递到目的地。

Journal
一个日志系统存储发送给一个PersistentActor的消息序列，可以在应用程序中控制是否一个PersistentActor将消息序列记录到日志中。日志系统是支持插件式的，默认情况下，消息被记录到本地文件系统中。

Akka Camel

Akka提供了一个模块，能够与Apache Camel整合。Apache Camel是一个实现了EIP（Enterprise Integration Patterns）的整合框架，支持通过各种各样的协议进行消息交换。所以Akka的Actor可以通过Scala或Java API与其它系统进行通信，协议比如HTTP、SOAP、TCP、FTP、SMTP、JMS。

Akka适用场景

事务处理（Transaction Processing）
在线游戏系统、金融/银行系统、交易系统、投注系统、社交媒体系统、电信服务系统。

后端服务（Service Backend）
任何行业的任何类型的应用都可以使用，比如提供REST、SOAP等风格的服务，类似于一个服务总线，Akka支持纵向&横向扩展，以及容错/高可用（HA）的特性。

并行计算（Concurrency/Parallelism）
任何具有并发/并行计算需求的行业，基于JVM的应用都可以使用，如使用编程语言Scala、Java、Groovy、JRuby开发。

仿真
Master/Slave架构风格的计算系统、计算网格系统、MapReduce系统。

通信Hub（Communications Hub）
电信系统、Web媒体系统、手机媒体系统。

复杂事件流处理（Complex Event Stream Processing）
Akka本身提供的Actor就适合处理基于事件驱动的应用，所以可以更加容易处理具有复杂事件流的应用。


Akka还支持很多其它特性，如下所示：

支持Future，可以同步或异步地获取发送消息的结果

支持基于事件的Dispatcher，将多个Actor与一个线程池绑定

支持消息路由，可以提供不同的消息路由策略，如Akka支持如下策略：

RoundRobinRoutingLogic、RandomRoutingLogic、SmallestMailboxRoutingLogic、BroadcastRoutingLogic、ScatterGatherFirstCompletedRoutingLogic、TailChoppingRoutingLogic、ConsistentHashingRoutingLogic

支持FSM，提供基于事件的状态转移





多核处理器的出现使并发编程（Concurrent Programming）成为开发人员必备的一项技能，许多现代编程语言都致力于解决并发编程问题。并发编程虽然能够提高程序的性能，但传统并发编程的共享内存通信机制对开发人员的编程技能要求很高，需要开发人员通过自身的专业编程技能去避免死锁、互斥等待及竞争条件（Race Condition）等，熟悉Java语言并发编程的读者们对这些问题的理解会比较深刻，这些问题使得并发编程比顺序编程要困难得多。
Scala语言并没有直接使用Java语言提供的并发编程库，而是通过Actor模型来解决Java并发编程中遇到的各种问题，为并发编程提供了更高级的抽象。
1 重要概念
（1）并发和并行
并发和并行从宏观来看，都是为进行多任务运行，但并发（Concurrency）和并行（parallelism）两者之间是有区别的。并行是指两个或者两个以上任务在同一时刻同时运行,；而并发是指两个或两个以上的任务在同一时间段内运行，即一个时间段中有几个任务都处于已启动运行到运行完毕之间，这若干任务在同一CPU上运行但任一个时刻点上只有一个任务运行。图121给出了多核处理器下的现代操作系统进程和线程模型，图中进程2的线程1被调用度到处理器的核2上运行、进程3的线程1被调度到处理器的核3上运行，进程2的线程1和进程3的线程1是并行的，它们可以同时运行，而进程1的线程1和线程2都调度到处理器的核1上运行，此外它们还共享线程1的内存空间，在运行时面临着资源竞争包括CPU、内存及其它如IO等，它们在同一时候只能运行一个，但在一段时间内都可以运行，因此进程1的线程1和线程2是并发执行的。
这里写图片描述
图1 进程、线程模型
（2）横向扩展和纵向扩展
所谓纵向扩展（Scale Up）指的是增加程序的进度或线程数量，提高程序的并发性；而横向扩展（Scale Out）指的是程序可以扩展到其它机器上运行，即通过分布式系统来提到程序的并行度。传统的Java并发编程模型不容易进行纵向扩展，因此并发的线程数越多，程序行为便会变得很难理解和控制，更多的线程加入到资源竞争，出现死锁等情况的概率增加。横向扩展比纵向扩展困难更大，此时的程序变为分布式环境下的应用，情况更为复杂，对开发人员的要求更高。Scala提供的Actor模型可以解决并发应用程序的横向扩展和纵向扩展问题，如图2、图3给出了基本Actor模型的横向扩展和纵向扩展。
这里写图片描述
图2 纵向扩展
这里写图片描述
图3 横向扩展

2 Actor模型
在使用Java语言进行并发编程时，需要特别关注共享的数据结构，线程间的资源竞争容易导致死锁等问题，而Actor模型便是要解决线程和锁带来的问题，Actor是一种基于事件（Event-Based）的轻量级线程，在使用Actor进行并发编程时只需要关注代码结构，而不需要过分关注数据结构，因此Actor最大限度地减少了数据的共享。 Actor由三个重要部分组成，它们是状态（state），行为（Behavior）和邮箱（Mailbox），Actor与Actor之间的交互通过消息发送来完成，Actor模型如图4所示，状态指的是Actor对象的变量信息，它可以是Actor对象中的局部变量、占用的机器资源等，状态只会根据Actor接受的消息而改变，从而避免并发环境下的死锁等问题；行为指的是Actor的计算行为逻辑，它通过处理Actor接收的消息而改变Actor状态；邮箱（mailbox）建立起Actor间的连接，即Actor发送消息后，另外一个Actor将接收的消息放入到邮箱中待后期处理，邮箱的内部实现是通过队列来实现的，队列可以是有界的（Bounded）也可以是无界的（Unbounded），有界队列实现的邮箱容量固定，无界队列实现的邮箱容易不受限制。
这里写图片描述
图4 Actor模型
不难看出，Actor模型是对现实世界的高度抽象，它具有如下特点：（1）Actor之间使用消息传递机制进行通信，传递的消息使用的是不可变消息，Actor之间并不共享数据结构，如果有数据共享则通过消息发送的方式进行；（2） 各Actor都有对应的mailbox，如果其它Actor向该Actor发送消息，消息将入队待后期处理；（3）Actor间的消息传递通过异步的方式进行，即消息的发送者发送完消息后不必等待回应便可以返回继承处理其它任务。

3 Akka并发编程框架
Scala语言中原生地支持Actor模型，只不过功能还不够强大，从Scala 2.10版本之后，Akka框架成为Scala包的一部分，可以在程序中直接使用。Akka框架作为Akka是一个以Actor模型为基础构建的基于事件的并发编程框架，底层使用Scala语言实现，提供Java和Scala两种API，它属于LightBend公司（原Typesafe公司）体系结构的一部分，如图5所示。
这里写图片描述
图5 Lightbend 体系结构[ ]
Akka框架意在简化高并发、可扩展及分布式应用程序的设计，它具有如下优势：
（1） 使用Akka框架编写的应用程序既可以横向扩展（Scale Out）、也可纵向扩展（Scale Up）。
（2） 编写并发应用程序更简单，Akka提供了更高的抽象，开发人员只需要专注于业务逻辑，而无需像Java语言那样需要处理底级语义如线程、锁及非阻塞IO等。
（3） 高容错，Akka使用“let it crashes”机制，当Actor出错时可以快速恢复。
（4） 事件驱动的架构，Akka中的Actor之间的通信采用异步消息发送，能够完美支持事件驱动。
（5） 位置透明，无论是Actor运行在本地机器还是远程机器上，对于用户来说都是透明的，这极大地简化了多核处理器和分布式系统上的应用程序编程。
（6） 事务支持能力，支持软件事务内存（software transactional memory，STM），使Actor具有原子消息流的操作能力。
Akka框架由下列十个组件构成：
（1） akka-actor ：包括经典的Actor、Typed Actors、IO Actor等
（2） akka-remote：远程Actor
（3） akka-testkit：测试Actor系统的工具箱
（4） akka-kernel ：Akka微内核，用于运行精简的微型应用程序服务器，无需运行于Java应用服务器上。
（5） akka-transactor ：Transactors 即支持事务的 actors，集成了Scala STM
（6） akka-agent – 代理, 同样集成了Scala STM
（7） akka-camel – 集成Apache Camel
（8） akka-zeromq – 集成ZeroMQ 消息队列
（9） akka-slf4j – 支持SLF4J 日志功能
（10） akka-filebased-mailbox – 支持基于文件的mailbox


=============================================================================

Akka提供可扩展的实时事务处理。

Akka是一个运行时与编程模型一致的系统，为以下目标设计：

垂直扩展（并发）
水平扩展（远程调用）
高容错
在Akka的世界里，只有一个内容需要学习和管理，具有高内聚和高一致的语义。

Akka是一种高度可扩展的软件，这不仅仅表现在性能方面，也表现在它所适用的应用的大小。Akka的核心，Akka-actor是非常小的，可以非常方便地放进你的应用中，提供你需要的异步无锁并行功能，不会有任何困扰。

你可以任意选择Akka的某些部分集成到你的应用中，也可以使用完整的包——Akka 微内核，它是一个独立的容器，可以直接部署你的Akka应用。随着CPU核数越来越多，即使你只使用一台电脑，Akka也可作为一种提供卓越性能的选择。 Akka还同时提供多种并发范型，允许用户选择正确的工具来完成工作。

使用akka带来的好处

AKKA提供一种Actor并发模型，其粒度比线程小很多，这意味着你可以在项目中使用大量的Actor。
Akka提供了一套容错机制，允许在Actor出错时进行一些恢复或者重置操作
AKKA不仅可以在单击上构建高并发程序，也可以在网络中构建分布式程序，并提供位置透明的Actor定位服务

Actor

actor是akka执行的基本单元，比线程更轻量级，使用akka可以忘掉线程了。事实上，线程调度已经被akka封装。

actor生命周期
消息投递

这个akka应用是有消息驱动的，消息是除了actor之外最重要的核心组件。在actor之前投递消息应该满足不可变性，也就是不便模式
消息投递有3种策略：之多一次投递，至少一次投递，精确的消息投递。BUT ，没必要在akka层面保证消息的可靠性，一般在业务层在保证
akka可以在一定程度上保证顺序性，但不具备传递性，见《java高并发程序设计 P295》
模块

Akka的模块化做得非常好，它为不同的功能提供了不同的Jar包。

akka-actor-2.0.jar – 标准Actor, 有类型Actor，等等
akka-remote-2.0.jar – 远程Actor
akka-slf4j-2.0.jar – SLF4J事件处理监听器
akka-testkit-2.0.jar – 用于测试Actor的工具包
akka-kernel-2.0.jar – Akka微内核，可运行一个基本的最小应用服务器
akka--mailbox-2.0.jar – Akka可容错邮箱
要查看每个Akka模块的jar包依赖见 依赖 章节. 虽然不重要不过akka-actor 没有外部依赖 (除了scala-library.jar JAR包).

我该如何使用和部署 Akka?

Akka 可以有几种使用方式:

作为一个库: 以普通jar包的形式放在classpath上，或放到web应用中的 WEB-INF/lib位置
作为一个独立的应用程序，使用 Microkernel（微内核），自己有一个main类来初始化Actor系统
参考资料

书籍《java高并发程序设计》
AKKA官方文档

流程




在Actor消息的第一部分，我们会建立一个Teacher Actor，而且会使用一个叫StudentSimulatorApp的主程序。

回顾学生-老师模式的细节
现在考虑下StudentSimulatorApp单独发消息给TeacherActor。当我说到StudentSimulatorApp，就只是意思是一个常规的带main函数的主程序。



这张图传递的意思是：
（如果太复杂，别担心，我们会详细过一遍）
1.学生创建了一个叫ActorSystem的东西
2.它用ActorSystem来创建一个叫ActorRef的东西。QuoteRequest消息被发送到ActorRef（一个TeacherActor的代理）
3.Actor ref同样把消息发给Dispatcher
4.Dispatcher将消息放入到目标Actor的邮箱中（MailBox）
5.Dispatcher将Mail放到一个线程中（下节详细介绍）
6.MailBox取出一个消息并且最后将消息送给实际的Teacher Actor的接收方法。

就像我说的，别担心。下面我们看看每一步的细节。你可以在后面重新回来看下这五步。

STUDENTSIMULATORAPP程序
我们用StudentSimulatorApp启动JVM并且初始化ActorSystem。



就像图片上画的，这个StudentSimulatorApp
1.创建了一个ActorSystem
2.使用ActorSustem创建了一个Teacher Actor的代理（ActorRef）
3.给代理发送QuoteRequest（请求格言）消息。

让我们一起看下这三点。

1.创建 一个ActorSystem

ActorSystem是一个进入Actor世界的入口点。ActorSystem在创建和停止Actors的时候自始至终都存在着。并且在关掉整个Actor环境的时候也存在着。

在另一个方面，Actors是按层级划分的，ActorSystem可以类比为对于所有Actor的java.lang.Object基类对象或者scala.Any- 意思是它是所有Actors的根对象。当你用ActorSystem的actorof方法创建了一个Actor对象，你实际上创建了一个ActorSystem下一个一个子Actor。


初始化ActorSystem的代码类似于这个样子

val system=ActorSystem("UniversityMessageSystem")

这里的UniversityMessageSystem就是一个你给ActorSystem的昵称。

2.创建一个TeacherActor的代理？

让我们看下下面的片段：

'val teacherActorRef:ActorRef=actorSystem.actorOf(props[TeacherActor])'

actorOf是ActorSystem中的Actor的创建方法。但是，你可以看见这个方法并不返回一个TeacherActor。它返回一个类型是ActorRef的东西。

ActorRef是一个真实Actors的代理。客户端并不直接跟Actor对话。这这种Actor的模型是为了防止TeacherActor的自定义/私有方法或变量被直接访问。

你只会直接给ActorRef发送消息并且消息最终会到达实际的Actor。你永远不能直接跟Actor交互。要是你找到一些方式干这个，你会被大家诅咒。



3.给代理发送一个QuoteRequest

你只需要将QuoteRequest消息tell告诉ActorRef。这个告诉的方法在Actor里面是！叹号。（ActorRef也有一个tell方法，作用是委托回调给！）

'//send a message to the Teacher Actor'
'teacherActorRef!QuoteRequest'

这就没了！

如果你觉得我骗你，下面是StudentSimulatorApp的代码：

STUDENTSIMULATORAPP.SCALA

package me.rerun.akkanotes.messaging.actormsg1

import akka.actor.ActorSystem
import akka.actor.Props
import akka.actor.actorRef2Scala
import me.rerun.akkanotes.messaging.protocols.TeacherProtocol._


object StudentSimulatorApp extends App{

  //Initialize the ActorSystem
  val actorSystem=ActorSystem("UniversityMessageSystem")

  //construct the Teacher Actor Ref
  val teacherActorRef=actorSystem.actorOf(Props[TeacherActor])

  //send a message to the Teacher Actor
  teacherActorRef!QuoteRequest

  //Let's wait for a couple of seconds before we shut down the system
  Thread.sleep (2000)

  //Shut down the ActorSystem.
  actorSystem.shutdown()

}
不过，我确实撒了一个小慌。你需要shutdown ActorSystem或者让JVM一直跑。我给这个main线程sleep一下只是为了给TeacherActor一点时间来完成它的任务。我知道这听起来有点傻。别担心这个。我们后面会写一些测试用例来避免这个。

这是我翻译的文章，原文在http://rerun.me/2014/09/19/akka-notes-actor-messaging-1/

文章来自微信平台「麦芽面包」,微信号「darkjune_think」。转载请注明。


本文出自 “祝坤荣” 博客，请务必保留此出处
好文要顶 关注我 收藏该文
祝坤荣
关注 - 2
粉丝 - 38
+加关注
1 0
« 上一篇：翻译：AKKA笔记 - 介绍Actors
» 下一篇：翻译：AKKA笔记 - Actor消息 -1（二）
posted @ 2015-08-16 23:52 祝坤荣 阅读(710) 评论(1) 编辑 收藏

评论列表
   #1楼 2015-08-17 06:28 要有好的心情
mark
支持(0)反对(0)
刷新评论刷新页面返回顶部
注册用户登录后才能发表评论，请 登录 或 注册，访问网站首页。
【推荐】50万行VC++源码: 大型组态工控、电力仿真CAD与GIS源码库
【推荐】腾讯云免费实验室，1小时搭建人工智能应用
【新闻】H3 BPM体验平台全面上线
AR_1206
最新IT新闻:
· 阿里向大润发母公司发出全面要约收购 已买36%股份
· 联通在线公司正式揭牌成立 全面发力消费互联网
· 如何做项目 Pitch？硅谷顶尖投资人给出了7点建议
· 徐小平爆有投资人讹诈创业者，称其为黑恶势力的抢劫
· 挖矿网站Nicehash被黑：创始人在Facebook直播中致歉
» 更多新闻...
阿里云C2-1208
最新知识库文章:
· 以操作系统的角度述说线程与进程
· 软件测试转型之路
· 门内门外看招聘
· 大道至简，职场上做人做事做管理
· 关于编程，你的练习是不是有效的？
» 更多知识库文章...
公告
查看祝坤荣的领英档案 查看ryan zhu的档案
微信公众号 麦芽面包

昵称：祝坤荣
园龄：6年3个月
粉丝：38
关注：2
+加关注
<	2017年12月	>
日	一	二	三	四	五	六
26	27	28	29	30	1	2
3	4	5	6	7	8	9
10	11	12	13	14	15	16
17	18	19	20	21	22	23
24	25	26	27	28	29	30
31	1	2	3	4	5	6
搜索

 找找看

 谷歌搜索
常用链接
我的随笔
我的评论
我的参与
最新评论
我的标签
我的标签
Akka(5)axis ssl client(1)ganglia(1)java序列化(1)Jetty(1)JVM(1)memory leak(1)proxool p6spy hibernate(1)Radius OTP(1)Redmine(1)更多
随笔档案
2017年9月 (1)
2017年5月 (2)
2017年3月 (1)
2017年1月 (2)
2016年12月 (1)
2016年10月 (1)
2016年8月 (1)
2016年7月 (2)
2016年6月 (4)
2016年4月 (2)
2016年2月 (3)
2016年1月 (2)
2015年12月 (2)
2015年11月 (3)
2015年10月 (3)
2015年9月 (2)
2015年8月 (3)
2015年7月 (2)
2015年6月 (3)
2015年5月 (2)
2015年4月 (1)
2015年3月 (2)
2015年2月 (8)
2015年1月 (2)
2014年11月 (1)
2014年9月 (1)
2014年8月 (2)
2014年7月 (3)
2014年6月 (3)
2014年5月 (1)
2014年4月 (5)
2014年3月 (3)
2014年2月 (1)
2014年1月 (1)
最新评论
1. Re:[翻译]AKKA笔记 - 有限状态机 -1
翻译得不错。学习了！！
--LewisChan
2. Re:Java序列化格式详解
写的挺清楚的，排版也很清楚，感谢博主
--helloc001
3. Re:程序员DNS知识指南
很详细 学习了
--程序人生0407
4. Re:外包公司做遗留项目有意思么？
@Sheldon_Lou 没意思...
--wpw
5. Re:服务注册/发现与二手房中介
> 刚买房的时候很费神> 考虑的点都一个个列出来- 小区　- 绿化率　- 容积率　- 物业　- 停车- 学校- 医院- 公园- 广场- 高铁站- 汽车站- 商场```逛了很多楼盘后，到最后只能对比买相......
--阿K&LiveCai
阅读排行榜
1. 谈谈应届生应聘的一点看法(3253)
2. Jetty 9 源码分析 Connector及Server类（一）(3199)
3. 一则线上MySql连接异常的排查过程(2576)
4. 服务注册/发现与二手房中介(2501)
5. 程序员DNS知识指南(2205)
评论排行榜
1. 谈谈应届生应聘的一点看法(34)
2. 外包公司做遗留项目有意思么？(15)
3. 系统上线那点事 - 记一次线上系统故障(9)
4. 程序员DNS知识指南(8)
5. 服务注册/发现与二手房中介(7)
推荐排行榜
1. 程序员DNS知识指南(6)
2. 服务注册/发现与二手房中介(6)
3. 谈谈应届生应聘的一点看法(4)
4. [翻译]AKKA笔记 - 有限状态机 -1(3)
5. 软件技术人员需要对数字的敏感性(2)

路由器Router
通常在分布式任务调度系统中会有这样的需求：一组actor提供相同的服务，我们在调用任务的时候只需要选择其中一个actor进行处理即可。
其实这就是一个负载均衡或者说路由策略，akka作为一个高性能支持并发的actor模型，可以用来作为任务调度集群使用，当然负载均衡就是其本职工作了，akka提供了Router来进行消息的调度。

由于负载均衡原理过于简单，既不多说了，直接上代码(这里借用之前章节的InboxTest类)：

package akka.router;

import akka.actor.*;
import akka.iInbox.InboxTest;
import akka.routing.*;
import com.typesafe.config.ConfigFactory;

import java.util.ArrayList;
import java.util.concurrent.atomic.AtomicBoolean;

/**
 * Created by liubenlong on 2017/1/12.
 */
public class RouterTest extends UntypedActor {

    public Router router;

    {
        ArrayList<Routee> routees = new ArrayList<>();
        for(int i = 0; i < 5; i ++) {
            //借用上面的 inboxActor
            ActorRef worker = getContext().actorOf(Props.create(InboxTest.class), "worker_" + i);
            getContext().watch(worker);//监听
            routees.add(new ActorRefRoutee(worker));
        }
        /**
         * RoundRobinRoutingLogic: 轮询
         * BroadcastRoutingLogic: 广播
         * RandomRoutingLogic: 随机
         * SmallestMailboxRoutingLogic: 空闲
         */
        router = new Router(new RoundRobinRoutingLogic(), routees);
    }

    @Override
    public void onReceive(Object o) throws Throwable {
        if(o instanceof InboxTest.Msg){
            router.route(o, getSender());//进行路由转发
        }else if(o instanceof Terminated){
            router = router.removeRoutee(((Terminated)o).actor());//发生中断，将该actor删除。当然这里可以参考之前的actor重启策略，进行优化，为了简单，这里仅进行删除处理
            System.out.println(((Terminated)o).actor().path() + " 该actor已经删除。router.size=" + router.routees().size());

            if(router.routees().size() == 0){//没有可用actor了
                System.out.print("没有可用actor了，系统关闭。");
                flag.compareAndSet(true, false);
                getContext().system().shutdown();
            }
        }else {
            unhandled(o);
        }

    }


    public  static AtomicBoolean flag = new AtomicBoolean(true);

    public static void main(String[] args) throws InterruptedException {
        ActorSystem system = ActorSystem.create("strategy", ConfigFactory.load("akka.config"));
        ActorRef routerTest = system.actorOf(Props.create(RouterTest.class), "RouterTest");

        int i = 1;
        while(flag.get()){
            routerTest.tell(InboxTest.Msg.WORKING, ActorRef.noSender());

            if(i % 10 == 0) routerTest.tell(InboxTest.Msg.CLOSE, ActorRef.noSender());

            Thread.sleep(500);

            i ++;
        }
    }
}



akka提供了几个RoutingLogic各位可以亲自尝试运行一下，看看效果。

运行结果：

"D:\Program Files\Java\jdk1.8.0_111\bin\java" -Didea.launcher.port=7533 "-Didea.launcher.bin.path=D:\Program Files (x86)\ideaIU-2016.2.5\bin" -Dfile.encoding=UTF-8 -classpath "D:\Program Files\Java\jdk1.8.0_111\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_111\jre\lib\rt.jar;D:\workspace_git_idea\luffi-master\luffi\target\test-classes;D:\workspace_git_idea\luffi-master\luffi\target\classes;D:\LocalRepository\commons-fileupload\commons-fileupload\1.3.2\commons-fileupload-1.3.2.jar;D:\LocalRepository\commons-io\commons-io\2.2\commons-io-2.2.jar;D:\LocalRepository\org\apache\httpcomponents\httpmime\4.3.1\httpmime-4.3.1.jar;D:\LocalRepository\org\apache\httpcomponents\httpclient\4.3.1\httpclient-4.3.1.jar;D:\LocalRepository\org\apache\httpcomponents\httpcore\4.3\httpcore-4.3.jar;D:\LocalRepository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\LocalRepository\commons-codec\commons-codec\1.6\commons-codec-1.6.jar;D:\LocalRepository\com\alibaba\fastjson\1.2.17\fastjson-1.2.17.jar;D:\LocalRepository\com\letv\openapi\openapi-sdk-java\1.0.0-SNAPSHOT\openapi-sdk-java-1.0.0-20160721.094717-1.jar;D:\LocalRepository\org\slf4j\slf4j-api\1.7.5\slf4j-api-1.7.5.jar;D:\workspace_git_idea\luffi-master\luffi-api\target\classes;D:\workspace_git_idea\luffi-master\luffi-model\target\classes;D:\LocalRepository\org\apache\commons\commons-lang3\3.1\commons-lang3-3.1.jar;D:\LocalRepository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\LocalRepository\javax\el\javax.el-api\2.2.4\javax.el-api-2.2.4.jar;D:\LocalRepository\org\glassfish\web\javax.el\2.2.4\javax.el-2.2.4.jar;D:\LocalRepository\org\hibernate\hibernate-validator\5.2.4.Final\hibernate-validator-5.2.4.Final.jar;D:\LocalRepository\org\projectlombok\lombok-maven-plugin\1.12.2.0\lombok-maven-plugin-1.12.2.0.jar;D:\LocalRepository\com\github\pagehelper\pagehelper\4.1.1\pagehelper-4.1.1.jar;D:\LocalRepository\com\github\jsqlparser\jsqlparser\0.9.4\jsqlparser-0.9.4.jar;D:\LocalRepository\org\apache\thrift\libthrift\0.9.3\libthrift-0.9.3.jar;D:\LocalRepository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\LocalRepository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\LocalRepository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;D:\workspace_git_idea\luffi-master\luffi-repository\target\classes;D:\LocalRepository\tk\mybatis\mapper\3.3.8\mapper-3.3.8.jar;D:\LocalRepository\javax\persistence\persistence-api\1.0\persistence-api-1.0.jar;D:\LocalRepository\org\mybatis\spring\boot\mybatis-spring-boot-starter\1.1.1\mybatis-spring-boot-starter-1.1.1.jar;D:\LocalRepository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\1.1.1\mybatis-spring-boot-autoconfigure-1.1.1.jar;D:\LocalRepository\org\mybatis\mybatis\3.4.0\mybatis-3.4.0.jar;D:\LocalRepository\org\mybatis\mybatis-spring\1.3.0\mybatis-spring-1.3.0.jar;D:\LocalRepository\org\springframework\boot\spring-boot\1.3.6.RELEASE\spring-boot-1.3.6.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot-autoconfigure\1.3.6.RELEASE\spring-boot-autoconfigure-1.3.6.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter-jdbc\1.3.3.RELEASE\spring-boot-starter-jdbc-1.3.3.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter\1.3.6.RELEASE\spring-boot-starter-1.3.6.RELEASE.jar;D:\LocalRepository\org\apache\tomcat\tomcat-jdbc\8.0.32\tomcat-jdbc-8.0.32.jar;D:\LocalRepository\org\apache\tomcat\tomcat-juli\8.0.32\tomcat-juli-8.0.32.jar;D:\LocalRepository\org\springframework\spring-jdbc\4.2.5.RELEASE\spring-jdbc-4.2.5.RELEASE.jar;D:\LocalRepository\org\springframework\spring-beans\4.2.4.RELEASE\spring-beans-4.2.4.RELEASE.jar;D:\LocalRepository\org\springframework\spring-core\4.2.4.RELEASE\spring-core-4.2.4.RELEASE.jar;D:\LocalRepository\org\springframework\spring-tx\4.2.5.RELEASE\spring-tx-4.2.5.RELEASE.jar;D:\workspace_git_idea\luffi-master\luffi-common\target\classes;D:\LocalRepository\org\apache\zookeeper\zookeeper\3.4.8\zookeeper-3.4.8.jar;D:\LocalRepository\jline\jline\0.9.94\jline-0.9.94.jar;D:\LocalRepository\io\netty\netty\3.7.0.Final\netty-3.7.0.Final.jar;D:\LocalRepository\com\101tec\zkclient\0.9\zkclient-0.9.jar;D:\LocalRepository\log4j\log4j\1.2.15\log4j-1.2.15.jar;D:\LocalRepository\javax\mail\mail\1.4\mail-1.4.jar;D:\LocalRepository\javax\activation\activation\1.1\activation-1.1.jar;D:\LocalRepository\com\alibaba\dubbo\2.8.4.lehi\dubbo-2.8.4.lehi.jar;D:\LocalRepository\org\springframework\spring-context\4.2.4.RELEASE\spring-context-4.2.4.RELEASE.jar;D:\LocalRepository\org\springframework\spring-aop\4.2.4.RELEASE\spring-aop-4.2.4.RELEASE.jar;D:\LocalRepository\org\springframework\spring-expression\4.2.4.RELEASE\spring-expression-4.2.4.RELEASE.jar;D:\LocalRepository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\LocalRepository\org\apache\logging\log4j\log4j-core\2.5\log4j-core-2.5.jar;D:\LocalRepository\org\apache\logging\log4j\log4j-api\2.5\log4j-api-2.5.jar;D:\LocalRepository\org\javassist\javassist\3.15.0-GA\javassist-3.15.0-GA.jar;D:\LocalRepository\org\springframework\spring-web\4.2.4.RELEASE\spring-web-4.2.4.RELEASE.jar;D:\LocalRepository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\LocalRepository\commons-pool\commons-pool\1.6\commons-pool-1.6.jar;D:\LocalRepository\org\apache\curator\curator-framework\2.5.0\curator-framework-2.5.0.jar;D:\LocalRepository\org\apache\curator\curator-client\2.5.0\curator-client-2.5.0.jar;D:\LocalRepository\com\google\guava\guava\16.0.1\guava-16.0.1.jar;D:\LocalRepository\org\yaml\snakeyaml\1.16\snakeyaml-1.16.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter-web\1.3.6.RELEASE\spring-boot-starter-web-1.3.6.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter-validation\1.3.6.RELEASE\spring-boot-starter-validation-1.3.6.RELEASE.jar;D:\LocalRepository\org\apache\tomcat\embed\tomcat-embed-el\8.0.36\tomcat-embed-el-8.0.36.jar;D:\LocalRepository\com\fasterxml\jackson\core\jackson-databind\2.6.7\jackson-databind-2.6.7.jar;D:\LocalRepository\com\fasterxml\jackson\core\jackson-annotations\2.6.0\jackson-annotations-2.6.0.jar;D:\LocalRepository\com\fasterxml\jackson\core\jackson-core\2.6.7\jackson-core-2.6.7.jar;D:\LocalRepository\org\springframework\spring-webmvc\4.2.7.RELEASE\spring-webmvc-4.2.7.RELEASE.jar;D:\LocalRepository\org\springframework\boot\spring-boot-starter-log4j2\1.3.6.RELEASE\spring-boot-starter-log4j2-1.3.6.RELEASE.jar;D:\LocalRepository\org\apache\logging\log4j\log4j-slf4j-impl\2.4.1\log4j-slf4j-impl-2.4.1.jar;D:\LocalRepository\org\slf4j\jcl-over-slf4j\1.7.21\jcl-over-slf4j-1.7.21.jar;D:\LocalRepository\org\slf4j\jul-to-slf4j\1.7.21\jul-to-slf4j-1.7.21.jar;D:\LocalRepository\mysql\mysql-connector-java\5.1.39\mysql-connector-java-5.1.39.jar;D:\LocalRepository\org\jboss\logging\jboss-logging\3.2.1.Final\jboss-logging-3.2.1.Final.jar;D:\LocalRepository\com\fasterxml\classmate\1.1.0\classmate-1.1.0.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-jaxrs\3.0.9.Final\resteasy-jaxrs-3.0.9.Final.jar;D:\LocalRepository\org\jboss\resteasy\jaxrs-api\3.0.9.Final\jaxrs-api-3.0.9.Final.jar;D:\LocalRepository\org\jboss\spec\javax\annotation\jboss-annotations-api_1.1_spec\1.0.1.Final\jboss-annotations-api_1.1_spec-1.0.1.Final.jar;D:\LocalRepository\net\jcip\jcip-annotations\1.0\jcip-annotations-1.0.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-client\3.0.9.Final\resteasy-client-3.0.9.Final.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-netty\3.0.14.Final\resteasy-netty-3.0.14.Final.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-jdk-http\3.0.14.Final\resteasy-jdk-http-3.0.14.Final.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-jackson-provider\3.0.14.Final\resteasy-jackson-provider-3.0.14.Final.jar;D:\LocalRepository\org\codehaus\jackson\jackson-core-asl\1.9.12\jackson-core-asl-1.9.12.jar;D:\LocalRepository\org\codehaus\jackson\jackson-mapper-asl\1.9.12\jackson-mapper-asl-1.9.12.jar;D:\LocalRepository\org\codehaus\jackson\jackson-jaxrs\1.9.12\jackson-jaxrs-1.9.12.jar;D:\LocalRepository\org\codehaus\jackson\jackson-xc\1.9.12\jackson-xc-1.9.12.jar;D:\LocalRepository\org\jboss\resteasy\resteasy-jaxb-provider\3.0.16.Final\resteasy-jaxb-provider-3.0.16.Final.jar;D:\LocalRepository\com\sun\xml\bind\jaxb-impl\2.2.7\jaxb-impl-2.2.7.jar;D:\LocalRepository\com\sun\xml\bind\jaxb-core\2.2.7\jaxb-core-2.2.7.jar;D:\LocalRepository\javax\xml\bind\jaxb-api\2.2.7\jaxb-api-2.2.7.jar;D:\LocalRepository\com\sun\istack\istack-commons-runtime\2.16\istack-commons-runtime-2.16.jar;D:\LocalRepository\com\sun\xml\fastinfoset\FastInfoset\1.2.12\FastInfoset-1.2.12.jar;D:\LocalRepository\javax\xml\bind\jsr173_api\1.0\jsr173_api-1.0.jar;D:\LocalRepository\org\apache\tomcat\embed\tomcat-embed-core\8.0.11\tomcat-embed-core-8.0.11.jar;D:\LocalRepository\org\apache\tomcat\embed\tomcat-embed-logging-juli\8.0.11\tomcat-embed-logging-juli-8.0.11.jar;D:\LocalRepository\junit\junit\4.12\junit-4.12.jar;D:\LocalRepository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;D:\LocalRepository\org\springframework\spring-test\4.2.4.RELEASE\spring-test-4.2.4.RELEASE.jar;D:\LocalRepository\redis\clients\jedis\2.9.0\jedis-2.9.0.jar;D:\LocalRepository\org\apache\commons\commons-pool2\2.4.2\commons-pool2-2.4.2.jar;D:\LocalRepository\org\springframework\spring-context-support\4.2.4.RELEASE\spring-context-support-4.2.4.RELEASE.jar;D:\LocalRepository\org\quartz-scheduler\quartz\2.2.3\quartz-2.2.3.jar;D:\LocalRepository\c3p0\c3p0\0.9.1.1\c3p0-0.9.1.1.jar;D:\LocalRepository\com\typesafe\akka\akka-actor_2.11\2.4.14\akka-actor_2.11-2.4.14.jar;D:\LocalRepository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;D:\LocalRepository\com\typesafe\config\1.3.0\config-1.3.0.jar;D:\LocalRepository\org\scala-lang\modules\scala-java8-compat_2.11\0.7.0\scala-java8-compat_2.11-0.7.0.jar;D:\LocalRepository\org\apache\maven\maven-plugin-api\3.0.4\maven-plugin-api-3.0.4.jar;D:\LocalRepository\org\apache\maven\maven-model\3.0.4\maven-model-3.0.4.jar;D:\LocalRepository\org\codehaus\plexus\plexus-utils\2.0.6\plexus-utils-2.0.6.jar;D:\LocalRepository\org\apache\maven\maven-artifact\3.0.4\maven-artifact-3.0.4.jar;D:\LocalRepository\org\sonatype\sisu\sisu-inject-plexus\2.3.0\sisu-inject-plexus-2.3.0.jar;D:\LocalRepository\org\codehaus\plexus\plexus-component-annotations\1.5.5\plexus-component-annotations-1.5.5.jar;D:\LocalRepository\org\codehaus\plexus\plexus-classworlds\2.4\plexus-classworlds-2.4.jar;D:\LocalRepository\org\sonatype\sisu\sisu-inject-bean\2.3.0\sisu-inject-bean-2.3.0.jar;D:\LocalRepository\org\sonatype\sisu\sisu-guice\3.1.0\sisu-guice-3.1.0-no_aop.jar;D:\LocalRepository\org\sonatype\sisu\sisu-guava\0.9.9\sisu-guava-0.9.9.jar;D:\LocalRepository\org\projectlombok\lombok\1.12.2\lombok-1.12.2.jar;D:\Program Files (x86)\ideaIU-2016.2.5\lib\idea_rt.jar" com.intellij.rt.execution.application.AppMain akka.router.RouterTest
[INFO] [01/16/2017 14:46:44.010] [strategy-akka.actor.default-dispatcher-6] [akka://strategy/user/RouterTest/worker_0] i am working.
[INFO] [01/16/2017 14:46:44.481] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:46:44.981] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_2] i am working.
[INFO] [01/16/2017 14:46:45.481] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:45.981] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_4] i am working.
[INFO] [01/16/2017 14:46:46.514] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_0] i am working.
[INFO] [01/16/2017 14:46:47.021] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:46:47.492] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_2] i am working.
[INFO] [01/16/2017 14:46:47.992] [strategy-akka.actor.default-dispatcher-10] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:48.492] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_4] i am working.
[INFO] [01/16/2017 14:46:48.492] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/user/RouterTest/worker_0] i am close.
[INFO] [01/16/2017 14:46:48.502] [strategy-akka.actor.default-dispatcher-10] [akka://strategy/deadLetters] Message [akka.iInbox.InboxTest$Msg] from Actor[akka://strategy/user/RouterTest/worker_0#-492254864] to Actor[akka://strategy/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
akka://strategy/user/RouterTest/worker_0 该actor已经删除。router.size=4
[INFO] [01/16/2017 14:46:48.992] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/user/RouterTest/worker_4] i am working.
[INFO] [01/16/2017 14:46:49.507] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:46:50.035] [strategy-akka.actor.default-dispatcher-7] [akka://strategy/user/RouterTest/worker_2] i am working.
[INFO] [01/16/2017 14:46:50.507] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:51.007] [strategy-akka.actor.default-dispatcher-7] [akka://strategy/user/RouterTest/worker_4] i am working.
[INFO] [01/16/2017 14:46:51.507] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:46:52.011] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_2] i am working.
[INFO] [01/16/2017 14:46:52.536] [strategy-akka.actor.default-dispatcher-7] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:53.036] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/user/RouterTest/worker_4] i am working.
akka://strategy/user/RouterTest/worker_2 该actor已经删除。router.size=3
[INFO] [01/16/2017 14:46:53.522] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/user/RouterTest/worker_2] i am close.
[INFO] [01/16/2017 14:46:53.522] [strategy-akka.actor.default-dispatcher-7] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:46:53.522] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/deadLetters] Message [akka.iInbox.InboxTest$Msg] from Actor[akka://strategy/user/RouterTest/worker_2#519939307] to Actor[akka://strategy/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [01/16/2017 14:46:54.022] [strategy-akka.actor.default-dispatcher-10] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:54.522] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_4] i am working.
[INFO] [01/16/2017 14:46:55.022] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:46:55.522] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:56.022] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_4] i am working.
[INFO] [01/16/2017 14:46:56.522] [strategy-akka.actor.default-dispatcher-7] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:46:57.023] [strategy-akka.actor.default-dispatcher-7] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:57.523] [strategy-akka.actor.default-dispatcher-7] [akka://strategy/user/RouterTest/worker_4] i am working.
[INFO] [01/16/2017 14:46:58.023] [strategy-akka.actor.default-dispatcher-7] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:46:58.566] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:58.566] [strategy-akka.actor.default-dispatcher-10] [akka://strategy/user/RouterTest/worker_4] i am close.
akka://strategy/user/RouterTest/worker_4 该actor已经删除。router.size=2
[INFO] [01/16/2017 14:46:58.566] [strategy-akka.actor.default-dispatcher-10] [akka://strategy/deadLetters] Message [akka.iInbox.InboxTest$Msg] from Actor[akka://strategy/user/RouterTest/worker_4#50964955] to Actor[akka://strategy/deadLetters] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [01/16/2017 14:46:59.076] [strategy-akka.actor.default-dispatcher-4] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:46:59.547] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:00.047] [strategy-akka.actor.default-dispatcher-4] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:47:00.547] [strategy-akka.actor.default-dispatcher-4] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:01.047] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:47:01.582] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:02.091] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_3] i am working.
[INFO] [01/16/2017 14:47:02.562] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:03.062] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_3] i am working.
akka://strategy/user/RouterTest/worker_3 该actor已经删除。router.size=1
[INFO] [01/16/2017 14:47:03.562] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:03.562] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/user/RouterTest/worker_3] i am close.
[INFO] [01/16/2017 14:47:03.563] [strategy-akka.actor.default-dispatcher-3] [akka://strategy/deadLetters] Message [akka.iInbox.InboxTest$Msg] from Actor[akka://strategy/user/RouterTest/worker_3#-667250877] to Actor[akka://strategy/deadLetters] was not delivered. [4] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
[INFO] [01/16/2017 14:47:04.062] [strategy-akka.actor.default-dispatcher-10] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:04.597] [strategy-akka.actor.default-dispatcher-10] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:05.099] [strategy-akka.actor.default-dispatcher-4] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:05.570] [strategy-akka.actor.default-dispatcher-4] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:06.070] [strategy-akka.actor.default-dispatcher-4] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:06.570] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:07.070] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:07.611] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:08.112] [strategy-akka.actor.default-dispatcher-4] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:08.583] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_1] i am working.
[INFO] [01/16/2017 14:47:08.583] [strategy-akka.actor.default-dispatcher-5] [akka://strategy/user/RouterTest/worker_1] i am close.
[INFO] [01/16/2017 14:47:08.585] [strategy-akka.actor.default-dispatcher-9] [akka://strategy/deadLetters] Message [akka.iInbox.InboxTest$Msg] from Actor[akka://strategy/user/RouterTest/worker_1#255839262] to Actor[akka://strategy/deadLetters] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
akka://strategy/user/RouterTest/worker_1 该actor已经删除。router.size=0
没有可用actor了，系统关闭。
Process finished with exit code 0

