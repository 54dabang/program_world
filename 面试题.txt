面试题1：给一个超过100G大小的log file, log中存着IP地址, 设计算法找到出现次数最多的IP地址？

解析：100G的文件给我们的感觉是太大，我们的电脑内存一般都为4G左右所以不可能一次性把这么多的信息都加载到内存，所以就要进行切分成100份。IP地址是字符串太长，我们可以把它转化为整型%100，这样取模后的值都落在0-99的区间里，所取模后值相同的IP地址都被分配到同一个文件，这时我们就可以采用哈希表统计出每个文件中最多的那个IP地址，最后比较得到100个IP中最大的那个IP就可以了 。

面试题2：与上题条件相同，如何找到top K的IP？

解析：看到求TOP K个IP就要立马反应到使用堆排序，这里的堆排序应该注意的是要建一个小堆，想一下我们建大堆的话只能保证堆顶元素为最大的，这样只能得到最大的那个IP。

面试题3：给定100亿个整数，设计算法找到只出现一次的整数

解析：整数分为有符号和无符号两种，有符号数的取值为-2147483648~2147483648 是从-21亿到+21亿， 无符号数的范围为0~4294967296是从0到42亿，然而给了我们100亿个整数，要找出只出现一次的整数，所以我们还是要用到哈希表的思想，但我们最好不要定义一个整型数组，因为 42亿*4B  约为16G，这么大的数组我们再进行切分的话就太麻烦了，这里我们可以使用BitMap,用一个位来表示一个数存不存在，不存在表示为0，出现一次表示为1，出现一次以上用另一个位表示。这样就可以将数组的大小减为原来的16分之一。还遇到一个问题，就是到底怎么定义这个数组，正数好定义，负数的话我们可以用32位全1（-1）和它取异或取到和正数相同的位置，我们此时定义一个二维数组，一半表示正数一半表示负数，都位于同一行。此时我们使用1G的空间就可以解决这个问题了。

拓展：要是面试官问我这里只有500M或者更少的空间的话怎么做？

解析：同样采用切分的思想，不过我觉得这里我们直接可以按数的范围直接切分。要是有500M 内存的话，我们就切一次就可以了，此时如果我们有50%的几率一次就找到这个只出现一次的数，效率可能更高。

面试题4：给两个文件，分别有100亿个整数，我们只有1G内存，如何找到两个文件交集？

解析：这道题思路和上面的一样。

面试题5：1个文件有100亿个int，1G内存，设计算法找到出现次数不超过2次的所有整数

解析：这个问题和以上唯一 不同这道题是找不超过两次的整数，方法一样。

面试题6：给两个文件，分别有100亿个query，我们只有1G内存，如何找到两个文件交集分别给出精确算法和近似算法!

解析：求两个文件的交集，这种算法我们肯定要用到比较，如果我们把两个文件都均分为100份，拿一个文件里的一份分别与另一个文件里的100份分别比较一次的话效率 就太低了，我们可以借用第1道面试题的思维对它们进行取模，这样我们只要比较取模的为同一值的两个文件比较就可以了，如果相同则标记。

面试题7：如何扩展BloomFilter使得它支持删除元素的操作？

解析：BloomFilter并不支持删除元素的操作，因为很可能产生哈希冲突（就是由不同的哈希函数算出的位置指向同一个位），这样改变一个位很可能会影响到其他元素的判断。这里我们可以按照和智能指针sharedptr的思想即“引用计数”来解决，我们添加一个count计数器，每当我们在这个位上表示一个元素时就让它count++，每删除一个涉及到这个位表示的元素时就让它count--,这样只当count为0时我们再对这一位置0，这样就完成了删除的操作。

面试题8：如何扩展BloomFilter使得它支持计数操作？

解析：这道题思想和上一道题一样。

面试题9：给上千个文件，每个文件大小为1K—100M。给n个词，设计算法对每个词找到所有包含它的文件，你只有100K内存

解析：我们可以使用布隆过滤器来判断一个文件是否包含这n个单词生成n个布隆过滤器放到外存，我们事先定义好一个包含这n个单词信息的文件info，每当我们在一个文件找到一个对应的单词就将这个文件的信息写入info对应单词的位置。我们只有100K内存，这100K内存我们一部分用来存放布隆过滤器一部分可以存放文件，因为文件最小都为100K，所以我们可以尝试把它切分为50K的小文件，每个文件标志好所属的大文件，这样我们每次读入一个布隆过滤器和一个小文件，如果这个文件有对应的单词则在info中标记所属大文件的信息，如果没有则读入下一个布隆过滤器，把所有布隆过滤器都使用后，再读下一个文件重复上述步骤直至把所有文件都遍历完。

面试题10：有一个词典，包含N个英文单词，现在任意给一个字符串，设计算法找出包含这个字符串的所有英文单词

解析：首先判断一个单词是否包含一个字符串我们可以用strstr这个函数，对于这个问题，我觉得如果该字符串的前缀和要找的单词一样的话可以采用字典树来查找，但是N个英文单词我们可以假设它很大，我们把它放到一个文件里，每次只读出固定个数个单词进行判断。

总结：对于此类大数据问题我们一般都是采用哈希切分即模上一个数组的长度将数据分配到一个合理的位置，同时将一个大文件切分为小文件，这样特别方便将其与其他数进行比较例如对IP地址取整后进行哈希切分，或者对内部元素进行操作。使用BloomFilter可以进行判断元素在集合的存在与否。

1. spark的runtime

这个主要是standalone模式下的master和worker，executor，driver，再加上yarn模式下的resourcemanager和nodemanager。要了解一个spark应用提交的过程，也即是driver和executor在集群管理器内部启动的过程，然后就是rpc过程，各个角色的作用。

高手的问题就是如何给两者分配合适内存，然后executor执行task倾斜的表现及如何解决。这些都在星球里分享过了。然后如何对executor的存活挂掉新增进行监控告警。executor动态分配表现及带来的问题。

再高级一点就是driver和executor的类加载器及加载类的原理及过程，当然包括rpc，依赖传输，task调度等。

就这吧……

2.spark core

spark core股名思义就是spark的核心内容，主要是rdd的五大特性及操作算子特点介绍。

DAG的生成，划分，task的调度执行。

数据本地性原理及如何利用和会存在哪些隐患。这也在公众号发过文章和视频了。

reducebykey，groupbykey的区别等等类似算子对比，如何高效使用mappartition，然后foreachPartition与foreach之间的区别及底层实现原理，这些星球里➕公众号都发过了。

宽依赖，窄依赖等老生常谈的不多说了...基础都不去了解记忆的人面试不过很正常。

来点猛料，广播变量的原理及演变过程，使用场景，使用广播变量一定划算吗？大变量咋办呢？

累加器的原理及应用场景，累加器使用有陷阱么？

序列化，反序列化，闭包，垃圾回收机制（过期rdd的回收，cache的回收等）。这个星球里打过了～

checkpoint如何在spark core应用呢？何种场景适合？源码系列教程。

并行度相关配置，这个星球里也反复强调了，合理设置可以大幅度提高性能。

害怕了吗，还是就此打住吧，太多了～

在星球里➕公众号都有讲过了。

3.spark streaming

spark streaming核心原理大家都知道是微批处理。

基于receiver和direct api两种模式的原理，最好读懂源码。

主要是跟Kafka 结合的两种模式的区别。

direct这种模式如何实现仅一次处理。checkpoint的使用。

如何进行状态管理，upstatebykey，redis，hbase，alluxio作为状态管理存储设备的时候优缺点，然后就是故障恢复会引起的问题及如何避免等等吧。

合理设置批处理时间，为啥批处理时间不能太大，也不能太小，task倾斜，数据倾斜如何解决。

内存申请，kafka分区设置的依据是啥？

并行度问题，这个也是浪尖反复强调的，彻底理解对spark任务调优帮助很大。

blockrdd和kafkardd的底层区别。

与spark sql和hivecontext结合使用。

广播变量的使用及释放机制等。

动态分区发现和topic发现机制。

executor存活监控，task执行情况监控，未处理队列积累的健康告警（非常重要）等价于对lagsize的监控告警。

小文件问题，星球里文章很详细。根源上避免才是王道。顺便提一句：为啥namenode那么怕小文件呢？

作为7*24小时的应用程序，如何进行监控告警及故障自动恢复～

可怕的内容，多的一笔，拿着手机一个字一个字打，好累。

4.spark sql

在数仓的领域，实时处理都用它，而且structured streaming也逐步依赖于sql引擎了。

常见算子的使用及理解，并行度问题，大小表join，如何广播小表。

join，group by等数据倾斜如何发现及处理方法，这个浪尖还专门录制过视频，星球里球友应该都知道，不知道回去翻看一下。

常见的存储格式，parquet，txt，json，orc对比及对性能的影响。

调优大部分也是针对并行度，文件大小，数据倾斜，task倾斜，内存和cpu合理设置等。

5.structured streaming

这个我也系统整理了案例，分享到了星球里，要是没用过的话，建议用一下。

动态表，增量sql引擎，仅一次处理，维表join等非常好用，watermark，还有就是繁杂的join 机制。

当然限制还是很多的，期待后续版本。

spark streaming在spark 2.4的时候都没更新了，后面就主推sql引擎相关内容了，还是值得期待的。

不过话虽这么说，我觉得flink也相对好用，就是可能bug多些，新版本好点。


