
Hive
HDFS 不适用于存储大量小文件
对小文件进行合并，是行之有效的提高调度效率的方法，假如我们的作业设置合理的文件数，对集群的整体调度效率也会产生积极的影响。HDFS不适用于存储大量的小文件，因为大量小文件的元数据会占用NameNode的大量内存。
在hive里小文件合并有两种比较常见的处理办法:
第一是使用Combinefileinputformat，将多个小文件打包作为一个整体的inputsplit，减少map任务数
set mapred.max.split.size=256000000
set mapred.min.split.size.per.node=256000000
set  Mapred.min.split.size.per.rack=256000000
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
第二是设置hive参数，将额外启动一个MR Job打包小文件
hive.merge.mapredfiles = false 是否合并 Reduce 输出文件，默认为 False
hive.merge.size.per.task = 256*1000*1000 合并文件的大小
表分区优化建议
1. 当数据量较大，且经常需要按天统计时，建议使用分区表，按天存放数据。
2. 为了避免在插入动态分区数据的过程中，产生过多的小文件，在执行插入时，在分区字段上加上distribute by。
案例：
insert overwrite  table temp partition(day)
        select c.* from
        (select a.*,    cast(rand() * 10 as int) as fileNum
       (select * from user ) a
        left join
        (select * from test) b
        on a.user_id =b.user_id ) c distribute by fileNum

存储文件格式优化建议
Hive支持多种存储格式，比如TextFile，RCFile，ORC，Sequence，Parquet等。为了节省存储空间，或者大部分时间只查询其中的一部分字段时，可以在建表时使用列式存储(比如ORC文件)。

数据倾斜问题优化
自己动手写sql解决数据倾斜问题是个不错的选择。set hive.groupby.skewindata=true;这是通用的算法优化，但算法优化总是漠视业务，习惯性提供通用的解决方法。 Etl开发人员更了解业务，更了解数据，所以通过业务逻辑解决倾斜的方法往往更精确，更有效。
在hive里比较常用的数据倾斜处理办法：
第一通过hive.groupby.skewindata=true控制生成两个MR Job,第一个MR Job Map的输出结果随机分配到reduce做次预汇总,减少某些key值条数过多某些key条数过小造成的数据倾斜问题。
第二是通过过滤无效数据来解决数据倾斜问题。案例：
问题：日志中常会出现信息丢失，比如每日约为 20 亿的全网日志，其中的 user_id 为主 键，在日志收集过程中会丢失，出现主键为 null 的情况，如果取其中的 user_id 和 bmw_users 关联，就会碰到数据倾斜的问题。原因是 Hive 中，主键为 null 值的项会被当做相同的 Key 而分配进同一个计算 Map。
      解决方法 1：user_id 为空的不参与关联，子查询过滤 null
SELECT * FROM log a
JOIN bmw_users b ON a.user_id IS NOT NULL AND a.user_id=b.user_id
UNION All SELECT * FROM log a WHERE a.user_id IS NULL
　　解决方法 2 如下所示：函数过滤 null
SELECT * FROM log a LEFT OUTER
JOIN bmw_users b ON
CASE WHEN a.user_id IS NULL THEN CONCAT(‘dp_hive’,RAND()) ELSE a.user_id END =b.user_id;
　　调优结果：原先由于数据倾斜导致运行时长超过 1 小时，解决方法 1 运行每日平均时长 25 分钟，解决方法 2 运行的每日平均时长在 20 分钟左右。优化效果很明显。
　　我们在工作中总结出：解决方法2比解决方法1效果更好，不但IO少了，而且作业数也少了。解决方法1中log读取两次，job 数为2。解决方法2中 job 数是1。这个优化适合无效 id（比如-99、 ‘’，null 等）产生的倾斜问题。把空值的 key 变成一个字符串加上随机数，就能把倾斜的 数据分到不同的Reduce上，从而解决数据倾斜问题。因为空值不参与关联，即使分到不同 的 Reduce 上，也不会影响最终的结果。附上 Hadoop 通用关联的实现方法是：关联通过二次排序实现的，关联的列为 partion key，关联的列和表的 tag 组成排序的 group key，根据 pariton key分配Reduce。同一Reduce内根据group key排序。

善用multi insert
multi insert适合基于同一个源表按照不同逻辑不同粒度处理插入不同表的场景，做到只需要扫描源表一次，job个数不变，减少源表扫描次数

善用left semi join
当可以使用left semi join 语法时不要使用inner join，前者效率更高。原因：对于左表中指定的一条记录，一旦在右表中找到立即停止扫描。

开启Strict Mode
hive.mapred.mode=true，严格模式不允许执行以下查询：
分区表上没有指定了分区
没有limit限制的order by语句
笛卡尔积：JOIN时没有ON语句

合理设置map/reduce数目
如果reduce太少：如果数据量很大，会导致这个reduce异常的慢，从而导致这个任务不能结束，也有可能会OOM 2、如果reduce太多：  产生的小文件太多，合并起来代价太高，namenode的内存占用也会增大。如果我们不指定mapred.reduce.tasks， hive会自动计算需要多少个reducer。
减少map数目：
　　set mapred.max.split.size
　　set mapred.min.split.size
　　set mapred.min.split.size.per.node
　　set mapred.min.split.size.per.rack
　　set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
增加map数目：
当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。
假设有这样一个任务：
　　select data_desc, count(1), count(distinct id),sum(case when …),sum(case when ...),sum(…) from a group by data_desc
如果表a只有一个文件，大小为120M，但包含几千万的记录，如果用1个map去完成这个任务，肯定是比较耗时的，这种情况下，我们要考虑将这一个文件合理的拆分成多个，这样就可以用多个map任务去完成。
　　set mapred.reduce.tasks=10;
　　create table a_1 as select * from a distribute by rand(123);
这样会将a表的记录，随机的分散到包含10个文件的a_1表中，再用a_1代替上面sql中的a表，则会用10个map任务去完成。每个map任务处理大于12M（几百万记录）的数据，效率肯定会好很多。
reduce数目设置：
　　reduce数主要由三个属性来决定：
• hive.exec.reducers.bytes.per.reducer   ＃这个参数控制一个job会有多少个reducer来处理，依据的是输入文件的总大小。默认1GB。
• hive.exec.reducers.max    ＃这个参数控制最大的reducer的数量， 如果 input / bytes per reduce > max  则会启动这个参数所指定的reduce个数。  这个并不会影响mapre.reduce.tasks参数的设置。默认的max是999。
• mapred.reduce.tasks ＃这个参数如果指定了，hive就不会用它的estimation函数来自动计算reduce的个数，而是用这个参数来启动reducer。默认是-1。

join优化
Join查找操作的基本原则：应该将条目少的表/子查询放在 Join 操作符的左边。原因是在 Join 操作的 Reduce 阶段，位于 Join 操作符左边的表的内容会被加载进内存，将条目少的表放在左边，可以有效减少发生内存溢出错误的几率。
Join查找操作中如果存在多个join，且所有参与join的表中其参与join的key都相同，则会将所有的join合并到一个mapred程序中。

案例：
SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key1)  在一个mapre程序中执行join SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key2)   在两个mapred程序中执行join
Map join的关键在于join操作中的某个表的数据量很小，案例：
SELECT /*+ MAPJOIN(b) */ a.key, a.value  FROM a join b on a.key = b.key
Mapjoin 的限制是无法执行a FULL/RIGHT OUTER JOIN b，和map join相关的hive参数：hive.join.emit.interval  hive.mapjoin.size.key  hive.mapjoin.cache.numrows
由于join操作是在where操作之前执行，所以当你在执行join时，where条件并不能起到减少join数据的作用；案例：
SELECT a.val, b.val FROM a LEFT OUTER JOIN b ON (a.key=b.key)  WHERE a.ds='2009-07-07' AND b.ds='2009-07-07'
最好修改为：
SELECT a.val, b.val FROM a LEFT OUTER JOIN b  ON (a.key=b.key AND b.ds='2009-07-07' AND a.ds='2009-07-07')

在join操作的每一个mapred程序中，hive都会把出现在join语句中相对靠后的表的数据stream化，相对靠前的变的数据缓存在内存中。当然，也可以手动指定stream化的表：SELECT /*+ STREAMTABLE(a) */ a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key1)

排序优化
Order by 实现全局排序，一个reduce实现，效率低。
Sort by 实现部分有序，单个reduce输出的结果是有序的，效率高，通常和DISTRIBUTE BY关键字一起使用（DISTRIBUTE BY关键字 可以指定map 到 reduce端的分发key）。
CLUSTER BY col1 等价于DISTRIBUTE BY col1 SORT BY col1

利用Hive对UNION ALL优化的特性
　　多表 union all 会优化成一个 job。
　　问题：比如推广效果表要和商品表关联，效果表中的 auction_id 列既有 32 为字符串商 品 id，也有数字 id，和商品表关联得到商品的信息。
　　解决方法：Hive SQL 性能会比较好
SELECT * FROM effect a
JOIN
(SELECT auction_id AS auction_id FROM auctions
UNION All
SELECT auction_string_id AS auction_id FROM auctions) b
ON a.auction_id=b.auction_id
　　比分别过滤数字 id，字符串 id 然后分别和商品表关联性能要好。
　　这样写的好处：1 个 MapReduce 作业，商品表只读一次，推广效果表只读取一次。把 这个 SQL 换成 Map/Reduce 代码的话，Map 的时候，把 a 表的记录打上标签 a，商品表记录 每读取一条，打上标签 b，变成两个<key,value>对，<(b,数字 id),value>，<(b,字符串 id),value>。
　　所以商品表的 HDFS 读取只会是一次。
解决Hive对UNION ALL优化的短板
　　Hive 对 union all 的优化的特性：对 union all 优化只局限于非嵌套查询。
• 消灭子查询内的 group by
     示例 1：子查询内有 group by
SELECT * FROM
(SELECT * FROM t1 GROUP BY c1,c2,c3 UNION ALL SELECT * FROM t2 GROUP BY c1,c2,c3)t3
GROUP BY c1,c2,c3
　　从业务逻辑上说，子查询内的 GROUP BY 怎么都看显得多余（功能上的多余，除非有 COUNT(DISTINCT)），如果不是因为 Hive Bug 或者性能上的考量（曾经出现如果不执行子查询 GROUP BY，数据得不到正确的结果的 Hive Bug）。所以这个 Hive 按经验转换成如下所示：
SELECT * FROM (SELECT * FROM t1 UNION ALL SELECT * FROM t2)t3 GROUP BY c1,c2,c3
　　调优结果：经过测试，并未出现 union all 的 Hive Bug，数据是一致的。MapReduce 的 作业数由 3 减少到 1。
     t1 相当于一个目录，t2 相当于一个目录，对 Map/Reduce 程序来说，t1，t2 可以作为 Map/Reduce 作业的 mutli inputs。这可以通过一个 Map/Reduce 来解决这个问题。Hadoop 的 计算框架，不怕数据多，就怕作业数多。
　　但如果换成是其他计算平台如 Oracle，那就不一定了，因为把大的输入拆成两个输入， 分别排序汇总后 merge（假如两个子排序是并行的话），是有可能性能更优的（比如希尔排 序比冒泡排序的性能更优）。
• 消灭子查询内的 COUNT(DISTINCT)，MAX，MIN。
SELECT * FROM
(SELECT * FROM t1
UNION ALL SELECT c1,c2,c3 COUNT(DISTINCT c4) FROM t2 GROUP BY c1,c2,c3) t3
GROUP BY c1,c2,c3;
　　由于子查询里头有 COUNT(DISTINCT)操作，直接去 GROUP BY 将达不到业务目标。这时采用 临时表消灭 COUNT(DISTINCT)作业不但能解决倾斜问题，还能有效减少 jobs。
INSERT t4 SELECT c1,c2,c3,c4 FROM t2 GROUP BY c1,c2,c3;
SELECT c1,c2,c3,SUM(income),SUM(uv) FROM
(SELECT c1,c2,c3,income,0 AS uv FROM t1
UNION ALL
SELECT c1,c2,c3,0 AS income,1 AS uv FROM t2) t3
GROUP BY c1,c2,c3;
　　job 数是 2，减少一半，而且两次 Map/Reduce 比 COUNT(DISTINCT)效率更高。
     调优结果：千万级别的类目表，member 表，与 10 亿级得商品表关联。原先 1963s 的任务经过调整，1152s 即完成。
• 消灭子查询内的 JOIN
SELECT * FROM
(SELECT * FROM t1 UNION ALL SELECT * FROM t4 UNION ALL SELECT * FROM t2 JOIN t3 ON t2.id=t3.id) x
GROUP BY c1,c2;
　　上面代码运行会有 5 个 jobs。加入先 JOIN 生存临时表的话 t5，然后 UNION ALL，会变成 2 个 jobs。
INSERT OVERWRITE TABLE t5
SELECT * FROM t2 JOIN t3 ON t2.id=t3.id;
SELECT * FROM (t1 UNION ALL t4 UNION ALL t5);
　　调优结果显示：针对千万级别的广告位表，由原先 5 个 Job 共 15 分钟，分解为 2 个 job 一个 8-10 分钟，一个3分钟。
GROUP BY替代COUNT(DISTINCT)达到优化效果
　　计算 uv 的时候，经常会用到 COUNT(DISTINCT)，但在数据比较倾斜的时候 COUNT(DISTINCT) 会比较慢。这时可以尝试用 GROUP BY 改写代码计算 uv。
• 原有代码
INSERT OVERWRITE TABLE s_dw_tanx_adzone_uv PARTITION (ds=20120329)
SELECT 20120329 AS thedate,adzoneid,COUNT(DISTINCT acookie) AS uv FROM s_ods_log_tanx_pv t WHERE t.ds=20120329 GROUP BY adzoneid
　　关于COUNT(DISTINCT)的数据倾斜问题不能一概而论，要依情况而定，下面是我测试的一组数据：
　　测试数据：169857条
#统计每日IP
CREATE TABLE ip_2014_12_29 AS SELECT COUNT(DISTINCT ip) AS IP FROM logdfs WHERE logdate='2014_12_29';
耗时：24.805 seconds
#统计每日IP（改造）
CREATE TABLE ip_2014_12_29 AS SELECT COUNT(1) AS IP FROM (SELECT DISTINCT ip from logdfs WHERE logdate='2014_12_29') tmp;
耗时：46.833 seconds
　　测试结果表名：明显改造后的语句比之前耗时，这是因为改造后的语句有2个SELECT，多了一个job，这样在数据量小的时候，数据不会存在倾斜问题。

Spark
RDD 多次使用时，建议将RDD 持久化
RDD在默认情况下的存储级别是StorageLevel.NONE，即既不存磁盘也不放在内存中，如果某个RDD需要多次使用，可以考虑将该RDD持久化，方法如下：
调用spark.RDD中的cache()、persist()、persist(newLevel: StorageLevel)函数均可将RDD持久化，cache()和persist()都是将RDD的存储级别设置为StorageLevel.MEMORY_ONLY，persist(newLevel: StorageLevel)可以为RDD设置其他存储级别，但是要求调用该方法之前RDD的存储级别为StorageLevel.NONE或者与newLevel相同，也就是说，RDD的存储级别一旦设置为StorageLevel.NONE之外的级别，则无法改变。
如果想要将RDD去持久化，那么可以调用unpersist(blocking: Boolean = true)，该函数功能如下：
1. 将该RDD从持久化列表中移除，RDD对应的数据进入可回收状态；
2. 将RDD的存储级别重新设置为StorageLevel.NONE。
慎重选择shuffle 过程的算子
该类算子称为宽依赖算子，其特点是父RDD的一个partition影响子RDD得多个partition，RDD中的元素一般都是<key, value>对。执行过程中都会涉及到RDD的partition重排，这个操作称为shuffle。
由于shuffle类算子存在节点之间的网络传输，因此对于数据量很大的RDD，应该尽量提取需要使用的信息，减小其单条数据的大小，然后再调用shuffle类算子。
常用的有如下几种：
combineByKey() : RDD[(K, V)] => RDD[(K, C)]，是将RDD[(K, V)]中key相同的数据的所有value转化成为一个类型为C的值。
groupByKey() 和reduceByKey()是combineByKey的两种具体实现，对于数据聚合比较复杂而groupByKey和reduceByKey不能满足使用需求的场景，可以使用自己定义的聚合函数作为combineByKey的参数来实现。
distinct(): RDD[T] => RDD[T]，作用是去除重复元素的算子。其处理过程代码如下：
map(x => (x, null)).reduceByKey((x, y) => x, numPartitions).map(_._1)
这个过程比较耗时，尤其是数据量很大时，建议不要直接对大文件生成的RDD使用。
join() : (RDD[(K, V)], RDD[(K, W)]) => RDD[(K, (V, W))]，作用是将两个RDD通过key做连接。如果RDD[(K, V)]中某个key有X个value，而RDD[(K, W)]中相同key有Y个value，那么最终在RDD[(K, (V, W))]中会生成X*Y条记录。
在业务情况允许的情况下使用高性能算子
1. 使用reduceByKey/aggregateByKey替代groupByKey
所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。 map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。
通常来说，在可能的情况下，建议使用reduceByKey或aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。
2. 使用mapPartitions替代普通map
mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。 但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！
3. 使用filter之后进行coalesce操作
通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的 partition数量，将RDD中的数据压缩到更少的partition中去。因为filter之后，RDD的每个partition中都会有很多数据 被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多， 可能速度反而越慢。因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即 可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。
4. 使用repartitionAndSortWithinPartitions替代repartition与sort类操作
repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子 可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。
5. 使用foreachPartitions替代foreach
原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数 据。在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个 partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。
RDD 共享变量
在应用开发中，一个函数被传递给Spark操作（例如map和reduce），在一个远程集群上运行，它实际上操作的是这个函数用到的所有变量的独立拷贝。这些变量会被拷贝到每一台机器。通常看来，在任务之间中，读写共享变量显然不够高效。Spark为两种常见的使用模式，提供了两种有限的共享变量：广播变量、累加器。
使用Kryo 优化序列化性能
在对性能要求比较高的场景下，可以使用Kryo 优化序列化性能。
Spark提供了两种序列化实现：
org.apache.spark.serializer.KryoSerializer：性能好，兼容性差
org.apache.spark.serializer.JavaSerializer：性能一般，兼容性好
使用：conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
说明
为什么不默认使用Kryo序列化？
Spark默认使用的是Java的序列化机制，也就是ObjectOutputStream/ObjectInputStream API来进行
序列化和反序列化。但是Spark同时支持使用Kryo序列化库，Kryo序列化类库的性能比Java序列
化类库的性能要高很多。官方介 绍，Kryo序列化机制比Java序列化机制，性能高10倍左右。
Spark之所以默认没有使用Kryo作为序列化类库，是因为Kryo要求最好要注册所 有需要进行序列
化的自定义类型，因此对于开发者来说，这种方式比较麻烦。
Spark Streaming 性能优化建议
1. 设置合理的批处理时间(batchDuration)
2. 设置合理的数据接收并行度
– 设置多个Receiver接收数据
– 设置合理的Receiver阻塞时间
3. 设置合理的数据处理并行度
4. 使用Kryo系列化
5. 内存调优
– 设置持久化级别减少GC开销
– 使用并发的标记-清理GC算法减少GC暂停时间










1、 数据倾斜问题
先大概介绍下数据倾斜的问题
从hive取出来的数据都是一个月一个月的，然而，有的数据虽然取的是30天的量，但实际上数据都集中在了一天，其他29天都是空的没有数据，在往druid导入的时候，底层实现实际上是一个个的MapReduce任务，那么hive这边产生的数据文件有多少个天的跨度，在往druid导入的时候就会有多少个MapReduce任务产生。
我们遇到的问题是，很多数据取出来都是只有一天的数据，而且量还很大，那么这就导致了在往druid导的时候，就只有一个MapReduce任务产生，hadoop是分布式的，有上百台机器在那里提供服务，有上千核上千兆的内存可以使用，如果只有一个MapReduce任务产生，那就意味着只有一台机器在跑这个数据，这就根本没有充分利用到hadoop分布式的特性和优势，所以，我们在集群上看到29个任务都在1秒内完成，剩下一个任务跑了几个小时都跑不完，这就是所谓的数据倾斜，解决的措施就是将数据打散，让一天的数据分布到30天里面去，也不是说必须将数据分布到30天里面去，至少不能全部都集中在一天里，10天20天都可以
将日期打散，示例如下，主要是利用随机函数将分区字段日期进行随机分布
insert overwrite directory 'hdfs://hdfs01-stg/tmp/gkdata/AGG_DIR_IND_EXPENSE_ANALY_TBL' row format delimited fields terminated by '\t'
select
etl_mon                ,
version                ,
full_version           ,
corp_segment_3_id      ,
corp_segment_3_name    ,
corp_segment_2_name    ,
corp_segment_1_name    ,
business_segment_id    ,
business_segment_name  ,
cost_center_id         ,
cost_center_name       ,
account_subject_id     ,
account_subject_4_name ,
account_subject_3_id   ,
account_subject_3_name ,
account_subject_2_id   ,
account_subject_2_name ,
account_subject_1_id   ,
account_subject_1_name ,
budget_subtitle_2_id   ,
budget_subtitle_2_name ,
budget_subtitle_1_id   ,
budget_subtitle_1_name ,
level3_item_code       ,
project_name_l3        ,
project_code_l2        ,
project_code_l1        ,
fee_code               ,
fee_code_name          ,
ma_amount1             ,
ma_amount2             ,
ma_amount3             ,
ma_amount4             ,
updated_date           ,
lcd                    ,
concat(substr(canc_date,0,8),concat(floor(rand(1)*3),floor(rand(1)*9+1)),substr(canc_date,11,24))
from sx_mas_safe.AGG_DIR_IND_EXPENSE_ANALY_TBL;

解释：
hive取出来的数据分区字段日期如下所示，我们要做的就是将01变成随机数
2017-12-01T00:00:00+08:00
上面的取数据脚本在执行完后会有报错，不知为什么concat函数后面不能直接跟其他函数，也就是这里的substr函数，但是不影响我们的工作，依然可以正常将数据取出来，应该是hive的bug，如果不想看到这个错误，可以将concat函数后面第一个属性substr(canc_date,0,8)写死，改为'2017-12-' ，但是，这样的话这个打散函数就没有通用性了

==============================================================================================



避免存储大量小文件，减少元数据数量；
文件压缩，比如ORC 格式；
避免对HDFS执行count、du等操作；

输入小文件合并
使用Combinefileinputformat，将多个小文件打包作为一个整体的inputsplit，减少map任务数
set mapred.max.split.size=256000000
set mapred.min.split.size.per.node=256000000
set  Mapred.min.split.size.per.rack=256000000
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
输出小文件合并
设置hive参数，将额外启动一个MR Job打包小文件
hive.merge.mapredfiles = false 是否合并 Reduce 输出文件，默认为 False
hive.merge.size.per.task = 256*1000*1000 合并文件的大小
当数据量较大，且经常需要按天统计时，建议使用分区表，按天存放数据使用；
为了避免在插入动态分区数据的过程中，产生过多的小文件，在执行插入时，在分区字段上加上distribute by；
从分区表读取数据时，明确指定分区值，不要读取整张表。
通过hive.groupby.skewindata=true控制生成两个MR Job,第一个MR Job Map的输出结果随机分配到reduce做次预汇总,减少某些key值条数过多某些key条数过小造成的数据倾斜问题；
通过过滤无效数据来解决数据倾斜问题；
Join查找操作的基本原则：应该将条目少的表/子查询放在 Join 操作符的左边；
Join查找操作中如果存在多个join，且所有参与join的表中其参与join的key都相同，则会将所有的join合并到一个mapred程序中；
如果某个表数据量很小，可以使用MapJoin。
通常应该由系统自动分配map/reduce数目。如果reduce太少：如果数据量很大，会导致这个reduce异常的慢，从而导致这个任务不能结束，也有可能会OOM ；如果reduce太多：  产生的小文件太多，合并起来代价太高；
当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率；
multi insert适合基于同一个源表按照不同逻辑不同粒度处理插入不同表的场景，做到只需要扫描源表一次，job个数不变，减少源表扫描次数；
当可以使用left semi join 语法时不要使用inner join，前者效率更高。原因：对于左表中指定的一条记录，一旦在右表中找到立即停止扫描；
排序优化：Order by 实现全局排序，一个reduce实现，效率低。Sort by 实现部分有序，单个reduce输出的结果是有序的，效率高，通常和DISTRIBUTE BY关键字一起使用（DISTRIBUTE BY关键字 可以指定map 到 reduce端的分发key）。CLUSTER BY col1 等价于DISTRIBUTE BY col1 SORT BY col1；
可以尝试用 GROUP BY替代COUNT(DISTINCT)达到优化效果；
RDD 多次使用时，建议将RDD 持久化；
在对性能要求比较高的场景下，可以使用Kryo 优化序列化性能，但Kryo要求最好要注册所有需要进行序列化的自定义类型；
由于shuffle类算子存在节点之间的网络传输，因此对于数据量很大的RDD，应该尽量提取需要使用的信息，减小其单条数据的大小，然后再调用shuffle类算子；
慎用distinct算子，尤其是数据量很大时，建议不要直接对大文件生成的RDD使用；
使用reduceByKey/aggregateByKey替代groupByKey。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差；
使用mapPartitions替代普通map。mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些，但易OOM；
通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的 partition数量；
使用repartitionAndSortWithinPartitions替代repartition+sort类操作；
使用foreachPartitions替代foreach；

