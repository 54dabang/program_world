
1.1.1 由 Redis 面试想到的 / 1

1.1.3 Redis 可以做什么 / 3

1.1.4 小结 / 3

1.1.5 扩展阅读 / 4

1.2 万丈高楼平地起——Redis 基础数据结构 / 4

1.2.1 Redis 的安装 / 5

1.2.2 5 种基础数据结构 / 6

1.2.3 容器型数据结构的通用规则 / 17

1.2.4 过期时间 / 17

1.2.5 思考&作业 / 17

1.3 千帆竞发——分布式锁 / 18

1.3.1 分布式锁的奥义 / 18

1.3.2 超时问题 / 20

1.3.3 可重入性 / 21

1.3.4 思考&作业 / 24

1.4 缓兵之计——延时队列 / 24

1.4.1 异步消息队列 / 24

1.4.2 队列空了怎么办 / 26

1.4.3 阻塞读 / 26

1.4.4 空闲连接自动断开 / 26

1.4.5 锁冲突处理 / 27

1.4.6 延时队列的实现 / 27

1.4.7 进一步优化 / 30

1.4.8 思考&作业 / 31

1.5 节衣缩食——位图 / 31

1.5.1 基本用法 / 31

1.5.2 统计和查找 / 34

1.5.3 魔术指令 bitfield / 35

1.5.4 思考&作业 / 38

1.6 四两拨千斤——HyperLogLog / 38

1.6.1 使用方法 / 39

1.6.2 pfadd 中的 pf 是什么意思 / 41

1.6.3 pfmerge 适合的场合 / 42

1.6.4 注意事项 / 42

1.6.5 HyperLogLog 实现原理 / 42

1.6.6 pf 的内存占用为什么是 12KB / 49

1.6.7 思考&作业 / 50

1.7 层峦叠嶂——布隆过滤器 / 50

1.7.1 布隆过滤器是什么 / 51

1.7.2 Redis 中的布隆过滤器 / 51

1.7.3 布隆过滤器的基本用法 / 52

1.7.4 注意事项 / 59

1.7.5 布隆过滤器的原理 / 60

1.7.6 空间占用估计 / 61

1.7.7 实际元素超出时，误判率会怎样变化 / 62

1.7.8 用不上 Redis 4.0 怎么办 / 63

1.7.9 布隆过滤器的其他应用 / 63

1.8 断尾求生——简单限流 / 64

1.8.1 如何使用 Redis 来实现简单限流策略 / 64

1.8.2 解决方案 / 65

1.8.3 小结 / 67

1.9 一毛不拔——漏斗限流 / 68

1.9.1 Redis-Cell / 71

1.9.2 思考&作业 / 72

1.9.3 扩展阅读：Redis-Cell 作者介绍 / 72

1.10 近水楼台——GeoHash / 73

1.10.1 用数据库来算附近的人 / 73

1.10.2 GeoHash 算法 / 74

1.10.3 Geo 指令的基本用法 / 75

1.10.4 注意事项 / 78

1.11 大海捞针——scan / 79

1.11.1 scan 基本用法 / 80

1.11.2 字典的结构 / 82

1.11.3 scan 遍历顺序 / 82

1.11.4 字典扩容 / 83

1.11.5 对比扩容、缩容前后的遍历顺序 / 84

1.11.6 渐进式 rehash / 85

1.11.7 更多的 scan 指令 / 85

1.11.8 大 key 扫描 / 85

第2 篇 原理篇 / 87

2.1 鞭辟入里——线程 IO 模型 / 87

2.1.1 非阻塞 IO / 87

2.1.2 事件轮询 （多路复用） / 88

2.1.3 指令队列 / 90

2.1.4 响应队列 / 90

2.1.5 定时任务 / 90

2.1.6 扩展阅读 / 90

2.2 交头接耳——通信协议 / 90

2.2.1 RESP / 91

2.2.2 客户端→服务器 / 92

2.2.3 服务器→客户端 / 92

2.2.4 小结 / 95

2.2.5 扩展阅读 / 95

2.3 未雨绸缪——持久化 / 95

2.3.1 快照原理 / 96

2.3.2 fork（多进程） / 96

2.3.3 AOF 原理 / 97

2.3.4 AOF 重写 / 98

2.3.5 fsync / 98

2.3.6 运维 / 98

2.3.7 Redis 4.0 混合持久化 / 99

2.3.8 思考&作业 / 100

2.4 雷厉风行——管道 / 100

2.4.1 Redis 的消息交互 / 100

2.4.2 管道压力测试 / 101

2.4.3 深入理解管道本质 / 102

2.4.4 小结 / 104

2.5 同舟共济——事务 / 104

2.5.1 Redis 事务的基本用法 / 104

2.5.2 原子性 / 105

2.5.3 discard（丢弃） / 106

2.5.4 优化 / 106

2.5.5 watch / 107

2.5.6 注意事项 / 108

2.5.7 思考&作业 / 110

2.6 小道消息——PubSub / 110

2.6.1 消息多播 / 110

2.6.2 PubSub / 111

2.6.3 模式订阅 / 113

2.6.4 消息结构 / 114

2.6.5 PubSub 的缺点 / 115

2.6.6 补充 / 115

2.7 开源节流——小对象压缩 / 115

2.7.1 32bit VS 64bit / 116

2.7.2 小对象压缩存储（ziplist） / 116

2.7.3 内存回收机制 / 120

2.7.4 内存分配算法 / 120

第3 篇 集群篇 / 122

3.1 有备无患——主从同步 / 122

3.1.1 CAP 原理 / 122

3.1.2 最终一致 / 123

3.1.3 主从同步与从从同步 / 123

3.1.4 增量同步 / 124

3.1.5 快照同步 / 124

3.1.6 增加从节点 / 125

3.1.7 无盘复制 / 125

3.1.8 wait 指令 / 125

3.1.9 小结 / 126

3.2 李代桃僵——Sentinel / 126

3.2.1 消息丢失 / 128

3.2.2 Sentinel 基本用法 / 128

3.2.3 思考&作业 / 129

3.3 分而治之——Codis / 130

3.3.1 Codis 分片原理 / 131

3.3.2 不同的 Codis 实例之间槽位关系如何同步 / 132

3.3.3 扩容 / 132

3.3.4 自动均衡 / 133

3.3.5 Codis 的代价 / 133

3.3.6 Codis 的优点 / 134

3.3.7 mget 指令的操作过程 / 134

3.3.8 架构变迁 / 135

3.3.9 Codis 的尴尬 / 135

3.3.10 Codis 的后台管理 / 136

3.3.11 思考&作业 / 136

3.4 众志成城——Cluster / 137

3.4.1 槽位定位算法 / 138

3.4.2 跳转 / 138

3.4.3 迁移 / 138

3.4.4 容错 / 140

3.4.5 网络抖动 / 140

3.4.6 可能下线（PFAIL）与确定下线（Fail） / 141

3.4.7 Cluster 基本用法 / 141

3.4.8 槽位迁移感知 / 142

3.4.9 集群变更感知 / 143

3.4.10 思考&作业 / 143

第4 篇 拓展篇 / 144

4.1 耳听八方——Stream / 144

4.1.1 消息 ID / 145

4.1.2 消息内容 / 145

4.1.3 增删改查 / 145

4.1.4 独立消费 / 147

4.1.5 创建消费组 / 148

4.1.6 消费 / 150

4.1.7 Stream 消息太多怎么办 / 152

4.1.8 消息如果忘记 ack 会怎样 / 153

4.1.9 PEL 如何避免消息丢失 / 153

4.1.10 Stream 的高可用 / 153

4.1.11 分区 Partition / 154

4.1.12 小结 / 154

4.2 无所不知——Info 指令 / 154

4.2.1 Redis 每秒执行多少次指令 / 155

4.2.2 Redis 连接了多少客户端 / 156

4.2.3 Redis 内存占用多大 / 156

4.2.4 复制积压缓冲区多大 / 157

4.2.5 思考&作业 / 158

4.3 拾遗补漏——再谈分布式锁 / 158

4.3.1 Redlock 算法 / 158

4.3.2 Redlock 使用场景 / 159

4.3.3 扩展阅读：redlock-py 的作者 / 160

4.4 朝生暮死——过期策略 / 160

4.4.1 过期的 key 集合 / 160

4.4.2 定时扫描策略 / 160

4.4.3 从节点的过期策略 / 161

4.5 优胜劣汰——LRU / 162

4.5.1 LRU 算法 / 163

4.5.2 近似 LRU 算法 / 164

4.5.3 思考&作业 / 165

4.6 平波缓进——懒惰删除 / 165

4.6.1 Redis 为什么使用懒惰删除 / 165

4.6.2 flush / 166

4.6.3 异步队列 / 166

4.6.4 AOF Sync 也很慢 / 166

4.6.5 更多异步删除点 / 166

4.7 妙手仁心——优雅地使用 Jedis / 167

4.7.1 重试 / 171

4.7.2 思考&作业 / 172

4.8 居安思危——保护 Redis / 172

4.8.1 指令安全 / 172

4.8.2 端口安全 / 173

4.8.3 Lua 脚本安全 / 174

4.8.4 SSL 代理 / 174

4.8.5 小结 / 174

4.9 隔墙有耳——Redis 安全通信 / 175

4.9.1 spiped 原理 / 176

4.9.2 spiped 使用入门 / 176

4.9.3 思考&作业 / 179

第5 篇 源码篇 / 180

5.1 丝分缕析——探索“字符串”内部 / 180

5.1.1 embstr VS raw / 181

5.1.2 扩容策略 / 184

5.1.3 思考&作业 / 184

5.2 循序渐进——探索“字典”内部 / 184

5.2.1 dict 内部结构 / 184

5.2.2 渐进式 rehash / 186

5.2.3 查找过程 / 187

5.2.4 hash 函数 / 188

5.2.5 hash 攻击 / 188

5.2.6 扩容条件 / 188

5.2.7 缩容条件 / 189

5.2.8 set 的结构 / 189

5.2.9 思考&作业 / 189

5.3 挨肩迭背——探索“压缩列表”内部 / 190

5.3.1 增加元素 / 192

5.3.2 级联更新 / 192

5.3.3 intset 小整数集合 / 194

5.3.4 思考&作业 / 195

5.4 风驰电掣——探索“快速列表”内部 / 195

5.4.1 每个 ziplist 存多少元素 / 197

5.4.2 压缩深度 / 198

5.5 凌波微步——探索“跳跃列表”内部 / 198

5.5.1 基本结构 / 199

5.5.2 查找过程 / 199

5.5.3 随机层数 / 200

5.5.4 插入过程 / 201

5.5.5 删除过程 / 202

5.5.6 更新过程 / 203

5.5.7 如果 score 值都一样呢 / 203

5.5.8 元素排名是怎么算出来的 / 203

5.5.9 思考&作业 / 204

5.5.10 题外话 / 204

5.6 破旧立新——探索“紧凑列表”内部 / 205

5.6.1 级联更新 / 207

5.6.2 取代 ziplist 尚需时日 / 207

5.6.3 思考&作业 / 207

5.7 金枝玉叶——探索“基数树”内部 / 207

5.7.1 应用 / 208

5.7.2 结构 / 210

5.7.3 思考&作业 / 213

5.8 精益求精——LFU VS LRU / 213

5.8.1 Redis 对象的热度 / 213

5.8.2 LRU 模式 / 213

5.8.3 LFU 模式 / 214

5.8.4 为什么 Redis 要缓存系统时间戳 / 217

5.8.5 Redis 为什么在获取 lruclock 时使用原子操作 / 217

5.8.6 如何打开 LFU 模式 / 218

5.8.7 思考&作业 / 218

5.9 如履薄冰——懒惰删除的巨大牺牲 / 218

5.9.1 懒惰删除的最初实现不是异步线程 / 219

5.9.2 异步线程方案其实也相当复杂 / 219

5.9.3 异步删除的实现 / 221

5.9.4 队列安全 / 224

5.9.5 思考&作业 / 225

5.10 跋山涉水——深入字典遍历 / 225

5.10.1 一边遍历一边修改 / 226

5.10.2 重复遍历的难题 / 227

5.10.3 迭代器的结构 / 227

5.10.4 迭代过程 / 229

5.10.5 迭代器的选择 / 231





1 为何选择Redis？ 1
尝试使用Redis 4

流行的使用模式 9

Redis不合心意？马上再试试！ 11


Redis键 14

Redis键模式 15

键分隔符和命名约定 17

手动创建Redis模式 19

解构Redis对象映射器 22

键过期 27

键的注意事项 27

大O符号 28

为自定义代码计算大O符号 30

回顾Redis数据结构的时间复杂度 32

字符串 32

哈希 33

列表 34

集合 35

有序集合 36

高级有序集合操作 39

位串和位操作 39

HyperLogLogs 41


配置Redis 44

主从复制 45

32位Redis 45

INFO memory详解 47

键过期 49

LRU键清除策略 54

创建内存高效的Redis数据结构 62

小巧的哈希、列表、集合和有序集合 62

把位、字节和Redis字符串用作随机访问数组 68

优化哈希，高效存储 69

硬件和网络延迟 72

操作系统建议 74


Redis的内部结构 76

理解redis．h和redis．c 83

Redis序列化协议 93

Redis RDB格式 97

使用Redis和Python创建协程 99

使用Node．js和Redis实现Todo列表应用 103

复制与公共访问 106


在Redis中使用Lua 108

使用Redis的KEYS和ARGV 117

Redis中的高级Lua脚本 121

MARC21数据提取 121

纸质文具在线商店 123

让JSON-LD、Lua和Redis协同工作 126

Redis Lua调试器 130

Redis的编程与管理 133

主从复制 134

使用MULTI和EXEC实现事务 136

Redis在DevOps中扮演的角色 139

6 可伸缩性：Redis集群和Sentinel 142
数据分区的方法 142
范围分区 143
列表分区 145
哈希分区 148
复合分区 149
键哈希标签 150
使用Twemproxy实现Redis集群 151
使用关联数据片段服务器测试Twemproxy 152
Redis集群的背景 158
Redis集群概览 159
使用Redis集群 160
Redis集群实时重新配置及重新分片 165
故障转移 168
在Redis集群中替换或者升级节点 170
使用Redis Sentinel进行监控 171
为区域代码列表分区配置Redis Sentinel 173

7 Redis与互补的NoSQL技术 177
NoSQL技术的繁荣 177
Redis作为MongoDB的分析补充 181
Redis作为ElasticSearch的预处理组件 192
在BIBCAT中使用Redis和ElasticSearch 193
ElasticSearch、Logstash和Redis 198
Redis作为Fedora Commons的智能缓存补充 199

8 Docker容器与云端部署 206
Linux容器 206
与Redis相关的Docker基础 211
Docker镜像中的层 219
Docker文件系统后端 220
Docker和Redis的问题 227
使用Docker Compose打包应用程序 227
Redis和AWS 232
专门的云托管选项 233
Redis Labs 234
DigitalOcean Redis 234

9 任务管理与消息队列 236
Redis的发布/订阅模式概述 236
发布/订阅RESP回复 237
SUBSCRIBE和UNSUBSCRIBE RESP数组 237
PSUBSCRIBE和UNSUBSCRIBE数组 239
使用redis-cli进行发布/订阅 240
Redis发布订阅实战 242
第一个工作站采用Python进行发布订阅 244
第二个工作站采用Node．js进行发布订阅 246
第三个工作站使用Lua客户端进行发布订阅 248
Redis键空间通知 251
使用Redis和Celery进行任务管理 255
GIS和RestMQ 259
使用RestMQ进行任务管理 262
使用Redis技术进行消息通信 264
使用Disque进行消息通信 264

10 信息流的测量与管理 267
基于Redis的ETL方案 267
将JSON转换成RESP 273
管理Redis时的安全考虑 279
使用Redis Web仪表板进行运营监测 282
机器学习 283
朴素贝叶斯与工作分类 284
使用Redis实现线性规划 294



1.2 下载和安装Redis

1.3 启动和停止Redis

1.4 使用redis-cli 连接到Redis

1.5 获取服务器信息.

1.6 理解Redis 事件模型

1.7 理解Redis 通信协议

2.2 使用字符串（string）类型
2.3 使用列表（list）类型
2.4 使用哈希（hash）类型
2.5 使用集合（set）类型
2.6 使用有序集合（sorted set）类型

2.7 使用HyperLogLog 类型.

2.8 使用Geo 类型.

2.9 键管理

3.2 使用位图（bitmap）

3.3 设置键的过期时间

3.4 使用SORT 命令

3.5 使用管道（pipeline）

3.6 理解Redis 事务（transaction）

3.7 使用发布订阅（PubSub）

3.8 使用Lua 脚本

3.9 调试Lua 脚本

4.2 Redis 常见应用场景

4.3 使用正确的数据类型

4.4 使用正确的API .

4.5 使用Java 连接到Redis

4.6 使用Python 连接到Redis

4.7 使用Spring Data 连接到Redis

4.8 使用Redis 编写MapReduce 作业

4.9 使用Redis 编写Spark 作业

第5 章复制

5.1 本章概要

5.2 配置Redis 的复制机制

5.3 复制机制的调优

5.4 复制机制的故障诊断

第6 章持久化

6.1 本章概要

6.2 使用RDB

6.3 探究RDB 文件

6.4 使用AOF

6.5 探究AOF 文件

6.6 RDB 和AOF 的结合使用.

第7 章配置高可用和集群

7.1 本章概要

7.2 配置Sentinel

7.3 测试Sentinel

7.4 管理Sentinel

7.5 配置Redis Cluster

7.6 测试Redis Cluster

7.7 管理Redis Cluster

第8 章生产环境部署

8.1 本章概要

8.2 在Linux 上部署Redis

8.3 Redis 安全相关设置

8.4 配置客户端连接选项

8.5 配置内存策略

8.6 基准测试

8.7 日志

第9 章管理Redis

9.1 本章概要

9.2 管理Redis 服务器配置

9.3 使用bin/redis-cli 操作Redis

9.4 备份和恢复

9.5 监控内存使用情况

9.6 管理客户端

9.7 数据迁移

第10 章Redis 的故障诊断

10.1 本章概要

10.2 Redis 的健康检查

10.3 使用SLOWLOG 识别慢查询

10.4 延迟问题的故障诊断

10.5 内存问题的故障诊断

10.6 崩溃问题的故障诊断

第11 章使用Redis 模块扩展Redis

11.1 本章概要.

11.2 加载Redis 模块

11.3 编写Redis 模块

第12 章Redis 生态系统

12.2 Redisson 客户端

12.3 Twemproxy

12.4 Codis—一个基于代理的高性能Redis 集群解决方案

12.5 CacheCloud 管理系统

12.6 Pika—一个与Redis 兼容的NoSQL 数据库


1．1 历史与发展 1
1．2 特性 2
1．2．1 存储结构 2
1．2．2 内存存储与持久化 3
1．2．3 功能丰富 3
1．2．4 简单稳定 4
2．1　安装Redis 7
2．1．1 在POSIX系统中安装 7
2．1．2　在OS X系统中安装 8
2．1．3　在Windows中安装 9
2．2　启动和停止Redis 11
2．2．1　启动Redis 12
2．2．2　停止Redis 14
2．3　Redis命令行客户端 14
2．3．1　发送命令 14
2．3．2　命令返回值 15
2．4　配置 17
2．5　多数据库 17
第3章　入门 19
3．1 热身 19
3．2 字符串类型 21
3．2．1 介绍 22
3．2．2 命令 22
3．2．3 实践 25
3．2．4 命令拾遗 27
3．3 散列类型 32
3．3．1 介绍 33
3．3．2 命令 34
3．3．3 实践 37
3．3．4 命令拾遗 39
3．4 列表类型 40
3．4．1 介绍 41
3．4．2 命令 41
3．4．3 实践 44
3．4．5 命令拾遗 46
3．5 集合类型 48
3．5．1 介绍 48
3．5．2 命令 49
3．5．3 实践 52
3．5．4 命令拾遗 54
3．6 有序集合类型 57
3．6．1 介绍 57
3．6．2 命令 58
3．6．3 实践 62
3．6．4 命令拾遗 63
第4章　进阶 67
4．1　事务 67
4．1．1　概述 68
4．1．2　错误处理 69
4．1．3　WATCH命令介绍 70
4．2　过期时间 72
4．2．1　命令介绍 73
4．2．2　实现访问频率限制之一 75
4．2．3　实现访问频率限制之二 76
4．2．4　实现缓存 77
4．3　排序 78
4．3．1　有序集合的集合操作 78
4．3．2　SORT命令 79
4．3．3　BY参数 81
4．3．4　GET参数 83
4．3．5　STORE参数 84
4．3．6　性能优化 85
4．4　消息通知 85
4．4．1　任务队列 86
4．4．2　使用Redis实现任务队列 87
4．4．3　优先级队列 88
4．4．4　“发布/订阅”模式 90
4．4．5　按照规则订阅 91
4．5　管道 92
4．6　节省空间 93
4．6．1　精简键名和键值 94
4．6．2　内部编码优化 94
第5章　实践 103
5．1 PHP与Redis 103
5．1．1 安装 104
5．1．2 使用方法 104
5．1．3 简便用法 105
5．1．4 实践：用户注册登录功能 107
5．2 Ruby与Redis 111
5．2．1 安装 111
5．2．2 使用方法 111
5．2．3 简便用法 112
5．2．4 实践：自动完成 112
5．3 Python与Redis 116
5．3．1 安装 116
5．3．2 使用方法 116
5．3．3 简便用法 117
5．3．4 实践：在线的好友 117
5．4 Node．js与Redis 123
5．4．1 安装 123
5．4．2 使用方法 123
5．4．3 简便用法 125
5．4．4 实践：IP地址查询 127
第6章　脚本 131
6．1 概览 131
6．1．1 脚本介绍 132
6．1．2 实例：访问频率限制 132
6．2 Lua语言 133
6．2．1 Lua语法 134
6．2．2 标准库 143
6．2．3 其他库 147
6．3 Redis与Lua 147
6．3．1 在脚本中调用Redis命令 148
6．3．2 从脚本中返回值 148
6．3．3 脚本相关命令 149
6．3．4 应用实例 150
6．4 深入脚本 153
6．4．1 KEYS与ARGV 153
6．4．2 沙盒与随机数 154
6．4．3 其他脚本相关命令 154
6．4．4 原子性和执行时间 155
第7章　持久化 157
7．1 RDB方式 157
7．1．1 根据配置规则进行自动快照 158
7．1．2 用户执行SAVE或BGSAVE命令 158
7．1．3 执行FLUSHALL命令 159
7．1．4 执行复制时 159
7．1．5 快照原理 159
7．2AOF方式 160
7．2．1 开启AOF 160
7．2．2 AOF的实现 161
7．2．3 同步硬盘数据 162
第8章　集群 165
8．1 复制 165
8．1．1 配置 165
8．1．2 原理 168
8．1．3 图结构 170
8．1．4 读写分离与一致性 170
8．1．5 从数据库持久化 171
8．1．6 硬盘复制 172
8．1．7 增量复制 172
8．2 哨兵 173
8．2．1 什么是哨兵 174
8．2．2 马上上手 175
8．2．3 实现原理 177
8．2．4 哨兵的部署 180
8．3 集群 181
8．3．1 配置集群 182
8．3．2 节点的增加 185
8．3．3 插槽的分配 185
8．3．4 获取与插槽对应的节点 189
8．3．5 故障恢复 191
第9章　管理 193
9．1 安全 193
9．1．1 可信的环境 193
9．1．2 数据库密码 194
9．1．3 命名命令 194
9．2 通信协议 195
9．2．1 简单协议 195
9．2．2 统一请求协议 197
9．3 管理工具 197
9．3．1 redis-cli 198
9．3．2 phpRedisAdmin 199
9．3．3 Rdbtools 201
附录A　Redis命令属性 203
附录B　配置参数索引 209
附录C　CRC16实现参考 213

第1章　初识Redis 1

1.1　盛赞Redis 1

1.2　Redis特性 2

1.3　Redis使用场景 5

1.3.1　Redis可以做什么 5

1.3.2　Redis不可以做什么 5

1.4　用好Redis的建议 6

1.5　正确安装并启动Redis 6

1.5.1　安装Redis 7

1.5.2　配置、启动、操作、关闭Redis 8

1.6　Redis重大版本 11

1.7　本章重点回顾 14

第2章　API的理解和使用 15

2.1　预备 15

2.1.1　全局命令 15

2.1.2　数据结构和内部编码 18

2.1.3　单线程架构 19

2.2　字符串 21

2.2.1　命令 22

2.2.2　内部编码 27

2.2.3　典型使用场景 28

2.3　哈希 31

2.3.1　命令 32

2.3.2　内部编码 35

2.3.3　使用场景 36

2.4　列表 38

2.4.1　命令 38

2.4.2　内部编码 43

2.4.3　使用场景 44

2.5　集合 46

2.5.1　命令 46

2.5.2　内部编码 50

2.5.3　使用场景 51

2.6　有序集合 52

2.6.1　命令 53

2.6.2　内部编码 59

2.6.3　使用场景 59

2.7　键管理 60

2.7.1　单个键管理 60

2.7.2　遍历键 67

2.7.3　数据库管理 70

2.8　本章重点回顾 73

第3章　小功能大用处 74

3.1　慢查询分析 74

3.1.1　慢查询的两个配置参数 75

3.1.2　最佳实践 77

3.2　Redis Shell 78

3.2.1　redis-cli详解 78

3.2.2　redis-server详解 82

3.2.3　redis-benchmark详解 83

3.3　Pipeline 84

3.3.1　Pipeline概念 84

3.3.2　性能测试 85

3.3.3　原生批量命令与Pipeline对比 86

3.3.4　最佳实践 87

3.4　事务与Lua 87

3.4.1　事务 87

3.4.2　Lua用法简述 90

3.4.3　Redis与Lua 92

3.4.4　案例 94

3.4.5　Redis如何管理Lua脚本 96

3.5　Bitmaps 98

3.5.1　数据结构模型 98

3.5.2　命令 98

3.5.3　Bitmaps分析 101

3.6　HyperLogLog 102

3.7　发布订阅 105

3.7.1　命令 106

3.7.2　使用场景 108

3.8　GEO 109

3.9　本章重点回顾 112

第4章　客户端 113

4.1　客户端通信协议 113

4.2　Java客户端Jedis 117

4.2.1　获取Jedis 117

4.2.2　Jedis的基本使用方法 118

4.2.3　Jedis连接池的使用方法 122

4.2.4　Redis中Pipeline的使用方法 125

4.2.5　Jedis的Lua脚本 126

4.3　Python客户端redis-py 128

4.3.1　获取redis-py 128

4.3.2　redis-py的基本使用方法 128

4.3.3　redis-py中Pipeline的使用方法 130

4.3.4　redis-py中的Lua脚本使用方法 130

4.4　客户端管理 131

4.4.1　客户端API 132

4.4.2　客户端相关配置 145

4.4.3　客户端统计片段 145

4.5　客户端常见异常 146

4.6　客户端案例分析 149

4.6.1　Redis内存陡增 149

4.6.2　客户端周期性的超时 151

4.7　本章重点回顾 153

第5章　持久化 154

5.1　RDB 154

5.1.1　触发机制 154

5.1.2　流程说明 155

5.1.3　RDB文件的处理 156

5.1.4　RDB的优缺点 156

5.2　AOF 157

5.2.1　使用AOF 157

5.2.2　命令写入 157

5.2.3　文件同步 158

5.2.4　重写机制 159

5.2.5　重启加载 161

5.2.6　文件校验 162

5.3　问题定位与优化 162

5.3.1　fork操作 162

5.3.2　子进程开销监控和优化 163

5.3.3　AOF追加阻塞 165

5.4　多实例部署 166

5.5　本章重点回顾 167

第6章　复制 168

6.1　配置 168

6.1.1　建立复制 168

6.1.2　断开复制 170

6.1.3　安全性 170

6.1.4　只读 170

6.1.5　传输延迟 171

6.2　拓扑 171

6.3　原理 172

6.3.1　复制过程 172

6.3.2　数据同步 175

6.3.3　全量复制 178

6.3.4　部分复制 181

6.3.5　心跳 183

6.3.6　异步复制 184

6.4　开发与运维中的问题 184

6.4.1　读写分离 184

6.4.2　主从配置不一致 186

6.4.3　规避全量复制 186

6.4.4　规避复制风暴 187

6.5　本章重点回顾 188

第7章　Redis的噩梦：阻塞 189

7.1　发现阻塞 189

7.2　内在原因 191

7.2.1　API或数据结构使用不合理 191

7.2.2　CPU饱和 193

7.2.3　持久化阻塞 194

7.3　外在原因 195

7.3.1　CPU竞争 195

7.3.2　内存交换 195

7.3.3　网络问题 196

7.4　本章重点回顾 199

第8章　理解内存 200

8.1　内存消耗 200

8.1.1　内存使用统计 200

8.1.2　内存消耗划分 201

8.1.3　子进程内存消耗 203

8.2　内存管理 204

8.2.1　设置内存上限 204

8.2.2　动态调整内存上限 204

8.2.3　内存回收策略 205

8.3　内存优化 209

8.3.1　redisObject对象 209

8.3.2　缩减键值对象 210

8.3.3　共享对象池 211

8.3.4　字符串优化 213

8.3.5　编码优化 216

8.3.6　控制键的数量 223

8.4　本章重点回顾 225

第9章　哨兵 226

9.1　基本概念 226

9.1.1　主从复制的问题 227

9.1.2　高可用 227

9.1.3　Redis Sentinel的高可用性 229

9.2　安装和部署 232

9.2.1　部署拓扑结构 232

9.2.2　部署Redis数据节点 233

9.2.3　部署Sentinel节点 234

9.2.4　配置优化 236

9.2.5　部署技巧 243

9.3　API 244

9.4　客户端连接 249

9.4.1　Redis Sentinel的客户端 249

9.4.2　Redis Sentinel客户端基本实现原理 249

9.4.3　Java操作Redis Sentinel 251

9.5　实现原理 254

9.5.1　三个定时监控任务 254

9.5.2　主观下线和客观下线 256

9.5.3　领导者Sentinel节点选举 258

9.5.4　故障转移 261

9.6　开发与运维中的问题 262

9.6.1　故障转移日志分析 262

9.6.2　节点运维 268

9.6.3　高可用读写分离 271

9.7　本章重点回顾 272

第10章　集群 274

10.1　数据分布 274

10.1.1　数据分布理论 274

10.1.2　Redis数据分区 277

10.1.3　集群功能限制 278

10.2　搭建集群 278

10.2.1　准备节点 278

10.2.2　节点握手 280

10.2.3　分配槽 282

10.2.4　用redis-trib.rb搭建集群 284

10.3　节点通信 287

10.3.1　通信流程 287

10.3.2　Gossip消息 287

10.3.3　节点选择 290

10.4　集群伸缩 291

10.4.1　伸缩原理 291

10.4.2　扩容集群 293

10.4.3　收缩集群 301

10.5　请求路由 305

10.5.1　请求重定向 305

10.5.2　Smart客户端 309

10.5.3　ASK重定向 318

10.6　故障转移 323

10.6.1　故障发现 323

10.6.2　故障恢复 329

10.6.3　故障转移时间 334

10.6.4　故障转移演练 334

10.7　集群运维 336

10.7.1　集群完整性 336

10.7.2　带宽消耗 337

10.7.3　Pub/Sub广播问题 337

10.7.4　集群倾斜 338

10.7.5　集群读写分离 339

10.7.6　手动故障转移 341

10.7.7　数据迁移 344

10.8　本章重点回顾 344

第11章　缓存设计 346

11.1　缓存的收益和成本 346

11.2　缓存更新策略 347

11.3　缓存粒度控制 349

11.4　穿透优化 350

11.5　无底洞优化 352

11.6　雪崩优化 359

11.7　热点key重建优化 360

11.8　本章重点回顾 364

第12章　开发运维的“陷阱” 365

12.1　Linux配置优化 365

12.1.1　内存分配控制 365

12.1.2　swappiness 367

12.1.3　THP 369

12.1.4　OOM killer 370

12.1.5　使用NTP 371

12.1.6　ulimit 371

12.1.7　TCP backlog 372

12.2　flushall/flushdb误操作 372

12.2.1　缓存与存储 373

12.2.2　借助AOF机制恢复 373

12.2.3　RDB有什么变化 374

12.2.4　从节点有什么变化 374

12.2.5　快速恢复数据 374

12.3　安全的Redis 375

12.3.1　Redis密码机制 377

12.3.2　伪装危险命令 378

12.3.3　防火墙 380

12.3.4　bind 380

12.3.5　定期备份数据 381

12.3.6　不使用默认端口 381

12.3.7　使用非root用户启动 381

12.4　处理bigkey 382

12.4.1　bigkey的危害 382

12.4.2　如何发现 382

12.4.3　如何删除 383

12.4.4　最佳实践思路 386

12.5　寻找热点key 386

12.6　本章重点回顾 391

第13章　Redis监控运维云平台CacheCloud 392

13.1　CacheCloud是什么 392

13.1.1　现有问题 393

13.1.2　CacheCloud基本功能 393

13.2　快速部署 395

13.2.1　CacheCloud环境需求 395

13.2.2　CacheCloud快速开始 395

13.3　机器部署 397

13.3.1　部署脚本 398

13.3.2　添加机器 399

13.4　接入应用 400

13.4.1　总体流程 401

13.4.2　账户申请和审批 401

13.4.3　应用申请和审批 402

13.4.4　客户端接入 405

13.5　用户功能 407

13.5.1　应用统计信息 408

13.5.2　实例列表 409

13.5.3　应用详情 409

13.5.4　命令曲线 409

13.5.5　CacheCloud Redis Shell控制台 410

13.5.6　慢查询 410

13.5.7　应用拓扑 411

13.6　运维功能 413

13.6.1　应用运维 413

13.6.2　接入已存在的Redis节点 415

13.6.3　Redis配置模板 416

13.6.4　迁移工具 417

13.6.5　监控报警 420

13.6.6　系统配置管理 422

13.7　客户端上报 423

13.7.1　客户端上报整体设计 424

13.7.2　Jedis核心代码修改 424

13.7.3　带上报功能的客户端 426

13.7.4　CacheCloud客户端统计 427

13.8　本章重点回顾 429

第14章　Redis配置统计字典 430

14.1　info系统状态说明 430

14.1.1　命令说明 430

14.1.2　详细说明 431

14.2　standalone配置说明和分析 436

14.2.1　总体配置 436

14.2.2　最大内存及策略 437

14.2.3　AOF相关配置 437

14.2.4　RDB相关配置 438

14.2.5　慢查询配置 438

14.2.6　数据结构优化配置 439

14.2.7　复制相关配置 439

14.2.8　客户端相关配置 440

14.2.9　安全相关配置 440

14.3　Sentinel配置说明和分析 440

14.4　Cluster配置说明和分析 441

第一部分　入门
第1章　初识Redis　2
1．1　Redis简介　3
1．1．1　Redis与其他数据库和软件的对比　3
1．1．2　附加特性　4
1．1．3　使用Redis的理由　5
1．2　Redis数据结构简介　6
1．2．1　Redis中的字符串　7
1．2．2　Redis中的列表　9
1．2．3　Redis的集合　10
1．2．4　Redis的散列　11
1．2．5　Redis的有序集合　12
1．3　你好Redis　13
1．3．1　对文章进行投票　15
1．3．2　发布并获取文章　17
1．3．3　对文章进行分组　19
1．4　寻求帮助　21
1．5　小结　21

第2章　使用Redis构建Web应用　23
2．1　登录和cookie缓存　24
2．2　使用Redis实现购物车　28
2．3　网页缓存　29
2．4　数据行缓存　30
2．5　网页分析　33
2．6　小结　34

第二部分　核心概念
第3章　Redis命令　38
3．1　字符串　39
3．2　列表　42
3．3　集合　44
3．4　散列　46
3．5　有序集合　48
3．6　发布与订阅　52
3．7　其他命令　54
3．7．1　排序　54
3．7．2　基本的Redis事务　56
3．7．3　键的过期时间　58
3．8　小结　60

第4章　数据安全与性能保障　61
4．1　持久化选项　61
4．1．1　快照持久化　62
4．1．2　AOF持久化　66
4．1．3　重写/压缩AOF文件　67
4．2　复制　68
4．2．1　配置Redis的配置选项　69
4．2．2　Redis复制的启动过程　70
4．2．3　主从链　71
4．2．4　检验磁盘写入　72
4．3　处理系统故障　73
4．3．1　验证快照文件和AOF文件　74
4．3．2　更换故障主服务器　75
4．4　Redis事务　76
4．4．1　定义用户信息和用户包裹　77
4．4．2　将物品放到市场上销售　78
4．4．3　购买物品　80
4．5　非事务型流水线　82
4．6　关于性能方面的注意事项　85
4．7　小结　87

第5章　使用Redis构建支持程序　88
5．1　使用Redis来记录日志　88
5．1．1　最新日志　89
5．1．2　常见日志　90
5．2　计数器和统计数据　91
5．2．1　将计数器存储到Redis里面　91
5．2．2　使用Redis存储统计数据　96
5．2．3　简化统计数据的记录与发现　98
5．3　查找IP所属城市以及国家　100
5．3．1　载入位置表格　100
5．3．2　查找IP所属城市　102
5．4　服务的发现与配置　103
5．4．1　使用Redis存储配置信息　103
5．4．2　为每个应用程序组件分别配置一个Redis服务器　104
5．4．3　自动Redis连接管理　106
5．5　小结　107

第6章　使用Redis构建应用程序组件　109
6．1　自动补全　109
6．1．1　自动补全最近联系人　110
6．1．2　通讯录自动补全　112
6．2　分布式锁　115
6．2．1　锁的重要性　116
6．2．2　简易锁　118
6．2．3　使用Redis构建锁　119
6．2．4　细粒度锁　122
6．2．5　带有超时限制特性的锁　124
6．3　计数信号量　126
6．3．1　构建基本的计数信号量　126
6．3．2　公平信号量　128
6．3．3　刷新信号量　131
6．3．4　消除竞争条件　132
6．4　任务队列　133
6．4．1　先进先出队列　133
6．4．2　延迟任务　136
6．5　消息拉取　139
6．5．1　单接收者消息的发送与订阅替代品　140
6．5．2　多接收者消息的发送与订阅替代品　141
6．6　使用Redis进行文件分发　145
6．6．1　根据地理位置聚合用户数据　146
6．6．2　发送日志文件　148
6．6．3　接收日志文件　149
6．6．4　处理日志文件　150
6．7　小结　152

第7章　基于搜索的应用程序　153
7．1　使用Redis进行搜索　153
7．1．1　基本搜索原理　154
7．1．2　对搜索结果进行排序　160
7．2　有序索引　162
7．2．1　使用有序集合对搜索结果进行排序　162
7．2．2　使用有序集合实现非数值排序　164
7．3　广告定向　166
7．3．1　什么是广告服务器？　167
7．3．2　对广告进行索引　167
7．3．3　执行广告定向操作　170
7．3．4　从用户行为中学习　174
7．4　职位搜索　180
7．4．1　逐个查找合适的职位　180
7．4．2　以搜索方式查找合适的职位　181
7．5　小结　182

第8章　构建简单的社交网站　184
8．1　用户和状态　185
8．1．1　用户信息　185
8．1．2　状态消息　186
8．2　主页时间线　187
8．3　关注者列表和正在关注列表　188
8．4　状态消息的发布与删除　191
8．5　流API　194
8．5．1　流API提供的数据　195
8．5．2　提供数据　196
8．5．3　对流消息进行过滤　199
8．6　小结　205

第三部分　进阶内容
第9章　降低内存占用　208
9．1　短结构　208
9．1．1　压缩列表表示　209
9．1．2　集合的整数集合编码　211
9．1．3　长压缩列表和大整数集合带来的性能问题　212
9．2　分片结构　214
9．2．1　分片式散列　215
9．2．2　分片集合　218
9．3　打包存储二进制位和字节　221
9．3．1　决定被存储位置信息的格式　221
9．3．2　存储打包后的数据　223
9．3．3　对分片字符串进行聚合计算　224
9．4　小结　226

第10章　扩展Redis　227
10．1　扩展读性能　227
10．2　扩展写性能和内存容量　230
10．2．1　处理分片配置信息　232
10．2．2　创建分片服务器连接装饰器　233
10．3　扩展复杂的查询　234
10．3．1　扩展搜索查询量　235
10．3．2　扩展搜索索引大小　235
10．3．3　对社交网站进行扩展　240
10．4　小结　247

第11章　Redis的Lua脚本编程　248
11．1　在不编写C代码的情况下添加新功能　248
11．1．1　将Lua脚本载入Redis　249
11．1．2　创建新的状态消息　251
11．2　使用Lua重写锁和信号量　254
11．2．1　使用Lua实现锁的原因　254
11．2．2　重写锁实现　255
11．2．3　使用Lua实现计数信号量　257
11．3　移除WATCH/MULTI/EXEC事务　258
11．3．1　回顾群组自动补全程序　259
11．3．2　再次对物品买卖市场进行改进　261
11．4　使用Lua对列表进行分片　263
11．4．1　分片列表的构成　263
11．4．2　将元素推入分片列表　265
11．4．3　从分片里面里面弹出元素　266
11．4．4　对分片列表执行阻塞弹出操作　267
11．5　小结　270

附录A　快速安装指南　271

附录B　其他资源和参考资料　279


第1篇 基础和应用篇 / 1

1.1 授人以鱼不如授人以渔 / 1

1.1.1 由 Redis 面试想到的 / 1

1.1.2 本书的内容范围 / 2

1.1.3 Redis 可以做什么 / 3

1.1.4 小结 / 3

1.1.5 扩展阅读 / 4

1.2 万丈高楼平地起——Redis 基础数据结构 / 4

1.2.1 Redis 的安装 / 5

1.2.2 5 种基础数据结构 / 6

1.2.3 容器型数据结构的通用规则 / 17

1.2.4 过期时间 / 17

1.2.5 思考&作业 / 17

1.3 千帆竞发——分布式锁 / 18

1.3.1 分布式锁的奥义 / 18

1.3.2 超时问题 / 20

1.3.3 可重入性 / 21

1.3.4 思考&作业 / 24

1.4 缓兵之计——延时队列 / 24

1.4.1 异步消息队列 / 24

1.4.2 队列空了怎么办 / 26

1.4.3 阻塞读 / 26

1.4.4 空闲连接自动断开 / 26

1.4.5 锁冲突处理 / 27

1.4.6 延时队列的实现 / 27

1.4.7 进一步优化 / 30

1.4.8 思考&作业 / 31

1.5 节衣缩食——位图 / 31

1.5.1 基本用法 / 31

1.5.2 统计和查找 / 34

1.5.3 魔术指令 bitfield / 35

1.5.4 思考&作业 / 38

1.6 四两拨千斤——HyperLogLog / 38

1.6.1 使用方法 / 39

1.6.2 pfadd 中的 pf 是什么意思 / 41

1.6.3 pfmerge 适合的场合 / 42

1.6.4 注意事项 / 42

1.6.5 HyperLogLog 实现原理 / 42

1.6.6 pf 的内存占用为什么是 12KB / 49

1.6.7 思考&作业 / 50

1.7 层峦叠嶂——布隆过滤器 / 50

1.7.1 布隆过滤器是什么 / 51

1.7.2 Redis 中的布隆过滤器 / 51

1.7.3 布隆过滤器的基本用法 / 52

1.7.4 注意事项 / 59

1.7.5 布隆过滤器的原理 / 60

1.7.6 空间占用估计 / 61

1.7.7 实际元素超出时，误判率会怎样变化 / 62

1.7.8 用不上 Redis 4.0 怎么办 / 63

1.7.9 布隆过滤器的其他应用 / 63

1.8 断尾求生——简单限流 / 64

1.8.1 如何使用 Redis 来实现简单限流策略 / 64

1.8.2 解决方案 / 65

1.8.3 小结 / 67

1.9 一毛不拔——漏斗限流 / 68

1.9.1 Redis-Cell / 71

1.9.2 思考&作业 / 72

1.9.3 扩展阅读：Redis-Cell 作者介绍 / 72

1.10 近水楼台——GeoHash / 73

1.10.1 用数据库来算附近的人 / 73

1.10.2 GeoHash 算法 / 74

1.10.3 Geo 指令的基本用法 / 75

1.10.4 注意事项 / 78

1.11 大海捞针——scan / 79

1.11.1 scan 基本用法 / 80

1.11.2 字典的结构 / 82

1.11.3 scan 遍历顺序 / 82

1.11.4 字典扩容 / 83

1.11.5 对比扩容、缩容前后的遍历顺序 / 84

1.11.6 渐进式 rehash / 85

1.11.7 更多的 scan 指令 / 85

1.11.8 大 key 扫描 / 85

第2 篇 原理篇 / 87

2.1 鞭辟入里——线程 IO 模型 / 87

2.1.1 非阻塞 IO / 87

2.1.2 事件轮询 （多路复用） / 88

2.1.3 指令队列 / 90

2.1.4 响应队列 / 90

2.1.5 定时任务 / 90

2.1.6 扩展阅读 / 90

2.2 交头接耳——通信协议 / 90

2.2.1 RESP / 91

2.2.2 客户端→服务器 / 92

2.2.3 服务器→客户端 / 92

2.2.4 小结 / 95

2.2.5 扩展阅读 / 95

2.3 未雨绸缪——持久化 / 95

2.3.1 快照原理 / 96

2.3.2 fork（多进程） / 96

2.3.3 AOF 原理 / 97

2.3.4 AOF 重写 / 98

2.3.5 fsync / 98

2.3.6 运维 / 98

2.3.7 Redis 4.0 混合持久化 / 99

2.3.8 思考&作业 / 100

2.4 雷厉风行——管道 / 100

2.4.1 Redis 的消息交互 / 100

2.4.2 管道压力测试 / 101

2.4.3 深入理解管道本质 / 102

2.4.4 小结 / 104

2.5 同舟共济——事务 / 104

2.5.1 Redis 事务的基本用法 / 104

2.5.2 原子性 / 105

2.5.3 discard（丢弃） / 106

2.5.4 优化 / 106

2.5.5 watch / 107

2.5.6 注意事项 / 108

2.5.7 思考&作业 / 110

2.6 小道消息——PubSub / 110

2.6.1 消息多播 / 110

2.6.2 PubSub / 111

2.6.3 模式订阅 / 113

2.6.4 消息结构 / 114

2.6.5 PubSub 的缺点 / 115

2.6.6 补充 / 115

2.7 开源节流——小对象压缩 / 115

2.7.1 32bit VS 64bit / 116

2.7.2 小对象压缩存储（ziplist） / 116

2.7.3 内存回收机制 / 120

2.7.4 内存分配算法 / 120

第3 篇 集群篇 / 122

3.1 有备无患——主从同步 / 122

3.1.1 CAP 原理 / 122

3.1.2 最终一致 / 123

3.1.3 主从同步与从从同步 / 123

3.1.4 增量同步 / 124

3.1.5 快照同步 / 124

3.1.6 增加从节点 / 125

3.1.7 无盘复制 / 125

3.1.8 wait 指令 / 125

3.1.9 小结 / 126

3.2 李代桃僵——Sentinel / 126

3.2.1 消息丢失 / 128

3.2.2 Sentinel 基本用法 / 128

3.2.3 思考&作业 / 129

3.3 分而治之——Codis / 130

3.3.1 Codis 分片原理 / 131

3.3.2 不同的 Codis 实例之间槽位关系如何同步 / 132

3.3.3 扩容 / 132

3.3.4 自动均衡 / 133

3.3.5 Codis 的代价 / 133

3.3.6 Codis 的优点 / 134

3.3.7 mget 指令的操作过程 / 134

3.3.8 架构变迁 / 135

3.3.9 Codis 的尴尬 / 135

3.3.10 Codis 的后台管理 / 136

3.3.11 思考&作业 / 136

3.4 众志成城——Cluster / 137

3.4.1 槽位定位算法 / 138

3.4.2 跳转 / 138

3.4.3 迁移 / 138

3.4.4 容错 / 140

3.4.5 网络抖动 / 140

3.4.6 可能下线（PFAIL）与确定下线（Fail） / 141

3.4.7 Cluster 基本用法 / 141

3.4.8 槽位迁移感知 / 142

3.4.9 集群变更感知 / 143

3.4.10 思考&作业 / 143

第4 篇 拓展篇 / 144

4.1 耳听八方——Stream / 144

4.1.1 消息 ID / 145

4.1.2 消息内容 / 145

4.1.3 增删改查 / 145

4.1.4 独立消费 / 147

4.1.5 创建消费组 / 148

4.1.6 消费 / 150

4.1.7 Stream 消息太多怎么办 / 152

4.1.8 消息如果忘记 ack 会怎样 / 153

4.1.9 PEL 如何避免消息丢失 / 153

4.1.10 Stream 的高可用 / 153

4.1.11 分区 Partition / 154

4.1.12 小结 / 154

4.2 无所不知——Info 指令 / 154

4.2.1 Redis 每秒执行多少次指令 / 155

4.2.2 Redis 连接了多少客户端 / 156

4.2.3 Redis 内存占用多大 / 156

4.2.4 复制积压缓冲区多大 / 157

4.2.5 思考&作业 / 158

4.3 拾遗补漏——再谈分布式锁 / 158

4.3.1 Redlock 算法 / 158

4.3.2 Redlock 使用场景 / 159

4.3.3 扩展阅读：redlock-py 的作者 / 160

4.4 朝生暮死——过期策略 / 160

4.4.1 过期的 key 集合 / 160

4.4.2 定时扫描策略 / 160

4.4.3 从节点的过期策略 / 161

4.5 优胜劣汰——LRU / 162

4.5.1 LRU 算法 / 163

4.5.2 近似 LRU 算法 / 164

4.5.3 思考&作业 / 165

4.6 平波缓进——懒惰删除 / 165

4.6.1 Redis 为什么使用懒惰删除 / 165

4.6.2 flush / 166

4.6.3 异步队列 / 166

4.6.4 AOF Sync 也很慢 / 166

4.6.5 更多异步删除点 / 166

4.7 妙手仁心——优雅地使用 Jedis / 167

4.7.1 重试 / 171

4.7.2 思考&作业 / 172

4.8 居安思危——保护 Redis / 172

4.8.1 指令安全 / 172

4.8.2 端口安全 / 173

4.8.3 Lua 脚本安全 / 174

4.8.4 SSL 代理 / 174

4.8.5 小结 / 174

4.9 隔墙有耳——Redis 安全通信 / 175

4.9.1 spiped 原理 / 176

4.9.2 spiped 使用入门 / 176

4.9.3 思考&作业 / 179

第5 篇 源码篇 / 180

5.1 丝分缕析——探索“字符串”内部 / 180

5.1.1 embstr VS raw / 181

5.1.2 扩容策略 / 184

5.1.3 思考&作业 / 184

5.2 循序渐进——探索“字典”内部 / 184

5.2.1 dict 内部结构 / 184

5.2.2 渐进式 rehash / 186

5.2.3 查找过程 / 187

5.2.4 hash 函数 / 188

5.2.5 hash 攻击 / 188

5.2.6 扩容条件 / 188

5.2.7 缩容条件 / 189

5.2.8 set 的结构 / 189

5.2.9 思考&作业 / 189

5.3 挨肩迭背——探索“压缩列表”内部 / 190

5.3.1 增加元素 / 192

5.3.2 级联更新 / 192

5.3.3 intset 小整数集合 / 194

5.3.4 思考&作业 / 195

5.4 风驰电掣——探索“快速列表”内部 / 195

5.4.1 每个 ziplist 存多少元素 / 197

5.4.2 压缩深度 / 198

5.5 凌波微步——探索“跳跃列表”内部 / 198

5.5.1 基本结构 / 199

5.5.2 查找过程 / 199

5.5.3 随机层数 / 200

5.5.4 插入过程 / 201

5.5.5 删除过程 / 202

5.5.6 更新过程 / 203

5.5.7 如果 score 值都一样呢 / 203

5.5.8 元素排名是怎么算出来的 / 203

5.5.9 思考&作业 / 204

5.5.10 题外话 / 204

5.6 破旧立新——探索“紧凑列表”内部 / 205

5.6.1 级联更新 / 207

5.6.2 取代 ziplist 尚需时日 / 207

5.6.3 思考&作业 / 207

5.7 金枝玉叶——探索“基数树”内部 / 207

5.7.1 应用 / 208

5.7.2 结构 / 210

5.7.3 思考&作业 / 213

5.8 精益求精——LFU VS LRU / 213

5.8.1 Redis 对象的热度 / 213

5.8.2 LRU 模式 / 213

5.8.3 LFU 模式 / 214

5.8.4 为什么 Redis 要缓存系统时间戳 / 217

5.8.5 Redis 为什么在获取 lruclock 时使用原子操作 / 217

5.8.6 如何打开 LFU 模式 / 218

5.8.7 思考&作业 / 218

5.9 如履薄冰——懒惰删除的巨大牺牲 / 218

5.9.1 懒惰删除的最初实现不是异步线程 / 219

5.9.2 异步线程方案其实也相当复杂 / 219

5.9.3 异步删除的实现 / 221

5.9.4 队列安全 / 224

5.9.5 思考&作业 / 225

5.10 跋山涉水——深入字典遍历 / 225

5.10.1 一边遍历一边修改 / 226

5.10.2 重复遍历的难题 / 227

5.10.3 迭代器的结构 / 227

5.10.4 迭代过程 / 229

5.10.5 迭代器的选择 / 231

5.10.6 思考&作业 / 232


1.2 下载和安装Redis

1.3 启动和停止Redis

1.4 使用redis-cli 连接到Redis

1.5 获取服务器信息.

1.6 理解Redis 事件模型

1.7 理解Redis 通信协议

第2 章数据类型

2.1 本章概要

2.2 使用字符串（string）类型

2.3 使用列表（list）类型

2.4 使用哈希（hash）类型

2.5 使用集合（set）类型

2.6 使用有序集合（sorted set）类型

2.7 使用HyperLogLog 类型.

2.8 使用Geo 类型.

2.9 键管理

第3 章数据特性

3.1 本章概要

3.2 使用位图（bitmap）

3.3 设置键的过期时间

3.4 使用SORT 命令

3.5 使用管道（pipeline）

3.6 理解Redis 事务（transaction）

3.7 使用发布订阅（PubSub）

3.8 使用Lua 脚本

3.9 调试Lua 脚本

第4 章使用Redis 进行开发

4.1 本章概要

4.2 Redis 常见应用场景

4.3 使用正确的数据类型

4.4 使用正确的API .

4.5 使用Java 连接到Redis

4.6 使用Python 连接到Redis

4.7 使用Spring Data 连接到Redis

4.8 使用Redis 编写MapReduce 作业

4.9 使用Redis 编写Spark 作业

第5 章复制

5.1 本章概要

5.2 配置Redis 的复制机制

5.3 复制机制的调优

5.4 复制机制的故障诊断

第6 章持久化

6.1 本章概要

6.2 使用RDB

6.3 探究RDB 文件

6.4 使用AOF

6.5 探究AOF 文件

6.6 RDB 和AOF 的结合使用.

第7 章配置高可用和集群

7.1 本章概要

7.2 配置Sentinel

7.3 测试Sentinel

7.4 管理Sentinel

7.5 配置Redis Cluster

7.6 测试Redis Cluster

7.7 管理Redis Cluster

第8 章生产环境部署

8.1 本章概要

8.2 在Linux 上部署Redis

8.3 Redis 安全相关设置

8.4 配置客户端连接选项

8.5 配置内存策略

8.6 基准测试

8.7 日志

第9 章管理Redis

9.1 本章概要

9.2 管理Redis 服务器配置

9.3 使用bin/redis-cli 操作Redis

9.4 备份和恢复

9.5 监控内存使用情况

9.6 管理客户端

9.7 数据迁移

第10 章Redis 的故障诊断

10.1 本章概要

10.2 Redis 的健康检查

10.3 使用SLOWLOG 识别慢查询

10.4 延迟问题的故障诊断

10.5 内存问题的故障诊断

10.6 崩溃问题的故障诊断

第11 章使用Redis 模块扩展Redis

11.1 本章概要.

11.2 加载Redis 模块

11.3 编写Redis 模块

第12 章Redis 生态系统

12.1 本章概要

12.2 Redisson 客户端

12.3 Twemproxy

12.4 Codis—一个基于代理的高性能Redis 集群解决方案

12.5 CacheCloud 管理系统

12.6 Pika—一个与Redis 兼容的NoSQL 数据库

附录A Windows 环境搭建



1 为何选择Redis？ 1
尝试使用Redis 4
流行的使用模式 9
Redis不合心意？马上再试试！ 11

2 高级键管理与数据结构 14
Redis键 14
Redis键模式 15
键分隔符和命名约定 17
手动创建Redis模式 19
解构Redis对象映射器 22
键过期 27
键的注意事项 27
大O符号 28
为自定义代码计算大O符号 30
回顾Redis数据结构的时间复杂度 32
字符串 32
哈希 33
列表 34
集合 35
有序集合 36
高级有序集合操作 39
位串和位操作 39
HyperLogLogs 41

3 内存管理的建议与技巧 44
配置Redis 44
主从复制 45
32位Redis 45
INFO memory详解 47
键过期 49
LRU键清除策略 54
创建内存高效的Redis数据结构 62
小巧的哈希、列表、集合和有序集合 62
把位、字节和Redis字符串用作随机访问数组 68
优化哈希，高效存储 69
硬件和网络延迟 72
操作系统建议 74

4 Redis编程第一部分：Redis核心、客户端和编程语言 76
Redis的内部结构 76
理解redis．h和redis．c 83
Redis序列化协议 93
Redis RDB格式 97
使用Redis和Python创建协程 99
使用Node．js和Redis实现Todo列表应用 103
复制与公共访问 106

5 Redis编程第二部分：Lua脚本、管理与DevOps 108
在Redis中使用Lua 108
使用Redis的KEYS和ARGV 117
Redis中的高级Lua脚本 121
MARC21数据提取 121
纸质文具在线商店 123
让JSON-LD、Lua和Redis协同工作 126
Redis Lua调试器 130
Redis的编程与管理 133
主从复制 134
使用MULTI和EXEC实现事务 136
Redis在DevOps中扮演的角色 139
总结 140

6 可伸缩性：Redis集群和Sentinel 142
数据分区的方法 142
范围分区 143
列表分区 145
哈希分区 148
复合分区 149
键哈希标签 150
使用Twemproxy实现Redis集群 151

使用关联数据片段服务器测试Twemproxy 152

Redis集群的背景 158

Redis集群概览 159
使用Redis集群 160
Redis集群实时重新配置及重新分片 165
故障转移 168
在Redis集群中替换或者升级节点 170
使用Redis Sentinel进行监控 171
为区域代码列表分区配置Redis Sentinel 173
总结 176


NoSQL技术的繁荣 177
Redis作为MongoDB的分析补充 181
Redis作为ElasticSearch的预处理组件 192
在BIBCAT中使用Redis和ElasticSearch 193
ElasticSearch、Logstash和Redis 198
Redis作为Fedora Commons的智能缓存补充 199
总结 205
8 Docker容器与云端部署 206
Linux容器 206
与Redis相关的Docker基础 211
Docker镜像中的层 219
Docker文件系统后端 220
Docker和Redis的问题 227
使用Docker Compose打包应用程序 227
Redis和AWS 232
专门的云托管选项 233
Redis Labs 234
DigitalOcean Redis 234
9 任务管理与消息队列 236
Redis的发布/订阅模式概述 236
发布/订阅RESP回复 237
SUBSCRIBE和UNSUBSCRIBE RESP数组 237
PSUBSCRIBE和UNSUBSCRIBE数组 239
使用redis-cli进行发布/订阅 240
Redis发布订阅实战 242
第一个工作站采用Python进行发布订阅 244
第二个工作站采用Node．js进行发布订阅 246
第三个工作站使用Lua客户端进行发布订阅 248
Redis键空间通知 251
使用Redis和Celery进行任务管理 255
GIS和RestMQ 259
使用RestMQ进行任务管理 262
使用Redis技术进行消息通信 264
使用Disque进行消息通信 264
总结 266
10 信息流的测量与管理 267
基于Redis的ETL方案 267
将JSON转换成RESP 273
管理Redis时的安全考虑 279
使用Redis Web仪表板进行运营监测 282
机器学习 283
朴素贝叶斯与工作分类 284
使用Redis实现线性规划 294




1．1　Redis简介　3
1．1．1　Redis与其他数据库和软件的对比　3
1．1．2　附加特性　4
1．1．3　使用Redis的理由　5
1．2　Redis数据结构简介　6
1．2．1　Redis中的字符串　7
1．2．2　Redis中的列表　9
1．2．3　Redis的集合　10
1．2．4　Redis的散列　11
1．2．5　Redis的有序集合　12
1．3　你好Redis　13
1．3．1　对文章进行投票　15
1．3．2　发布并获取文章　17
1．3．3　对文章进行分组　19
1．4　寻求帮助　21
1．5　小结　21

第2章　使用Redis构建Web应用　23
2．1　登录和cookie缓存　24
2．2　使用Redis实现购物车　28
2．3　网页缓存　29
2．4　数据行缓存　30
2．5　网页分析　33
2．6　小结　34

第二部分　核心概念
第3章　Redis命令　38
3．1　字符串　39
3．2　列表　42
3．3　集合　44
3．4　散列　46
3．5　有序集合　48
3．6　发布与订阅　52
3．7　其他命令　54
3．7．1　排序　54
3．7．2　基本的Redis事务　56
3．7．3　键的过期时间　58
3．8　小结　60

第4章　数据安全与性能保障　61
4．1　持久化选项　61
4．1．1　快照持久化　62
4．1．2　AOF持久化　66
4．1．3　重写/压缩AOF文件　67
4．2　复制　68
4．2．1　配置Redis的配置选项　69
4．2．2　Redis复制的启动过程　70
4．2．3　主从链　71
4．2．4　检验磁盘写入　72
4．3　处理系统故障　73
4．3．1　验证快照文件和AOF文件　74
4．3．2　更换故障主服务器　75
4．4　Redis事务　76
4．4．1　定义用户信息和用户包裹　77
4．4．2　将物品放到市场上销售　78
4．4．3　购买物品　80
4．5　非事务型流水线　82
4．6　关于性能方面的注意事项　85
4．7　小结　87

第5章　使用Redis构建支持程序　88
5．1　使用Redis来记录日志　88
5．1．1　最新日志　89
5．1．2　常见日志　90
5．2　计数器和统计数据　91
5．2．1　将计数器存储到Redis里面　91
5．2．2　使用Redis存储统计数据　96
5．2．3　简化统计数据的记录与发现　98
5．3　查找IP所属城市以及国家　100
5．3．1　载入位置表格　100
5．3．2　查找IP所属城市　102
5．4　服务的发现与配置　103
5．4．1　使用Redis存储配置信息　103
5．4．2　为每个应用程序组件分别配置一个Redis服务器　104
5．4．3　自动Redis连接管理　106
5．5　小结　107

第6章　使用Redis构建应用程序组件　109
6．1　自动补全　109
6．1．1　自动补全最近联系人　110
6．1．2　通讯录自动补全　112
6．2　分布式锁　115
6．2．1　锁的重要性　116
6．2．2　简易锁　118
6．2．3　使用Redis构建锁　119
6．2．4　细粒度锁　122
6．2．5　带有超时限制特性的锁　124
6．3　计数信号量　126
6．3．1　构建基本的计数信号量　126
6．3．2　公平信号量　128
6．3．3　刷新信号量　131
6．3．4　消除竞争条件　132
6．4　任务队列　133
6．4．1　先进先出队列　133
6．4．2　延迟任务　136
6．5　消息拉取　139
6．5．1　单接收者消息的发送与订阅替代品　140
6．5．2　多接收者消息的发送与订阅替代品　141
6．6　使用Redis进行文件分发　145
6．6．1　根据地理位置聚合用户数据　146
6．6．2　发送日志文件　148
6．6．3　接收日志文件　149
6．6．4　处理日志文件　150
6．7　小结　152

第7章　基于搜索的应用程序　153
7．1　使用Redis进行搜索　153
7．1．1　基本搜索原理　154
7．1．2　对搜索结果进行排序　160
7．2　有序索引　162
7．2．1　使用有序集合对搜索结果进行排序　162
7．2．2　使用有序集合实现非数值排序　164
7．3　广告定向　166
7．3．1　什么是广告服务器？　167
7．3．2　对广告进行索引　167
7．3．3　执行广告定向操作　170
7．3．4　从用户行为中学习　174
7．4　职位搜索　180
7．4．1　逐个查找合适的职位　180
7．4．2　以搜索方式查找合适的职位　181
7．5　小结　182

第8章　构建简单的社交网站　184
8．1　用户和状态　185
8．1．1　用户信息　185
8．1．2　状态消息　186
8．2　主页时间线　187
8．3　关注者列表和正在关注列表　188
8．4　状态消息的发布与删除　191
8．5　流API　194
8．5．1　流API提供的数据　195
8．5．2　提供数据　196
8．5．3　对流消息进行过滤　199
8．6　小结　205

第三部分　进阶内容
第9章　降低内存占用　208
9．1　短结构　208
9．1．1　压缩列表表示　209
9．1．2　集合的整数集合编码　211
9．1．3　长压缩列表和大整数集合带来的性能问题　212
9．2　分片结构　214
9．2．1　分片式散列　215
9．2．2　分片集合　218
9．3　打包存储二进制位和字节　221
9．3．1　决定被存储位置信息的格式　221
9．3．2　存储打包后的数据　223
9．3．3　对分片字符串进行聚合计算　224
9．4　小结　226

第10章　扩展Redis　227
10．1　扩展读性能　227
10．2　扩展写性能和内存容量　230
10．2．1　处理分片配置信息　232
10．2．2　创建分片服务器连接装饰器　233
10．3　扩展复杂的查询　234
10．3．1　扩展搜索查询量　235
10．3．2　扩展搜索索引大小　235
10．3．3　对社交网站进行扩展　240
10．4　小结　247

第11章　Redis的Lua脚本编程　248
11．1　在不编写C代码的情况下添加新功能　248
11．1．1　将Lua脚本载入Redis　249
11．1．2　创建新的状态消息　251
11．2　使用Lua重写锁和信号量　254
11．2．1　使用Lua实现锁的原因　254
11．2．2　重写锁实现　255
11．2．3　使用Lua实现计数信号量　257
11．3　移除WATCH/MULTI/EXEC事务　258
11．3．1　回顾群组自动补全程序　259
11．3．2　再次对物品买卖市场进行改进　261
11．4　使用Lua对列表进行分片　263
11．4．1　分片列表的构成　263
11．4．2　将元素推入分片列表　265
11．4．3　从分片里面里面弹出元素　266
11．4．4　对分片列表执行阻塞弹出操作　267




1.1 Redis版本说明 1
1.2 章节编排 1
1.3 推荐的阅读方法 4
1.4 行文规则 4
1.5 配套网站 5


第一部分·数据结构与对象
第2章 简单动态字符串 8
2.1 SDS的定义 9
2.2 SDS与C字符串的区别 10
2.3 SDS API 17
2.4 重点回顾 18
2.5 参考资料 18
第3章 链表 19
3.1 链表和链表节点的实现 20
3.2 链表和链表节点的API 21
3.3 重点回顾 22
第4章 字典 23
4.1 字典的实现 24
4.2 哈希算法 27
4.3 解决键冲突 28
4.4 rehash 29
4.5 渐进式rehash 32
4.6 字典API 36
4.7 重点回顾 37
第5章 跳跃表 38
5.1 跳跃表的实现 39
5.2 跳跃表API 44
5.3 重点回顾 45
第6章 整数集合 46
6.1 整数集合的实现 46
6.2 升级 48
6.3 升级的好处 50
6.4 降级 51
6.5 整数集合API 51
6.6 重点回顾 51
第7章 压缩列表 52
7.1 压缩列表的构成 52
7.2 压缩列表节点的构成 54
7.3 连锁更新 57
7.4 压缩列表API 59
7.5 重点回顾 59
第8章 对象 60
8.1 对象的类型与编码 60
8.2 字符串对象 64
8.3 列表对象 68
8.4 哈希对象 71
8.5 集合对象 75
8.6 有序集合对象 77
8.7 类型检查与命令多态 81
8.8 内存回收 84
8.9 对象共享 85
8.10 对象的空转时长 87
8.11 重点回顾 88


第二部分·单机数据库的实现
第9章 数据库 90
9.1 服务器中的数据库 90
9.2 切换数据库 91
9.3 数据库键空间 93
9.4 设置键的生存时间或过期时间 99
9.5 过期键删除策略 107
9.6 Redis的过期键删除策略 108
9.7 AOF、RDB和复制功能对过期键的处理 111
9.8 数据库通知 113
9.9 重点回顾 117
第10章 RDB持久化 118
10.1 RDB 文件的创建与载入 119
10.2 自动间隔性保存 121
10.3 RDB 文件结构 125
10.4 分析RDB文件 133
10.5 重点回顾 137
10.6 参考资料 137
第11章 AOF持久化 138
11.1 AOF持久化的实现 139
11.2 AOF文件的载入与数据还原 142
11.3 AOF重写 143
11.4 重点回顾 150
第12章 事件 151
12.1 文件事件 151
12.2 时间事件 156
12.3 事件的调度与执行 159
12.4 重点回顾 161
12.5 参考资料 161
第13章 客户端 162
13.1 客户端属性 163
13.2 客户端的创建与关闭 172
13.3 重点回顾 174
第14章 服务器 176
14.1 命令请求的执行过程 176
14.2 serverCron函数 184
14.3 初始化服务器 192
14.4 重点回顾 196


第三部分·多机数据库的实现
第15章 复制 198
15.1 旧版复制功能的实现 199
15.2 旧版复制功能的缺陷 201
15.3 新版复制功能的实现 203
15.4 部分重同步的实现 204
15.5 PSYNC 命令的实现 209
15.6 复制的实现 211
15.7 心跳检测 216
15.8 重点回顾 218
第16章 Sentinel 219
16.1 启动并初始化Sentinel 220
16.2 获取主服务器信息 227
16.3 获取从服务器信息 229
16.4 向主服务器和从服务器发送信息 230
16.5 接收来自主服务器和从服务器的频道信息 231
16.6 检测主观下线状态 234
16.7 检查客观下线状态 236
16.8 选举领头Sentinel 238
16.9 故障转移 240
16.10 重点回顾 243
16.11 参考资料 244
第17章 集群 245
17.1 节点 245
17.2 槽指派 251
17.3 在集群中执行命令 258
17.4 重新分片 265
17.5 ASK错误 267
17.6 复制与故障转移 273
17.7 消息 281
17.8 重点回顾 288


第四部分·独立功能的实现
第18章 发布与订阅 290
18.1 频道的订阅与退订 292
18.2 模式的订阅与退订 295
18.3 发送消息 298
18.4 查看订阅信息 300
18.5 重点回顾 303
18.6 参考资料 304
第19章 事务 305
19.1 事务的实现 306
19.2 WATCH 命令的实现 310
19.3 事务的ACID 性质 314
19.4 重点回顾 319
19.5 参考资料 320
第20章 Lua脚本 321
20.1 创建并修改Lua 环境 322
20.2 Lua 环境协作组件 327
20.3 EVAL命令的实现 329
20.4 EVALSHA 命令的实现 332
20.5 脚本管理命令的实现 333
20.6 脚本复制 336
20.7 重点回顾 342
20.8 参考资料 343
第21章 排序 344
21.1 SORT 命令的实现 345
21.2 ALPHA 选项的实现 347
21.3 ASC 选项和DESC 选项的实现 348
21.4 BY选项的实现 350
21.5 带有ALPHA 选项的BY 选项的实现 352
21.6 LIMIT 选项的实现 353
21.7 GET选项的实现 355
21.8 STORE 选项的实现 358
21.9 多个选项的执行顺序 359
21.10 重点回顾 361
第22章 二进制位数组 362
22.1 位数组的表示 363
22.2 GETBIT命令的实现 365
22.3 SETBIT 命令的实现 366
22.4 BITCOUNT 命令的实现 369
22.5 BITOP 命令的实现 376
22.6 重点回顾 377
22.7 参考资料 377
第23章 慢查询日志 378
23.1 慢查询记录的保存 380
23.2 慢查询日志的阅览和删除 382
23.3 添加新日志 383
23.4 重点回顾 385
第24章 监视器 386
24.1 成为监视器 387
24.2 向监视器发送命令信息 387


-----------------------------------

一、键值设计
1. key名设计
(1)【建议】: 可读性和可管理性

以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id

ugc:video:1
(2)【建议】：简洁性

保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：

user:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}。
(3)【强制】：不要包含特殊字符

反例：包含空格、换行、单双引号以及其他转义字符

2. value设计
(1)【强制】：拒绝bigkey(防止网卡流量、慢查询)

string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。

反例：一个包含200万个元素的list。

非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法

(2)【推荐】：选择适合的数据类型。

例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡)

反例：

set user:1:name tom
set user:1:age 19
set user:1:favor football
正例:

hmset user:1 name tom age 19 favor football
3.【推荐】：控制key的生命周期，redis不是垃圾桶。
建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。

二、命令使用
1.【推荐】 O(N)命令关注N的数量
例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。

2.【推荐】：禁用命令
禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。

3.【推荐】合理使用select
redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。

4.【推荐】使用批量操作提高效率
原生命令：例如mget、mset。
非原生命令：可以使用pipeline提高效率。
但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。

注意两者不同：

1. 原生是原子操作，pipeline是非原子操作。
2. pipeline可以打包不同的命令，原生做不到
3. pipeline需要客户端和服务端同时支持。
5.【建议】Redis事务功能较弱，不建议过多使用
Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决)

6.【建议】Redis集群版本在使用Lua上有特殊要求：
1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，"-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array"

2.所有key，必须在1个slot上，否则直接返回error, "-ERR eval/evalsha command keys must in same slot"

7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。
三、客户端使用
1.【推荐】
避免多个应用使用一个Redis实例

正例：不相干的业务拆分，公共数据做服务化。

2.【推荐】
使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：

执行命令如下：
Jedis jedis = null;
try {
    jedis = jedisPool.getResource();
    //具体的命令
    jedis.executeCommand()
} catch (Exception e) {
    logger.error("op key {} error: " + e.getMessage(), key, e);
} finally {
    //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。
    if (jedis != null)
        jedis.close();
}
下面是JedisPool优化方法的文章:

Jedis常见异常汇总

JedisPool资源池优化

3.【建议】
高并发下建议客户端添加熔断功能(例如netflix hystrix)

4.【推荐】
设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持）

5.【建议】
根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。

默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。

其他策略如下：
allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。

allkeys-random：随机删除所有键，直到腾出足够空间为止。

volatile-random:随机删除过期键，直到腾出足够空间为止。

volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。

noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。

四、相关工具
1.【推荐】：数据同步
redis间数据同步可以使用：redis-port

2.【推荐】：big key搜索
redis大key搜索工具

3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)
facebook的redis-faina

阿里云Redis已经在内核层面解决热点key问题，欢迎使用。

五 附录：删除bigkey

1. 下面操作可以使用pipeline加速。

2. redis 4.0已经支持key的异步删除，欢迎使用。

1. Hash删除: hscan + hdel
public void delBigHash(String host, int port, String password, String bigHashKey) {
    Jedis jedis = new Jedis(host, port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<Entry<String, String>> scanResult = jedis.hscan(bigHashKey, cursor, scanParams);
        List<Entry<String, String>> entryList = scanResult.getResult();
        if (entryList != null && !entryList.isEmpty()) {
            for (Entry<String, String> entry : entryList) {
                jedis.hdel(bigHashKey, entry.getKey());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigHashKey);
}
2. List删除: ltrim
public void delBigList(String host, int port, String password, String bigListKey) {
    Jedis jedis = new Jedis(host, port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    long llen = jedis.llen(bigListKey);
    int counter = 0;
    int left = 100;
    while (counter < llen) {
        //每次从左侧截掉100个
        jedis.ltrim(bigListKey, left, llen);
        counter += left;
    }
    //最终删除key
    jedis.del(bigListKey);
}
3. Set删除: sscan + srem
public void delBigSet(String host, int port, String password, String bigSetKey) {
    Jedis jedis = new Jedis(host, port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<String> scanResult = jedis.sscan(bigSetKey, cursor, scanParams);
        List<String> memberList = scanResult.getResult();
        if (memberList != null && !memberList.isEmpty()) {
            for (String member : memberList) {
                jedis.srem(bigSetKey, member);
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigSetKey);
}
4. SortedSet删除: zscan + zrem
public void delBigZset(String host, int port, String password, String bigZsetKey) {
    Jedis jedis = new Jedis(host, port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<Tuple> scanResult = jedis.zscan(bigZsetKey, cursor, scanParams);
        List<Tuple> tupleList = scanResult.getResult();
        if (tupleList != null && !tupleList.isEmpty()) {
            for (Tuple tuple : tupleList) {
                jedis.zrem(bigZsetKey, tuple.getElement());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigZsetKey);
}







179. redis 是什么？都有哪些使用场景？

Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。



Redis 使用场景：

数据高并发的读写

海量数据的读写

对扩展性要求高的数据

180. redis 有哪些功能？

数据缓存功能

分布式锁的功能

支持数据持久化

支持事务

支持消息队列

181. redis 和 memecache 有什么区别？

memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型

redis的速度比memcached快很多

redis可以持久化其数据

182. redis 为什么是单线程的？

因为 cpu 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且 cpu 又不会成为瓶颈，那就顺理成章地采用单线程的方案了。



关于 Redis 的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求。



而且单线程并不代表就慢 nginx 和 nodejs 也都是高性能单线程的代表。

183. 什么是缓存穿透？怎么解决？

缓存穿透：指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。



解决方案：最简单粗暴的方法如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们就把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

184. redis 支持的数据类型有哪些？

string、list、hash、set、zset。

185. redis 支持的 java 客户端都有哪些？

Redisson、Jedis、lettuce等等，官方推荐使用Redisson。

186. jedis 和 redisson 有哪些区别？



Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持。



Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。

187. 怎么保证缓存和数据库数据的一致性？

合理设置缓存的过期时间。

新增、更改、删除数据库操作时同步更新 Redis，可以使用事物机制来保证数据的一致性。

188. redis 持久化有几种方式？

Redis 的持久化有两种方式，或者说有两种策略：



RDB（Redis Database）：指定的时间间隔能对你的数据进行快照存储。

AOF（Append Only File）：每一个收到的写命令都通过write函数追加到文件中。

189. redis 怎么实现分布式锁？

Redis 分布式锁其实就是在系统里面占一个“坑”，其他程序也要占“坑”的时候，占用成功了就可以继续执行，失败了就只能放弃或稍后重试。



占坑一般使用 setnx(set if not exists)指令，只允许被一个程序占有，使用完调用 del 释放锁。

190. redis 分布式锁有什么缺陷？

Redis 分布式锁不能解决超时的问题，分布式锁有一个超时时间，程序的执行如果超出了锁的超时时间就会出现问题。

191. redis 如何做内存优化？

尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。



比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面。

192. redis 淘汰策略有哪些？

volatile-lru：从已设置过期时间的数据集（server. db[i]. expires）中挑选最近最少使用的数据淘汰。

volatile-ttl：从已设置过期时间的数据集（server. db[i]. expires）中挑选将要过期的数据淘汰。

volatile-random：从已设置过期时间的数据集（server. db[i]. expires）中任意选择数据淘汰。

allkeys-lru：从数据集（server. db[i]. dict）中挑选最近最少使用的数据淘汰。

allkeys-random：从数据集（server. db[i]. dict）中任意选择数据淘汰。

no-enviction（驱逐）：禁止驱逐数据。

193. redis 常见的性能问题有哪些？该如何解决？

主服务器写内存快照，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以主服务器最好不要写内存快照。

Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，主从库最好在同一个局域网内。


本文主要讲了 Redis 的持久化相关功能，持久化一直是影响 Redis 性能的高发地，也是面试中经常被问到的。

包括 RDB 相关的特定和优缺点，AOF 的优缺点，事实上，由于 RDB 的数据实时性问题，目前用 AOF 比较多了，而持久化恢复也是优先 AOF。

RDB 是旧的模式，现在基本上都使用 AOF，当然，今天两个都会一起聊聊。

二、RDB
RDB 流程图：



RDB 特点：

1、RDB 是一种快照模式，即——保存的是 key value 数据内容。

2、RDB 有 2 种持久方式，同步 save 模式和异步 bgsave 模式。由于 save 是同步的，所以可以保证数据一致性，而 bgsave 则不能。

3、save 可以在客户端显式触发，也可以在 shutdown 时自动触发；bgsave 可以在客户端显式触发，也可以通过配置由定时任务触发，也可以在 slave 节点触发。

4、save 导致 redis 同步阻塞，基本已经废弃。bgsave 则不会导致阻塞，但也有缺点：在 fork 时，需要增加内存服务器开销，因为当内存不够时，将使用虚拟内存，导致阻塞 Redis 运行。所以，需要保证空闲内存足够。

5、默认执行 shutdown 时，如果没有开启 AOF，则自动执行 bgsave。

6、每次的 RDB 文件都是替换的。

关于优化：

Redis 会压缩 RDB 文件，使用 LZF 算法，让最终的 RDB 文件远小于内存大小，默认开启。但会消耗 CPU。

RDB 缺点：

1、无法秒级持久化。

2、老版本 Redis 无法兼容新版本 RDB。

RDB 优点：

1、文件紧凑，适合备份，全量复制场景。例如每 6 小时执行 bgsave，保存到文件系统之类的。

2、Redis 加载 RDB 恢复数据远远快于 AOF。

三、AOF
由于 RDB 的数据实时性问题，AOF（append only file） 是目前 Redis 持久化的主流方式。

AOF 特点：

1、默认文件名是 appendonly.aof。和 RDB 一样，保存在配置中 dir 目录下。

2、AOF 相比较于 RDB，每次都会保存写命令，数据实时性更高。

3、AOF 由于每次都会记录写命令，文件会很大，因此需要进行优化，称之为“重写机制”（下面详细说）。

4、AOF 每次保存的写命令都放在一个缓冲区，根据不同的策略（下面详细说）同步到磁盘。

“重写机制” 细节：

1、fork 子进程（类似 bgsave）

2、主进程会写到2个缓冲区，一个是原有的 “AOF 缓存区”，一个是专门为子进程准备的 “AOF 重写缓冲区”；

3、子进程写到到新的 AOF 文件中，批量的，默认 32m；写完后通知主进程。

4、主进程把“AOF 重写缓冲区”的数据写到新 AOF 文件中。

5、将新的 AOF 文件替换老文件。

重写流程图：



缓冲区同步策略，由参数 appendfsync 控制，一共3种：

1、always：调用系统 fsync 函数，直到同步到硬盘返回；严重影响redis性能。

2、everysec：先调用 OS write 函数， 写到缓冲区，然后 redis 每秒执行一次 OS fsync 函数。推荐使用这种方式。

3、no: 只执行 write OS 函数，具体同步硬盘策略由 OS 决定；不推荐，数据不安全，容易丢失数据。

四、持久化恢复
AOF 和 RDB 文件都可以用于服务器重启时的数据恢复，具体流程如下图：



从图中可以看出优先加载 AOF，当没有 AOF 时才加载 RDB。当 AOF 或者 RDB 存在错误，则加载失败。

五、问题排查和性能优化
Redis 持久化是影响 Redis 性能的高发地，也是面试中常问的问题。

1、fork 操作

当 Redis 做 RDB 或者 AOF 重写时，必然要进行 fork 操作，对于 OS 来说，fork 都是一个重量级操作。而且，fork 还会拷贝一些数据，虽然不会拷贝主进程所有的物理空间，但会复制主进程的空间内存页表。对于 10GB 的 Redis 进程，需要复制大约 20MB 的内存页表，因此 fork 操作耗时跟进程总内存量息息相关，再加上，如果使用虚拟化技术，例如 Xen 虚拟机，fork 会更加耗时。

一个正常的 fork 耗时大概在 20毫秒左右。为什么呢，假设一个 Redis 实例的 OPS 在 5 万以上，如果 fork 操作耗时在秒级，那么僵拖慢几万条命令的执行，对生产环境影响明显。

我们可以在 Info stats 统计中查询 latestforkusec 指标获取最近一次 fork 操作耗时，单位微秒。

如何优化：

1) 优先使用物理机或者高效支持 fork 的虚拟化技术，避免使用 Xen。

2) 控制 redis 实例最大内存，尽量控制在 10GB 以内。

3) 合理配置 Linux 内存分配策略，避免内存不足导致 fork 失败。

4) 降低 fork 的频率，如适度放宽 AOF 自动触发时机，避免不必要的全量复制。

2、子进程开销

fork 完毕之后，会创建子进程，子进程负责 RDB 或者 AOF 重写，这部分过程主要涉及到 CPU，内存，硬盘三个地方的优化。

1) CPU 写入文件的过程是 CPU 密集的过程，通常子进程对单核 CPU 利用率接近 90%。如何优化呢？既然是 CPU 密集型操作，就不要绑定单核 CPU，因为这样会和父 CPU 进行竞争。同时，不要和其他 CPU 密集型服务不是在一个机器上。如果部署了多个 Redis 实例，尽力保证统一时刻只有一个子进程执行重写工作。

2) 内存子进程通过 fork 操作产生，占用内存大小等同于父进程，理论上需要两倍的内存完成持久化操作，但 Linux 有 copy on write 机制，父子进程会共享相同的物理内存页，当父进程处理写操作时，会把要修改的页创建对应的副本，而子进程在 fork 操作过程中，共享整个父进程内存快照。即——如果重写过程中存在内存修改操作，父进程负责创建所修改内存页的副本。这里就是内存消耗的地方。如何优化呢？尽量保证同一时刻只有一个子进程在工作；避免大量写入时做重写操作。

3) 硬盘 硬盘开销分析：子进程主要职责是将 RDB 或者 AOF 文件写入硬盘进行持久化，势必对硬盘造成压力，可通过工具例如 iostat，iotop 等，分析硬盘负载情况。

如何优化：

1) 不要和其他高硬盘负载的服务放在一台机器上，例如 MQ，存储。

2) AOF 重写时会消耗大量硬盘 IO，可以开启配置 no-appendfsync-on-rewrite，默认关闭。表示在 AOF 重写期间不做 fsync 操作。

3) 当开启 AOF 的 Redis 在高并发场景下，如果使用普通机械硬盘，每秒的写速率是 100MB左右，这时，Redis 的性能瓶颈在硬盘上，建议使用 SSD。

4) 对于单机配置多个 Redis 实例的情况，可以配置不同实例分盘存储 AOF 文件，分摊硬盘压力。

3、AOF 追加阻塞

当开启 AOF 持久化时，常用的同步硬盘的策略是“每秒同步” everysec，用于平衡性能和数据安全性，对于这种方式，redis 使用另一条线程每秒执行 fsync 同步硬盘，当系统资源繁忙时，将造成 Redis 主线程阻塞。

流程图如下：



通过上图可以发现：everysec 配置最多可能丢失 2 秒数据，不是 1 秒；如果系统 fsync 缓慢，将会导致 Redis 主线程阻塞影响效率。

问题定位：

1) 发生 AOF 阻塞时，会输入日志。用于记录 AOF fsync 阻塞导致拖慢 Redis 服务的行为。

2) 每当 AOF 追加阻塞事件发生时，在 info Persistence 统计中，aofdelayedfsync 指标会累加，查看这个指标方便定位 AOF 阻塞问题。

3) AOF 同步最多运行 2 秒的延迟，当延迟发生时说明硬盘存在性能问题，可通过监控工具 iotop 查看，定位消耗 IO 的进程。

4、单机多实例部署

Redis 单线程架构无法充分利用多核CPU，通常的做法是一台机器上部署多个实例，当多个实例开启 AOF 后，彼此之间就会产生CPU 和 IO 的竞争。

如何解决这个问题呢？

让所有实例的 AOF 串行执行。

我们通过 info Persistence 中关于 AOF 的信息写出 Shell 脚本，然后串行执行实例的 AOF 持久化。

整个过程如图：



通过不断判断 AOF 的状态，手动执行 AOF 重写，保证 AOF 不会存在竞争。具体的 Shell 编写以及 info 信息判断，可以查看下图：

本文主要讲了 Redis 的持久化相关功能，持久化一直是影响 Redis 性能的高发地，也是面试中经常被问到的。包括 RDB 相关的特定和优缺点，AOF 的优缺点，事实上，由于 RDB 的数据实时性问题，目前用 AOF 比较多了。而持久化恢复也是优先 AOF。

关于持久化的问题排查，就很麻烦了，但无非几个方面，fork 耗时，子进程的 CPU，内存，硬盘开销，AOF 的同步阻塞，单机多实例部署。

这些优化，可以通过前面写的分析进行排查。

https://help.aliyun.com/product/26340.html?spm=a2c4g.11186623.6.28.e0d672f4BgZEpj

游戏玩家积分排行榜
更新时间：2019-01-23 00:11:10

编辑 ·
 · 我的收藏
本页目录
场景介绍
运行结果
场景介绍
云数据库 Redis 版在功能上与 Redis 基本一致，因此很容易用它来实现一个在线游戏中的积分排行榜功能。

代码示例

import java.util.ArrayList;
import java.util.List;
import java.util.Set;
import java.util.UUID;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.Tuple;
public class GameRankSample {
    static int TOTAL_SIZE = 20;
    public static void main(String[] args)
    {
        //连接信息，从控制台可以获得
        String host = "xxxxxxxxxx.m.cnhz1.kvstore.aliyuncs.com";
        int port = 6379;
        Jedis jedis = new Jedis(host, port);
        try {
            //实例密码
            String authString = jedis.auth("password");//password
            if (!authString.equals("OK"))
            {
                System.err.println("AUTH Failed: " + authString);
                return;
            }
            //Key(键)
            String key = "游戏名：奔跑吧，阿里！";
            //清除可能的已有数据
            jedis.del(key);
            //模拟生成若干个游戏玩家
            List<String> playerList = new ArrayList<String>();
            for (int i = 0; i < TOTAL_SIZE; ++i)
            {
                //随机生成每个玩家的ID
                playerList.add(UUID.randomUUID().toString());
            }
            System.out.println("输入所有玩家 ");
            //记录每个玩家的得分
            for (int i = 0; i < playerList.size(); i++)
            {
                //随机生成数字，模拟玩家的游戏得分
                int score = (int)(Math.random()*5000);
                String member = playerList.get(i);
                System.out.println("玩家ID：" + member + "， 玩家得分: " + score);
                //将玩家的ID和得分，都加到对应key的SortedSet中去
                jedis.zadd(key, score, member);
            }
            //输出打印全部玩家排行榜
            System.out.println();
            System.out.println("       "+key);
            System.out.println("       全部玩家排行榜                    ");
            //从对应key的SortedSet中获取已经排好序的玩家列表
            Set<Tuple> scoreList = jedis.zrevrangeWithScores(key, 0, -1);
            for (Tuple item : scoreList) {
                System.out.println("玩家ID："+item.getElement()+"， 玩家得分:"+Double.valueOf(item.getScore()).intValue());
            }
            //输出打印Top5玩家排行榜
            System.out.println();
            System.out.println("       "+key);
            System.out.println("       Top 玩家");
            scoreList = jedis.zrevrangeWithScores(key, 0, 4);
            for (Tuple item : scoreList) {
                System.out.println("玩家ID："+item.getElement()+"， 玩家得分:"+Double.valueOf(item.getScore()).intValue());
            }
            //输出打印特定玩家列表
            System.out.println();
            System.out.println("         "+key);
            System.out.println("          积分在1000至2000的玩家");
            //从对应key的SortedSet中获取已经积分在1000至2000的玩家列表
            scoreList = jedis.zrangeByScoreWithScores(key, 1000, 2000);
            for (Tuple item : scoreList) {
                System.out.println("玩家ID："+item.getElement()+"， 玩家得分:"+Double.valueOf(item.getScore()).intValue());
            }
        } catch (Exception e) {
            e.printStackTrace();
        }finally{
            jedis.quit();
            jedis.close();
        }
    }
}
运行结果
在输入了正确的云数据库 Redis 版实例访问地址和密码之后，运行以上 Java 程序，输出结果如下：

输入所有玩家
玩家ID：9193e26f-6a71-4c76-8666-eaf8ee97ac86， 玩家得分: 3860
玩家ID：db03520b-75a3-48e5-850a-071722ff7afb， 玩家得分: 4853
玩家ID：d302d24d-d380-4e15-a4d6-84f71313f27a， 玩家得分: 2931
玩家ID：bee46f9d-4b05-425e-8451-8aa6d48858e6， 玩家得分: 1796
玩家ID：ec24fb9e-366e-4b89-a0d5-0be151a8cad0， 玩家得分: 2263
玩家ID：e11ecc2c-cd51-4339-8412-c711142ca7aa， 玩家得分: 1848
玩家ID：4c396f67-da7c-4b99-a783-25919d52d756， 玩家得分: 958
玩家ID：a6299dd2-4f38-4528-bb5a-aa2d48a9f94a， 玩家得分: 2428
玩家ID：2e4ec631-1e4e-4ef0-914f-7bf1745f7d65， 玩家得分: 4478
玩家ID：24235a85-85b9-476e-8b96-39f294f57aa7， 玩家得分: 1655
玩家ID：e3e8e1fa-6aac-4a0c-af80-4c4a1e126cd1， 玩家得分: 4064
玩家ID：99bc5b4f-e32a-4295-bc3a-0324887bb77e， 玩家得分: 4852
玩家ID：19e2aa6b-a2d8-4e56-bdf7-8b59f64bd8e0， 玩家得分: 3394
玩家ID：cb62bb24-1318-4af2-9d9b-fbff7280dbec， 玩家得分: 3405
玩家ID：ec0f06da-91ee-447b-b935-7ca935dc7968， 玩家得分: 4391
玩家ID：2c814a6f-3706-4280-9085-5fe5fd56b71c， 玩家得分: 2510
玩家ID：9ee2ed6d-08b8-4e7f-b52c-9adfe1e32dda， 玩家得分: 63
玩家ID：0293b43a-1554-4157-a95b-b78de9edf6dd， 玩家得分: 1008
玩家ID：674bbdd1-2023-46ae-bbe6-dfcd8e372430， 玩家得分: 2265
玩家ID：34574e3e-9cc5-43ed-ba15-9f5405312692， 玩家得分: 3734
              游戏名：奔跑吧，阿里！
              全部玩家排行榜
玩家ID：db03520b-75a3-48e5-850a-071722ff7afb， 玩家得分:4853
玩家ID：99bc5b4f-e32a-4295-bc3a-0324887bb77e， 玩家得分:4852
玩家ID：2e4ec631-1e4e-4ef0-914f-7bf1745f7d65， 玩家得分:4478
玩家ID：ec0f06da-91ee-447b-b935-7ca935dc7968， 玩家得分:4391
玩家ID：e3e8e1fa-6aac-4a0c-af80-4c4a1e126cd1， 玩家得分:4064
玩家ID：9193e26f-6a71-4c76-8666-eaf8ee97ac86， 玩家得分:3860
玩家ID：34574e3e-9cc5-43ed-ba15-9f5405312692， 玩家得分:3734
玩家ID：cb62bb24-1318-4af2-9d9b-fbff7280dbec， 玩家得分:3405
玩家ID：19e2aa6b-a2d8-4e56-bdf7-8b59f64bd8e0， 玩家得分:3394
玩家ID：d302d24d-d380-4e15-a4d6-84f71313f27a， 玩家得分:2931
玩家ID：2c814a6f-3706-4280-9085-5fe5fd56b71c， 玩家得分:2510
玩家ID：a6299dd2-4f38-4528-bb5a-aa2d48a9f94a， 玩家得分:2428
玩家ID：674bbdd1-2023-46ae-bbe6-dfcd8e372430， 玩家得分:2265
玩家ID：ec24fb9e-366e-4b89-a0d5-0be151a8cad0， 玩家得分:2263
玩家ID：e11ecc2c-cd51-4339-8412-c711142ca7aa， 玩家得分:1848
玩家ID：bee46f9d-4b05-425e-8451-8aa6d48858e6， 玩家得分:1796
玩家ID：24235a85-85b9-476e-8b96-39f294f57aa7， 玩家得分:1655
玩家ID：0293b43a-1554-4157-a95b-b78de9edf6dd， 玩家得分:1008
玩家ID：4c396f67-da7c-4b99-a783-25919d52d756， 玩家得分:958
玩家ID：9ee2ed6d-08b8-4e7f-b52c-9adfe1e32dda， 玩家得分:63
      游戏名：奔跑吧，阿里！
         Top 玩家
玩家ID：db03520b-75a3-48e5-850a-071722ff7afb， 玩家得分:4853
玩家ID：99bc5b4f-e32a-4295-bc3a-0324887bb77e， 玩家得分:4852
玩家ID：2e4ec631-1e4e-4ef0-914f-7bf1745f7d65， 玩家得分:4478
玩家ID：ec0f06da-91ee-447b-b935-7ca935dc7968， 玩家得分:4391
玩家ID：e3e8e1fa-6aac-4a0c-af80-4c4a1e126cd1， 玩家得分:4064
          游戏名：奔跑吧，阿里！
          积分在1000至2000的玩家
玩家ID：0293b43a-1554-4157-a95b-b78de9edf6dd， 玩家得分:1008
玩家ID：24235a85-85b9-476e-8b96-39f294f57aa7， 玩家得分:1655
玩家ID：bee46f9d-4b05-425e-8451-8aa6d48858e6， 玩家得分:1796
玩家ID：e11ecc2c-cd51-4339-8412-c711142ca7aa， 玩家得分:1848


-------------------------------------------------------------------------

网上商城商品相关性分析
更新时间：2019-01-23 00:11:12

编辑 ·
 · 我的收藏
本页目录
场景介绍
运行结果
场景介绍
云数据库 Redis 版在功能上与 Redis 基本一致，因此很容易利用它来实现一个网上商城的商品相关性分析程序。

商品的相关性就是某个产品与其他另外某商品同时出现在购物车中的情况。这种数据分析对于电商行业是很重要的，可以用来分析用户购买行为。例如：

在某一商品的 detail 页面，推荐给用户与该商品相关的其他商品；

在添加购物车成功页面，当用户把一个商品添加到购物车，推荐给用户与之相关的其他商品；

在货架上将相关性比较高的几个商品摆放在一起。

利用云数据库 Redis 版的有序集合，为每种商品构建一个有序集合，集合的成员为和该商品同时出现在购物车中的商品，成员的 score 为同时出现的次数。每次 A 和 B 商品同时出现在购物车中时，分别更新云数据库 Redis 版中 A 和 B 对应的有序集合。

代码示例

package shop.kvstore.aliyun.com;
import java.util.Set;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.Tuple;
    public class AliyunShoppingMall {
        public static void main(String[] args)
        {
            //ApsaraDB for Redis的连接信息，从控制台可以获得
            String host = "xxxxxxxx.m.cnhza.kvstore.aliyuncs.com";
            int port = 6379;
            Jedis jedis = new Jedis(host, port);
            try {
                //ApsaraDB for Redis的实例密码
                String authString = jedis.auth("password");//password
                if (!authString.equals("OK"))
                {
                    System.err.println("AUTH Failed: " + authString);
                    return;
                }
                //产品列表
                String key0="阿里云:产品:啤酒";
                String key1="阿里云:产品:巧克力";
                String key2="阿里云:产品:可乐";
                String key3="阿里云:产品:口香糖";
                String key4="阿里云:产品:牛肉干";
                String key5="阿里云:产品:鸡翅";
                final String[] aliyunProducts=new String[]{key0,key1,key2,key3,key4,key5};
                //初始化，清除可能的已有旧数据
                for (int i = 0; i < aliyunProducts.length; i++) {
                    jedis.del(aliyunProducts[i]);
                }
                //模拟用户购物
                for (int i = 0; i < 5; i++) {//模拟多人次的用户购买行为
                    customersShopping(aliyunProducts,i,jedis);
                }
                System.out.println();
                //利用ApsaraDB for Redis来输出各个商品间的关联关系
                for (int i = 0; i < aliyunProducts.length; i++) {
                    System.out.println(">>>>>>>>>>与"+aliyunProducts[i]+"一起被购买的产品有<<<<<<<<<<<<<<<");
                    Set<Tuple> relatedList = jedis.zrevrangeWithScores(aliyunProducts[i], 0, -1);
                    for (Tuple item : relatedList) {
                        System.out.println("商品名称："+item.getElement()+"， 共同购买次数:"+Double.valueOf(item.getScore()).intValue());
                    }
                    System.out.println();
                }
            } catch (Exception e) {
                e.printStackTrace();
            }finally{
                jedis.quit();
                jedis.close();
            }
        }
        private static void customersShopping(String[] products, int i, Jedis jedis) {
            //简单模拟3种购买行为，随机选取作为用户的购买选择
            int bought=(int)(Math.random()*3);
            if(bought==1){
                //模拟业务逻辑：用户购买了如下产品
                System.out.println("用户"+i+"购买了"+products[0]+","+products[2]+","+products[1]);
                //将产品之间的关联情况记录到ApsaraDB for Redis的SortSet之中
                jedis.zincrby(products[0], 1, products[1]);
                jedis.zincrby(products[0], 1, products[2]);
                jedis.zincrby(products[1], 1, products[0]);
                jedis.zincrby(products[1], 1, products[2]);
                jedis.zincrby(products[2], 1, products[0]);
                jedis.zincrby(products[2], 1, products[1]);
            }else if(bought==2){
                //模拟业务逻辑：用户购买了如下产品
                System.out.println("用户"+i+"购买了"+products[4]+","+products[2]+","+products[3]);
                //将产品之间的关联情况记录到ApsaraDB for Redis的SortSet之中
                jedis.zincrby(products[4], 1, products[2]);
                jedis.zincrby(products[4], 1, products[3]);
                jedis.zincrby(products[3], 1, products[4]);
                jedis.zincrby(products[3], 1, products[2]);
                jedis.zincrby(products[2], 1, products[4]);
                jedis.zincrby(products[2], 1, products[3]);
            }else if(bought==0){
                //模拟业务逻辑：用户购买了如下产品
                System.out.println("用户"+i+"购买了"+products[1]+","+products[5]);
                //将产品之间的关联情况记录到ApsaraDB for Redis的SortSet之中
                jedis.zincrby(products[5], 1, products[1]);
                jedis.zincrby(products[1], 1, products[5]);
            }
        }
    }
运行结果
在输入了正确的云数据库 Redis 版实例访问地址和密码之后，运行以上 Java 程序，输出结果如下：

用户0购买了阿里云:产品:巧克力,阿里云:产品:鸡翅
用户1购买了阿里云:产品:牛肉干,阿里云:产品:可乐,阿里云:产品:口香糖
用户2购买了阿里云:产品:啤酒,阿里云:产品:可乐,阿里云:产品:巧克力
用户3购买了阿里云:产品:牛肉干,阿里云:产品:可乐,阿里云:产品:口香糖
用户4购买了阿里云:产品:巧克力,阿里云:产品:鸡翅
>>>>>>>>>>与阿里云:产品:啤酒一起被购买的产品有<<<<<<<<<<<<<<<
商品名称：阿里云:产品:巧克力， 共同购买次数:1
商品名称：阿里云:产品:可乐， 共同购买次数:1
>>>>>>>>>>与阿里云:产品:巧克力一起被购买的产品有<<<<<<<<<<<<<<<
商品名称：阿里云:产品:鸡翅， 共同购买次数:2
商品名称：阿里云:产品:啤酒， 共同购买次数:1
商品名称：阿里云:产品:可乐， 共同购买次数:1
>>>>>>>>>>与阿里云:产品:可乐一起被购买的产品有<<<<<<<<<<<<<<<
商品名称：阿里云:产品:牛肉干， 共同购买次数:2
商品名称：阿里云:产品:口香糖， 共同购买次数:2
商品名称：阿里云:产品:巧克力， 共同购买次数:1
商品名称：阿里云:产品:啤酒， 共同购买次数:1
>>>>>>>>>>与阿里云:产品:口香糖一起被购买的产品有<<<<<<<<<<<<<<<
商品名称：阿里云:产品:牛肉干， 共同购买次数:2
商品名称：阿里云:产品:可乐， 共同购买次数:2
>>>>>>>>>>与阿里云:产品:牛肉干一起被购买的产品有<<<<<<<<<<<<<<<
商品名称：阿里云:产品:可乐， 共同购买次数:2
商品名称：阿里云:产品:口香糖， 共同购买次数:2
>>>>>>>>>>与阿里云:产品:鸡翅一起被购买的产品有<<<<<<<<<<<<<<<
商品名称：阿里云:产品:巧克力， 共同购买次数:2

-----------------

消息发布与订阅
更新时间：2018-11-20 14:42:26

编辑 ·
 · 我的收藏
本页目录
场景介绍
代码示例
运行结果
场景介绍
云数据库 Redis 版也提供了与 Redis 相同的消息发布（pub）与订阅（sub）功能。即一个 client 发布消息，其他多个 client 订阅消息。

需要注意的是，云数据库 Redis 版发布的消息是“非持久”的，即消息发布者只负责发送消息，而不管消息是否有接收方，也不会保存之前发送的消息，即发布的消息“即发即失”；消息订阅者也只能得到订阅之后的消息，频道（channel）中此前的消息将无从获得。

此外，消息发布者（即 publish 客户端）无需独占与服务器端的连接，您可以在发布消息的同时，使用同一个客户端连接进行其他操作（例如 List 操作等）。但是，消息订阅者（即 subscribe 客户端）需要独占与服务器端的连接，即进行 subscribe 期间，该客户端无法执行其他操作，而是以阻塞的方式等待频道（channel）中的消息；因此消息订阅者需要使用单独的服务器连接，或者需要在单独的线程中使用（参见如下示例）。

代码示例
消息发布者 (即 publish client)

package message.kvstore.aliyun.com;
import redis.clients.jedis.Jedis;
public class KVStorePubClient {
    private Jedis jedis;
    public KVStorePubClient(String host,int port, String password){
        jedis = new Jedis(host,port);
        //KVStore的实例密码
        String authString = jedis.auth(password);
        if (!authString.equals("OK"))
        {
            System.err.println("AUTH Failed: " + authString);
            return;
        }
    }
    public void pub(String channel,String message){
        System.out.println("  >>> 发布(PUBLISH) > Channel:"+channel+" > 发送出的Message:"+message);
        jedis.publish(channel, message);
    }
    public void close(String channel){
        System.out.println("  >>> 发布(PUBLISH)结束 > Channel:"+channel+" > Message:quit");
        //消息发布者结束发送，即发送一个“quit”消息；
        jedis.publish(channel, "quit");
    }
}
消息订阅者 (即 subscribe client)

package message.kvstore.aliyun.com;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPubSub;
public class KVStoreSubClient extends Thread{
    private Jedis jedis;
    private String channel;
    private JedisPubSub listener;
    public KVStoreSubClient(String host,int port, String password){
        jedis = new Jedis(host,port);
                //ApsaraDB for Redis的实例密码
                String authString = jedis.auth(password);//password
                if (!authString.equals("OK"))
                {
                    System.err.println("AUTH Failed: " + authString);
                    return;
                }
    }
    public void setChannelAndListener(JedisPubSub listener,String channel){
        this.listener=listener;
        this.channel=channel;
    }
    private void subscribe(){
        if(listener==null || channel==null){
            System.err.println("Error:SubClient> listener or channel is null");
        }
        System.out.println("  >>> 订阅(SUBSCRIBE) > Channel:"+channel);
        System.out.println();
        //接收者在侦听订阅的消息时，将会阻塞进程，直至接收到quit消息（被动方式），或主动取消订阅
        jedis.subscribe(listener, channel);
    }
    public void unsubscribe(String channel){
        System.out.println("  >>> 取消订阅(UNSUBSCRIBE) > Channel:"+channel);
        System.out.println();
        listener.unsubscribe(channel);
    }
    @Override
    public void run() {
        try{
            System.out.println();
            System.out.println("----------订阅消息SUBSCRIBE 开始-------");
            subscribe();
            System.out.println("----------订阅消息SUBSCRIBE 结束-------");
            System.out.println();
        }catch(Exception e){
            e.printStackTrace();
        }
    }
}
消息监听者

package message.kvstore.aliyun.com;
import redis.clients.jedis.JedisPubSub;
public class KVStoreMessageListener extends JedisPubSub{
    @Override
    public void onMessage(String channel, String message) {
        System.out.println("  <<< 订阅(SUBSCRIBE)< Channel:" + channel + " >接收到的Message:" + message );
        System.out.println();
        //当接收到的message为quit时，取消订阅(被动方式)
        if(message.equalsIgnoreCase("quit")){
            this.unsubscribe(channel);
        }
    }
    @Override
    public void onPMessage(String pattern, String channel, String message) {
        // TODO Auto-generated method stub
    }
    @Override
    public void onSubscribe(String channel, int subscribedChannels) {
        // TODO Auto-generated method stub
    }
    @Override
    public void onUnsubscribe(String channel, int subscribedChannels) {
        // TODO Auto-generated method stub
    }
    @Override
    public void onPUnsubscribe(String pattern, int subscribedChannels) {
        // TODO Auto-generated method stub
    }
    @Override
    public void onPSubscribe(String pattern, int subscribedChannels) {
        // TODO Auto-generated method stub
    }
}
示例主程序

package message.kvstore.aliyun.com;
import java.util.UUID;
import redis.clients.jedis.JedisPubSub;
public class KVStorePubSubTest {
    //ApsaraDB for Redis的连接信息，从控制台可以获得
    static final String host = "xxxxxxxxxx.m.cnhza.kvstore.aliyuncs.com";
    static final int port = 6379;
    static final String password="password";//password
    public static void main(String[] args) throws Exception{
            KVStorePubClient pubClient = new KVStorePubClient(host, port,password);
            final String channel = "KVStore频道-A";
            //消息发送者开始发消息，此时还无人订阅，所以此消息不会被接收
            pubClient.pub(channel, "Aliyun消息1：（此时还无人订阅，所以此消息不会被接收）");
            //消息接收者
            KVStoreSubClient subClient = new KVStoreSubClient(host, port,password);
            JedisPubSub listener = new KVStoreMessageListener();
            subClient.setChannelAndListener(listener, channel);
            //消息接收者开始订阅
            subClient.start();
            //消息发送者继续发消息
            for (int i = 0; i < 5; i++) {
                String message=UUID.randomUUID().toString();
                pubClient.pub(channel, message);
                Thread.sleep(1000);
            }
            //消息接收者主动取消订阅
            subClient.unsubscribe(channel);
            Thread.sleep(1000);
            pubClient.pub(channel, "Aliyun消息2：（此时订阅取消，所以此消息不会被接收）");
            //消息发布者结束发送，即发送一个“quit”消息；
            //此时如果有其他的消息接收者，那么在listener.onMessage()中接收到“quit”时，将执行“unsubscribe”操作。
            pubClient.close(channel);
        }
    }
运行结果
在输入了正确的云数据库 Redis 版实例访问地址和密码之后，运行以上 Java 程序，输出结果如下。

  >>> 发布(PUBLISH) > Channel:KVStore频道-A > 发送出的Message:Aliyun消息1：（此时还无人订阅，所以此消息不会被接收）
----------订阅消息SUBSCRIBE 开始-------
  >>> 订阅(SUBSCRIBE) > Channel:KVStore频道-A
  >>> 发布(PUBLISH) > Channel:KVStore频道-A > 发送出的Message:0f9c2cee-77c7-4498-89a0-1dc5a2f65889
  <<< 订阅(SUBSCRIBE)< Channel:KVStore频道-A >接收到的Message:0f9c2cee-77c7-4498-89a0-1dc5a2f65889
  >>> 发布(PUBLISH) > Channel:KVStore频道-A > 发送出的Message:ed5924a9-016b-469b-8203-7db63d06f812
  <<< 订阅(SUBSCRIBE)< Channel:KVStore频道-A >接收到的Message:ed5924a9-016b-469b-8203-7db63d06f812
  >>> 发布(PUBLISH) > Channel:KVStore频道-A > 发送出的Message:f1f84e0f-8f35-4362-9567-25716b1531cd
  <<< 订阅(SUBSCRIBE)< Channel:KVStore频道-A >接收到的Message:f1f84e0f-8f35-4362-9567-25716b1531cd
  >>> 发布(PUBLISH) > Channel:KVStore频道-A > 发送出的Message:746bde54-af8f-44d7-8a49-37d1a245d21b
  <<< 订阅(SUBSCRIBE)< Channel:KVStore频道-A >接收到的Message:746bde54-af8f-44d7-8a49-37d1a245d21b
  >>> 发布(PUBLISH) > Channel:KVStore频道-A > 发送出的Message:8ac3b2b8-9906-4f61-8cad-84fc1f15a3ef
  <<< 订阅(SUBSCRIBE)< Channel:KVStore频道-A >接收到的Message:8ac3b2b8-9906-4f61-8cad-84fc1f15a3ef
  >>> 取消订阅(UNSUBSCRIBE) > Channel:KVStore频道-A
----------订阅消息SUBSCRIBE 结束-------
  >>> 发布(PUBLISH) > Channel:KVStore频道-A > 发送出的Message:Aliyun消息2：（此时订阅取消，所以此消息不会被接收）
  >>> 发布(PUBLISH)结束 > Channel:KVStore频道-A > Message:quit
以上示例中仅演示了一个发布者与一个订阅者的情况，实际上发布者与订阅者都可以为多个，发送消息的频道（channel）也可以是多个，对以上代码稍作修改即可。


------------

管道传输
云数据库 Redis 版提供了与 Redis 相同的管道传输（pipeline）机制。管道（pipeline）将客户端 client 与服务器端的交互明确划分为单向的发送请求（Send Request）和接收响应（Receive Response）：用户可以将多个操作连续发给服务器，但在此期间服务器端并不对每个操作命令发送响应数据；全部请求发送完毕后用户关闭请求，开始接收响应获取每个操作命令的响应结果。

管道（pipeline）在某些场景下非常有用，比如有多个操作命令需要被迅速提交至服务器端，但用户并不依赖每个操作返回的响应结果，对结果响应也无需立即获得，那么管道就可以用来作为优化性能的批处理工具。性能提升的原因主要是减少了 TCP 连接中交互往返的开销。

不过在程序中使用管道请注意，使用 pipeline 时客户端将独占与服务器端的连接，此期间将不能进行其他“非管道”类型操作，直至 pipeline 被关闭；如果要同时执行其他操作，可以为 pipeline 操作单独建立一个连接，将其与常规操作分离开来。

代码示例1
性能对比

package pipeline.kvstore.aliyun.com;
import java.util.Date;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.Pipeline;
public class RedisPipelinePerformanceTest {
        static final String host = "xxxxxx.m.cnhza.kvstore.aliyuncs.com";
        static final int port = 6379;
        static final String password = "password";
        public static void main(String[] args) {
            Jedis jedis = new Jedis(host, port);
                //ApsaraDB for Redis的实例密码
                String authString = jedis.auth(password);// password
                if (!authString.equals("OK")) {
                    System.err.println("AUTH Failed: " + authString);
                    jedis.close();
                    return;
                }
                //连续执行多次命令操作
                final int COUNT=5000;
                String key = "KVStore-Tanghan";
                // 1 ---不使用pipeline操作---
                jedis.del(key);//初始化key
                Date ts1 = new Date();
                for (int i = 0; i < COUNT; i++) {
                    //发送一个请求，并接收一个响应（Send Request and  Receive Response）
                    jedis.incr(key);
                }
                Date ts2 = new Date();
                System.out.println("不用Pipeline > value为:"+jedis.get(key)+" > 操作用时：" + (ts2.getTime() - ts1.getTime())+ "ms");
                //2 ----对比使用pipeline操作---
                jedis.del(key);//初始化key
                Pipeline p1 = jedis.pipelined();
                Date ts3 = new Date();
                for (int i = 0; i < COUNT; i++) {
                    //发出请求 Send Request
                    p1.incr(key);
                }
                //接收响应 Receive Response
                p1.sync();
                Date ts4 = new Date();
                System.out.println("使用Pipeline > value为:"+jedis.get(key)+" > 操作用时：" + (ts4.getTime() - ts3.getTime())+ "ms");
                jedis.close();
        }
    }
运行结果1
在输入了正确的云数据库 Redis 版实例访问地址和密码之后，运行以上 Java 程序，输出结果如下。从中可以看出使用 pipeline 的性能要快的多。

不用Pipeline > value为:5000 > 操作用时：5844ms
使用Pipeline > value为:5000 > 操作用时：78ms
代码示例2
在 Jedis 中使用管道（pipeline）时，对于响应数据（response）的处理有两种方式，请参考以下代码示例。

package pipeline.kvstore.aliyun.com;
import java.util.List;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.Pipeline;
import redis.clients.jedis.Response;
    public class PipelineClientTest {
        static final String host = "xxxxxxxx.m.cnhza.kvstore.aliyuncs.com";
        static final int port = 6379;
        static final String password = "password";
        public static void main(String[] args) {
            Jedis jedis = new Jedis(host, port);
                // ApsaraDB for Redis的实例密码
                String authString = jedis.auth(password);// password
                if (!authString.equals("OK")) {
                    System.err.println("AUTH Failed: " + authString);
                    jedis.close();
                    return;
                }
                String key = "KVStore-Test1";
                jedis.del(key);//初始化
                // -------- 方法1
                Pipeline p1 = jedis.pipelined();
                System.out.println("-----方法1-----");
                for (int i = 0; i < 5; i++) {
                    p1.incr(key);
                    System.out.println("Pipeline发送请求");
                }
                // 发送请求完成，开始接收响应
                System.out.println("发送请求完成，开始接收响应");
                List<Object> responses = p1.syncAndReturnAll();
                if (responses == null || responses.isEmpty()) {
                    jedis.close();
                    throw new RuntimeException("Pipeline error: 没有接收到响应");
                }
                for (Object resp : responses) {
                    System.out.println("Pipeline接收响应Response: " + resp.toString());
                }
                System.out.println();
                //-------- 方法2
                System.out.println("-----方法2-----");
                jedis.del(key);//初始化
                Pipeline p2 = jedis.pipelined();
                //需要先声明Response
                Response<Long> r1 = p2.incr(key);
                System.out.println("Pipeline发送请求");
                Response<Long> r2 = p2.incr(key);
                System.out.println("Pipeline发送请求");
                Response<Long> r3 = p2.incr(key);
                System.out.println("Pipeline发送请求");
                Response<Long> r4 = p2.incr(key);
                System.out.println("Pipeline发送请求");
                Response<Long> r5 = p2.incr(key);
                System.out.println("Pipeline发送请求");
                try{
                    r1.get();  //此时还未开始接收响应，所以此操作会出错
                }catch(Exception e){
                    System.out.println(" <<< Pipeline error：还未开始接收响应  >>> ");
                }
             // 发送请求完成，开始接收响应
                System.out.println("发送请求完成，开始接收响应");
                p2.sync();
                System.out.println("Pipeline接收响应Response: " + r1.get());
                System.out.println("Pipeline接收响应Response: " + r2.get());
                System.out.println("Pipeline接收响应Response: " + r3.get());
                System.out.println("Pipeline接收响应Response: " + r4.get());
                System.out.println("Pipeline接收响应Response: " + r5.get());
                jedis.close();
            }
    }
运行结果2
在输入了正确的云数据库 Redis 版实例访问地址和密码之后，运行以上 Java 程序，输出结果如下:

-----方法1-----
Pipeline发送请求
Pipeline发送请求
Pipeline发送请求
Pipeline发送请求
Pipeline发送请求
发送请求完成，开始接收响应
Pipeline接收响应Response: 1
Pipeline接收响应Response: 2
Pipeline接收响应Response: 3
Pipeline接收响应Response: 4
Pipeline接收响应Response: 5
-----方法2-----
Pipeline发送请求
Pipeline发送请求
Pipeline发送请求
Pipeline发送请求
Pipeline发送请求
 <<< Pipeline error：还未开始接收响应  >>>
发送请求完成，开始接收响应
Pipeline接收响应Response: 1
Pipeline接收响应Response: 2
Pipeline接收响应Response: 3
Pipeline接收响应Response: 4
Pipeline接收响应Response: 5


====================
事务处理
代码示例2：两个 client 操作相同的 key
云数据库 Redis 版支持 Redis 中 定义的“事务（transaction）”机制，即用户可以使用 MULTI，EXEC，DISCARD，WATCH，UNWATCH 指令用来执行原子性的事务操作。

需要强调的是，Redis 中定义的事务，并不是关系数据库中严格意义上的事务。当 Redis 事务中的某个操作执行失败，或者用 DISCARD 取消事务时候，Redis 并不执行“事务回滚”，在使用时要注意这点。

代码示例1：两个 client 操作不同的 key

package transcation.kvstore.aliyun.com;
import java.util.List;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.Transaction;
public class KVStoreTranscationTest {
    static final String host = "xxxxxx.m.cnhza.kvstore.aliyuncs.com";
    static final int port = 6379;
    static final String password = "password";
    //**注意这两个key的内容是不同的
    static String client1_key = "KVStore-Transcation-1";
    static String client2_key = "KVStore-Transcation-2";
    public static void main(String[] args) {
        Jedis jedis = new Jedis(host, port);
        // ApsaraDB for Redis的实例密码
        String authString = jedis.auth(password);//password
        if (!authString.equals("OK")) {
            System.err.println("认证失败: " + authString);
            jedis.close();
            return;
        }
        jedis.set(client1_key, "0");
        //启动另一个thread，模拟另外的client
        new KVStoreTranscationTest().new OtherKVStoreClient().start();
        Thread.sleep(500);
        Transaction tx = jedis.multi();//开始事务
        //以下操作会集中提交服务器端处理，作为“原子操作”
        tx.incr(client1_key);
        tx.incr(client1_key);
        Thread.sleep(400);//此处Thread的暂停对事务中前后连续的操作并无影响，其他Thread的操作也无法执行
        tx.incr(client1_key);
        Thread.sleep(300);//此处Thread的暂停对事务中前后连续的操作并无影响，其他Thread的操作也无法执行
        tx.incr(client1_key);
        Thread.sleep(200);//此处Thread的暂停对事务中前后连续的操作并无影响，其他Thread的操作也无法执行
        tx.incr(client1_key);
        List<Object> result = tx.exec();//提交执行
        //解析并打印出结果
        for(Object rt : result){
            System.out.println("Client 1 > 事务中> "+rt.toString());
        }
        jedis.close();
    }
    class OtherKVStoreClient extends Thread{
        @Override
        public void run() {
            Jedis jedis = new Jedis(host, port);
            // ApsaraDB for Redis的实例密码
            String authString = jedis.auth(password);// password
            if (!authString.equals("OK")) {
                System.err.println("AUTH Failed: " + authString);
                jedis.close();
                return;
            }
            jedis.set(client2_key, "100");
            for (int i = 0; i < 10; i++) {
                try {
                    Thread.sleep(300);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("Client 2 > "+jedis.incr(client2_key));
            }
            jedis.close();
        }
    }
}
运行结果1
在输入了正确的云数据库 Redis 版实例访问地址和密码之后，运行以上 Java 程序，输出结果如下。从中可以看到 client1 和 client2 在两个不同的 Thread 中，client1 所提交的事务操作都是集中顺序执行的，在此期间尽管 client2 是对另外一个 key 进行操作，它的命令操作也都被阻塞等待，直至 client1 事务中的全部操作执行完毕。

Client 2 > 101
Client 2 > 102
Client 2 > 103
Client 2 > 104
Client 1 > 事务中> 1
Client 1 > 事务中> 2
Client 1 > 事务中> 3
Client 1 > 事务中> 4
Client 1 > 事务中> 5
Client 2 > 105
Client 2 > 106
Client 2 > 107
Client 2 > 108
Client 2 > 109
Client 2 > 110
代码示例2：两个 client 操作相同的 key
对以上的代码稍作改动，使得两个 client 操作同一个 key，其余部分保持不变。

    ... ...
//**注意这两个key的内容现在是相同的
    static String client1_key = "KVStore-Transcation-1";
    static String client2_key = "KVStore-Transcation-1";
    ... ...
运行结果2
再次运行修改后的此 Java 程序，输出结果如下。可以看到不同 Thread 中的两个 client 在操作同一个 key，但是当 client1 利用事务机制来操作这个 key 时，client2 被阻塞不得不等待 client1 事务中的操作完全执行完毕。

Client 2 > 101
Client 2 > 102
Client 2 > 103
Client 2 > 104
Client 1 > 事务中> 105
Client 1 > 事务中> 106
Client 1 > 事务中> 107
Client 1 > 事务中> 108
Client 1 > 事务中> 109
Client 2 > 110
Client 2 > 111
Client 2 > 112
Client 2 > 113
Client 2 > 114
Client 2 > 115

==============

通过数据集成将数据导入 Redis
更新时间：2019-01-23 00:54:05

编辑 ·
 · 我的收藏
本页目录
数据集成简介
一、创建 Redis 数据源
数据集成简介
数据集成（Data Integration）是阿里集团对外提供的可跨异构数据存储系统的、可靠、安全、低成本、可弹性扩展的数据同步平台，为20多种数据源提供不同网络环境下的离线(全量/增量)数据进出通道。详细的数据源类型列表请参考支持的数据源类型。您可以通过数据集成向云数据库 Redis 版进行数据的导入数据。

一、创建 Redis 数据源
Redis 数据源支持写入 Redis 的通道，可以通过脚本模式配置同步任务 。

注意
只有项目管理员角色才能够新建数据源，其他角色的成员仅能查看数据源。

如您想用子账号创建数据集成任务，需赋予子账号相应的权限。具体请参考：开通阿里云主账号设置子账号。

操作步骤

以开发者身份进入阿里云数加平台，单击项目列表下对应项目操作栏中的进入工作区。
单击顶部菜单栏中数据集成模块的数据源。
单击新增数据源。
在新建数据源对话框中，选择数据源类型为 Redis。
配置 Redis 数据源的各个信息项，如下图所示。

注意
若账号没有授权数据集成默认角色，需要前往 RAM 进行角色授权。

配置项具体说明如下：

数据源名称：由英文字母、数字、下划线组成且需以字符或下划线开头，长度不超过60个字符。

数据源描述：对数据源进行简单描述，不得超过80个字符。

数据源类型：当前选择的数据源类型为 Redis：有公网IP的自建数据库。

服务地址：格式为 host:port。

添加访问地址：添加访问地址，格式为 host:port。

密码：数据库对应的密码 。

完成上述信息项的配置后，单击测试连通性。
测试连通性通过后，单击确定。
二、配置脚本模式的同步任务
以项目管理员身份进入数加管理控制台，单击大数据开发套件下对应项目操作栏中的进入工作区。

进入顶部菜单栏中的数据集成页面，选择脚本模式，如下图。


说明
Redis 不支持向导模式。进入脚本界面你可以选择相应的模板，此模板包含了同步任务的主要参数，将相关的信息填写完整，但是脚本模式不能转化成向导模式。

在导入模板对话框中选择需要的来源类型和目标类型，并单击确认。如下图所示：

在脚本模式配置页面，根据自身情况进行配置，如有问题可单击右上方的 Redis Writer 帮助手册进行查看。如下图所示：

说明：RedisWriter 脚本案例如下：

{
   "type": "job",
   "configuration": {
     "setting": {
       "speed": {
         "concurrent": "1",//并发数
         "mbps": "1"//同步能达到的最大数率
       },
       "errorLimit": {
         "record": "0"
       }
     },
     "reader": {
       "parameter": {
         "splitPk": "id",//切分键
         "column": [
           "id",
           "name",
           "year"
         ],
         "table": "person",//表名
         "where": "",//
         "datasource": "px_mysql"//数据源名，建议数据源都先添加数据源后再配置同步任务,此配置项填写的内容必须要与添加的数据源名称保持一致
       },
       "plugin": "mysql"
     },
     "writer": {
       "parameter": {
         "expireTime": {
           "seconds": "1000"//相对当前时间的秒数，该时间指定了从现在开始多长时间后数据失效
         },
         "keyFieldDelimiter": "\u0001",//写入 redis 的 key 分隔符。比如: key=key1\u0001id,如果 key 有多个需要拼接时，该值为必填项，如果 key 只有一个则可以忽略该配置项。
         "writeMode": {
           "valueFieldDelimiter": "\u0001",//value 类型是 string 时，value 之间的分隔符，比如 value1\u0001value2\u0001value3；
           "type": "string",//value类型
           "mode": "set"//写入的模式,存储这个数据，如果已经存在则覆盖
         },
         "batchSize": "1000",//一次性批量提交的记录数大小
         "dateFormat": "yyyy-MM-dd HH:mm:ss",//时间格式
         "keyIndexes": [
           0,
           1
         ],//keyIndexes 表示源端哪几列需要作为 key（第一列是从 0 开始），如果是第一列和第二列需要组合作为 key，那么 keyIndexes 的值则为 [0,1]。
         "datasource": "px_redis_datasource"//数据源名，建议数据源都先添加数据源后再配置同步任务,此配置项填写的内容必须要与添加的数据源名称保持一致
       },
       "plugin": "redis"
     }
   },
   "version": "1.0"
 }
运行结果如下：


RedisWriter 参数说明请参考 RedisWriter 配置。

=========
热点Key问题的发现与解决
更新时间：2019-02-27 15:04:08

编辑 ·
 · 我的收藏
本页目录
热点问题概述
热点问题的危害
常见解决方案
阿里云数据库解热点之道
两种方案对比
热点问题概述
产生原因

热点问题产生的原因大致有以下两种：

用户消费的数据远大于生产的数据（热卖商品、热点新闻、热点评论、明星直播）。

在日常工作生活中一些突发的的事件，例如：双十一期间某些热门商品的降价促销，当这其中的某一件商品被数万次点击浏览或者购买时，会形成一个较大的需求量，这种情况下就会造成热点问题。同理，被大量刊发、浏览的热点新闻、热点评论、明星直播等，这些典型的读多写少的场景也会产生热点问题。

请求分片集中，超过单Server的性能极限。

在服务端读数据进行访问时，往往会对数据进行分片切分，此过程中会在某一主机Server上对相应的Key进行访问，当访问超过Server极限时，就会导致热点Key问题的产生。

热点问题的危害

流量集中，达到物理网卡上限。
请求过多，缓存分片服务被打垮。
DB击穿，引起业务雪崩。
如前文讲到的，当某一热点Key的请求在某一主机上超过该主机网卡上限时，由于流量的过度集中，会导致服务器中其它服务无法进行。如果热点过于集中，热点Key的缓存过多，超过目前的缓存容量时，就会导致缓存分片服务被打垮现象的产生。当缓存服务崩溃后，此时再有请求产生，会缓存到后台DB上，由于DB本身性能较弱，在面临大请求时很容易发生请求穿透现象，会进一步导致雪崩现象，严重影响设备的性能。

常见解决方案
通常的解决方案主要集中在对客户端和Server端进行相应的改造。

服务端缓存方案


首先Client会将请求发送至Server上，而Server又是一个多线程的服务，本地就具有一个基于Cache LRU策略的缓存空间。当Server本身就拥堵时，Server不会将请求进一步发送给DB而是直接返回，只有当Server本身畅通时才会将Client请求发送至DB，并且将该数据重新写入到缓存中。此时就完成了缓存的访问跟重建。

但该方案也存在以下问题：

缓存失效，多线程构建缓存问题

缓存丢失，缓存构建问题

脏读问题

使用Memcache、Redis方案


该方案通过在客户端单独部署缓存的方式来解决热点Key问题。使用过程中Client首先访问服务层，再对同一主机上的缓存层进行访问。该种解决方案具有就近访问、速度快、没有带宽限制的优点，但是同时也存在以下问题。

内存资源浪费

脏读问题

使用本地缓存方案

使用本地缓存则存在以下问题：

需要提前获知热点

缓存容量有限

不一致性时间增长

热点Key遗漏

传统的热点解决方案都存在各种各样的问题，那么究竟该如何解决热点问题呢？

阿里云数据库解热点之道
读写分离方案解决热读


架构中各节点的作用如下：

SLB层做负载均衡

Proxy层做读写分离自动路由

Master负责写请求

ReadOnly节点负责读请求

Replica节点和Master节点做高可用

实际过程中Client将请求传到SLB，SLB又将其分发至多个Proxy内，通过Proxy对请求的识别，将其进行分类发送。例如，将同为Write的请求发送到Master模块内，而将Read的请求发送至ReadOnly模块。而模块中的只读节点可以进一步扩充，从而有效解决热点读的问题。读写分离同时具有可以灵活扩容读热点能力、可以存储大量热点Key、对客户端友好等优点。

热点数据解决方案


该方案通过主动发现热点并对其进行存储来解决热点Key的问题。首先Client也会访问SLB，并且通过SLB将各种请求分发至Proxy中，Proxy会按照基于路由的方式将请求转发至后端的Redis中。

在热点key的解决上是采用在服务端增加缓存的方式进行。具体来说就是在Proxy上增加本地缓存，本地缓存采用LRU算法来缓存热点数据，后端db节点增加热点数据计算模块来返回热点数据。

Proxy架构的主要有以下优点：

Proxy本地缓存热点，读能力可水平扩展

DB节点定时计算热点数据集合

DB反馈 Proxy 热点数据

对客户端完全透明，不需做任何兼容

热点key处理

热点数据的读取


在热点Key的处理上主要分为写入跟读取两种形式，在数据写入过程当SLB收到数据K1并将其通过某一个Proxy写入一个Redis，完成数据的写入。假若经过后端热点模块计算发现K1成为热点key后， Proxy会将该热点进行缓存，当下次客户端再进行访问K1时，可以不经Redis。最后由于proxy是可以水平扩充的，因此可以任意增强热点数据的访问能力。

热点数据的发现


对于db上热点数据的发现，首先会在一个周期内对Key进行请求统计，在达到请求量级后会对热点Key进行热点定位，并将所有的热点Key放入一个小的LRU链表内，在通过Proxy请求进行访问时，若Redis发现待访点是一个热点，就会进入一个反馈阶段，同时对该数据进行标记。

DB计算热点时，主要运用的方法和优势有：

基于统计阀值的热点统计

基于统计周期的热点统计

基于版本号实现的无需重置初值统计方法

DB 计算同时具有对性能影响极其微小、内存占用极其微小等优点

两种方案对比
通过上述对比分析可以看出，阿里云在解决热点Key上较传统方法相比都有较大的提高，无论是基于读写分离方案还是热点数据解决方案，在实际处理环境中都可以做灵活的水平能力扩充、都对客户端透明、都有一定的数据不一致性。此外读写分离模式可以存储更大量的热点数据，而基于Proxy的模式有成本上的优势

==================

JedisPool 资源池优化
更新时间：2018-12-03 15:09:22

编辑 ·
 · 我的收藏
本页目录
使用方法
参数说明
关键参数设置建议
常见问题
合理的 JedisPool 资源池参数设置能够有效地提升 Redis 性能。本文档将对 JedisPool 的使用和资源池的参数进行详细说明，并提供优化配置的建议。

使用方法
以 Jedis 2.9.0 为例，其 Maven 依赖如下：

<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
    <version>2.9.0</version>
    <scope>compile</scope>
</dependency>
Jedis 使用 Apache Commons-pool2 对资源池进行管理，在定义 JedisPool 时需注意其关键参数 GenericObjectPoolConfig（资源池）。该参数的使用示例如下，其中的参数的说明请参见下文。

GenericObjectPoolConfig jedisPoolConfig = new GenericObjectPoolConfig();
jedisPoolConfig.setMaxTotal(...);
jedisPoolConfig.setMaxIdle(...);
jedisPoolConfig.setMinIdle(...);
jedisPoolConfig.setMaxWaitMillis(...);
...
JedisPool 的初始化方法如下：

// redisHost为实例的IP， redisPort 为实例端口，redisPassword 为实例的密码，timeout 既是连接超时又是读写超时
JedisPool jedisPool = new JedisPool(jedisPoolConfig, redisHost, redisPort, timeout, redisPasswor//d);
//执命令如下
Jedis jedis = null;
try {
    jedis = jedisPool.getResource();
    //具体的命令
    jedis.executeCommand()
} catch (Exception e) {
    logger.error(e.getMessage(), e);
} finally {
    //在 JedisPool 模式下，Jedis 会被归还给资源池
    if (jedis != null)
        jedis.close();
}
参数说明
Jedis 连接就是连接池中 JedisPool 管理的资源， JedisPool 保证资源在一个可控范围内，并且保障线程安全。使用合理的 GenericObjectPoolConfig 配置能够提升 Redis 的服务性能，降低资源开销。下列两表将对一些重要参数进行说明，并提供设置建议。

表 1. 资源设置与使用相关参数
参数	说明	默认值	建议
maxTotal	资源池中的最大连接数	8	参见关键参数设置建议。
maxIdle	资源池允许的最大空闲连接数	8	参见关键参数设置建议。
minIdle	资源池确保的最少空闲连接数	0	参见关键参数设置建议。
blockWhenExhausted	当资源池用尽后，调用者是否要等待。只有当值为 true 时，下面的 maxWaitMillis 才会生效。	true	建议使用默认值。
maxWaitMillis	当资源池连接用尽后，调用者的最大等待时间（单位为毫秒）。	-1（表示永不超时）	不建议使用默认值。
testOnBorrow	向资源池借用连接时是否做连接有效性检测（ping）。检测到的无效连接将会被移除。	false	业务量很大时候建议设置为 false，减少一次 ping 的开销。
testOnReturn	向资源池归还连接时是否做连接有效性检测（ping）。检测到无效连接将会被移除。	false	业务量很大时候建议设置为 false，减少一次 ping 的开销。
jmxEnabled	是否开启 JMX 监控	true	建议开启，请注意应用本身也需要开启。
空闲 Jedis 对象检测由下列四个参数组合完成，testWhileIdle 是该功能的开关。

表 2. 空闲资源检测相关参数
名称	说明	默认值	建议
testWhileIdle	是否开启空闲资源检测。	false	true
timeBetweenEvictionRunsMillis	空闲资源的检测周期（单位为毫秒）	-1（不检测）	建议设置，周期自行选择，也可以默认也可以使用下方 JedisPoolConfig 中的配置。
minEvictableIdleTimeMillis	资源池中资源的最小空闲时间（单位为毫秒），达到此值后空闲资源将被移除。	180000（即30分钟）	可根据自身业务决定，一般默认值即可，也可以考虑使用下方 JeidsPoolConfig 中的配置。
numTestsPerEvictionRun	做空闲资源检测时，每次检测资源的个数。	3	可根据自身应用连接数进行微调，如果设置为 -1，就是对所有连接做空闲监测。
为了方便使用，Jedis 提供了 JedisPoolConfig ，它继承了 GenericObjectPoolConfig 在空闲检测上的一些设置。

public class JedisPoolConfig extends GenericObjectPoolConfig {
  public JedisPoolConfig() {
    // defaults to make your life with connection pool easier :)
    setTestWhileIdle(true);
    //
    setMinEvictableIdleTimeMillis(60000);
    //
    setTimeBetweenEvictionRunsMillis(30000);
    setNumTestsPerEvictionRun(-1);
    }
}
说明 可以在 org.apache.commons.pool2.impl.BaseObjectPoolConfig 中查看全部默认值。
关键参数设置建议
maxTotal（最大连接数）

想合理设置maxTotal（最大连接数）需要考虑的因素较多，如：

业务希望的 Redis 并发量；
客户端执行命令时间；
Redis资源，例如 nodes （如应用个数等） * maxTotal 不能超过 Redis 的最大连接数；
资源开销，例如虽然希望控制空闲连接，但又不希望因为连接池中频繁地释放和创建连接造成不必要的开销。
假设一次命令时间，即 borrow|return resource 加上 Jedis 执行命令 （ 含网络耗时）的平均耗时约为1ms，一个连接的 QPS 大约是1000，业务期望的 QPS 是50000，那么理论上需要的资源池大小是 50000 / 1000 = 50。

但事实上这只是个理论值，除此之外还要预留一些资源，所以 maxTotal 可以比理论值大一些。这个值不是越大越好，一方面连接太多会占用客户端和服务端资源，另一方面对于 Redis 这种高 QPS 的服务器，如果出现大命令的阻塞，即使设置再大的资源池也无济于事。

maxIdle 与 minIdle

maxIdle 实际上才是业务需要的最大连接数，maxTotal 是为了给出余量，所以 maxIdle 不要设置得过小，否则会有 new Jedis （新连接）开销，而 minIdle 是为了控制空闲资源检测。

连接池的最佳性能是 maxTotal = maxIdle ，这样就避免了连接池伸缩带来的性能干扰。但如果并发量不大或者 maxTotal 设置过高，则会导致不必要的连接资源浪费。

您可以根据实际总 QPS 和调用 Redis 的客户端规模整体评估每个节点所使用的连接池大小。

使用监控获取合理值

在实际环境中，比较可靠的方法是通过监控来尝试获取参数的最佳值。可以考虑通过 JMX 等方式实现监控，从而找到合理值。

常见问题
资源不足

下面两种情况均属于无法从资源池获取到资源。

超时：
redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool
…
Caused by: java.util.NoSuchElementException: Timeout waiting for idle object
at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:449)
blockWhenExhausted 为 false ，因此不会等待资源释放：

redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool
…
Caused by: java.util.NoSuchElementException: Pool exhausted
at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:464)
此类异常的原因不一定是资源池不够大，请参见关键参数设置建议中的分析。建议从网络、资源池参数设置、资源池监控（如果对 JMX 监控）、代码（例如没执行jedis.close()）、慢查询、DNS等方面进行排查。

预热 JedisPool

由于一些原因（如超时时间设置较小等），项目在启动成功后可能会出现超时。 JedisPool 定义最大资源数、最小空闲资源数时，不会在连接池中创建 Jedis 连接。初次使用时，池中没有资源使用则会先 new Jedis ，使用后再放入资源池，该过程会有一定的时间开销，所以建议在定义 JedisPool 后，以最小空闲数量为基准对 JedisPool 进行预热，示例如下：

List<Jedis> minIdleJedisList = new ArrayList<Jedis>(jedisPoolConfig.getMinIdle());

for (int i = 0; i < jedisPoolConfig.getMinIdle(); i++) {
    Jedis jedis = null;
    try {
        jedis = pool.getResource();
        minIdleJedisList.add(jedis);
        jedis.ping();
    } catch (Exception e) {
        logger.error(e.getMessage(), e);
    } finally {
    }
}

for (int i = 0; i < jedisPoolConfig.getMinIdle(); i++) {
    Jedis jedis = null;
    try {
        jedis = minIdleJedisList.get(i);
        jedis.close();
    } catch (Exception e) {
        logger.error(e.getMessage(), e);
    } finally {

    }
}

=========
Redis 4.0 热点Key查询方法

高性能是Redis最大的特点，保障Redis的性能是Redis使用过程中的必要举措。可能导致Redis性能问题的因素各种各样，而热点Key是其中最常见的因素之一。找出热点Key有利于进一步处理问题，本文介绍利用Redis 4.0版本新增特性查询热点Key的方法。

背景信息
Redis 4.0新增了allkey-lfu和volatile-lfu两种数据逐出策略，同时还可以通过OBJECT命令来获取某个key的访问频度，如下图所示。


Redis 原生客户端也增加了--hotkeys选项，可以快速帮您找出业务中的热点Key。

说明 本文旨在介绍热点Key发现方法，从而优化Redis的性能，因此适用于已经拥有一定的云数据库Redis版使用基础，且在寻求进阶技巧的用户。如果您刚开始接触Redis，建议先阅读产品简介和快速入门。
前提条件
拥有与Redis实例互通的ECS实例；
ECS中已经安装了Redis 4.0以上版本；
说明 目的为使用其自带的工具redis-cli。
云数据库Redis版实例的maxmemory-policy参数设置为volatile-lfu或allkeys-lfu。
说明 参数修改的方法请参见参数设置。
操作步骤
在有业务进行时，使用以下命令查询热点Key。
redis-cli -h r-***************.redis.rds.aliyuncs.com -a <password> --hotkeys
说明 本文使用redis-benchmark模拟业务中大量写入的场景。
表 1. 选项说明
名称	说明
-h	指定Redis的连接地址。
-a	指定Redis的认证密码。
--hotkeys	用来查询热点Key。
执行结果
执行命令后得到的结果示例如下：


执行结果的summary部分即是分析得出的热点Key

=====================

解密 Redis 助力双十一背后的技术
更新时间：2019-01-23 00:50:34

编辑 ·
 · 我的收藏
本页目录
背景介绍
微淘社区之亿级关系链存储
天猫直播之评论商品游标分页
菜鸟单据履行中心之订单排序
背景介绍
双十一如火如荼，云数据库 Redis 版也圆满完成了双十一的保障工作。目前云数据库 Redis 版提供了标准单副本、标准双副本和集群版本。

标准单副本和标准双副本 Redis 具有很高的兼容性，并且支持 Lua 脚本及地理位置计算。集群版本具有大容量、高性能的特性，能够突破 Redis 单线程的单机性能极限。

云数据库 Redis 版默认双机热备并提供了备份恢复支持，同时阿里云 Redis 源码团队持续对 Redis 进行优化升级，提供了强大的安全防护能力。本文将选取双十一的一些业务场景简化之后进行介绍，实际业务场景会比本文复杂。

微淘社区之亿级关系链存储
微淘社区承载了亿级淘宝用户的社交关系链，每个用户都有自己的关注列表，每个商家有自己的粉丝信息，整个微淘社区承载的关系链如下图所示。


如果选用传统的关系型数据库模型表达如上的关系信息，会使业务设计繁杂，并且不能获得良好的性能体验。微淘社区使用 Redis 集群缓存存储社区的关注链，简化了关注信息的存储，并保证了双十一业务丝滑一般的体验。微淘社区使用了 Hashes 存储用户之间的关注信息，存储结构如下，并提供了以下两种的查询接口：

用户 A 是否和用户 B 产生过关注关系
用户 A 的主动关系列表

天猫直播之评论商品游标分页
双十一用户在观看无线端直播的时候，需要对直播对应的评论进行刷新动作，主要有以下三种模式:

增量下拉：从指定位置向上获取指定个数（增量）的评论。
下拉刷新：获取最新的指定个数的评论。
增量上拉：从指定位置向下获取指定个数（增量）的评论。
无线直播系统使用 Redis 优化该场景的业务，保证了直播评论接口的成功率，并能够保证5万以上的 TPS 和毫秒级的 response time 请求。直播系统对于每个直播会写入两份数据，分别为索引和评论数据，索引数据为 SortedSet 的数据结构用于对评论的排序，而评论数据使用 Hashes 进行存储，在获取评论的时候通过索引拿到需要的索引 id 之后通过 Hashes 的读取来获得评论的列表。评论的写入过程如下：


用户在刷新列表之后后台需要获取对应的评论信息，获取的流程如下：

获取当前索引位置
获取索引列表
获取评论数据

菜鸟单据履行中心之订单排序
双十一用户在产生一个交易订单之后会随之产生一个物流订单，需要经过菜鸟仓配系统处理。为了让仓配各个阶段能够更加智能的协同作业，决策系统会根据订单信息指定出对应的订单履行计划，包括什么时候下发仓、什么时候出库、什么时候配送揽收、什么时候送达等信息。单据履行中心根据履行计划，对每个阶段按照对应的时间去履行物流服务。由于仓、配的运力有限，对于有限的运力下，期望最早作业的单据是业务认为优先级最高的单据，所以订单在真正下发给仓或者配之前，需要按照优先级进行排序。

订单履行中心通过使用 Redis 来对所有的物流订单进行排序决定哪个订单是最高优先级的。

Redis 内存分析方法
KB: 50037 ·
更新时间：2018-04-24 12:46:05


本页目录
背景
创建备份
生成内存快照
redis-rdb-tools 安装
使用 redis-rdb-tools 生成内存快照
分析内存快照
总结
背景
线上经常遇到用户想知道自己 Redis 实例中数据的内存分布情况。为了不影响线上实例的使用，我们一般会采用 bgsave 生成 dump.rdb 文件，再结合 redis-rdb-tools 和 sqlite 来进行静态分析。总的来说，整个分析的过程简单而实用，是每一个 Redis 的用户都非常值得掌握的一个方法。

创建备份
自建 Redis 可在客户端执行 bgsave 生成 rdb 文件。云数据库 Redis 版可以在控制台上可以进行数据备份和下载的操作，下载后的数据为 rdb 格式文件。步骤详见下图：



生成内存快照
redis-rdb-tools 是一个 python 的解析 rdb 文件的工具，在分析内存的时候，我们主要用它生成内存快照。主要有以下三个功能：

生成内存快照
转储成 json 格式
使用标准的 diff 工具比较两个 dump 文件
redis-rdb-tools 安装
redis-rdb-tools 有两种安装方式，任选其一即可。

使用 PYPI 安装

pip install rdbtools
从源码安装

git clone https://github.com/sripathikrishnan/redis-rdb-tools
cd redis-rdb-tools
sudo python setup.py install
使用 redis-rdb-tools 生成内存快照
生成内存快照的命令为：

rdb -c memory dump.rdb > memory.csv
生成 CSV 格式的内存报告。包含的列有：数据库 ID，数据类型，key，内存使用量(byte)，编码。内存使用量包含 key、value 和其他值。

注意：内存使用量是理论上的近似值，在一般情况下，略低于实际值。memory.csv 例子：

$head memory.csv
database,type,key,size_in_bytes,encoding,num_elements,len_largest_element
0,string,"orderAt:377671748",96,string,8,8
0,string,"orderAt:413052773",96,string,8,8
0,sortedset,"Artical:Comments:7386",81740,skiplist,479,41
0,sortedset,"pay:id:18029",2443,ziplist,84,16
0,string,"orderAt:452389458",96,string,8,8
分析内存快照
SQLite 是一款轻型的数据库。我们可以将前面生成的 csv 导入到数据库中之后，就可以利用 sql 语句很方便的对 Redis 的内存数据进行各种分析了。

注意：SQLite版本必须是3.16.0以上。

导入方法

sqlite3 memory.db
sqlite> create table memory(database int,type varchar(128),key varchar(128),size_in_bytes int,encoding varchar(128),num_elements int,len_largest_element varchar(128));
sqlite>.mode csv memory
sqlite>.import memory.csv memory
数据导入以后，接下来想怎么分析就怎么分析了，举几个简单的例子：

查询key个数

sqlite>select count(*) from memory;
查询总的内存占用

sqlite>select sum(size_in_bytes) from memory;
查询内存占用最高的10个 key

sqlite>select * from memory order by size_in_bytes desc limit 10;
查询成员个数1000个以上的 list

sqlite>select * from memory where type='list' and num_elements > 1000 ;
总结
通过使用 redis-rdb-tools + sqlite 的方式，可以方便的对 redis 实例的内存情况进行静态的分析。整个过程也比较简单，获取到 rdb 之后即可。

rdb -c memory dump.rdb > memory.csv;
sqlite3 memory.db
sqlite> create table memory(database int,type varchar(128),key varchar(128),size_in_bytes int,encoding varchar(128),num_elements int,len_largest_element varchar(128));
sqlite>.mode csv memory
sqlite>.import memory.csv memory
实际使用中，发现过一个 List 积攒了10多 GB 的内容，也发现过43 MB 以上的 string 类型的 value， 往往不仅能解答用户的疑惑，而且能够帮助用户排除业务中潜在的风险点，找到业务性能瓶颈。





解析Redis持久化的AOF文件
更新时间：2018-12-13 17:36:30

编辑 ·
 · 我的收藏
本页目录
背景信息
Redis持久化模式
AOF持久化模式的详细说明
AOF文件解析
背景信息
在日常开发测试中，为了方便查看历史命令和查看某个Key的记录，需要对AOF文件进行解析。

Redis持久化模式
RDB 快照模式：该模式用于生成某个时间点的备份信息，并且会对当前的Key value进行编码，然后存储在rdb文件中。
AOF 持久化模式：该模式类似binlog的形式，会记录服务器所有的写请求，在服务重启时用于恢复原有的数据。
AOF持久化模式的详细说明
Redis客户端和服务端之间通过RESP (REdis Serialization Protocol)进行通信。RESP协议主要由以下几种数据类型组成，每种数据类型的定义如下：

简单字符串：
以+号开头，结尾为rn，比如：+OKrn。

错误信息：
以-号开头，结尾为rn的字符串，比如：-ERR Readonlyrn。

整数：
以冒号开头，结尾为rn，开头和结尾之间为整数，比如（:1rn）。

大字符串：
以$开头，随后为该字符串长度和rn，长度限制512M，最后为字符串内容和rn，比如：$0rnrn。

数组：
以*开头，随后指定数组元素个数并通过rn划分，每个数组元素都可以为上面的四种，比如：*1rn$4rnpingrn。

Redis客户端发送给服务端的是一个数组命令，服务端根据不同命令的实现方式进行回复，并记录到AOF文件中。

AOF文件解析
这里通过Python代码调用hiredis库来进行Redis AOF文件的解析，代码如下：

#!/usr/bin/env python

""" A redis appendonly file parser
"""

import logging
import hiredis
import sys

if len(sys.argv) != 2:
   print sys.argv[0], 'AOF_file'
   sys.exit()
file = open(sys.argv[1])
line = file.readline()
cur_request = line
while line:
    req_reader = hiredis.Reader()
    req_reader.setmaxbuf(0)
    req_reader.feed(cur_request)
    command = req_reader.gets()
    try:
        if command is not False:
            print command
            cur_request = ''
    except hiredis.ProtocolError:
        print 'protocol error'
    line = file.readline()
    cur_request += line
file.close
使用以上脚本解析一个AOF文件的结果如下。得到如下结果后方便您随时查看某个Key相关的操作。

['PEXPIREAT', 'RedisTestLog', '1479541381558']
['SET', 'RedisTestLog', '39124268']
['PEXPIREAT', 'RedisTestLog', '1479973381559']
['HSET', 'RedisTestLogHash', 'RedisHashField', '16']
['PEXPIREAT', 'RedisTestLogHash', '1479973381561']
['SET', 'RedisTestLogString', '79146']

=========
==========


Redis读写分离技术解析
更新时间：2019-03-05 09:45:42

编辑 ·
 · 我的收藏
本页目录
背景
架构
Redis读写分离优势
背景
云数据库Redis版不管主从版还是集群规格，replica作为备库不对外提供服务，只有在发生HA的时候，replica提升为master后才承担读写流量。这种架构读写请求都在master上完成，一致性较高，但性能受到master数量的限制。经常有用户数据较少，但因为流量或者并发太高而不得不升级到更大的集群规格。

为满足读多写少的业务场景，最大化节约用户成本，云数据库Redis版推出了读写分离规格，为用户提供透明、高可用、高性能、高灵活的读写分离服务。

架构
Redis集群模式有redis-proxy、master、replica、HA等几个角色。在读写分离实例中，新增read-only replica角色来承担读流量，replica作为热备不提供服务，架构上保持对现有集群规格的兼容性。redis-proxy按权重将读写请求转发到master或者某个read-only replica上；HA负责监控DB节点的健康状态，异常时发起主从切换或重搭read-only replica，并更新路由。

一般来说，根据master和read-only replica的数据同步方式，可以分为两种架构：星型复制和链式复制。

星型复制

星型复制就是将所有的read-only replica直接和master保持同步，每个read-only replica之间相互独立，任何一个节点异常不影响到其他节点，同时因为复制链比较短，read-only replica上的复制延迟比较小。

Redis是单进程单线程模型，主从之间的数据复制也在主线程中处理，read-only replica数量越多，数据同步对master的CPU消耗就越严重，集群的写入性能会随着read-only replica的增加而降低。此外，星型架构会让master的出口带宽随着read-only replica的增加而成倍增长。Master上较高的CPU和网络负载会抵消掉星型复制延迟较低的优势，因此，星型复制架构会带来比较严重的扩展问题，整个集群的性能会受限于master。


链式复制

链式复制将所有的read-only replica组织成一个复制链，如下图所示，master只需要将数据同步给replica和复制链上的第一个read-only replica。

链式复制解决了星型复制的扩展问题，理论上可以无限增加read-only replica的数量，随着节点的增加整个集群的性能也可以基本上呈线性增长。

链式复制的架构下，复制链越长，复制链末端的read-only replica和master之间的同步延迟就越大，考虑到读写分离主要使用在对一致性要求不高的场景下，这个缺点一般可以接受。但是如果复制链中的某个节点异常，会导致下游的所有节点数据都会大幅滞后。更加严重的是这可能带来全量同步，并且全量同步将一直传递到复制链的末端，这会对服务带来一定的影响。为了解决这个问题，读写分离的Redis都使用阿里云优化后的binlog复制版本，最大程度的降低全量同步的概率。


结合上述的讨论和比较，Redis读写分离选择链式复制的架构。

Redis读写分离优势
透明兼容

读写分离和普通集群规格一样，都使用了redis-proxy做请求转发，多分片令使用存在一定的限制，但从主从升级单分片读写分离，或者从集群升级到多分片的读写分离集群可以做到完全兼容。

用户和redis-proxy建立连接，redis-proxy会识别出客户端连接发送过来的请求是读还是写，然后按照权重作负载均衡，将请求转发到后端不同的DB节点中，写请求转发给master，读操作转发给read-only replica（master默认也提供读，可以通过权重控制）。

用户只需要购买读写分离规格的实例，直接使用任何客户端即可直接使用，业务不用做任何修改就可以开始享受读写分离服务带来的巨大性能提升，接入成本几乎为0。

高可用

高可用模块（HA）监控所有DB节点的健康状态，为整个实例的可用性保驾护航。master宕机时自动切换到新主。如果某个read-only replica宕机，HA也能及时感知，然后重搭一个新的read-only replica，下线宕机节点。

除HA之外，redis-proxy也能实时感知每个read-only replica的状态。在某个read-only replica异常期间，redis-proxy会自动降低这个节点的权重，如果发现某个read-only replica连续失败超过一定次数以后，会暂时屏蔽异常节点，直到异常消失以后才会恢复其正常权重。

redis-proxy和HA一起做到尽量减少业务对后端异常的感知，提高服务可用性。

高性能

对于读多写少的业务场景，直接使用集群版本往往不是最合适的方案，现在读写分离提供了更多的选择，业务可以根据场景选择最适合的规格，充分利用每一个read-only replica的资源。

目前单shard对外售卖1 master + 1/3/5 read-only replica多种规格（如果有更大的需求可以提工单反馈），提供60万QPS和192 MB/s的服务能力，在完全兼容所有命令的情况下突破单机的资源限制。后续将去掉规格限制，让用户根据业务流量随时自由的增加或减少read-only replica数量。

规格	QPS	带宽
1 master	8-10万读写	10-48 MB
1 master + 1 read-only replica	10万写 + 10万读	20-64 MB
1 master + 3 read-only replica	10万写 + 30万读	40-128 MB
1 master + 5 read-only replica	10万写 + 50万读	60-192 MB
后续

Redis主从异步复制，从read-only replica中可能读到旧的数据，使用读写分离需要业务可以容忍一定程度的数据不一致，后续将会给客户更灵活的配置和更大的自由，比如配置可以容忍的最大延迟时间。


===============
使用 Redis 搭建视频直播间信息系统
更新时间：2018-12-10 10:07:28

编辑 ·
 · 我的收藏
本页目录
背景信息
实时排行类信息
计数类信息
时间线信息
相关资源
您可以使用云数据库 Redis 版方便快捷地构建大流量、低延迟的视频直播间消息服务。

背景信息
视频直播间作为直播系统对外的表现形式，是整个系统的核心之一。除了视频直播窗口外，直播间的在线用户、礼物、评论、点赞、排行榜等数据信息时效性高，互动性强，对系统时延有着非常高的要求，非常适合使用 Redis 缓存服务来处理。

本篇最佳实践将向您展示使用云数据库 Redis 版搭建视频直播间信息系统的示例。您将了解三类信息的构建方法：

实时排行类信息
计数类信息
时间线信息
实时排行类信息
实时排行类信息包含直播间在线用户列表、各种礼物的排行榜、弹幕消息（类似于按消息维度排序的的消息排行榜）等，适合使用 Redis 中的有序集合（sorted set）结构进行存储。

Redis 集合使用空值散列表（hash table）实现，因此对集合的增删改查操作的时间复杂度都是O（1）。有序集合中的每个成员都关联一个分数（score），可以方便地实现排序等操作。下面以增加和返回弹幕消息为例对有序集合在直播间信息系统中的实际运用进行说明。

以 unix timestamp + 毫秒数为分值，记录 user55 的直播间增加的5条弹幕：
redis> ZADD user55:_danmu 1523959031601166 message111111111111
(integer) 1
11.160.24.14:3003> ZADD user55:_danmu 1523959031601266 message222222222222
(integer) 1
11.160.24.14:3003> ZADD user55:_danmu 1523959088894232 message33333
(integer) 1
11.160.24.14:3003> ZADD user55:_danmu 1523959090390160 message444444
(integer) 1
11.160.24.14:3003> ZADD user55:_danmu 1523959092951218 message5555
(integer) 1
返回最新的3条弹幕信息：
redis> ZREVRANGEBYSCORE user55:_danmu +inf -inf LIMIT 0 3
1) "message5555"
2) "message444444"
3) "message33333"
返回指定时间段内的3条弹幕信息：
redis> ZREVRANGEBYSCORE user55:_danmu 1523959088894232 -inf LIMIT 0 3
1) "message33333"
2) "message222222222222"
3) "message111111111111"
计数类信息
计数类信息以用户相关数据为例，有未读消息数、关注数、粉丝数、经验值等等。这类消息适合以Redis中的散列（hash）结构进行存储。比如关注数可以用如下的方法处理：

redis> HSET user:55 follower 5
(integer) 1
redis> HINCRBY user:55 follower 1 //关注数+1
(integer) 6
redis> HGETALL user:55
1) "follow"
2) "6"
时间线信息
时间线信息是以时间为维度的信息列表，典型有主播动态、新帖等。这类信息是按照固定的时间顺序排列，可以使用列表（list）或者有序列表来存储，请参考以下示例。

redis> LPUSH user:55_recent_activitiy  '{datetime:201804112010,type:publish,title:开播啦,content:加油}'
(integer) 1
redis> LPUSH user:55_recent_activitiy '{datetime:201804131910,type:publish,title:请假,content:抱歉，今天有事鸽一天}'
(integer) 2
redis> LRANGE user:55_recent_activitiy 0 10
1) "{datetime:201804131910,type:publish,title:\xe8\xaf\xb7\xe5\x81\x87\",content:\xe6\x8a\xb1\xe6\xad\x89\xef\xbc\x8c\xe4\xbb\x8a\xe5\xa4\xa9\xe6\x9c\x89\xe4\xba\x8b\xe9\xb8\xbd\xe4\xb8\x80\xe5\xa4\xa9}"
2) "{datetime:201804112010,type:publish,title:\xe5\xbc\x80\xe6\x92\xad\xe5\x95\xa6,content:\xe5\x8a\xa0\xe6\xb2\xb9}"
相关资源
直播系统常见的热点 Key 问题的解决方法请参见热点 Key 问题的发现与解决。
使用Redis 内存分析方法排除业务中潜在的风险点，找到业务性能瓶颈。
云数据库 Redis 集群版助您解决高并发问题。


==========

Redis 内存分析方法

本页目录
背景
创建备份
生成内存快照
redis-rdb-tools 安装
使用 redis-rdb-tools 生成内存快照
分析内存快照
总结
背景
线上经常遇到用户想知道自己 Redis 实例中数据的内存分布情况。为了不影响线上实例的使用，我们一般会采用 bgsave 生成 dump.rdb 文件，再结合 redis-rdb-tools 和 sqlite 来进行静态分析。总的来说，整个分析的过程简单而实用，是每一个 Redis 的用户都非常值得掌握的一个方法。

创建备份
自建 Redis 可在客户端执行 bgsave 生成 rdb 文件。云数据库 Redis 版可以在控制台上可以进行数据备份和下载的操作，下载后的数据为 rdb 格式文件。步骤详见下图：



生成内存快照
redis-rdb-tools 是一个 python 的解析 rdb 文件的工具，在分析内存的时候，我们主要用它生成内存快照。主要有以下三个功能：

生成内存快照
转储成 json 格式
使用标准的 diff 工具比较两个 dump 文件
redis-rdb-tools 安装
redis-rdb-tools 有两种安装方式，任选其一即可。

使用 PYPI 安装

pip install rdbtools
从源码安装

git clone https://github.com/sripathikrishnan/redis-rdb-tools
cd redis-rdb-tools
sudo python setup.py install
使用 redis-rdb-tools 生成内存快照
生成内存快照的命令为：

rdb -c memory dump.rdb > memory.csv
生成 CSV 格式的内存报告。包含的列有：数据库 ID，数据类型，key，内存使用量(byte)，编码。内存使用量包含 key、value 和其他值。

注意：内存使用量是理论上的近似值，在一般情况下，略低于实际值。memory.csv 例子：

$head memory.csv
database,type,key,size_in_bytes,encoding,num_elements,len_largest_element
0,string,"orderAt:377671748",96,string,8,8
0,string,"orderAt:413052773",96,string,8,8
0,sortedset,"Artical:Comments:7386",81740,skiplist,479,41
0,sortedset,"pay:id:18029",2443,ziplist,84,16
0,string,"orderAt:452389458",96,string,8,8
分析内存快照
SQLite 是一款轻型的数据库。我们可以将前面生成的 csv 导入到数据库中之后，就可以利用 sql 语句很方便的对 Redis 的内存数据进行各种分析了。

注意：SQLite版本必须是3.16.0以上。

导入方法

sqlite3 memory.db
sqlite> create table memory(database int,type varchar(128),key varchar(128),size_in_bytes int,encoding varchar(128),num_elements int,len_largest_element varchar(128));
sqlite>.mode csv memory
sqlite>.import memory.csv memory
数据导入以后，接下来想怎么分析就怎么分析了，举几个简单的例子：

查询key个数

sqlite>select count(*) from memory;
查询总的内存占用

sqlite>select sum(size_in_bytes) from memory;
查询内存占用最高的10个 key

sqlite>select * from memory order by size_in_bytes desc limit 10;
查询成员个数1000个以上的 list

sqlite>select * from memory where type='list' and num_elements > 1000 ;
总结
通过使用 redis-rdb-tools + sqlite 的方式，可以方便的对 redis 实例的内存情况进行静态的分析。整个过程也比较简单，获取到 rdb 之后即可。

rdb -c memory dump.rdb > memory.csv;
sqlite3 memory.db
sqlite> create table memory(database int,type varchar(128),key varchar(128),size_in_bytes int,encoding varchar(128),num_elements int,len_largest_element varchar(128));
sqlite>.mode csv memory
sqlite>.import memory.csv memory
实际使用中，发现过一个 List 积攒了10多 GB 的内容，也发现过43 MB 以上的 string 类型的 value， 往往不仅能解答用户的疑惑，而且能够帮助用户排除业务中潜在的风险点，找到业务性能瓶颈。

-----------------

集群实例特定子节点中热点Key的分析方法
更新时间：2018-12-06 09:56:33

编辑 ·
 · 我的收藏
本页目录
背景信息
前提条件
操作步骤
您可以使用阿里云自研的 imonitor 命令监控 Redis 集群中某一节点的请求状态，并利用请求解析工具 redis-faina 快速地从监控数据中分析出热点 Key 和命令。

背景信息
在使用云数据库 Redis 集群版的过程中，如果某一节点上的热点 Key 流量过大，可能导致服务器中其它服务无法进行。若热点 Key 的缓存超过当前的缓存容量，就会产生缓存分片服务负载过高，进而造成缓存雪崩等严重问题。

您可以利用云数据库 Redis 版的性能监控和报警规则对集群状况进行实时监控并设置告警，在发现特定子节点负载突出时，使用 imonitor 命令查看该节点的客户端请求，并使用 redis-faina 分析出热点 Key 。

前提条件
已部署与云数据库 Redis 集群版互通的 ECS 实例。
ECS 实例中已安装 Python 和 Telnet。
说明 本文中的示例环境使用 CentOS 7.4 系统和 Python 2.7.5。
操作步骤
在 ECS 实例中，以 Telnet 方式连接到 Redis 集群。
使用# telnet <host> <port>连接到 Redis 集群。
说明 host为 Redis 集群的连接地址， port为连接端口（默认为6379）。
输入auth <password>进行认证。
说明 password为 Redis 集群的密码。

说明 返回 +OK表示连接成功。
使用imonitor <db_idx>收集目的节点的请求数据。

说明
imonitor 命令与 iinfo、 iscan 类似，在 monitor 命令的基础上新增了一个参数，用户指定 monitor 执行的节点（db_idx），db_idx 的范围是 [0, nodecount)， nodecount 可以通过 info 命令获取，或者从控制台上的实例拓扑图中查看。

本例中目的节点的 db_idx 为 0 。

返回+OK后将会持续输出监控到的请求记录。

根据需要收集一定数量的监控数据，之后输入 QUIT 命令并按 Enter 关闭 Telnet 连接。
将监控数据保存到一个 .txt 文件中，删除行首的 “+”（可在文本编辑工具中使用全部替换的方式）删除。保存的文件如下。

创建进行请求分析的 Python 脚本，保存为 redis-faina.py 。代码如下。
#! /usr/bin/env python
import argparse
import sys
from collections import defaultdict
import re

line_re_24 = re.compile(r"""
    ^(?P<timestamp>[\d\.]+)\s(\(db\s(?P<db>\d+)\)\s)?"(?P<command>\w+)"(\s"(?P<key>[^(?<!\\)"]+)(?<!\\)")?(\s(?P<args>.+))?$
    """, re.VERBOSE)

line_re_26 = re.compile(r"""
    ^(?P<timestamp>[\d\.]+)\s\[(?P<db>\d+)\s\d+\.\d+\.\d+\.\d+:\d+]\s"(?P<command>\w+)"(\s"(?P<key>[^(?<!\\)"]+)(?<!\\)")?(\s(?P<args>.+))?$
    """, re.VERBOSE)

class StatCounter(object):

    def __init__(self, prefix_delim=':', redis_version=2.6):
        self.line_count = 0
        self.skipped_lines = 0
        self.commands = defaultdict(int)
        self.keys = defaultdict(int)
        self.prefixes = defaultdict(int)
        self.times = []
        self._cached_sorts = {}
        self.start_ts = None
        self.last_ts = None
        self.last_entry = None
        self.prefix_delim = prefix_delim
        self.redis_version = redis_version
        self.line_re = line_re_24 if self.redis_version < 2.5 else line_re_26

    def _record_duration(self, entry):
        ts = float(entry['timestamp']) * 1000 * 1000 # microseconds
        if not self.start_ts:
            self.start_ts = ts
            self.last_ts = ts
        duration = ts - self.last_ts
        if self.redis_version < 2.5:
            cur_entry = entry
        else:
            cur_entry = self.last_entry
            self.last_entry = entry
        if duration and cur_entry:
            self.times.append((duration, cur_entry))
        self.last_ts = ts

    def _record_command(self, entry):
        self.commands[entry['command']] += 1

    def _record_key(self, key):
        self.keys[key] += 1
        parts = key.split(self.prefix_delim)
        if len(parts) > 1:
            self.prefixes[parts[0]] += 1

    @staticmethod
    def _reformat_entry(entry):
        max_args_to_show = 5
        output = '"%(command)s"' % entry
        if entry['key']:
            output += ' "%(key)s"' % entry
        if entry['args']:
            arg_parts = entry['args'].split(' ')
            ellipses = ' ...' if len(arg_parts) > max_args_to_show else ''
            output += ' %s%s' % (' '.join(arg_parts[0:max_args_to_show]), ellipses)
        return output


    def _get_or_sort_list(self, ls):
        key = id(ls)
        if not key in self._cached_sorts:
            sorted_items = sorted(ls)
            self._cached_sorts[key] = sorted_items
        return self._cached_sorts[key]

    def _time_stats(self, times):
        sorted_times = self._get_or_sort_list(times)
        num_times = len(sorted_times)
        percent_50 = sorted_times[int(num_times / 2)][0]
        percent_75 = sorted_times[int(num_times * .75)][0]
        percent_90 = sorted_times[int(num_times * .90)][0]
        percent_99 = sorted_times[int(num_times * .99)][0]
        return (("Median", percent_50),
                ("75%", percent_75),
                ("90%", percent_90),
                ("99%", percent_99))

    def _heaviest_commands(self, times):
        times_by_command = defaultdict(int)
        for time, entry in times:
            times_by_command[entry['command']] += time
        return self._top_n(times_by_command)

    def _slowest_commands(self, times, n=8):
        sorted_times = self._get_or_sort_list(times)
        slowest_commands = reversed(sorted_times[-n:])
        printable_commands = [(str(time), self._reformat_entry(entry)) \
                              for time, entry in slowest_commands]
        return printable_commands

    def _general_stats(self):
        total_time = (self.last_ts - self.start_ts) / (1000*1000)
        return (
            ("Lines Processed", self.line_count),
            ("Commands/Sec", '%.2f' % (self.line_count / total_time))
        )

    def process_entry(self, entry):
        self._record_duration(entry)
        self._record_command(entry)
        if entry['key']:
            self._record_key(entry['key'])

    def _top_n(self, stat, n=8):
        sorted_items = sorted(stat.iteritems(), key = lambda x: x[1], reverse = True)
        return sorted_items[:n]

    def _pretty_print(self, result, title, percentages=False):
        print title
        print '=' * 40
        if not result:
            print 'n/a\n'
            return

        max_key_len = max((len(x[0]) for x in result))
        max_val_len = max((len(str(x[1])) for x in result))
        for key, val in result:
            key_padding = max(max_key_len - len(key), 0) * ' '
            if percentages:
                val_padding = max(max_val_len - len(str(val)), 0) * ' '
                val = '%s%s\t(%.2f%%)' % (val, val_padding, (float(val) / self.line_count) * 100)
            print key,key_padding,'\t',val
        print


    def print_stats(self):
        self._pretty_print(self._general_stats(), 'Overall Stats')
        self._pretty_print(self._top_n(self.prefixes), 'Top Prefixes', percentages = True)
        self._pretty_print(self._top_n(self.keys), 'Top Keys', percentages = True)
        self._pretty_print(self._top_n(self.commands), 'Top Commands', percentages = True)
        self._pretty_print(self._time_stats(self.times), 'Command Time (microsecs)')
        self._pretty_print(self._heaviest_commands(self.times), 'Heaviest Commands (microsecs)')
        self._pretty_print(self._slowest_commands(self.times), 'Slowest Calls')

    def process_input(self, input):
        for line in input:
            self.line_count += 1
            line = line.strip()
            match = self.line_re.match(line)
            if not match:
                if line != "OK":
                    self.skipped_lines += 1
                continue
            self.process_entry(match.groupdict())

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        'input',
        type = argparse.FileType('r'),
        default = sys.stdin,
        nargs = '?',
        help = "File to parse; will read from stdin otherwise")
    parser.add_argument(
        '--prefix-delimiter',
        type = str,
        default = ':',
        help = "String to split on for delimiting prefix and rest of key",
        required = False)
    parser.add_argument(
        '--redis-version',
        type = float,
        default = 2.6,
        help = "Version of the redis server being monitored",
        required = False)
    args = parser.parse_args()
    counter = StatCounter(prefix_delim = args.prefix_delimiter, redis_version = args.redis_version)
    counter.process_input(args.input)
    counter.print_stats()
说明 以上脚本来自 redis-faina。
使用python redis-faina imonitorOut.txt命令解析监控数据。其中imonitorOut.txt为本文示例中保存的监控数据。
说明 在以上分析结果中， Top Keys 显示该时间段内请求次数最多的键， Top Commands 显示使用最频繁的命令。您可以根据分析情况解决热点 Key 问题。

==============

先看一下Redis是一个什么东西。官方简介解释到：Redis是一个基于BSD开源的项目，是一个把结构化的数据放在内存中的一个存储系统，你可以把它作为数据库，缓存和消息中间件来使用。同时支持strings，lists，hashes，sets，sorted sets，bitmaps，hyperloglogs和geospatial indexes等数据类型。它还内建了复制，lua脚本，LRU，事务等功能，通过redis sentinel实现高可用，通过redis cluster实现了自动分片。以及事务，发布/订阅，自动故障转移等等。

综上所述，Redis提供了丰富的功能，初次见到可能会感觉眼花缭乱，这些功能都是干嘛用的？都解决了什么问题？什么情况下才会用到相应的功能？那么下面从零开始，一步一步的演进来粗略的解释下。

1 从零开始
最初的需求非常简单，我们有一个提供热点新闻列表的api：http://api.xxx.com/hot-news，api的消费者抱怨说每次请求都要2秒左右才能返回结果。

随后我们就着手于如何提升一下api消费者感知的性能，很快最简单粗暴的第一个方案就出来了：为API的响应加上基于HTTP的缓存控制 cache-control:max-age=600 ，即让消费者可以缓存这个响应十分钟。如果api消费者如果有效的利用了响应中的缓存控制信息，则可以有效的改善其感知的性能（10分钟以内）。但是还有2个弊端：第一个是在缓存生效的10分钟内，api消费者可能会得到旧的数据；第二个是如果api的客户端无视缓存直接访问API依然是需要2秒，治标不治本呐。

2 基于本机内存的缓存
为了解决调用API依然需要2秒的问题，经过排查，其主要原因在于使用SQL获取热点新闻的过程中消耗了将近2秒的时间，于是乎，我们又想到了一个简单粗暴的解决方案，即把SQL查询的结果直接缓存在当前api服务器的内存中（设置缓存有效时间为1分钟）。后续1分钟内的请求直接读缓存，不再花费2秒去执行SQL了。假如这个api每秒接收到的请求时100个，那么一分钟就是6000个，也就是只有前2秒拥挤过来的请求会耗时2秒，后续的58秒中的所有请求都可以做到即使响应，而无需再等2秒的时间。

其他API的小伙伴发现这是个好办法，于是很快我们就发现API服务器的内存要爆满了。。。

3 服务端的Redis
在API服务器的内存都被缓存塞满的时候，我们发现不得不另想解决方案了。最直接的想法就是我们把这些缓存都丢到一个专门的服务器上吧，把它的内存配置的大大的。然后我们就盯上了redis。。。至于如何配置部署redis这里不解释了，redis官方有详细的介绍。随后我们就用上了一台单独的服务器作为Redis的服务器，API服务器的内存压力得以解决。

3.1 持久化（Persistence）
单台的Redis服务器一个月总有那么几天心情不好，心情不好就罢工了，导致所有的缓存都丢失了（redis的数据是存储在内存的嘛）。虽然可以把Redis服务器重新上线，但是由于内存的数据丢失，造成了缓存雪崩，API服务器和数据库的压力还是一下子就上来了。所以这个时候Redis的持久化功能就派上用场了，可以缓解一下缓存雪崩带来的影响。redis的持久化指的是redis会把内存的中的数据写入到硬盘中，在redis重新启动的时候加载这些数据，从而最大限度的降低缓存丢失带来的影响。

3.2 哨兵（Sentinel）和复制（Replication）
Redis服务器毫无征兆的罢工是个麻烦事。那么怎办办？答曰：备份一台，你挂了它上。那么如何得知某一台redis服务器挂了，如何切换，如何保证备份的机器是原始服务器的完整备份呢？这时候就需要Sentinel和Replication出场了。Sentinel可以管理多个Redis服务器，它提供了监控，提醒以及自动的故障转移的功能；Replication则是负责让一个Redis服务器可以配备多个备份的服务器。Redis也是利用这两个功能来保证Redis的高可用的。此外，Sentinel功能则是对Redis的发布和订阅功能的一个利用。

3.3 集群（Cluster）
单台服务器资源的总是有上限的，CPU资源和IO资源我们可以通过主从复制，进行读写分离，把一部分CPU和IO的压力转移到从服务器上。但是内存资源怎么办，主从模式做到的只是相同数据的备份，并不能横向扩充内存；单台机器的内存也只能进行加大处理，但是总有上限的。所以我们就需要一种解决方案，可以让我们横向扩展。最终的目的既是把每台服务器只负责其中的一部分，让这些所有的服务器构成一个整体，对外界的消费者而言，这一组分布式的服务器就像是一个集中式的服务器一样（之前在解读REST的博客中解释过分布式于基于网络的差异：基于网络应用的架构）。

在Redis官方的分布式方案出来之前，有twemproxy和codis两种方案，这两个方案总体上来说都是依赖proxy来进行分布式的，也就是说redis本身并不关心分布式的事情，而是交由twemproxy和codis来负责。而redis官方给出的cluster方案则是把分布式的这部分事情做到了每一个redis服务器中，使其不再需要其他的组件就可以独立的完成分布式的要求。我们这里不关心这些方案的优略，我们关注一下这里的分布式到底是要处理那些事情?也就是twemproxy和codis独立处理的处理分布式的这部分逻辑和cluster集成到redis服务的这部分逻辑到底在解决什么问题？

如我们前面所说的，一个分布式的服务在外界看来就像是一个集中式的服务一样。那么要做到这一点就面临着有一个问题需要解决：既是增加或减少分布式服务中的服务器的数量，对消费这个服务的客户端而言应该是无感的；那么也就意味着客户端不能穿透分布式服务，把自己绑死到某一个台的服务器上去，因为一旦如此，你就再也无法新增服务器，也无法进行故障替换。解决这个问题有两个路子：第一个路子最直接，那就是我加一个中间层来隔离这种具体的依赖，即twemproxy采用的方式，让所有的客户端只能通过它来消费redsi服务，通过它来隔离这种依赖（但是你会发现twermproxy会成为一个单点），这种情况下每台redis服务器都是独立的，它们之间彼此不知对方的存在；第二个路子是让redis服务器知道彼此的存在，通过重定向的机制来引导客户端来完成自己所需要的操作，比如客户端链接到了某一个redis服务器，说我要执行这个操作，redis服务器发现自己无法完成这个操作，那么就把能完成这个操作的服务器的信息给到客户端，让客户端去请求另外的一个服务器，这时候你就会发现每一个redis服务器都需要保持一份完整的分布式服务器信息的一份资料，不然它怎么知道让客户端去找其他的哪个服务器来执行客户端想要的操作呢。

上面这一大段解释了这么多，不知有没有发现不管是第一个路子还是第二个路子，都有一个共同的东西存在，那就是分布式服务中所有服务器以及其能提供的服务的信息。这些信息无论如何也是要存在的，区别在于第一个路子是把这部分信息单独来管理，用这些信息来协调后端的多个独立的redis服务器；第二个路子则是让每一个redis服务器都持有这份信息，彼此知道对方的存在，来达成和第一个路子一样的目的，优点是不再需要一个额外的组件来处理这部分事情。

Redis Cluster的具体实现细节则是采用了Hash槽的概念，即预先分配出来16384个槽：在客户端通过对Key进行CRC16（key）% 16384运算得到对应的槽是哪一个；在redis服务端则是每个服务器负责一部分槽，当有新的服务器加入或者移除的时候，再来迁移这些槽以及其对应的数据，同时每个服务器都持有完整的槽和其对应的服务器的信息，这就使得服务器端可以进行对客户端的请求进行重定向处理。

4 客户端的Redis
上面的第三小节主要介绍的是Redis服务端的演进步骤，解释了Redis如何从一个单机的服务，进化为一个高可用的、去中心化的、分布式的存储系统。这一小节则是关注下客户端可以消费的redis服务。

4.1 数据类型
redis支持丰富的数据类型，从最基础的string到复杂的常用到的数据结构都有支持：

string：最基本的数据类型，二进制安全的字符串，最大512M。

list：按照添加顺序保持顺序的字符串列表。

set：无序的字符串集合，不存在重复的元素。

sorted set：已排序的字符串集合。

hash：key-value对的一种集合。

bitmap：更细化的一种操作，以bit为单位。

hyperloglog：基于概率的数据结构。

这些众多的数据类型，主要是为了支持各种场景的需要，当然每种类型都有不同的时间复杂度。其实这些复杂的数据结构相当于之前我在《解读REST》这个系列博客基于网络应用的架构风格中介绍到的远程数据访问（Remote Data Access = RDA）的具体实现，即通过在服务器上执行一组标准的操作命令，在服务端之间得到想要的缩小后的结果集，从而简化客户端的使用，也可以提高网络性能。比如如果没有list这种数据结构，你就只能把list存成一个string，客户端拿到完整的list，操作后再完整的提交给redis，会产生很大的浪费。

4.2 事务
上述数据类型中，每一个数据类型都有独立的命令来进行操作，很多情况下我们需要一次执行不止一个命令，而且需要其同时成功或者失败。redis对事务的支持也是源自于这部分需求，即支持一次性按顺序执行多个命令的能力，并保证其原子性。

4.3 Lua脚本
在事务的基础上，如果我们需要在服务端一次性的执行更复杂的操作（包含一些逻辑判断），则lua就可以排上用场了（比如在获取某一个缓存的时候，同时延长其过期时间）。redis保证lua脚本的原子性，一定的场景下，是可以代替redis提供的事务相关的命令的。相当于基于网络应用的架构风格中介绍到的远程求值（Remote Evluation = REV）的具体实现。

4.4 管道
因为redis的客户端和服务器的连接时基于TCP的， 默认每次连接都时只能执行一个命令。管道则是允许利用一次连接来处理多条命令，从而可以节省一些tcp连接的开销。管道和事务的差异在于管道是为了节省通信的开销，但是并不会保证原子性。

4.5 分布式锁
官方推荐采用Redlock算法，即使用string类型，加锁的时候给的一个具体的key，然后设置一个随机的值；取消锁的时候用使用lua脚本来先执行获取比较，然后再删除key。具体的命令如下：

SET resource_name my_random_value NX PX 30000

if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end

=======================================

为什么Redis单线程却能支撑高并发？
Draveness  码农code之路  今天

原文链接：draveness.me/redis-io-multiplexing

最近在看 UNIX 网络编程并研究了一下 Redis 的实现，感觉 Redis 的源代码十分适合阅读和分析，其中 I/O 多路复用（mutiplexing）部分的实现非常干净和优雅，在这里想对这部分的内容进行简单的整理。

几种 I/O 模型
为什么 Redis 中要使用 I/O 多路复用这种技术呢？

首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的。

Blocking I/O
先来看一下传统的阻塞 I/O 模型到底是如何工作的：当使用 read 或者 write 对某一个文件描述符（File Descriptor 以下简称 FD)进行读写时，如果当前 FD 不可读或不可写，整个 Redis 服务就不会对其它的操作作出响应，导致整个服务不可用。

这也就是传统意义上的，也就是我们在编程中使用最多的阻塞模型：



阻塞模型虽然开发中非常常见也非常易于理解，但是由于它会影响其他 FD 对应的服务，所以在需要处理多个客户端任务的时候，往往都不会使用阻塞模型。

I/O 多路复用
虽然还有很多其它的 I/O 模型，但是在这里都不会具体介绍。

阻塞式的 I/O 模型并不能满足这里的需求，我们需要一种效率更高的 I/O 模型来支撑 Redis 的多个客户（redis-cli），这里涉及的就是 I/O 多路复用模型了：



在 I/O 多路复用模型中，最重要的函数调用就是 select，该方法的能够同时监控多个文件描述符的可读可写情况，当其中的某些文件描述符可读或者可写时，select 方法就会返回可读以及可写的文件描述符个数。

关于 select 的具体使用方法，在网络上资料很多，这里就不过多展开介绍了；

与此同时也有其它的 I/O 多路复用函数 epoll/kqueue/evport，它们相比 select 性能更优秀，同时也能支撑更多的服务。

Reactor 设计模式
Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）



文件事件处理器使用 I/O 多路复用模块同时监听多个 FD，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器。

虽然整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单。

I/O 多路复用模块
I/O 多路复用模块封装了底层的 select、epoll、avport 以及 kqueue 这些 I/O 多路复用函数，为上层提供了相同的接口。



在这里我们简单介绍 Redis 是如何包装 select 和 epoll 的，简要了解该模块的功能，整个 I/O 多路复用模块抹平了不同平台上 I/O 多路复用函数的差异性，提供了相同的接口：

static int aeApiCreate(aeEventLoop *eventLoop)

static int aeApiResize(aeEventLoop *eventLoop, int setsize)

static void aeApiFree(aeEventLoop *eventLoop)

static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask)

static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int mask)

static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp)

同时，因为各个函数所需要的参数不同，我们在每一个子模块内部通过一个 aeApiState 来存储需要的上下文信息：

// select
typedef struct aeApiState {
    fd_set rfds, wfds;
    fd_set _rfds, _wfds;
} aeApiState;

// epoll
typedef struct aeApiState {
    int epfd;
    struct epoll_event *events;
} aeApiState;
这些上下文信息会存储在 eventLoop 的 void *state 中，不会暴露到上层，只在当前子模块中使用。

封装 select 函数
select 可以监控 FD 的可读、可写以及出现错误的情况。

在介绍 I/O 多路复用模块如何对 select 函数封装之前，先来看一下 select 函数使用的大致流程：

int fd = /* file descriptor */

fd_set rfds;
FD_ZERO(&rfds);
FD_SET(fd, &rfds)

for ( ; ; ) {
    select(fd+1, &rfds, NULL, NULL, NULL);
    if (FD_ISSET(fd, &rfds)) {
        /* file descriptor `fd` becomes readable */
    }
}


初始化一个可读的 fd_set 集合，保存需要监控可读性的 FD；

使用 FD_SET 将 fd 加入 rfds；

调用 select 方法监控 rfds 中的 FD 是否可读；

当 select 返回时，检查 FD 的状态并完成对应的操作。

而在 Redis 的 ae_select 文件中代码的组织顺序也是差不多的，首先在 aeApiCreate 函数中初始化 rfds 和 wfds：

static int aeApiCreate(aeEventLoop *eventLoop) {
    aeApiState *state = zmalloc(sizeof(aeApiState));
    if (!state) return -1;
    FD_ZERO(&state->rfds);
    FD_ZERO(&state->wfds);
    eventLoop->apidata = state;
    return 0;
}
而 aeApiAddEvent 和 aeApiDelEvent 会通过 FD_SET 和 FD_CLR 修改 fd_set 中对应 FD 的标志位：

static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) {
    aeApiState *state = eventLoop->apidata;
    if (mask & AE_READABLE) FD_SET(fd,&state->rfds);
    if (mask & AE_WRITABLE) FD_SET(fd,&state->wfds);
    return 0;
}
整个 ae_select 子模块中最重要的函数就是 aeApiPoll，它是实际调用 select 函数的部分，其作用就是在 I/O 多路复用函数返回时，将对应的 FD 加入 aeEventLoop 的 fired 数组中，并返回事件的个数：

static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) {
    aeApiState *state = eventLoop->apidata;
    int retval, j, numevents = 0;

    memcpy(&state->_rfds,&state->rfds,sizeof(fd_set));
    memcpy(&state->_wfds,&state->wfds,sizeof(fd_set));

    retval = select(eventLoop->maxfd+1,
                &state->_rfds,&state->_wfds,NULL,tvp);
    if (retval > 0) {
        for (j = 0; j <= eventLoop->maxfd; j++) {
            int mask = 0;
            aeFileEvent *fe = &eventLoop->events[j];

            if (fe->mask == AE_NONE) continue;
            if (fe->mask & AE_READABLE && FD_ISSET(j,&state->_rfds))
                mask |= AE_READABLE;
            if (fe->mask & AE_WRITABLE && FD_ISSET(j,&state->_wfds))
                mask |= AE_WRITABLE;
            eventLoop->fired[numevents].fd = j;
            eventLoop->fired[numevents].mask = mask;
            numevents++;
        }
    }
    return numevents;
}
封装 epoll 函数
Redis 对 epoll 的封装其实也是类似的，使用 epoll_create 创建 epoll 中使用的 epfd：

static int aeApiCreate(aeEventLoop *eventLoop) {
    aeApiState *state = zmalloc(sizeof(aeApiState));

    if (!state) return -1;
    state->events = zmalloc(sizeof(struct epoll_event)*eventLoop->setsize);
    if (!state->events) {
        zfree(state);
        return -1;
    }
    state->epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */
    if (state->epfd == -1) {
        zfree(state->events);
        zfree(state);
        return -1;
    }
    eventLoop->apidata = state;
    return 0;
}
在 aeApiAddEvent 中使用 epoll_ctl 向 epfd 中添加需要监控的 FD 以及监听的事件：

static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) {
    aeApiState *state = eventLoop->apidata;
    struct epoll_event ee = {0}; /* avoid valgrind warning */
    /* If the fd was already monitored for some event, we need a MOD
     * operation. Otherwise we need an ADD operation. */
    int op = eventLoop->events[fd].mask == AE_NONE ?
            EPOLL_CTL_ADD : EPOLL_CTL_MOD;

    ee.events = 0;
    mask |= eventLoop->events[fd].mask; /* Merge old events */
    if (mask & AE_READABLE) ee.events |= EPOLLIN;
    if (mask & AE_WRITABLE) ee.events |= EPOLLOUT;
    ee.data.fd = fd;
    if (epoll_ctl(state->epfd,op,fd,&ee) == -1) return -1;
    return 0;
}
由于 epoll 相比 select 机制略有不同，在 epoll_wait 函数返回时并不需要遍历所有的 FD 查看读写情况；在 epoll_wait 函数返回时会提供一个 epoll_event 数组：

typedef union epoll_data {
    void    *ptr;
    int      fd; /* 文件描述符 */
    uint32_t u32;
    uint64_t u64;
} epoll_data_t;

struct epoll_event {
    uint32_t     events; /* Epoll 事件 */
    epoll_data_t data;
};
其中保存了发生的 epoll 事件（EPOLLIN、EPOLLOUT、EPOLLERR 和 EPOLLHUP）以及发生该事件的 FD。

aeApiPoll 函数只需要将 epoll_event 数组中存储的信息加入 eventLoop 的 fired 数组中，将信息传递给上层模块：

static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) {
    aeApiState *state = eventLoop->apidata;
    int retval, numevents = 0;

    retval = epoll_wait(state->epfd,state->events,eventLoop->setsize,
            tvp ? (tvp->tv_sec*1000 + tvp->tv_usec/1000) : -1);
    if (retval > 0) {
        int j;

        numevents = retval;
        for (j = 0; j < numevents; j++) {
            int mask = 0;
            struct epoll_event *e = state->events+j;

            if (e->events & EPOLLIN) mask |= AE_READABLE;
            if (e->events & EPOLLOUT) mask |= AE_WRITABLE;
            if (e->events & EPOLLERR) mask |= AE_WRITABLE;
            if (e->events & EPOLLHUP) mask |= AE_WRITABLE;
            eventLoop->fired[j].fd = e->data.fd;
            eventLoop->fired[j].mask = mask;
        }
    }
    return numevents;
}
子模块的选择
因为 Redis 需要在多个平台上运行，同时为了最大化执行的效率与性能，所以会根据编译平台的不同选择不同的 I/O 多路复用函数作为子模块，提供给上层统一的接口；在 Redis 中，我们通过宏定义的使用，合理的选择不同的子模块：

#ifdef HAVE_EVPORT
#include "ae_evport.c"
#else
    #ifdef HAVE_EPOLL
    #include "ae_epoll.c"
    #else
        #ifdef HAVE_KQUEUE
        #include "ae_kqueue.c"
        #else
        #include "ae_select.c"
        #endif
    #endif
#endif
因为 select 函数是作为 POSIX 标准中的系统调用，在不同版本的操作系统上都会实现，所以将其作为保底方案：



Redis 会优先选择时间复杂度为 $O(1)$ 的 I/O 多路复用函数作为底层实现，包括 Solaries 10 中的 evport、Linux 中的 epoll 和 macOS/FreeBSD 中的 kqueue，上述的这些函数都使用了内核内部的结构，并且能够服务几十万的文件描述符。

但是如果当前编译环境没有上述函数，就会选择 select 作为备选方案，由于其在使用时会扫描全部监听的描述符，所以其时间复杂度较差 $O(n)$，并且只能同时服务 1024 个文件描述符，所以一般并不会以 select 作为第一方案使用。

总结
Redis 对于 I/O 多路复用模块的设计非常简洁，通过宏保证了 I/O 多路复用模块在不同平台上都有着优异的性能，将不同的 I/O 多路复用函数封装成相同的 API 提供给上层使用。

整个模块使 Redis 能以单进程运行的同时服务成千上万个文件描述符，避免了由于多进程应用的引入导致代码实现复杂度的提升，减少了出错的可能性。

参考
http://man7.org/linux/man-pages/man2/select.2.html
https://en.wikipedia.org/wiki/Reactor_pattern
https://people.eecs.berkeley.edu/~sangjin/2012/12/21/epoll-vs-kqueue.html

