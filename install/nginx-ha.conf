
*****************************************
使用Nginx实现负载均衡
一、nginx简介
nginx是一个高性能的HTTP服务器和反向代理服务器。它起初是俄罗斯人Igor Sysoev开发的，至今支撑者俄罗斯的很多大型的网站。
二、nginx支持的三种负载均衡策略
轮询：将请求依次轮询发给每个服务器。
最少链接：将请求发送给持有最少活动链接的服务器。
ip哈希：通过哈希函数决定请求发送给哪个服务器。
权重：服务器的权重越高，处理请求的概率越大。
三、轮询负载均衡
在nginx.conf配置文件中添加如下配置，此配置有三台服务器提供支付服务。

http {
  upstream CashServers {
    server CashServers1.com;
    server CashServers2.com;
    server CashServers3.com;
  }

  server {
    listen 80;

    location / {
      proxy_pass http://CashServers;
    }
  }
}



需要注意以下几点
1.缺省配置就是轮询策略;
2.nginx负载均衡支持http和https协议，只需要修改 proxy_pass后协议即可;
3.nginx支持FastCGI, uwsgi, SCGI,memcached的负载均衡,只需将 proxy_pass改为fastcgi_pass, uwsgi_pass, scgi_pass,memcached_pass即可。
4.此策略适合服务器配置相当，无状态且短平快的服务使用。
四、最少链接负载均衡

http {
  upstream CashServers {
    least_conn;
    server CashServers1.com;
    server CashServers2.com;
    server CashServers3.com;
  }

  server {
    listen 80;

    location / {
      proxy_pass http://CashServers;
    }
  }
}



需要注意以下几点
1.最少链接负载均衡通过least_conn指令定义;
2.此负载均衡策略适合请求处理时间长短不一造成服务器过载的情况;
五、ip哈希负载均衡

http {
  upstream CashServers {
    ip_hash;
    server CashServers1.com;
    server CashServers2.com;
    server CashServers3.com;
  }

  server {
    listen 80;

    location / {
      proxy_pass http://CashServers;
    }
  }
}



需要注意以下几点
1.ip哈希负载均衡使用ip_hash指令定义;
2.nginx使用请求客户端的ip地址进行哈希计算，确保使用同一个服务器响应请求;
3.此策略适合有状态服务，比如session;
六、权重负载均衡

http {
  upstream CashServers {
    server CashServers1.com weight=3;
    server CashServers2.com weight=2;
    server CashServers3.com weight=1;
  }

  server {
    listen 80;
    location / {
      proxy_pass http://CashServers;
    }
  }
}



需要注意以下几点
1. 权重负载均衡需要使用weight指令定义;
2. 权重越高分配到需要处理的请求越多;
3.此策略可以与最少链接负载和ip哈希策略结合使用;
4.此策略比较适合服务器的硬件配置差别比较大的情况;

七、健康检测
nginx内置了针对服务器的健康检测机制，如果特定服务器请求失败，则nginx即可进行标记待下次就不会请求分配给它

max_fails定义失败指定次数后进行标记服务器不可用。


******************************************
nginx配置轮询分流-实现负载均衡【测试通过】

准备工作，3台服务器，或者开虚拟机吧！我就是开虚拟机实现的。
ip分别为：192.168.1.10  192.168.1.11  192.168.1.12   （环境：安装了ngixn 没有做任何配置）
3台服务器环境最好一样，我是再vm里直接克隆出来的，环境绝对一样吧！不一样，我估计会遇到很多奇怪的问题，没试过。

192.168.1.10  作为  负载均衡服务器  （一会负载均衡就在这里台服务器做配置，另外2台不用做配置）

先了解下负载一些常见知识

nginx 的 upstream目前支持 4 种方式的分配
1)、轮询（默认）
每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
2)、weight
指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
2)、ip_hash
每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
3)、fair（第三方）
按后端服务器的响应时间来分配请求，响应时间短的优先分配。
4)、url_hash（第三方）
可以开始配置了。打开192.168.1.10 的nginx.conf  只需要在配置文件增加如下代码
[html]
upstream  www.129.com  {
  server   192.168.1.11:80;
  server   192.168.1.12:80;
}

server {
  listen 80;
  server_name www.juzheke.com;
  location / {
    proxy_pass        http://www.juzheke.com;
      proxy_set_header   Host             $host;
    proxy_set_header   X-Real-IP        $remote_addr;
    proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;
  }
  access_log logs/access_log;
  error_log logs/error_log;
}

实践结果：
http://www.juzheke.com  我通过修改host 指向了  192.168.1.10
  为了使测试结果明显，我修改了ngixn默认页面的html
vi /usr/local/nginx/html/index.html
再index.html 加入显示本机ip
192.168.1.11 和  192.168.1.12  都要修改，这样测才明显
我通过本机浏览器，输入 http://www.juzheke.com
  每次刷新，都会跳转到不同的服务器上页面（当然我这个是为了明显所以用的是轮询的方式，大家可以根据自己需求进行修改）

=========================

nginx upstream模块--负载均衡

Module ngx_http_upstream_module英文文档

upstream模块相关说明
1、upstream模块应放于nginx.conf配置的http{}标签内
2、upstream模块默认算法是wrr (权重轮询 weighted round-robin)
一、分配方式
Nginx的upstream支持5种分配方式，下面将会详细介绍，其中前三种为Nginx原生支持的分配方式，后两种为第三方支持的分配方式。

1、轮询
轮询是upstream的默认分配方式，即每个请求按照时间顺序轮流分配到不同的后端服务器，如果某个后端服务器down掉后，能自动剔除。

upstream backend {
  server 192.168.1.101:8888;
  server 192.168.1.102:8888;
  server 192.168.1.103:8888;
}
2、weight
轮询的加强版，即可以指定轮询比率，weight和访问几率成正比，主要应用于后端服务器异质的场景下。

upstream backend {
  server 192.168.1.101 weight=1;
  server 192.168.1.102 weight=2;
  server 192.168.1.103 weight=3;
}
3、ip_hash
每个请求按照访问ip（即Nginx的前置服务器或者客户端IP）的hash结果分配，这样每个访客会固定访问一个后端服务器，可以解决session一致问题。

upstream backend {
  ip_hash;
  server 192.168.1.101:7777;
  server 192.168.1.102:8888;
  server 192.168.1.103:9999;
}


注意：
1、当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。
2、导致负载不均衡。

4、fair
fair顾名思义，公平地按照后端服务器的响应时间（rt）来分配请求，响应时间短即rt小的后端服务器优先分配请求。如果需要使用这种调度算法，必须下载Nginx的upstr_fair模块。

upstream backend {
  server 192.168.1.101;
  server 192.168.1.102;
  server 192.168.1.103;
  fair;
}
5、url_hash，目前用consistent_hash替代url_hash
与ip_hash类似，但是按照访问url的hash结果来分配请求，使得每个url定向到同一个后端服务器，主要应用于后端服务器为缓存时的场景下。


upstream backend {
  server 192.168.1.101;
  server 192.168.1.102;
  server 192.168.1.103;
  hash $request_uri;
  hash_method crc32;
}

其中，hash_method为使用的hash算法，需要注意的是：此时，server语句中不能加weight等参数。
提示：url_hash用途cache服务业务，memcached，squid，varnish。特点：每个rs都是不同的。



二、设备状态
从上面实例不难看出upstream中server指令语法如下：server address [parameters]
参数说明：
server：关键字，必选。
address：主机名、域名、ip或unix socket，也可以指定端口号，必选。
parameters：可选参数，可选参数如下：
1.down：表示当前server已停用
2.backup：表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或者很忙才会分配到请求。
3.weight：表示当前server负载权重，权重越大被请求几率越大。默认是1.
4.max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉了，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即默认情况是只要发生错误就认为服务器挂掉了，如果将max_fails设置为0，则表示取消这项检查。

举例说明如下：

upstream backend {
  server    backend1.example.com weight=5;
  server    127.0.0.1:8080 max_fails=3 fail_timeout=30s;
  server    unix:/tmp/backend3;
}



#############################

user  nobody;

worker_processes 1;

error_log/usr/local/nginx/logs/error.log notice;

pid/usr/local/nginx/logs/nginx.pid;

worker_rlimit_nofile 51200;

events{
  use epoll;
  worker_connections 51200;
}

http{
  includemime.types;
  default_typeapplication/octet-stream;
  log_formatmain'$remote_addr-$remote_user[$time_local]"$request"'
  '$status$body_bytes_sent"$http_referer"'
  '"$http_user_agent""$http_x_forwarded_for"';
  access_loglogs/access.log main;
  server_names_hash_bucket_size 128;
  client_header_buffer_size 32k;
  large_client_header_buffers 432k;
  client_max_body_size 8m;
  sendfileon;
  tcp_nopushon;
  server_tokens off;
  keepalive_timeout 60;
  fastcgi_connect_timeout 300;
  fastcgi_send_timeout 300;
  fastcgi_read_timeout 300;
  fastcgi_buffer_size 64k;
  fastcgi_buffers 464k;
  fastcgi_busy_buffers_size 128k;
  fastcgi_temp_file_write_size 128k;
  gzipon;

  upstreambackend
    {
      server 192.168.15.128;
      server 192.168.15.130;
    }

  server{
    listen80;
    server_name192.168.15.135;
    location/{
      root html;
      index index.phpindex.htmlindex.htm;
      proxy_redirect off;
      proxy_set_header Host $host;
      proxy_set_headerX-Real-IP $remote_addr;
      #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
      proxy_set_headerX-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_pass http://backend;
    }
    error_page 500 502 503 504 /50x.html;
    location=/50x.html{
      root html;
    }

    location/nginx_status{
      stub_status on;
      auth_basic "NginxStatus";
      auth_basic_user_file /usr/local/nginx/htpasswd;
      #allow 127.0.0.1;
      #deny all;
    }
    location~*\.(ini|docx|txt|doc|pdf)${

    #禁止访问文档性文件
    root /usr/share/nginx/html;
    deny all;
  }
  location~.*\.(gif|jpg|jpeg|png|bmp|swf|js|html|htm|css)${
  root /home/image;
  proxy_storeon;
  proxy_store_accessuser:rwgroup:rwall:rw;
  proxy_temp_path /home/image;
  if(!-e$request_filename){
    proxy_pass http://backend;
  }
}
}
}
#这里面配置较多，其中比较有用的已经标红了，可以直接将此部分配置在默认的nginx的配置文件里面即可















