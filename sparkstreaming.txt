10．1　一个简单的例子　　162
10．2　架构与抽象　　164
10．3　转化操作　　167
10．3．1　无状态转化操作　　167
10．3．2　有状态转化操作　　169
10．4　输出操作　　173
10．5　输入源　　175
10．5．1　核心数据源　　175
10．5．2　附加数据源　　176
10．5．3　多数据源与集群规模　　179
10．6　24/7不间断运行　　180
10．6．1　检查点机制　　180
10．6．2　驱动器程序容错　　181
10．6．3　工作节点容错　　182
10．6．4　接收器容错　　182
10．6．5　处理保证　　183
10．7　Streaming用户界面　　183
10．8　性能考量　　184
10．8．1　批次和窗口大小　　184
10．8．2　并行度　　184
10．8．3　垃圾回收和内存使用　　185

第1章 Spark Streaming应用概述 ······1
1.1 Spark Streaming应用案例 ·······2
1.2　Spark Streaming应用剖析 ·····13
第2章 Spark Streaming基本原理 ····15
2.1　Spark Core简介 ··················16
2.2 Spark Streaming设计思想 ·····26
2.3 Spark Streaming整体架构 ·····30
2.4 编程接口 ·························33
第3章 Spark Streaming运行流程详解·············39
3.1 从StreamingContext的初始化到启动 ··········40
3.2 数据接收 ·························54
3.3 数据处理 ·························91
3.4 数据清理 ························115
3.5 容错机制 ························127
3.5.1 容错原理 ·························128
3.5.2 Driver容错机制 ·················152
3.5.3 Executor容错机制 ··············161
3.6 No Receiver方式 ···············167
3.7 输出不重复 ·····················175
3.8 消费速率的动态控制 ·········176
3.9 状态操作 ························189
3.10 窗口操作 ·······················212
3.11 页面展示 ·······················216
3.12 Spark Streaming应用程序的停止··········227
第4章Spark Streaming 性能调优机制···········237
4.1 并行度解析 ·····················238
4.1.1 数据接收的并行度 ·············238
4.1.2 数据处理的并行度 ·············240
4.2 内存······························240
4.3 序列化 ···························240
4.4 Batch Interval ···················241
4.5 Task ·······························242
4.6 JVM GC ·························242
第5章Spark 2.0中的流计算 ··········245
5.1 连续应用程序 ··················246
5.2 无边界表unbounded table ····248
5.3 增量输出模式 ··················249
5.4 API简化 ··························250
5.5 其他改进 ························250


1.1　Spark前传 1
1.1.1　Web 2.0时代 2
1.1.2　无处不在的传感器 7
1.2　Spark Streaming：MapReduce和CEP的交集 9
第2章　Spark简介 10
2.1　安装 11
2.2　执行 12
2.2.1　独立集群模式（Standalone Cluster） 12
2.2.2　YARN模式 13
2.3　第一个应用程序 13
2.3.1　构建 16
2.3.2　执行 17
2.4　SparkContext 19
2.4.1　RDDs创建 19
2.4.2　处理依赖关系 20
2.4.3　创建共享变量 21
2.4.4　作业执行 22
2.5　RDD 22
2.5.1　持久化 23
2.5.2　转换 24
2.5.3　行动（Action） 28
小结 29
第3章　实时RDD：DStream 30
3.1　从连续流到离散流 30
3.2　第一个Spark Streaming应用程序 31
3.2.1　构建和执行 34
3.2.2　Streaming Context 34
3.3　DStreams 36
3.3.1　Spark Streaming应用程序剖析 38
3.3.2　转换 42
小结 52
第4章　高速流：并行化及其他 54
4.1　流数据的一大飞跃 54
4.2　并行化 56
4.2.1　Worker 56
4.2.2　执行器（Executor） 57
4.2.3　任务（Task） 59
4.3　批处理间隔 62
4.4　调度 64
4.4.1　应用程序间调度 64
4.4.2　批处理调度 64
4.4.3　作业间调度 65
4.4.4　一个行动，一个作业 65
4.5　内存 66
4.5.1　序列化 67
4.5.2　压缩（Compression） 70
4.5.3　垃圾收集 70
4.6　Shuffle 70
4.6.1　早期投影和过滤 70
4.6.2　经常使用组合器 70
4.6.3　大量运用平行化 70
4.6.4　文件合并（File Consolidation） 71
4.6.5　更多内存 71
小结 71
第5章　链接外部数据源 72
5.1　智慧城市，智慧地球，一切更智慧 72
5.2　ReceiverInputDStream 74
5.3　套接字 76
5.4　MQTT 85
5.5　Flume 89
5.5.1　基于推模式的Flume数据摄取 91
5.5.2　基于拉模式的Flume数据摄取 92
5.6　Kafka 92
5.6.1　基于接收器的Kafka消费者 95
5.6.2　直接Kafka消费者 98
5.7　Twitter 99
5.8　块间隔 100
5.9　自定义接收器 100
小结 104
第6章　边界效应 106
6.1　盘点股市 106
6.2　foreachRDD 108
6.2.1　为每条记录创建一个连接 110
6.2.2　为每个分区创建一个连接 111
6.2.3　静态连接 112
6.2.4　惰性静态连接 113
6.2.5　静态连接池 114
6.3　可扩展流存储 116
6.3.1　HBase 117
6.3.2　股市控制台（Dashboard） 118
6.3.3　SparkOnHBase 120
6.3.4　Cassandra 122
6.3.5　Spark Cassandra连接器 124
6.4　全局状态（Global State） 126
6.4.1　静态变量 126
6.4.2　updateStateByKey() 128
6.4.3　累加器 129
6.4.4　外部解决方案 131
小结 133
第7章　充分准备 134
7.1　每个点击都异乎重要 134
7.2　Tachyon（Alluxio） 135
7.3　Spark Web UI 138
7.3.1　历史分析 151
7.3.2　RESTful度量 152
7.4　日志记录 153
7.5　外部度量 154
7.6　系统度量 156
7.7　监控和报警 157
小结 159
第8章　实时ETL和分析技术 160
8.1　交易数据记录的强大功能 160
8.2　第一个流式Spark SQL应用程序 162
8.3　SQLContext 165
8.3.1　创建数据框 165
8.3.2　执行SQL 168
8.3.3　配置 169
8.3.4　用户自定义函数 169
8.3.5　Catalyst：查询执行和优化 171
8.3.6　HiveContext 171
8.4　数据框（Data Frame） 173
8.4.1　类型 173
8.4.2　查询转换 173
8.4.3　行动 180
8.4.4　RDD操作 182
8.4.5　持久化 182
8.4.6　最佳做法 183
8.5　SparkR 183
8.6　第一个SparkR应用程序 184
8.6.1　执行 185
8.6.2　流式SparkR 185
小结 188

第9章　大规模机器学习 189
9.1　传感器数据风暴 189
9.2　流式MLlib应用程序 191
9.3　MLlib 194
9.3.1　数据类型 194
9.3.2　统计分析 197
9.3.3　预处理 198
9.4　特征选择和提取 199
9.4.1　卡方选择 199
9.4.2　主成分分析 200
9.5　学习算法 201
9.5.1　分类 202
9.5.2　聚类 202
9.5.3　推荐系统 204
9.5.4　频繁模式挖掘 207
9.6　流式ML管道应用程序 208
9.7　ML 211
9.8　管道交叉验证 212
小结 213
第10章　云、Lambda及Python 215
10.1　一条好评胜过一千个广告 216
10.2　Google Dataproc 217
10.3　基于Dataproc应用程序创建的第一个Spark 220
10.4　PySpark 227
10.5　Lambda架构 229
10.6　流式图分析 238

文末送书 | Spark Streaming 场景应用
徐胜国  Spark技术日报  昨天
Spark Streaming 是一套优秀的实时计算框架。其良好的可扩展性、高吞吐量以及容错机制能够满足我们很多的场景应用。

本篇结合我们的应用场景，介结我们在使用 Spark Streaming 方面的技术架构，并着重讲解 Spark Streaming 两种计算模型；接着介绍了 Spark Streaming 在监控方面所做的一些事情，最后总结了 Spark Streaming 的优缺点。



一、概述



Spark Streaming 由于其本身的扩展性、高吞吐量以及容错能力等特性，并且能够和离线各种框架有效结合起来，因而是当下是比较受欢迎的一种流式处理框架。



根据其官方文档介绍，Spark Streaming 有高扩展性、高吞吐量和容错能力强的特点。Spark Streaming 支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ 和简单的 TCP 套接字等等。数据输入后可以用 Spark 的高度抽象原语如：map、reduce、join、window 等进行运算。而结果也能保存在很多地方，如 HDFS，数据库等。另外 Spark Streaming 也能和 MLlib(机器学习)以及 Graphx 完美融合。其架构见下图：







Spark Streaming 其优秀的特点给我们带来很多的应用场景，如网站监控和网络监控、异常监测、网页点击、用户行为、用户迁移等。本文中，将为大家详细介绍，我们的应用场景中，Spark Streaming 的技术架构、两种状态模型以及 Spark Streaming 监控等。



二、应用场景



在 Spark Streaming 中，处理数据的单位是一批而不是单条，而数据采集却是逐条进行的，因此 Spark Streaming 系统需要设置间隔使得数据汇总到一定的量后再一并操作，这个间隔就是批处理间隔。

批处理间隔是 Spark Streaming 的核心概念和关键参数，它决定了 Spark Streaming 提交作业的频率和数据处理的延迟，同时也影响着数据处理的吞吐量和性能。







2.1 框架



目前我们 Spark Streaming 的业务应用场景包括异常监测、网页点击、用户行为以及用户地图迁徙等场景。按计算模型来看大体可分为无状态的计算模型以及状态计算模型两种。

在实际的应用场景中，我们采用Kafka作为实时输入源，Spark Streaming 作为计算引擎处理完数据之后，再持久化到存储中，包括 MySQL、HDFS、ElasticSearch 以及 MongoDB 等；同时 Spark Streaming 数据清洗后也会写入 Kafka，然后经由 Flume 持久化到 HDFS；接着基于持久化的内容做一些 UI 的展现。架构见下图：







2.2 无状态模型



该模型由于没有状态，并不需要考虑有状态的情况，只需要根据业务场景保证数据不丢就行。此种情况一般采用 Direct 方式读取 Kafka 数据，并采用监听器方式持久化 Offsets 即可。具体流程如下：







其上模型框架包含以下几个处理步骤：



读取 Kafka 实时数据；

Spark Streaming Transformations 以及 actions 操作；

将数据结果持久化到存储中，跳转到步骤一。



受网络、集群等一些因素的影响，实时程序出现长时失败，导致数据出现堆积。此种情况下是丢掉堆积的数据从 Kafka largest 处消费还是从之前的 Kafka offsets处消费，这个取决具体的业务场景。



2.3 状态模型



有状态模型是指 DStreams 在指定的时间范围内有依赖关系，具体的时间范围由业务场景来指定，可以是 2 个及以上的多个 batch time RDD 组成。Spark Streaming 提供了 updateStateByKey 方法来满足此类的业务场景。

因涉及状态的问题，所以在实际的计算过程中需要保存计算的状态，Spark Streaming 中通过 checkpoint 来保存计算的元数据以及计算的进度。该状态模型的应用场景有网站具体模块的累计访问统计、最近 N batch time 的网站访问情况以及 app 新增累计统计等等。具体流程如下：







上述流程中，每 batch time 计算时，需要依赖最近 2 个 batch time 内的数据，经过转换及相关统计，最终持久化到 MySQL 中去。不过为了确保每个计算仅计算 2 个 batch time 内的数据，需要维护数据的状态，清除过期的数据。我们先来看下 updateStateByKey 的实现，其代码如下：



暴露了全局状态数据中的 key 类型的方法。

def updateStateByKey[S: ClassTag](

updateFunc: (Iterator[(K, Seq[V], Option[S])]) => Iterator[(K, S)],

partitioner: Partitioner,

rememberPartitioner: Boolean

): DStream[(K, S)] = ssc.withScope {

new StateDStream(self, ssc.sc.clean(updateFunc), partitioner, rememberPartitioner, None)

}



隐藏了全局状态数据中的 key 类型，仅对 Value 提供自定义的方法。

def updateStateByKey[S: ClassTag](

updateFunc: (Seq[V], Option[S]) => Option[S],

partitioner: Partitioner,

initialRDD: RDD[(K, S)]

): DStream[(K, S)] = ssc.withScope {

val cleanedUpdateF = sparkContext.clean(updateFunc)

val newUpdateFunc = (iterator: Iterator[(K, Seq[V], Option[S])]) => {

iterator.flatMap(t => cleanedUpdateF(t._2, t._3).map(s => (t._1, s)))

}

updateStateByKey(newUpdateFunc, partitioner, true, initialRDD)

}



以上两种方法分别给我们提供清理过期数据的思路：

泛型 K 进行过滤。K 表示全局状态数据中对应的 key，如若 K 不满足指定条件则反回 false；

返回值过滤。第二个方法中自定义函数指定了 Option[S] 返回值，若过期数据返回 None，那么该数据将从全局状态中清除。



三、Spark Streaming 监控



同 Spark 一样，Spark Streaming 也提供了 Jobs、Stages、Storage、Enviorment、Executors 以及 Streaming 的监控，其中 Streaming 监控页的内容如下图：







上图是 Spark UI 中提供一些数据监控，包括实时输入数据、Scheduling Delay、处理时间以及总延迟的相关监控数据的趋势展现。另外除了提供上述数据监控外，Spark UI 还提供了 Active Batches 以及 Completed Batches 相关信息。

Active Batches 包含当前正在处理的 batch 信息以及堆积的 batch 相关信息，而 Completed Batches 刚提供每个 batch 处理的明细数据，具体包括 batch time、input size、scheduling delay、processing Time、Total Delay等，具体信息见下图：







Spark Streaming 能够提供如此优雅的数据监控，是因在对监听器设计模式的使用。如若 Spark UI 无法满足你所需的监控需要，用户可以定制个性化监控信息。 Spark Streaming 提供了 StreamingListener 特质，通过继承此方法，就可以定制所需的监控，其代码如下：



@DeveloperApi

trait StreamingListener {

/** Called when a receiver has been started */

def onReceiverStarted(receiverStarted: StreamingListenerReceiverStarted) { }

/** Called when a receiver has reported an error */

def onReceiverError(receiverError: StreamingListenerReceiverError) { }

/** Called when a receiver has been stopped */

def onReceiverStopped(receiverStopped: StreamingListenerReceiverStopped) { }

/** Called when a batch of jobs has been submitted for processing. */

def onBatchSubmitted(batchSubmitted: StreamingListenerBatchSubmitted) { }

/** Called when processing of a batch of jobs has started.  */

def onBatchStarted(batchStarted: StreamingListenerBatchStarted) { }

/** Called when processing of a batch of jobs has completed. */

def onBatchCompleted(batchCompleted: StreamingListenerBatchCompleted) { }

/** Called when processing of a job of a batch has started. */

def onOutputOperationStarted(

outputOperationStarted: StreamingListenerOutputOperationStarted) { }

/** Called when processing of a job of a batch has completed. */

def onOutputOperationCompleted(

outputOperationCompleted: StreamingListenerOutputOperationCompleted) { }

}



目前，我们保存 Offsets 时，采用继承 StreamingListener 方式，此是一种应用场景。当然也可以监控实时计算程序的堆积情况，并在达到一阈值后发送报警邮件。具体监听器的定制还得依据应用场景而定。



四、Spark Streaming 优缺点



4.1 优点



Spark Streaming 基于 Spark Core API，因此其能够与 Spark 中的其他模块保持良好的兼容性，为编程提供了良好的可扩展性;

Spark Streaming 是粗粒度的准实时处理框架，一次读取完或异步读完之后处理数据，且其计算可基于大内存进行，因而具有较高的吞吐量;

Spark Streaming 采用统一的 DAG 调度以及 RDD，因此能够利用其lineage 机制，对实时计算有很好的容错支持;

Spark Streaming 的 DStream 是基于 RDD 的在流式数据处理方面的抽象，其 transformations 以及 actions 有较大的相似性，这在一定程度上降低了用户的使用门槛，在熟悉 Spark 之后，能够快速上手 Spark Streaming。



4.2 缺点



Spark Streaming 是准实时的数据处理框架，采用粗粒度的处理方式，当 batch time 到时才会触发计算，这并非像 Storm 那样是纯流式的数据处理方式。此种方式不可避免会出现相应的计算延迟 。



目前来看，Spark Streaming 稳定性方面还是会存在一些问题。有时会因一些莫名的异常导致退出，这种情况下得需要自己来保证数据一致性以及失败重启功能等。


第1章 Spark和Spark Streaming的安装与配置

安装Spark

配置和运行Spark集群

你的第一个Spark程序

管理员/开发者工具

提交Spark作业

故障定位

总结

第2章 Spark和Spark Streaming的体系结构与组件

批处理和实时数据处理的比较

Spark的体系结构

Spark Streaming的体系结构

你的第一个Spark Streaming程序

总结

第3章 实时处理分布式日志文件

Spark的封装结构和客户端API

弹性分布式数据集及离散流

从分布的、多样的数据源中加载数据

总结

第4章 在流数据中应用Transformation

理解并应用Transformation功能

性能调优

总结

第5章 日志分析数据的持久化

Spark Streaming的输出操作

集成Cassandra

总结

第6章 与Spark高级库集成

实时查询流数据

了解Spark SQL

集成Spark SQL与流数据

图的分析——Spark GraphX

GraphX API介绍

总结

第7章 产品部署

Spark部署模式

高可用性和容错性

Streaming作业的监听

===========

Spark Streaming 是一套优秀的实时计算框架。其良好的可扩展性、高吞吐量以及容错机制能够满足我们很多的场景应用。本篇结合我们的应用场景，介结我们在使用 Spark Streaming 方面的技术架构，并着重讲解 Spark Streaming 两种计算模型，无状态和状态计算模型以及该两种模型的注意事项;接着介绍了 Spark Streaming 在监控方面所做的一些事情，最后总结了 Spark Streaming 的优缺点。



一、概述



数据是非常宝贵的资源，对各级企事业单均有非常高的价值。但是数据的爆炸，导致原先单机的数据处理已经无法满足业务的场景需求。因此在此基础上出现了一些优秀的分布式计算框架，诸如 Hadoop、Spark 等。离线分布式处理框架虽然能够处理非常大量的数据，但是其迟滞性很难满足一些特定的需求场景，比如 push 反馈、实时推荐、实时用户行为等。为了满足这些场景，使数据处理能够达到实时的响应和反馈，又随之出现了实时计算框架。目前的实时处理框架有 Apache Storm、Apache Flink 以及 Spark Streaming 等。其中 Spark Streaming 由于其本身的扩展性、高吞吐量以及容错能力等特性，并且能够和离线各种框架有效结合起来，因而是当下是比较受欢迎的一种流式处理框架。



根据其官方文档介绍，Spark Streaming 有高扩展性、高吞吐量和容错能力强的特点。Spark Streaming 支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ 和简单的 TCP 套接字等等。数据输入后可以用 Spark 的高度抽象原语如：map、reduce、join、window 等进行运算。而结果也能保存在很多地方，如 HDFS，数据库等。另外 Spark Streaming 也能和 MLlib(机器学习)以及 Graphx 完美融合。其架构见下图：







Spark Streaming 其优秀的特点给我们带来很多的应用场景，如网站监控和网络监控、异常监测、网页点击、用户行为、用户迁移等。本文中，将为大家详细介绍，我们的应用场景中，Spark Streaming 的技术架构、两种状态模型以及 Spark Streaming 监控等。



二、应用场景



在 Spark Streaming 中，处理数据的单位是一批而不是单条，而数据采集却是逐条进行的，因此 Spark Streaming 系统需要设置间隔使得数据汇总到一定的量后再一并操作，这个间隔就是批处理间隔。批处理间隔是 Spark Streaming 的核心概念和关键参数，它决定了 Spark Streaming 提交作业的频率和数据处理的延迟，同时也影响着数据处理的吞吐量和性能。







2.1 框架



目前我们 Spark Streaming 的业务应用场景包括异常监测、网页点击、用户行为以及用户地图迁徙等场景。按计算模型来看大体可分为无状态的计算模型以及状态计算模型两种。在实际的应用场景中，我们采用Kafka作为实时输入源，Spark Streaming 作为计算引擎处理完数据之后，再持久化到存储中，包括 MySQL、HDFS、ElasticSearch 以及 MongoDB 等；同时 Spark Streaming 数据清洗后也会写入 Kafka，然后经由 Flume 持久化到 HDFS；接着基于持久化的内容做一些 UI 的展现。架构见下图：







2.2 无状态模型



无状态模型只关注当前新生成的 DStream 数据，所以的计算逻辑均基于该批次的数据进行处理。无状态模型能够很好地适应一些应用场景，比如网站点击实时排行榜、指定 batch 时间段的用户访问以及点击情况等。该模型由于没有状态，并不需要考虑有状态的情况，只需要根据业务场景保证数据不丢就行。此种情况一般采用 Direct 方式读取 Kafka 数据，并采用监听器方式持久化 Offsets 即可。具体流程如下：







其上模型框架包含以下几个处理步骤：



读取 Kafka 实时数据；

Spark Streaming Transformations 以及 actions 操作；

将数据结果持久化到存储中，跳转到步骤一。



受网络、集群等一些因素的影响，实时程序出现长时失败，导致数据出现堆积。此种情况下是丢掉堆积的数据从 Kafka largest 处消费还是从之前的 Kafka offsets处消费，这个取决具体的业务场景。



2.3 状态模型



有状态模型是指 DStreams 在指定的时间范围内有依赖关系，具体的时间范围由业务场景来指定，可以是 2 个及以上的多个 batch time RDD 组成。Spark Streaming 提供了 updateStateByKey 方法来满足此类的业务场景。因涉及状态的问题，所以在实际的计算过程中需要保存计算的状态，Spark Streaming 中通过 checkpoint 来保存计算的元数据以及计算的进度。该状态模型的应用场景有网站具体模块的累计访问统计、最近 N batch time 的网站访问情况以及 app 新增累计统计等等。具体流程如下：







上述流程中，每 batch time 计算时，需要依赖最近 2 个 batch time 内的数据，经过转换及相关统计，最终持久化到 MySQL 中去。不过为了确保每个计算仅计算 2 个 batch time 内的数据，需要维护数据的状态，清除过期的数据。我们先来看下 updateStateByKey 的实现，其代码如下：



暴露了全局状态数据中的 key 类型的方法。



def updateStateByKey[S: ClassTag](

updateFunc: (Iterator[(K, Seq[V], Option[S])]) => Iterator[(K, S)],

partitioner: Partitioner,

rememberPartitioner: Boolean

): DStream[(K, S)] = ssc.withScope {

new StateDStream(self, ssc.sc.clean(updateFunc), partitioner, rememberPartitioner, None)

}



隐藏了全局状态数据中的 key 类型，仅对 Value 提供自定义的方法。



def updateStateByKey[S: ClassTag](

updateFunc: (Seq[V], Option[S]) => Option[S],

partitioner: Partitioner,

initialRDD: RDD[(K, S)]

): DStream[(K, S)] = ssc.withScope {

val cleanedUpdateF = sparkContext.clean(updateFunc)

val newUpdateFunc = (iterator: Iterator[(K, Seq[V], Option[S])]) => {

iterator.flatMap(t => cleanedUpdateF(t._2, t._3).map(s => (t._1, s)))

}

updateStateByKey(newUpdateFunc, partitioner, true, initialRDD)

}



以上两种方法分别给我们提供清理过期数据的思路：



泛型 K 进行过滤。K 表示全局状态数据中对应的 key，如若 K 不满足指定条件则反回 false；

返回值过滤。第二个方法中自定义函数指定了 Option[S] 返回值，若过期数据返回 None，那么该数据将从全局状态中清除。



三、Spark Streaming 监控



同 Spark 一样，Spark Streaming 也提供了 Jobs、Stages、Storage、Enviorment、Executors 以及 Streaming 的监控，其中 Streaming 监控页的内容如下图：







上图是 Spark UI 中提供一些数据监控，包括实时输入数据、Scheduling Delay、处理时间以及总延迟的相关监控数据的趋势展现。另外除了提供上述数据监控外，Spark UI 还提供了 Active Batches 以及 Completed Batches 相关信息。Active Batches 包含当前正在处理的 batch 信息以及堆积的 batch 相关信息，而 Completed Batches 刚提供每个 batch 处理的明细数据，具体包括 batch time、input size、scheduling delay、processing Time、Total Delay等，具体信息见下图：







Spark Streaming 能够提供如此优雅的数据监控，是因在对监听器设计模式的使用。如若 Spark UI 无法满足你所需的监控需要，用户可以定制个性化监控信息。 Spark Streaming 提供了 StreamingListener 特质，通过继承此方法，就可以定制所需的监控，其代码如下：



@DeveloperApi

trait StreamingListener {

/** Called when a receiver has been started */

def onReceiverStarted(receiverStarted: StreamingListenerReceiverStarted) { }

/** Called when a receiver has reported an error */

def onReceiverError(receiverError: StreamingListenerReceiverError) { }

/** Called when a receiver has been stopped */

def onReceiverStopped(receiverStopped: StreamingListenerReceiverStopped) { }

/** Called when a batch of jobs has been submitted for processing. */

def onBatchSubmitted(batchSubmitted: StreamingListenerBatchSubmitted) { }

/** Called when processing of a batch of jobs has started.  */

def onBatchStarted(batchStarted: StreamingListenerBatchStarted) { }

/** Called when processing of a batch of jobs has completed. */

def onBatchCompleted(batchCompleted: StreamingListenerBatchCompleted) { }

/** Called when processing of a job of a batch has started. */

def onOutputOperationStarted(

outputOperationStarted: StreamingListenerOutputOperationStarted) { }

/** Called when processing of a job of a batch has completed. */

def onOutputOperationCompleted(

outputOperationCompleted: StreamingListenerOutputOperationCompleted) { }

}



目前，我们保存 Offsets 时，采用继承 StreamingListener 方式，此是一种应用场景。当然也可以监控实时计算程序的堆积情况，并在达到一阈值后发送报警邮件。具体监听器的定制还得依据应用场景而定。



四、Spark Streaming 优缺点



Spark Streaming 并非是 Storm 那样，其并非是真正的流式处理框架，而是一次处理一批次数据。也正是这种方式，能够较好地集成 Spark 其他计算模块，包括 MLlib(机器学习)、Graphx 以及 Spark SQL。这给实时计算带来很大的便利，与此带来便利的同时，也牺牲作为流式的实时性等性能。



4.1 优点



Spark Streaming 基于 Spark Core API，因此其能够与 Spark 中的其他模块保持良好的兼容性，为编程提供了良好的可扩展性;

Spark Streaming 是粗粒度的准实时处理框架，一次读取完或异步读完之后处理数据，且其计算可基于大内存进行，因而具有较高的吞吐量;

Spark Streaming 采用统一的 DAG 调度以及 RDD，因此能够利用其lineage 机制，对实时计算有很好的容错支持;

Spark Streaming 的 DStream 是基于 RDD 的在流式数据处理方面的抽象，其 transformations 以及 actions 有较大的相似性，这在一定程度上降低了用户的使用门槛，在熟悉 Spark 之后，能够快速上手 Spark Streaming。



4.2 缺点



Spark Streaming 是准实时的数据处理框架，采用粗粒度的处理方式，当 batch time 到时才会触发计算，这并非像 Storm 那样是纯流式的数据处理方式。此种方式不可避免会出现相应的计算延迟 。



目前来看，Spark Streaming 稳定性方面还是会存在一些问题。有时会因一些莫名的异常导致退出，这种情况下得需要自己来保证数据一致性以及失败重启功能等。



四、总结

本篇文章主要介绍了 Spark Streaming 在实际应用场景中的两种计算模型，包括无状态模型以及状态模型；并且重点关注了下 Spark Streaming 在监控方面所作的努力。

首先本文介绍了 Spark Streaming 应用场景以及在我们的实际应用中所采取的技术架构。在此基础上，引入无状态计算模型以及有状态模型两种计算模型;接着通过监听器模式介绍 Spark UI 相关监控信息等；最后对 Spark Streaming 的优缺点进行概括。


SparkStreaming如何解决小文件问题

使用sparkstreaming时，如果实时计算结果要写入到HDFS，那么不可避免的会遇到一个问题，那就是在默认情况下会产生非常多的小文件，这是由sparkstreaming的微批处理模式和DStream(RDD)的分布式(partition)特性导致的，sparkstreaming为每个partition启动一个独立的线程来处理数据，一旦文件输出到HDFS，那么这个文件流就关闭了，再来一个batch的parttition任务，就再使用一个新的文件流，那么假设，一个batch为10s，每个输出的DStream有32个partition，那么一个小时产生的文件数将会达到(3600/10)*32=11520个之多。众多小文件带来的结果是有大量的文件元信息，比如文件的location、文件大小、block number等需要NameNode来维护，NameNode会因此鸭梨山大。不管是什么格式的文件，parquet、text,、JSON或者 Avro，都会遇到这种小文件问题，这里讨论几种处理Sparkstreaming小文件的典型方法。



增加batch大小
这种方法很容易理解，batch越大，从外部接收的event就越多，内存积累的数据也就越多，那么输出的文件数也就回变少，比如上边的时间从10s增加为100s，那么一个小时的文件数量就会减少到1152个。但别高兴太早，实时业务能等那么久吗，本来人家10s看到结果更新一次，现在要等快两分钟，是人都会骂娘。所以这种方法适用的场景是消息实时到达，但不想挤压在一起处理，因为挤压在一起处理的话，批处理任务在干等，这时就可以采用这种方法(是不是很像spark内部的pipeline模式，但是要注意区别哦)。



Coalesce大法好？
文章开头讲了，小文件的基数是：batch_number*partition_number，而第一种方法是减少batch_number，那么这种方法就是减少partition_number了，这个api不细说，就是减少初始的分区个数。看过spark源码的童鞋都知道，对于窄依赖，一个子RDD的partition规则继承父RDD，对于宽依赖(就是那些个叉叉叉ByKey操作)，如果没有特殊指定分区个数，也继承自父rdd。那么初始的SourceDstream是几个partiion，最终的输出就是几个partition。所以Coalesce大法的好处就是，可以在最终要输出的时候，来减少一把partition个数。但是这个方法的缺点也很明显，本来是32个线程在写256M数据，现在可能变成了4个线程在写256M数据，而没有写完成这256M数据，这个batch是不算做结束的。那么一个batch的处理时延必定增长，batch挤压会逐渐增大。这种方法也要慎用，切鸡切鸡啊！



SparkStreaming外部来处理
我们既然把数据输出到hdfs，那么说明肯定是要用hive或者sparksql这样的“sql on hadoop”系统类进一步进行数据分析，而这些表一般都是按照半小时或者一小时、一天，这样来分区的(注意不要和sparkStreaming的分区混淆，这里的分区，是用来做分区裁剪优化的)，那么我们可以考虑在SparkStreaming外再启动定时的批处理任务来合并SparkStreaming产生的小文件。这种方法不是很直接，但是却比较有用，“性价比”较高，唯一要注意的是，批处理的合并任务在时间切割上要把握好，搞不好就可能回去合并一个还在写入的SparkStreaming小文件。



自己调用foreach去append
SparkStreaming提供的foreach这个outout类api，可以让我们自定义输出计算结果的方法。那么我们其实也可以利用这个特性，那就是每个batch在要写文件时，并不是去生成一个新的文件流，而是把之前的文件打开。考虑这种方法的可行性，首先，HDFS上的文件不支持修改，但是很多都支持追加，那么每个batch的每个partition就对应一个输出文件，每次都去追加这个partition对应的输出文件，这样也可以实现减少文件数量的目的。这种方法要注意的就是不能无限制的追加，当判断一个文件已经达到某一个阈值时，就要产生一个新的文件进行追加了。


关于Spark Streaming感知kafka动态分区的问题
原创： 浪尖  Spark学习技巧  2018-07-19
本文主要是讲解Spark Streaming与kafka结合的新增分区检测的问题。读本文前关于kafka与Spark Streaming结合问题请参考下面两篇文章：

1，必读：再讲Spark与kafka 0.8.2.1+整合

2，必读：Spark与kafka010整合

读本文前是需要了解Spark Streaming的原理和源码结构基础。

Spark Streaming源码系列视频教程请点阅读原文进入浪尖的知识星球：Spark技术学院。

kafka 0.8版本

进入正题，之所以会有今天题目的疑惑，是由于在08版本kafka和Spark Streaming结合的DirectStream这种形式的API里面，是不支持kafka新增分区或者topic检测的。而这个问题，对于很多业务增长比较明显的公司都是会有碰到相应的问题。

比如，原来的公司业务增长比较明显，那么kafka吞吐量，刚开始创建的topic数目和分区数目可能满足不了并发需求，需要增加分区。新增加的分区会有生产者往里面写数据，而Spark Streaming跟kafka 0.8版本结合的API是满足不了动态发现kafka新增topic或者分区的需求的。

这么说有什么依据吗？我们做项目不能人云亦云，所以我们可以从源码入手验证我们的想法。

我们在这里不会详细讲Spark Streaming源码，但是我们可以在这里思考一下，Spark Streaming分区检测是在哪做的？

很明显对于批处理的Spark Streaming任务来说，分区检测应该在每次job生成获取kafkaRDD，来给kafkaRDD确定分区数并且每个分区赋值offset范围的时候有牵扯，而这段代码就在DirectKafkaInputDStream#compute方法中。(看过浪尖Spark Streaming源码视频教程的肯定会知道）

那么我们就贴出这块源码去验证我们的想法，首先compute方法的第一行：

val untilOffsets = clamp(latestLeaderOffsets(maxRetries))

这里面获取的是当前生成KafkaRDD每个分区消费的offset的最大值，那么我们需要进入latestLeaderOffsets进一步去看，可以发现下面一行代码：

val o = kc.getLatestLeaderOffsets(currentOffsets.keySet)


这个是根据currentOffsets信息来获取最大的offset，由此此处继续深入发现，由于它只是根据currentOffsets信息来获取最大的offset，没有去感知新增的分区，所以Spark Streaming与kafka 0.8结合是不能动态感知分区的。

kafka 0.10版本

相似的我们也可以直接去看kafka 0.10这块的源码去检查，他是否会动态生成kafka分区。

进入DirectKafkaInputDStream的compute，看到的第一行代码也是：

val untilOffsets = clamp(latestOffsets())

在latestOffsets里面，有了新的大陆：



到这里本文就算结束了，kafka 0.10版本与SparkStreaming结合支持新增分区检测，这件事告诉我们没事要多看源码，增长见识。




论Spark Streaming的数据可靠性和一致性
华为叶琪  Spark学习技巧  2017-11-24
摘要：Spark Streaming自发布起就得到了广泛的关注，然而作为一个年轻的项目，需要提升的地方同样很多，比如1.2之前版本driver挂掉可能会丢失数据。这里将分析它的可靠性机制。



眼下大数据领域最热门的词汇之一便是流计算了，其中最耀眼的项目无疑是来自Spark社区的Spark Streaming项目，其从一诞生就受到广泛关注并迅速发展，目前已有追赶并超越Storm的架势。

对于流计算而言，毫无疑问最核心的特点是它的低时延能力，这主要是来自对数据不落磁盘就进行计算的内部机制，但这也带来了数据可靠性的问题，即有节点失效或者网络异常时，如何在节点间进行合适的协商来进行重传。更进一步的，若发生计划外的数据重传，怎么能保证没有产生重复的数据，所有数据都是精确一次的（Exact Once）？如果不解决这些问题，大数据的流计算将无法满足大多数企业级可靠性要求而流于徒有虚名。

本文将重点分析Spark Streaming是如何设计可靠性机制并实现数据一致性的。

Driver HA
由于流计算系统是长期运行、数据不断流入的，因此其Spark守护进程（Driver）的可靠性是至关重要的，它决定了Streaming程序能否一直正确地运行下去。



图一 Driver数据持久化

Driver实现HA的解决方案就是将元数据持久化，以便重启后的状态恢复。如图一所示，Driver持久化的元数据包括：

Block元数据（图一中的绿色箭头）：Receiver从网络上接收到的数据，组装成Block后产生的Block元数据；

Checkpoint数据（图一中的橙色箭头）：包括配置项、DStream操作、未完成的Batch状态、和生成的RDD数据等；





图二 Driver故障恢复

Driver失败重启后：

恢复计算（图二中的橙色箭头）：使用Checkpoint数据重启driver，重新构造上下文并重启接收器。

恢复元数据块（图二中的绿色箭头）：恢复Block元数据。

恢复未完成的作业（图二中的红色箭头）：使用恢复出来的元数据，再次产生RDD和对应的job，然后提交到Spark集群执行。



通过如上的数据备份和恢复机制，Driver实现了故障后重启、依然能恢复Streaming任务而不丢失数据，因此提供了系统级的数据高可靠。

可靠的上下游IO系统
流计算主要通过网络socket通信来实现与外部IO系统的数据交互。由于网络通信的不可靠特点，发送端与接收端需要通过一定的协议来保证数据包的接收确认、和失败重发机制。

不是所有的IO系统都支持重发，这至少需要实现数据流的持久化，同时还要实现高吞吐和低时延。在Spark Streaming官方支持的data source里面，能同时满足这些要求的只有Kafka，因此在最近的Spark Streaming release里面，也是把Kafka当成推荐的外部数据系统。

除了把Kafka当成输入数据源（inbound data source）之外，通常也将其作为输出数据源（outbound data source）。所有的实时系统都通过Kafka这个MQ来做数据的订阅和分发，从而实现流数据生产者和消费者的解耦。

一个典型的企业大数据中心数据流向视图如下所示：



图三 企业大数据中心数据流向视图

除了从源头保证数据可重发之外，Kafka更是流数据Exact Once语义的重要保障。Kafka提供了一套低级API，使得client可以访问topic数据流的同时也能访问其元数据。Spark Streaming的每个接收任务可以从指定的Kafka topic、partition和offset去获取数据流，各个任务的数据边界很清晰，任务失败后可以重新去接收这部分数据而不会产生“重叠的”数据，因而保证了流数据“有且仅处理一次”。

可靠的接收器
在Spark 1.3版本之前，Spark Streaming是通过启动专用的Receiver任务来完成从Kafka集群的数据流拉取。

Receiver任务启动后，会使用Kafka的高级API来创建topicMessageStreams对象，并逐条读取数据流缓存，每个batchInerval时刻到来时由JobGenerator提交生成一个spark计算任务。

由于Receiver任务存在宕机风险，因此Spark提供了一个高级的可靠接收器-ReliableKafkaReceiver类型来实现可靠的数据收取，它利用了Spark 1.2提供的WAL（Write Ahead Log）功能，把接收到的每一批数据持久化到磁盘后，更新topic-partition的offset信息，再去接收下一批Kafka数据。万一Receiver失败，重启后还能从WAL里面恢复出已接收的数据，从而避免了Receiver节点宕机造成的数据丢失（以下代码删除了细枝末节的逻辑）：

class ReliableKafkaReceiver{  private var topicPartitionOffsetMap: mutable.HashMap[TopicAndPartition, Long] = null  private var blockOffsetMap: ConcurrentHashMap[StreamBlockId, Map[TopicAndPartition, Long]] = null  override def onStart(): Unit = {    // Initialize the topic-partition / offset hash map.    topicPartitionOffsetMap = new mutable.HashMap[TopicAndPartition, Long]    // Initialize the block generator for storing Kafka message.    blockGenerator = new BlockGenerator(new GeneratedBlockHandler, streamId, conf)    messageHandlerThreadPool = Utils.newDaemonFixedThreadPool(      topics.values.sum, "KafkaMessageHandler")    blockGenerator.start()    val topicMessageStreams = consumerConnector.createMessageStreams(      topics, keyDecoder, valueDecoder)    topicMessageStreams.values.foreach { streams =>      streams.foreach { stream =>        messageHandlerThreadPool.submit(new MessageHandler(stream))      }    }  }
启用WAL后虽然Receiver的数据可靠性风险降低了，但却由于磁盘持久化带来的开销，系统整体吞吐率会有明显的下降。因此，在最新发布的Spark 1.3版本里，Spark Streaming增加了使用Direct API的方式来实现Kafka数据源的访问。

引入了Direct API后，Spark Streaming不再启动常驻的Receiver接收任务，而是直接分配给每个Batch及RDD最新的topic partition offset。job启动运行后Executor使用Kafka的simple consumer API去获取那一段offset的数据。

这样做的好处不仅避免了Receiver宕机带来的数据可靠性风险，同时也由于避免使用ZooKeeper做offset跟踪，而实现了数据的精确一次性（以下代码删除了细枝末节的逻辑）：

class DirectKafkaInputDStream{  protected val kc = new KafkaCluster(kafkaParams)  protected var currentOffsets = fromOffsets  override def compute(validTime: Time): Option[KafkaRDD[K, V, U, T, R]] = {    val untilOffsets = clamp(latestLeaderOffsets(maxRetries))    val rdd = KafkaRDD[K, V, U, T, R](      context.sparkContext, kafkaParams, currentOffsets, untilOffsets, messageHandler)    currentOffsets = untilOffsets.map(kv => kv._1 -> kv._2.offset)    Some(rdd)  }
预写日志 Write Ahead Log
Spark 1.2开始提供了预写日志能力，用于Receiver数据及Driver元数据的持久化和故障恢复。WAL之所以能提供持久化能力，是因为它利用了可靠的HDFS做数据存储。

Spark Streaming预写日志机制的核心API包括：

管理WAL文件的WriteAheadLogManager

读/写WAL的WriteAheadLogWriter和WriteAheadLogReader

基于WAL的RDD：WriteAheadLogBackedBlockRDD

基于WAL的Partition：WriteAheadLogBackedBlockRDDPartition



以上核心API在数据接收和恢复阶段的交互示意图如图四所示。



图四 基于WAL的数据接收和恢复示意图

从WriteAheadLogWriter的源码里可以清楚地看到，每次写入一块数据buffer到HDFS后都会调用flush方法去强制刷入磁盘，然后才去取下一块数据。因此receiver接收的数据是可以保证持久化到磁盘了，因而做到了较好的数据可靠性。

private[streaming] class WriteAheadLogWriter{  private lazy val stream = HdfsUtils.getOutputStream(path, hadoopConf)  def write(data: ByteBuffer): WriteAheadLogFileSegment = synchronized {    data.rewind() // Rewind to ensure all data in the buffer is retrieved    val lengthToWrite = data.remaining()    val segment = new WriteAheadLogFileSegment(path, nextOffset, lengthToWrite)    stream.writeInt(lengthToWrite)    if (data.hasArray) {      stream.write(data.array())    } else {      while (data.hasRemaining) {        val array = new Array[Byte](data.remaining)        data.get(array)        stream.write(array)      }    }    flush()    nextOffset = stream.getPos()    segment  }
结束语
得益于Kafka这类可靠的data source、以及自身的checkpoint/WAL等机制，Spark Streaming的数据可靠性得到了很好的保证，数据能保证“至少一次”（at least once）被处理。但由于其outbound端的一致性实现还未完善，因此Exact once语义仍然不能端到端保证。Spark Streaming社区已经在跟进这个特性的实现（SPARK-4122），预计很快将合入trunk发布。


===============

Airbnb 是如何通过 balanced Kafka reader 来扩展 Spark streaming 实时流处理能力的
原创： 过往记忆大数据  过往记忆大数据  昨天
本文原文（点击下面阅读原文即可进入） https://www.iteblog.com/archives/2551.html

Airbnb 日志事件获取

日志事件从客户端（例如移动应用程序和 Web 浏览器）和在线服务发出，其中包含行为或操作的关键信息。每个事件都有一个特定的信息。例如，当客人在 Airbnb.com 上搜索马里布的海滨别墅时，将生成包含位置，登记和结账日期等的搜索事件。

在 Airbnb，事件记录对于我们理解客人和房东，然后为他们提供更好的体验至关重要。它为业务决策提供信息，并推动工程功能（如搜索，实验，付款等）中的产品开发。例如，日志事件是训练机器学习模型以进行列表搜索排名的主要来源。

日志事件近实时地摄取到数据仓库中，并作为许多 ETL 和分析作业的数据来源。事件从客户和服务商发布到 Kafka。Spark streaming 作业（建立在 Airstream 之上，Airbnb 的流处理框架）不断从 Kafka 读取并将事件写入 HBase 以进行重复数据删除。最后，每小时将事件从 HBase 转储到 Hive 表中。 由于日志记录事件传输到许多 pipelines 并为整个公司的众多仪表板提供数据，因此确保它们及时写入数据仓库并满足 SLA 是非常重要的。



如果想及时了解Spark、Hadoop或者Hbase相关的文章，欢迎关注微信公众号：iteblog_hadoop

产生的事件条数非常多并且在迅速增加。这对现有的数据处理基础设施构成了严峻的挑战，特别是从 Kafka 到 HBase 的事件摄取 Spark streaming 作业。在本文，我们将讨论扩展基础架构所面临的挑战，以及可以支持更高吞吐量和更高效率的解决方案。



如果想及时了解Spark、Hadoop或者Hbase相关的文章，欢迎关注微信公众号：iteblog_hadoop

挑战

Spark 的并行度由 Kafka 分区数量决定

在当前的 Spark Kafka connector 中，Kafka 分区与 Spark 任务之间存在一对一的对应关系。也就是说，一个 Spark 任务从一个 Kafka 分区读取数据，以确保在 Spark 中处理事件时对事件进行排序。但是，通过这种设计，我们不能通过增加并行度和分配更多的资源来简单地扩展 Spark streaming 作业。

要增加 Spark 并行度和吞吐量，必须为具有高 QPS 事件的主题分配更多的 Kafka 分区。不幸的是，这是一个相当笨的过程，并且在存在大量主题（不断增加）时可扩展变得很棘手。

另一个问题是为 Kafka 中的主题分配更多的分区不会改变之前已经存在 Kafka 中消息的分区。改变分区仅适用于新的事件。我们预测事件的高峰并预先为受影响的 Kafka 主题分配更多分区是不切实际的。任何时候都可能出现高峰，可能是由于各种原因，例如新产品功能或一些假期。

当事件的数量达到临界水平时，通常无法以足够快的速度从 Kafka 主题中摄取事件并写入到数据仓库。特别是在数据存在倾斜的时候，这个问题更加严重。

事件的倾斜和大小不一

记录不同消息的事件，其数量和大小有很大差异。有些事件非常稀疏的，有些可能有几个数量级的 QPS。事件的大小可以从几百字节到几百千字节。下图显示了 Kafka 主题的平均事件大小的变化（请注意Y轴是对数刻度）。虽然我们尝试为更大的事件主题分配更多的分区，但 Kafka 分区仍然存在严重的数据倾斜。



如果想及时了解Spark、Hadoop或者Hbase相关的文章，欢迎关注微信公众号：iteblog_hadoop

对于数据产品来说，偏斜是一个严重的问题。在这种情况下，一些 Spark 任务比其他任务需要更长的时间才能完成。它会导致许多 executors 空闲并浪费资源，因为当一个 stage 中的所有 tasks 完成时，Spark 作业才会进入下一个 stage。 如果主题没有足够的分区，那么具有最大事件的 Kafka 分区将花费很长的时间去处理数据。这会导致 Spark streaming 作业滞后，因为这些作业是按顺序处理的。

近实时摄取数据

由于上述挑战，Spark streaming 作业的吞吐量几乎没有很大的提升空间。 一旦作业由于各种问题（例如错误的数据节点或 Hive Metastore 中断）而出现延迟，这就需要很长时间才能消费这些滞后的数据。

例如，我们有一个间隔为2分钟的作业平均在1分钟内处理一个批次。 如果作业滞后4小时，这时候我们需要4个小时才能消费滞后的数据。如果我们希望它在1小时内消费完，则需要4倍的资源。 除了从事故中恢复之外，还需要很多资源来处理季节性峰值。因此，对于近实时摄取，在吞吐量方面具有额外的资源是至关重要的。

解决方案

在理想的系统中，我们希望能够横向扩展 Spark streaming 作业（即通过增加并行度和分配更多的资源来实现更高的吞吐量）。我们还希望这些作业能够进行负载平衡，因此每个任务都需要大致相同的时间来读取 Kafka 中的数据。

为实现这两个目标，Airbnb 数据平台团队开发了一个 balanced Spark Kafka reader，可满足这两个要求。

Balanced Spark Kafka Reader

对于流数据的摄取，事件的有序不是必需的，因为摄取的事件最后都单独存储到 HBase 中。这使得我们能够重新思考模型并寻找解决扩展问题的新方法。因此，我们为 Spark 创建了一个新的 balanced Kafka reader，主要有以下特点：

允许任意数量的分片（splits），因此可以增加并行度以提供更高的吞吐量；

根据事件的数量和大小计算分片数量。

在高层次上，balanced Kafka reader 工作流程如下：

它预先计算每个主题中的平均事件大小，并将其保存在 CSV 文件中；

当 Spark streaming 作业实例化 balanced Kafka reader 时，它会传递一个额外的参数 numberOfSplits 来指定所需的并行度；

对于每个 Kafka 分区，它计算需要读取的偏移范围（从当前偏移到最新偏移），如果设置了 maxRatePerPartition 将会进行限流；

它使用平衡分区算法（balanced partitioning algorithm）将偏移范围子集均匀分配给每个分片；

每个 Spark 任务根据分片从 Kafka 读取一个或多个偏移范围。

下面是一个简单的例子，其包含2个 Kafka 主题和3个分片。主题 A 中的事件具有更高的 QPS 但是大小比主题B小。balanced Kafka reader 将这些事件的子集组合在一起，使得每个分片读取来自 Kafka 的1/3数据。 一个分片（分片2）将包括来自主题A的4个事件和来自主题B的1个事件，因此每个分片的总大小为8kb。



如果想及时了解Spark、Hadoop或者Hbase相关的文章，欢迎关注微信公众号：iteblog_hadoop

注意，通过动态计算平均事件大小，将来可以改进步骤1，从而更好地考虑事件大小频繁变化的主题以及新增的新主题。

平衡分区算法

将偏移范围均匀地分配给分片的问题非常类似于装箱问题（bin packing problem）。 最优解决方案的复杂算法和非最优解的快速算法确实存在非线性计算复杂性。然而，我们并不会使用它，因为我们的问题有些不同：1）分片的数量是固定的；2）偏移范围可以分成更小的部分。



我们开发了一种简单而有效的算法，而不是采用复杂的现有算法，如下所示：



根据上面的公式计算每个分片需要处理的数据量（weight-per-split）。对于不在预先计算列表中的新事件类型，可以改用所有事件类型的平均大小；

从分片0开始，对于每个偏移范围进行如下操作

如果当前偏移范围的总大小小于 weight-per-split，则将这个偏移范围分配给当前分片；

如果大于 weight-per-split，则将这个偏移范围进行拆分，将合适的偏移范围分配给当前分片；

如果当前分片处理的数据量大于 weight-per-split，则将多余的偏移范围分配个下一个分片。

该算法的时间复杂度为 O(number of splits) 。它只是按顺序遍历分片和 Kafka 分区。结果是大多数分片处理的数据量是非常平衡的，除了最后的分片可能处理少一些的数据。在一次测试中，估计的 weight-per-split 为 489,541,767，分片为20k。 最小和最大分片处理的数据量分别为 278,068,116 和 489,725,277。第二小的分片处理的数据量为 489,541,772。排除最小的分片，第二小的分片与最大的分片之间的差异为 183,505（仅为最大分片的0.04％）。

平衡分区算法在测试和生产中都表现良好。Spark 任务运行时间的变化（如下图所示）比原始的 Spark Kafka reader 分布更均匀。大多数任务在2分钟内完成，其中一小部分花了2到3分钟。与大范围的事件 QPS 和大小相比，任务运行时间的微小差异表明了平衡分区算法的令人难以置信的有效性。通过考虑事件大小和数量，可确保摄取工作负载均匀分布在 executors中。



如果想及时了解Spark、Hadoop或者Hbase相关的文章，欢迎关注微信公众号：iteblog_hadoop

总结

由于得益于 balanced Kafka reader，从 Kafka 消费的 Spark 应用程序现在可以横向扩展，并具有任意并行度。平衡分区算法很简单，并且已被证明非常有效。由于这些改进，用于摄取日志记录事件的 Spark streaming 作业可以处理比以前多一个数量级的事件。系统的稳定性已经提高了很多，以至于自部署变更以来我们没有看到任何明显的滞后。

对于未来的事件流量增长和峰值增加，用于处理事件摄取的 Spark streaming 作业将能够平稳有效地处理它们。不再担心不同分区之间数据发生倾斜，如果由于底层基础设施问题导致作业发生延迟，它将能够迅速赶上。

我们在这里解决的问题在大规模 Spark 应用程序和数据应用程序非常常见。重要的是要仔细了解数据本身及其在每个步骤中的处理方式，这可能会揭示潜在的瓶颈，数据倾斜以及优化机会。例如，Spark 提供了一个很好的 UI，其中显示了每个作业的 DAG，从中我们可以了解作业是如何执行的，以及是否可以通过缓存，重新分区等来调整作业以获得更好的性能。



猜你喜欢
欢迎关注本公众号：iteblog_hadoop:

回复 spark_summit_201806 下载 Spark Summit North America 201806 全部PPT

回复 spark_summit_eu_2018 下载 Spark+AI Summit europe 2018 全部PPT

回复 HBase_book 下载 2018HBase技术总结 专刊

回复 all 获取本公众号所有资料

0、回复 电子书 获取 本站所有可下载的电子书

1、Apache Spark 2.4 回顾以及 3.0 展望

2、重磅 | Apache Spark 社区期待的 Delta Lake 开源了

3、Apache Spark 3.0 将内置支持 GPU 调度

4、分布式原理：一致性哈希算法简介

5、分布式快照算法: Chandy-Lamport 算法

6、Kafka分区分配策略

7、分布式原理：一文了解 Gossip 协议

8、列式存储和行式存储它们真正的区别是什么

9、HBase Rowkey 设计指南

10、HBase 入门之数据刷写详细说明

11、更多大数据文章欢迎访问https://www.iteblog.com及本公众号(iteblog_hadoop)
12、Flink中文文档：
http://flink.iteblog.com
13、Carbondata 中文文档：
http://carbondata.iteblog.com

============

