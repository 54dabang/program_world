10．1　一个简单的例子　　162
10．2　架构与抽象　　164
10．3　转化操作　　167
10．3．1　无状态转化操作　　167
10．3．2　有状态转化操作　　169
10．4　输出操作　　173
10．5　输入源　　175
10．5．1　核心数据源　　175
10．5．2　附加数据源　　176
10．5．3　多数据源与集群规模　　179
10．6　24/7不间断运行　　180
10．6．1　检查点机制　　180
10．6．2　驱动器程序容错　　181
10．6．3　工作节点容错　　182
10．6．4　接收器容错　　182
10．6．5　处理保证　　183
10．7　Streaming用户界面　　183
10．8　性能考量　　184
10．8．1　批次和窗口大小　　184
10．8．2　并行度　　184
10．8．3　垃圾回收和内存使用　　185

第1章 Spark Streaming应用概述 ······1
1.1 Spark Streaming应用案例 ·······2
1.2　Spark Streaming应用剖析 ·····13
第2章 Spark Streaming基本原理 ····15
2.1　Spark Core简介 ··················16
2.2 Spark Streaming设计思想 ·····26
2.3 Spark Streaming整体架构 ·····30
2.4 编程接口 ·························33
第3章 Spark Streaming运行流程详解·············39
3.1 从StreamingContext的初始化到启动 ··········40
3.2 数据接收 ·························54
3.3 数据处理 ·························91
3.4 数据清理 ························115
3.5 容错机制 ························127
3.5.1 容错原理 ·························128
3.5.2 Driver容错机制 ·················152
3.5.3 Executor容错机制 ··············161
3.6 No Receiver方式 ···············167
3.7 输出不重复 ·····················175
3.8 消费速率的动态控制 ·········176
3.9 状态操作 ························189
3.10 窗口操作 ·······················212
3.11 页面展示 ·······················216
3.12 Spark Streaming应用程序的停止··········227
第4章Spark Streaming 性能调优机制···········237
4.1 并行度解析 ·····················238
4.1.1 数据接收的并行度 ·············238
4.1.2 数据处理的并行度 ·············240
4.2 内存······························240
4.3 序列化 ···························240
4.4 Batch Interval ···················241
4.5 Task ·······························242
4.6 JVM GC ·························242
第5章Spark 2.0中的流计算 ··········245
5.1 连续应用程序 ··················246
5.2 无边界表unbounded table ····248
5.3 增量输出模式 ··················249
5.4 API简化 ··························250
5.5 其他改进 ························250


1.1　Spark前传 1
1.1.1　Web 2.0时代 2
1.1.2　无处不在的传感器 7
1.2　Spark Streaming：MapReduce和CEP的交集 9
第2章　Spark简介 10
2.1　安装 11
2.2　执行 12
2.2.1　独立集群模式（Standalone Cluster） 12
2.2.2　YARN模式 13
2.3　第一个应用程序 13
2.3.1　构建 16
2.3.2　执行 17
2.4　SparkContext 19
2.4.1　RDDs创建 19
2.4.2　处理依赖关系 20
2.4.3　创建共享变量 21
2.4.4　作业执行 22
2.5　RDD 22
2.5.1　持久化 23
2.5.2　转换 24
2.5.3　行动（Action） 28
小结 29
第3章　实时RDD：DStream 30
3.1　从连续流到离散流 30
3.2　第一个Spark Streaming应用程序 31
3.2.1　构建和执行 34
3.2.2　Streaming Context 34
3.3　DStreams 36
3.3.1　Spark Streaming应用程序剖析 38
3.3.2　转换 42
小结 52
第4章　高速流：并行化及其他 54
4.1　流数据的一大飞跃 54
4.2　并行化 56
4.2.1　Worker 56
4.2.2　执行器（Executor） 57
4.2.3　任务（Task） 59
4.3　批处理间隔 62
4.4　调度 64
4.4.1　应用程序间调度 64
4.4.2　批处理调度 64
4.4.3　作业间调度 65
4.4.4　一个行动，一个作业 65
4.5　内存 66
4.5.1　序列化 67
4.5.2　压缩（Compression） 70
4.5.3　垃圾收集 70
4.6　Shuffle 70
4.6.1　早期投影和过滤 70
4.6.2　经常使用组合器 70
4.6.3　大量运用平行化 70
4.6.4　文件合并（File Consolidation） 71
4.6.5　更多内存 71
小结 71
第5章　链接外部数据源 72
5.1　智慧城市，智慧地球，一切更智慧 72
5.2　ReceiverInputDStream 74
5.3　套接字 76
5.4　MQTT 85
5.5　Flume 89
5.5.1　基于推模式的Flume数据摄取 91
5.5.2　基于拉模式的Flume数据摄取 92
5.6　Kafka 92
5.6.1　基于接收器的Kafka消费者 95
5.6.2　直接Kafka消费者 98
5.7　Twitter 99
5.8　块间隔 100
5.9　自定义接收器 100
小结 104
第6章　边界效应 106
6.1　盘点股市 106
6.2　foreachRDD 108
6.2.1　为每条记录创建一个连接 110
6.2.2　为每个分区创建一个连接 111
6.2.3　静态连接 112
6.2.4　惰性静态连接 113
6.2.5　静态连接池 114
6.3　可扩展流存储 116
6.3.1　HBase 117
6.3.2　股市控制台（Dashboard） 118
6.3.3　SparkOnHBase 120
6.3.4　Cassandra 122
6.3.5　Spark Cassandra连接器 124
6.4　全局状态（Global State） 126
6.4.1　静态变量 126
6.4.2　updateStateByKey() 128
6.4.3　累加器 129
6.4.4　外部解决方案 131
小结 133
第7章　充分准备 134
7.1　每个点击都异乎重要 134
7.2　Tachyon（Alluxio） 135
7.3　Spark Web UI 138
7.3.1　历史分析 151
7.3.2　RESTful度量 152
7.4　日志记录 153
7.5　外部度量 154
7.6　系统度量 156
7.7　监控和报警 157
小结 159
第8章　实时ETL和分析技术 160
8.1　交易数据记录的强大功能 160
8.2　第一个流式Spark SQL应用程序 162
8.3　SQLContext 165
8.3.1　创建数据框 165
8.3.2　执行SQL 168
8.3.3　配置 169
8.3.4　用户自定义函数 169
8.3.5　Catalyst：查询执行和优化 171
8.3.6　HiveContext 171
8.4　数据框（Data Frame） 173
8.4.1　类型 173
8.4.2　查询转换 173
8.4.3　行动 180
8.4.4　RDD操作 182
8.4.5　持久化 182
8.4.6　最佳做法 183
8.5　SparkR 183
8.6　第一个SparkR应用程序 184
8.6.1　执行 185
8.6.2　流式SparkR 185
小结 188

第9章　大规模机器学习 189
9.1　传感器数据风暴 189
9.2　流式MLlib应用程序 191
9.3　MLlib 194
9.3.1　数据类型 194
9.3.2　统计分析 197
9.3.3　预处理 198
9.4　特征选择和提取 199
9.4.1　卡方选择 199
9.4.2　主成分分析 200
9.5　学习算法 201
9.5.1　分类 202
9.5.2　聚类 202
9.5.3　推荐系统 204
9.5.4　频繁模式挖掘 207
9.6　流式ML管道应用程序 208
9.7　ML 211
9.8　管道交叉验证 212
小结 213
第10章　云、Lambda及Python 215
10.1　一条好评胜过一千个广告 216
10.2　Google Dataproc 217
10.3　基于Dataproc应用程序创建的第一个Spark 220
10.4　PySpark 227
10.5　Lambda架构 229
10.6　流式图分析 238

第1章 Spark和Spark Streaming的安装与配置

安装Spark

配置和运行Spark集群

你的第一个Spark程序

管理员/开发者工具

提交Spark作业

故障定位

总结

第2章 Spark和Spark Streaming的体系结构与组件

批处理和实时数据处理的比较

Spark的体系结构

Spark Streaming的体系结构

你的第一个Spark Streaming程序

总结

第3章 实时处理分布式日志文件

Spark的封装结构和客户端API

弹性分布式数据集及离散流

从分布的、多样的数据源中加载数据

总结

第4章 在流数据中应用Transformation

理解并应用Transformation功能

性能调优

总结

第5章 日志分析数据的持久化

Spark Streaming的输出操作

集成Cassandra

总结

第6章 与Spark高级库集成

实时查询流数据

了解Spark SQL

集成Spark SQL与流数据

图的分析——Spark GraphX

GraphX API介绍

总结

第7章 产品部署

Spark部署模式

高可用性和容错性

Streaming作业的监听

===========

Spark Streaming 是一套优秀的实时计算框架。其良好的可扩展性、高吞吐量以及容错机制能够满足我们很多的场景应用。本篇结合我们的应用场景，介结我们在使用 Spark Streaming 方面的技术架构，并着重讲解 Spark Streaming 两种计算模型，无状态和状态计算模型以及该两种模型的注意事项;接着介绍了 Spark Streaming 在监控方面所做的一些事情，最后总结了 Spark Streaming 的优缺点。



一、概述



数据是非常宝贵的资源，对各级企事业单均有非常高的价值。但是数据的爆炸，导致原先单机的数据处理已经无法满足业务的场景需求。因此在此基础上出现了一些优秀的分布式计算框架，诸如 Hadoop、Spark 等。离线分布式处理框架虽然能够处理非常大量的数据，但是其迟滞性很难满足一些特定的需求场景，比如 push 反馈、实时推荐、实时用户行为等。为了满足这些场景，使数据处理能够达到实时的响应和反馈，又随之出现了实时计算框架。目前的实时处理框架有 Apache Storm、Apache Flink 以及 Spark Streaming 等。其中 Spark Streaming 由于其本身的扩展性、高吞吐量以及容错能力等特性，并且能够和离线各种框架有效结合起来，因而是当下是比较受欢迎的一种流式处理框架。



根据其官方文档介绍，Spark Streaming 有高扩展性、高吞吐量和容错能力强的特点。Spark Streaming 支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ 和简单的 TCP 套接字等等。数据输入后可以用 Spark 的高度抽象原语如：map、reduce、join、window 等进行运算。而结果也能保存在很多地方，如 HDFS，数据库等。另外 Spark Streaming 也能和 MLlib(机器学习)以及 Graphx 完美融合。其架构见下图：







Spark Streaming 其优秀的特点给我们带来很多的应用场景，如网站监控和网络监控、异常监测、网页点击、用户行为、用户迁移等。本文中，将为大家详细介绍，我们的应用场景中，Spark Streaming 的技术架构、两种状态模型以及 Spark Streaming 监控等。



二、应用场景



在 Spark Streaming 中，处理数据的单位是一批而不是单条，而数据采集却是逐条进行的，因此 Spark Streaming 系统需要设置间隔使得数据汇总到一定的量后再一并操作，这个间隔就是批处理间隔。批处理间隔是 Spark Streaming 的核心概念和关键参数，它决定了 Spark Streaming 提交作业的频率和数据处理的延迟，同时也影响着数据处理的吞吐量和性能。







2.1 框架



目前我们 Spark Streaming 的业务应用场景包括异常监测、网页点击、用户行为以及用户地图迁徙等场景。按计算模型来看大体可分为无状态的计算模型以及状态计算模型两种。在实际的应用场景中，我们采用Kafka作为实时输入源，Spark Streaming 作为计算引擎处理完数据之后，再持久化到存储中，包括 MySQL、HDFS、ElasticSearch 以及 MongoDB 等；同时 Spark Streaming 数据清洗后也会写入 Kafka，然后经由 Flume 持久化到 HDFS；接着基于持久化的内容做一些 UI 的展现。架构见下图：







2.2 无状态模型



无状态模型只关注当前新生成的 DStream 数据，所以的计算逻辑均基于该批次的数据进行处理。无状态模型能够很好地适应一些应用场景，比如网站点击实时排行榜、指定 batch 时间段的用户访问以及点击情况等。该模型由于没有状态，并不需要考虑有状态的情况，只需要根据业务场景保证数据不丢就行。此种情况一般采用 Direct 方式读取 Kafka 数据，并采用监听器方式持久化 Offsets 即可。具体流程如下：







其上模型框架包含以下几个处理步骤：



读取 Kafka 实时数据；

Spark Streaming Transformations 以及 actions 操作；

将数据结果持久化到存储中，跳转到步骤一。



受网络、集群等一些因素的影响，实时程序出现长时失败，导致数据出现堆积。此种情况下是丢掉堆积的数据从 Kafka largest 处消费还是从之前的 Kafka offsets处消费，这个取决具体的业务场景。



2.3 状态模型



有状态模型是指 DStreams 在指定的时间范围内有依赖关系，具体的时间范围由业务场景来指定，可以是 2 个及以上的多个 batch time RDD 组成。Spark Streaming 提供了 updateStateByKey 方法来满足此类的业务场景。因涉及状态的问题，所以在实际的计算过程中需要保存计算的状态，Spark Streaming 中通过 checkpoint 来保存计算的元数据以及计算的进度。该状态模型的应用场景有网站具体模块的累计访问统计、最近 N batch time 的网站访问情况以及 app 新增累计统计等等。具体流程如下：







上述流程中，每 batch time 计算时，需要依赖最近 2 个 batch time 内的数据，经过转换及相关统计，最终持久化到 MySQL 中去。不过为了确保每个计算仅计算 2 个 batch time 内的数据，需要维护数据的状态，清除过期的数据。我们先来看下 updateStateByKey 的实现，其代码如下：



暴露了全局状态数据中的 key 类型的方法。



def updateStateByKey[S: ClassTag](

updateFunc: (Iterator[(K, Seq[V], Option[S])]) => Iterator[(K, S)],

partitioner: Partitioner,

rememberPartitioner: Boolean

): DStream[(K, S)] = ssc.withScope {

new StateDStream(self, ssc.sc.clean(updateFunc), partitioner, rememberPartitioner, None)

}



隐藏了全局状态数据中的 key 类型，仅对 Value 提供自定义的方法。



def updateStateByKey[S: ClassTag](

updateFunc: (Seq[V], Option[S]) => Option[S],

partitioner: Partitioner,

initialRDD: RDD[(K, S)]

): DStream[(K, S)] = ssc.withScope {

val cleanedUpdateF = sparkContext.clean(updateFunc)

val newUpdateFunc = (iterator: Iterator[(K, Seq[V], Option[S])]) => {

iterator.flatMap(t => cleanedUpdateF(t._2, t._3).map(s => (t._1, s)))

}

updateStateByKey(newUpdateFunc, partitioner, true, initialRDD)

}



以上两种方法分别给我们提供清理过期数据的思路：



泛型 K 进行过滤。K 表示全局状态数据中对应的 key，如若 K 不满足指定条件则反回 false；

返回值过滤。第二个方法中自定义函数指定了 Option[S] 返回值，若过期数据返回 None，那么该数据将从全局状态中清除。



三、Spark Streaming 监控



同 Spark 一样，Spark Streaming 也提供了 Jobs、Stages、Storage、Enviorment、Executors 以及 Streaming 的监控，其中 Streaming 监控页的内容如下图：







上图是 Spark UI 中提供一些数据监控，包括实时输入数据、Scheduling Delay、处理时间以及总延迟的相关监控数据的趋势展现。另外除了提供上述数据监控外，Spark UI 还提供了 Active Batches 以及 Completed Batches 相关信息。Active Batches 包含当前正在处理的 batch 信息以及堆积的 batch 相关信息，而 Completed Batches 刚提供每个 batch 处理的明细数据，具体包括 batch time、input size、scheduling delay、processing Time、Total Delay等，具体信息见下图：







Spark Streaming 能够提供如此优雅的数据监控，是因在对监听器设计模式的使用。如若 Spark UI 无法满足你所需的监控需要，用户可以定制个性化监控信息。 Spark Streaming 提供了 StreamingListener 特质，通过继承此方法，就可以定制所需的监控，其代码如下：



@DeveloperApi

trait StreamingListener {

/** Called when a receiver has been started */

def onReceiverStarted(receiverStarted: StreamingListenerReceiverStarted) { }

/** Called when a receiver has reported an error */

def onReceiverError(receiverError: StreamingListenerReceiverError) { }

/** Called when a receiver has been stopped */

def onReceiverStopped(receiverStopped: StreamingListenerReceiverStopped) { }

/** Called when a batch of jobs has been submitted for processing. */

def onBatchSubmitted(batchSubmitted: StreamingListenerBatchSubmitted) { }

/** Called when processing of a batch of jobs has started.  */

def onBatchStarted(batchStarted: StreamingListenerBatchStarted) { }

/** Called when processing of a batch of jobs has completed. */

def onBatchCompleted(batchCompleted: StreamingListenerBatchCompleted) { }

/** Called when processing of a job of a batch has started. */

def onOutputOperationStarted(

outputOperationStarted: StreamingListenerOutputOperationStarted) { }

/** Called when processing of a job of a batch has completed. */

def onOutputOperationCompleted(

outputOperationCompleted: StreamingListenerOutputOperationCompleted) { }

}



目前，我们保存 Offsets 时，采用继承 StreamingListener 方式，此是一种应用场景。当然也可以监控实时计算程序的堆积情况，并在达到一阈值后发送报警邮件。具体监听器的定制还得依据应用场景而定。



四、Spark Streaming 优缺点



Spark Streaming 并非是 Storm 那样，其并非是真正的流式处理框架，而是一次处理一批次数据。也正是这种方式，能够较好地集成 Spark 其他计算模块，包括 MLlib(机器学习)、Graphx 以及 Spark SQL。这给实时计算带来很大的便利，与此带来便利的同时，也牺牲作为流式的实时性等性能。



4.1 优点



Spark Streaming 基于 Spark Core API，因此其能够与 Spark 中的其他模块保持良好的兼容性，为编程提供了良好的可扩展性;

Spark Streaming 是粗粒度的准实时处理框架，一次读取完或异步读完之后处理数据，且其计算可基于大内存进行，因而具有较高的吞吐量;

Spark Streaming 采用统一的 DAG 调度以及 RDD，因此能够利用其lineage 机制，对实时计算有很好的容错支持;

Spark Streaming 的 DStream 是基于 RDD 的在流式数据处理方面的抽象，其 transformations 以及 actions 有较大的相似性，这在一定程度上降低了用户的使用门槛，在熟悉 Spark 之后，能够快速上手 Spark Streaming。



4.2 缺点



Spark Streaming 是准实时的数据处理框架，采用粗粒度的处理方式，当 batch time 到时才会触发计算，这并非像 Storm 那样是纯流式的数据处理方式。此种方式不可避免会出现相应的计算延迟 。



目前来看，Spark Streaming 稳定性方面还是会存在一些问题。有时会因一些莫名的异常导致退出，这种情况下得需要自己来保证数据一致性以及失败重启功能等。



四、总结

本篇文章主要介绍了 Spark Streaming 在实际应用场景中的两种计算模型，包括无状态模型以及状态模型；并且重点关注了下 Spark Streaming 在监控方面所作的努力。

首先本文介绍了 Spark Streaming 应用场景以及在我们的实际应用中所采取的技术架构。在此基础上，引入无状态计算模型以及有状态模型两种计算模型;接着通过监听器模式介绍 Spark UI 相关监控信息等；最后对 Spark Streaming 的优缺点进行概括。

