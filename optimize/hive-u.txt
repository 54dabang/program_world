


避免存储大量小文件，减少元数据数量；
文件压缩，比如ORC 格式；
避免对HDFS执行count、du等操作；

输入小文件合并
使用Combinefileinputformat，将多个小文件打包作为一个整体的inputsplit，减少map任务数
set mapred.max.split.size=256000000
set mapred.min.split.size.per.node=256000000
set  Mapred.min.split.size.per.rack=256000000
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
输出小文件合并
设置hive参数，将额外启动一个MR Job打包小文件
hive.merge.mapredfiles = false 是否合并 Reduce 输出文件，默认为 False
hive.merge.size.per.task = 256*1000*1000 合并文件的大小
当数据量较大，且经常需要按天统计时，建议使用分区表，按天存放数据使用；
为了避免在插入动态分区数据的过程中，产生过多的小文件，在执行插入时，在分区字段上加上distribute by；
从分区表读取数据时，明确指定分区值，不要读取整张表。
通过hive.groupby.skewindata=true控制生成两个MR Job,第一个MR Job Map的输出结果随机分配到reduce做次预汇总,减少某些key值条数过多某些key条数过小造成的数据倾斜问题；
通过过滤无效数据来解决数据倾斜问题；
Join查找操作的基本原则：应该将条目少的表/子查询放在 Join 操作符的左边；
Join查找操作中如果存在多个join，且所有参与join的表中其参与join的key都相同，则会将所有的join合并到一个mapred程序中；
如果某个表数据量很小，可以使用MapJoin。
通常应该由系统自动分配map/reduce数目。如果reduce太少：如果数据量很大，会导致这个reduce异常的慢，从而导致这个任务不能结束，也有可能会OOM ；如果reduce太多：  产生的小文件太多，合并起来代价太高；
当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率；
multi insert适合基于同一个源表按照不同逻辑不同粒度处理插入不同表的场景，做到只需要扫描源表一次，job个数不变，减少源表扫描次数；
当可以使用left semi join 语法时不要使用inner join，前者效率更高。原因：对于左表中指定的一条记录，一旦在右表中找到立即停止扫描；
排序优化：Order by 实现全局排序，一个reduce实现，效率低。Sort by 实现部分有序，单个reduce输出的结果是有序的，效率高，通常和DISTRIBUTE BY关键字一起使用（DISTRIBUTE BY关键字 可以指定map 到 reduce端的分发key）。CLUSTER BY col1 等价于DISTRIBUTE BY col1 SORT BY col1；
可以尝试用 GROUP BY替代COUNT(DISTINCT)达到优化效果；
RDD 多次使用时，建议将RDD 持久化；
在对性能要求比较高的场景下，可以使用Kryo 优化序列化性能，但Kryo要求最好要注册所有需要进行序列化的自定义类型；
由于shuffle类算子存在节点之间的网络传输，因此对于数据量很大的RDD，应该尽量提取需要使用的信息，减小其单条数据的大小，然后再调用shuffle类算子；
慎用distinct算子，尤其是数据量很大时，建议不要直接对大文件生成的RDD使用；
使用reduceByKey/aggregateByKey替代groupByKey。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差；
使用mapPartitions替代普通map。mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些，但易OOM；
通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的 partition数量；
使用repartitionAndSortWithinPartitions替代repartition+sort类操作；
使用foreachPartitions替代foreach；

